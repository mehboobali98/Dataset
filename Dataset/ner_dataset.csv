sentence_id,word,label
0,The,O
0,results,O
0,validate,B
0,that,I
0,GCNs,B
0,are,O
0,effective,B
0,at,I
0,encoding,I
0,syntactic,B
0,information,I
0,.,O
1,PCNN,O
1,+,O
1,ATT,O
1,:,O
1,A,O
1,piecewise,B
1,max,I
1,-,I
1,pooling,I
1,over,I
1,CNN,B
1,based,I
1,model,I
1,which,O
1,is,O
1,used,O
1,by,O
1,to,B
1,get,I
1,sentence,B
1,representation,I
1,followed,B
1,by,O
1,attention,B
1,over,O
1,sentences,O
1,.,O
2,Glo,O
2,Ve,O
2,vectors,O
2,are,O
2,used,B
2,as,I
2,the,O
2,initialization,B
2,for,B
2,word,B
2,embeddings,I
2,.,O
3,In,O
3,this,O
3,paper,O
3,",",O
3,we,O
3,investigate,B
3,several,B
3,methods,I
3,of,B
3,constructing,B
3,an,B
3,auxiliary,B
3,sentence,B
3,and,O
3,transform,B
3,(,B
3,T,I
3,),I
3,ABSA,I
3,into,B
3,a,O
3,sentence,O
3,-,O
3,pair,O
3,classification,O
3,task,O
3,.,O
4,We,O
4,fine,B
4,-,I
4,tune,I
4,the,O
4,pre-trained,B
4,model,I
4,from,B
4,BERT,B
4,and,O
4,achieve,O
4,new,O
4,state,O
4,-,O
4,of,O
4,-,O
4,the,O
4,-,O
4,art,O
4,results,O
4,on,O
4,(,O
4,T,O
4,),O
4,ABSA,O
4,task,O
4,.,O
5,LR,B
5,:,O
5,a,O
5,logistic,B
5,regression,I
5,classifier,I
5,with,B
5,n-gram,B
5,and,I
5,pos-tag,I
5,features,I
5,.,O
6,LSTM,O
6,-,O
6,Final,B
6,),O
6,:,O
6,a,O
6,biLSTM,B
6,model,I
6,with,B
6,the,O
6,final,O
6,state,O
6,as,O
6,a,O
6,representation,O
6,.,O
7,LSTM,O
7,-,O
7,Loc,O
7,),O
7,:,O
7,a,O
7,biLSTM,B
7,model,I
7,with,I
7,the,O
7,state,B
7,associated,B
7,with,O
7,the,O
7,target,B
7,position,I
7,as,I
7,a,O
7,representation,O
7,.,O
8,LSTM,O
8,+,O
8,TA,O
8,+,O
8,SA,O
8,),O
8,:,O
8,a,O
8,biLSTM,B
8,model,I
8,which,O
8,introduces,B
8,complex,B
8,target,I
8,-,I
8,level,I
8,and,I
8,sentence,I
8,-,O
8,level,O
8,attention,O
8,mechanisms,O
8,.,O
9,SenticLSTM,B
9,:,O
9,an,O
9,upgraded,B
9,version,I
9,of,B
9,the,O
9,LSTM,B
9,+,I
9,TA,I
9,+,O
9,SA,O
9,model,O
9,which,O
9,introduces,B
9,external,B
9,information,I
9,from,I
9,Sentic,I
9,-,I
9,Net,I
9,.,O
10,Dmu,O
10,-,O
10,Entnet,O
10,:,O
10,a,O
10,bidirectional,B
10,EntNet,O
10,with,B
10,external,B
10,"""",I
10,memory,I
10,chains,I
10,"""",O
10,with,O
10,a,O
10,delayed,B
10,memory,O
10,update,O
10,mechanism,O
10,to,B
10,track,I
10,entities,B
10,.,O
11,We,O
11,use,B
11,the,O
11,pre-trained,B
11,uncased,I
11,BERT,I
11,-,I
11,base,I
11,model,I
11,5,O
11,for,B
11,fine,B
11,-,O
11,tuning,O
11,.,O
12,The,O
12,number,O
12,of,O
12,Transformer,O
12,blocks,O
12,is,B
12,12,B
12,",",O
12,the,O
12,hidden,B
12,layer,I
12,size,I
12,is,O
12,768,B
12,",",O
12,the,O
12,number,O
12,of,O
12,self,O
12,-,O
12,attention,O
12,heads,O
12,is,O
12,12,O
12,",",O
12,and,O
12,the,O
12,total,B
12,number,O
12,of,O
12,parameters,O
12,for,B
12,the,O
12,pretrained,B
12,model,I
12,is,O
12,110M,B
12,.,O
13,In,O
13,this,O
13,paper,O
13,",",O
13,we,O
13,propose,B
13,the,O
13,novel,B
13,Attention,I
13,Guided,I
13,Graph,I
13,Convolutional,I
13,Networks,I
13,(,I
13,AGGCNs,I
13,),I
13,",",O
13,which,O
13,operate,B
13,directly,I
13,on,I
13,the,O
13,full,B
13,tree,I
13,.,O
14,The,O
14,initial,B
14,learning,I
14,rate,I
14,is,B
14,2,B
14,e,I
14,-,I
14,5,I
14,",",O
14,and,O
14,the,O
14,batch,B
14,size,I
14,is,O
14,24,B
14,.,O
15,the,O
15,dropout,B
15,probability,I
15,at,B
15,0.1,B
15,",",O
15,set,B
15,the,O
15,number,B
15,of,I
15,epochs,I
15,to,B
15,4,B
15,.,O
16,Utilizing,O
16,BERT,O
16,for,O
16,Aspect,B
16,-,I
16,Based,I
16,Sentiment,I
16,Analysis,I
16,via,O
16,Constructing,O
16,Auxiliary,O
16,Sentence,O
17,Aspect,O
17,-,O
17,based,O
17,sentiment,B
17,analysis,I
17,(,I
17,ABSA,O
17,),O
17,",",O
17,which,O
17,aims,O
17,to,O
17,identify,O
17,fine,O
17,-,O
17,grained,O
17,opinion,O
17,polarity,O
17,towards,O
17,a,O
17,specific,O
17,aspect,O
17,",",O
17,is,O
17,a,O
17,challenging,O
17,subtask,O
17,of,O
17,sentiment,O
17,analysis,O
17,(,O
17,SA,O
17,),O
17,.,O
18,Both,O
18,SA,B
18,and,O
18,ABSA,B
18,are,O
18,sentence,O
18,-,O
18,level,O
18,or,O
18,document,O
18,-,O
18,level,O
18,tasks,O
18,",",O
18,but,O
18,one,O
18,comment,O
18,may,O
18,refer,O
18,to,O
18,more,O
18,than,O
18,one,O
18,object,O
18,",",O
18,and,O
18,sentence,O
18,-,O
18,level,O
18,tasks,O
18,can,O
18,not,O
18,handle,O
18,sentences,O
18,with,O
18,multiple,O
18,targets,O
18,.,O
19,Therefore,O
19,",",O
19,introduce,O
19,the,O
19,task,O
19,of,O
19,targeted,B
19,aspect,I
19,-,I
19,based,I
19,sentiment,I
19,analysis,I
19,(,I
19,TABSA,I
19,),I
19,",",O
19,which,O
19,aims,O
19,to,O
19,identify,O
19,fine,O
19,-,O
19,grained,O
19,opinion,O
19,polarity,O
19,towards,O
19,a,O
19,specific,O
19,aspect,O
19,associated,O
19,with,O
19,a,O
19,given,O
19,target,O
19,.,O
20,We,O
20,find,O
20,that,O
20,BERT,B
20,-,I
20,single,I
20,has,O
20,achieved,B
20,better,B
20,results,I
20,on,O
20,these,O
20,two,O
20,subtasks,O
20,",",O
20,and,O
20,BERT,O
20,-,O
20,pair,O
20,has,O
20,achieved,O
20,further,B
20,improvements,I
20,over,B
20,BERT,O
20,-,O
20,single,O
20,.,O
21,The,O
21,BERT,B
21,-,I
21,pair,I
21,-,O
21,NLI,O
21,-,O
21,B,O
21,model,O
21,achieves,B
21,the,O
21,best,B
21,performance,I
21,for,B
21,aspect,B
21,category,I
21,detection,I
21,.,O
22,For,B
22,aspect,B
22,category,I
22,polarity,I
22,",",I
22,BERTpair,B
22,-,I
22,QA,I
22,-,O
22,B,O
22,performs,B
22,best,B
22,on,B
22,all,B
22,4,I
22,-,O
22,way,O
22,",",O
22,3,O
22,-,O
22,way,O
22,",",O
22,and,O
22,binary,O
22,settings,O
22,.,O
23,The,O
23,two,B
23,major,I
23,designs,I
23,in,B
23,our,O
23,adjacency,B
23,matrix,I
23,A,I
23,",",O
23,i.e.,B
24,",",O
24,global,B
24,connection,I
24,and,I
24,symmetric,I
24,adjacency,I
24,matrix,I
24,designs,I
24,",",O
24,are,O
24,helpful,B
24,in,I
24,recognizing,B
24,emotions,I
24,.,O
25,Intuitively,O
25,",",O
25,we,O
25,develop,B
25,a,O
25,"""",O
25,soft,O
25,pruning,O
25,"""",O
25,strategy,O
25,that,B
25,transforms,I
25,the,O
25,original,B
25,dependency,I
25,tree,I
25,into,B
25,a,O
25,fully,B
25,connected,I
25,edgeweighted,I
25,graph,I
25,.,O
26,The,O
26,global,B
26,connection,I
26,models,B
26,the,O
26,asymmetric,B
26,difference,I
26,between,B
26,neuronal,B
26,activities,I
26,in,B
26,the,O
26,left,B
26,and,I
26,right,I
26,hemispheres,I
26,and,O
26,have,O
26,been,O
26,shown,B
26,to,I
26,reveal,I
26,certain,B
26,emotions,I
26,",",O
26,",",O
26,.,O
27,Our,O
27,NodeDAT,B
27,regularizer,I
27,has,O
27,a,O
27,noticeable,B
27,positive,I
27,impact,I
27,on,B
27,the,O
27,performance,B
27,of,B
27,our,O
27,model,O
27,",",O
27,which,O
27,demonstrates,O
27,that,O
27,domain,O
27,adaptation,O
27,is,O
27,significantly,O
27,helpful,O
27,in,O
27,crosssubject,O
27,classification,O
27,.,O
28,DL,O
28,regularizer,O
28,improves,B
28,performance,B
28,of,B
28,our,B
28,model,I
28,by,B
28,around,B
28,3,I
28,%,I
28,in,B
28,accuracy,B
28,on,B
28,both,B
28,datasets,I
28,.,O
29,In,O
29,addition,O
29,",",O
29,if,B
29,NodeDAT,B
29,is,B
29,removed,B
29,",",O
29,the,O
29,performance,B
29,of,B
29,our,B
29,model,I
29,has,O
29,a,O
29,greater,B
29,variance,I
29,",",O
29,demonstrating,O
29,the,O
29,importance,O
29,of,O
29,NodeDAT,O
29,in,O
29,improving,O
29,the,O
29,robustness,O
29,of,O
29,our,O
29,model,O
29,against,O
29,cross,O
29,-,O
29,subject,O
29,variations,O
29,.,O
30,For,O
30,our,O
30,RGNN,B
30,in,O
30,all,O
30,experiments,O
30,",",O
30,we,O
30,empirically,B
30,set,B
30,the,O
30,number,B
30,of,B
30,convolutional,B
30,layers,I
30,L,I
30,=,I
30,2,I
30,",",O
30,dropout,B
30,rate,I
30,of,O
30,0.7,B
30,at,B
30,the,O
30,output,B
30,fully,I
30,-,I
30,connected,I
30,layer,I
30,",",O
30,and,O
30,batch,B
30,size,I
30,of,O
30,16,B
30,.,O
31,We,O
31,use,B
31,Adam,B
31,optimization,I
31,with,B
31,default,B
31,values,I
31,",",O
31,i.e.,B
32,We,O
32,only,O
32,tune,B
32,the,O
32,output,B
32,feature,I
32,dimension,I
32,d,I
32,",",O
32,label,B
32,noise,I
32,level,I
32,",",O
32,learning,B
32,rate,I
32,?,I
33,",",O
33,L1,B
33,regularization,I
33,factor,I
33,?,I
34,",",O
34,and,O
34,L2,B
34,regularization,I
34,for,O
34,each,O
34,experiment,O
34,.,O
35,In,O
35,this,O
35,paper,O
35,",",O
35,we,O
35,propose,B
35,a,O
35,regularized,B
35,graph,I
35,neural,I
35,network,I
35,(,I
35,RGNN,I
35,),I
35,aiming,O
35,to,O
35,address,O
35,all,O
35,three,O
35,aforementioned,O
35,challenges,O
35,.,O
36,Inspired,O
36,by,O
36,",",O
36,",",O
36,we,O
36,consider,B
36,each,B
36,channel,I
36,in,B
36,EEG,B
36,signals,I
36,as,B
36,a,O
36,node,B
36,in,O
36,our,B
36,graph,I
36,.,O
37,Our,O
37,RGNN,B
37,model,I
37,extends,B
37,the,O
37,simple,B
37,graph,I
37,convolution,I
37,network,I
37,(,I
37,SGC,I
37,),I
37,and,O
37,leverages,B
37,the,O
37,topological,B
37,structure,I
37,of,B
37,EEG,B
37,signals,I
37,",",O
37,i.e.,O
38,",",O
38,according,B
38,to,B
38,the,O
38,economy,B
38,of,I
38,brain,I
38,network,I
38,organization,I
38,",",O
38,we,O
38,propose,B
38,a,O
38,biologically,B
38,supported,I
38,sparse,I
38,adjacency,I
38,matrix,I
38,to,O
38,capture,O
38,both,O
38,local,B
38,and,I
38,global,I
38,inter-channel,I
38,relations,I
38,.,O
39,These,O
39,weights,B
39,can,B
39,be,I
39,viewed,B
39,as,I
39,the,O
39,strength,B
39,of,I
39,relatedness,I
39,between,B
39,nodes,B
39,",",O
39,which,O
39,can,O
39,be,O
39,learned,O
39,in,O
39,an,O
39,end,O
39,-,O
39,to,O
39,-,O
39,end,O
39,fashion,O
39,by,B
39,using,I
39,self,B
39,-,O
39,attention,O
39,mechanism,O
39,.,O
40,Local,O
40,interchannel,O
40,relations,O
40,connect,B
40,nearby,B
40,groups,I
40,of,I
40,neurons,I
40,and,O
40,may,O
40,reveal,B
40,anatomical,B
40,connectivity,I
40,at,B
40,macroscale,B
40,",",O
40,.,O
41,Global,O
41,inter-channel,O
41,relations,O
41,connect,B
41,distant,B
41,groups,I
41,of,I
41,neurons,I
41,between,B
41,the,O
41,left,B
41,and,I
41,right,I
41,hemispheres,I
41,and,O
41,may,B
41,reveal,I
41,emotion,B
41,-,I
41,related,I
41,functional,I
41,connectivity,I
41,",",O
41,.,O
42,It,O
42,is,O
42,encouraging,O
42,to,O
42,see,O
42,that,O
42,our,B
42,model,I
42,achieves,B
42,superior,B
42,performance,I
42,on,B
42,both,B
42,datasets,I
42,as,O
42,compared,B
42,to,O
42,all,O
42,baselines,O
42,including,B
42,the,I
42,stateof,B
42,-,I
42,the,O
42,-,O
42,art,O
42,BiHDM,O
42,when,O
42,DE,O
42,features,O
42,from,O
42,all,O
42,frequency,O
42,bands,O
42,are,O
42,used,O
42,.,O
43,It,O
43,is,O
43,worth,O
43,noting,O
43,that,O
43,our,O
43,model,O
43,improves,B
43,the,I
43,accuracy,B
43,of,I
43,the,O
43,state,B
43,-,I
43,of,O
43,-,O
43,the,O
43,-,O
43,art,O
43,model,O
43,on,B
43,SEED,B
43,-,O
43,IV,O
43,by,B
43,around,B
43,5,I
43,%,I
43,.,O
44,In,B
44,particular,O
44,",",O
44,our,O
44,model,O
44,performs,B
44,better,B
44,than,B
44,DGCNN,B
44,",",O
44,which,O
44,is,O
44,another,B
44,GNN,B
44,-,I
44,based,I
44,model,O
44,that,O
44,leverages,B
44,the,O
44,topological,B
44,structure,I
44,in,O
44,EEG,B
44,signals,I
44,.,O
45,One,O
45,subtle,O
45,difference,O
45,between,O
45,our,O
45,model,O
45,and,O
45,other,O
45,models,O
45,is,O
45,that,O
45,our,O
45,model,O
45,performs,O
45,consistently,B
45,better,I
45,in,B
45,gamma,B
45,band,I
45,than,B
45,beta,B
45,band,O
45,",",O
45,whereas,O
45,other,O
45,models,O
45,perform,O
45,comparably,O
45,in,O
45,both,O
45,bands,O
45,",",O
45,indicating,O
45,that,O
45,gamma,O
45,band,O
45,maybe,O
45,the,O
45,most,O
45,discriminative,O
45,band,O
45,for,O
45,our,O
45,model,O
45,.,O
46,In,B
46,subject,B
46,-,I
46,dependent,I
46,experiments,I
46,on,B
46,SEED,B
46,",",I
46,STRNN,B
46,achieves,B
46,the,O
46,highest,B
46,accuracy,I
46,in,O
46,delta,B
46,",",O
46,theta,O
46,and,O
46,alpha,O
46,bands,O
46,",",O
46,BiDANN,B
46,performs,B
46,best,B
46,in,O
46,beta,B
46,band,I
46,",",O
46,and,O
46,our,B
46,model,I
46,performs,O
46,best,O
46,in,O
46,gamma,B
46,band,O
46,.,O
47,In,B
47,subject,B
47,-,I
47,independent,I
47,experiments,I
47,on,B
47,SEED,B
47,",",I
47,BiDANN,B
47,-,O
47,S,O
47,achieves,B
47,the,O
47,highest,B
47,accuracy,I
47,in,O
47,theta,B
47,and,I
47,alpha,I
47,bands,I
47,",",O
47,and,O
47,our,B
47,model,I
47,performs,B
47,best,B
47,in,O
47,delta,B
47,",",O
47,beta,O
47,and,O
47,gamma,O
47,bands,O
47,.,O
48,we,O
48,next,O
48,introduce,B
48,dense,B
48,connections,I
48,),O
48,to,B
48,the,O
48,GCN,B
48,model,I
48,following,O
48,.,O
49,For,B
49,both,O
49,subject,B
49,-,I
49,dependent,I
49,and,I
49,subjectindependent,I
49,settings,I
49,on,B
49,SEED,B
49,",",O
49,we,O
49,compare,O
49,the,O
49,performance,O
49,of,O
49,each,O
49,model,O
49,across,O
49,different,O
49,frequency,O
49,bands,O
49,.,O
50,In,O
50,general,O
50,",",O
50,most,O
50,models,O
50,including,O
50,our,B
50,model,I
50,achieve,B
50,better,B
50,performance,I
50,on,B
50,beta,B
50,and,I
50,gamma,B
50,bands,I
50,than,B
50,delta,B
50,",",O
50,theta,O
50,and,O
50,alpha,O
50,bands,O
50,",",O
50,with,B
50,one,I
50,exception,I
50,of,I
50,STRNN,B
50,",",O
50,which,O
50,performs,B
50,the,O
50,worst,B
50,on,O
50,gamma,O
50,band,O
50,.,O
51,Non-Transfer,B
52,To,O
52,demonstrate,O
52,the,O
52,benefits,O
52,from,O
52,coarse,O
52,-,O
52,tofine,O
52,task,O
52,transfer,O
52,",",O
52,we,O
52,compare,O
52,with,O
52,the,O
52,following,O
52,state,O
52,-,O
52,of,O
52,the,O
52,-,O
52,art,O
52,AT,O
52,-,O
52,level,O
52,methods,O
52,without,O
52,transfer,O
52,:,O
52,Target,B
52,Network,I
52,(,I
52,TN,I
52,),I
52,:,O
53,It,O
53,is,B
53,our,O
53,proposed,B
53,base,I
53,model,I
53,(,I
53,BiLSTM,I
53,+,I
53,C2A,I
53,+,O
53,Pas,O
53,),O
53,trained,B
53,on,I
53,D,B
53,t,I
53,for,B
53,the,O
53,target,B
53,task,I
53,.,O
54,Transfer,B
55,It,O
55,uses,B
55,a,O
55,source,B
55,network,I
55,trained,B
55,on,I
55,D,B
55,s,I
55,to,B
55,initialize,I
55,a,O
55,target,B
55,network,O
55,and,O
55,then,O
55,tests,B
55,it,O
55,on,O
55,D,O
55,t,O
55,.,O
56,Fine-tuning,O
56,(,O
56,FT,O
56,),O
56,:,O
56,It,O
56,advances,B
56,SO,B
56,with,B
56,further,I
56,finetuning,I
56,the,O
56,target,B
56,network,I
56,on,B
56,D,B
56,t,I
56,.,O
57,M-,O
57,DAN,O
57,:,O
57,It,O
57,is,B
57,a,O
57,multi-adversarial,B
57,version,I
57,of,B
57,Domain,I
57,Adversarial,I
57,Network,I
57,(,I
57,DAN,O
57,),O
57,),O
57,based,B
57,on,I
57,multiple,B
57,domain,O
57,discriminators,O
57,.,O
58,For,B
58,GCNs,B
58,",",O
58,L,B
58,layers,I
58,will,O
58,be,O
58,needed,O
58,in,O
58,order,O
58,to,B
58,capture,I
58,neighborhood,B
58,information,I
58,that,B
58,is,I
58,L,O
58,hops,O
58,away,O
58,.,O
59,M,O
59,-,O
59,MMD,O
59,:,O
59,Similar,O
59,with,O
59,M,O
59,-,O
59,DAN,O
59,",",O
59,M,O
59,-,O
59,MMD,O
59,aligns,B
59,different,B
59,class,I
59,distributions,I
59,between,B
59,domains,B
59,based,B
59,on,I
59,multiple,B
59,Maximum,I
59,Mean,I
59,Discrepancy,I
59,(,I
59,MMD,O
59,),O
59,),O
59,.,O
60,The,O
60,word,B
60,embeddings,I
60,are,O
60,initialized,B
60,with,I
60,200,B
60,-,I
60,dimension,I
60,GloVE,I
60,vectors,I
60,and,O
60,fine,B
60,-,O
60,tuned,O
60,during,O
60,the,O
60,training,B
60,.,O
61,The,O
61,fc,B
61,layer,I
61,size,I
61,is,B
61,300,B
61,.,O
62,The,O
62,Adam,B
62,(,I
62,Kingma,I
62,and,I
62,Ba,I
62,2014,I
62,),I
62,is,O
62,used,B
62,as,I
62,the,O
62,optimizer,B
62,with,B
62,the,O
62,initial,O
62,learning,O
62,rate,O
62,10,O
62,?,O
63,Gradients,B
63,with,B
63,the,O
63,2,B
63,norm,I
63,larger,B
63,than,I
63,40,B
63,are,B
63,normalized,B
63,to,B
63,be,I
63,40,O
63,.,O
64,All,O
64,weights,O
64,in,B
64,networks,B
64,are,O
64,randomly,B
64,initialized,I
64,from,I
64,a,O
64,uniform,O
64,distribution,O
64,U,O
64,(,O
64,?,O
65,The,O
65,batch,B
65,sizes,I
65,are,B
65,64,B
65,and,I
65,32,I
65,for,B
65,source,B
65,and,O
65,target,O
65,domains,O
65,",",O
65,respectively,O
65,.,O
66,To,O
66,alleviate,O
66,overfitting,B
66,",",O
66,we,O
66,apply,B
66,dropout,B
66,on,B
66,the,O
66,word,B
66,embeddings,I
66,of,B
66,the,O
66,context,B
66,with,B
66,dropout,O
66,rate,O
66,0.5,O
66,.,O
67,We,O
67,also,O
67,perform,B
67,early,B
67,stopping,I
67,on,B
67,the,O
67,validation,B
67,set,I
67,during,B
67,the,O
67,training,B
67,process,I
67,.,O
68,The,O
68,hyperparameters,O
68,are,O
68,tuned,B
68,on,I
68,10,B
68,%,I
68,randomly,I
68,held,I
68,-,I
68,out,I
68,training,I
68,data,I
68,of,B
68,the,O
68,target,B
68,domain,I
68,in,I
68,R1?L,B
68,task,I
68,and,O
68,are,O
68,fixed,B
68,to,I
68,be,I
68,used,I
68,in,O
68,all,O
68,transfer,B
68,pairs,I
68,.,O
69,With,B
69,the,O
69,help,O
69,of,O
69,dense,B
69,connections,I
69,",",O
69,we,O
69,are,O
69,able,B
69,to,I
69,train,B
69,the,O
69,AGGCN,B
69,model,I
69,with,O
69,a,O
69,large,B
69,depth,I
69,",",O
69,allowing,O
69,rich,O
69,local,O
69,and,O
69,non-local,O
69,dependency,O
69,information,O
69,to,O
69,be,O
69,captured,O
69,.,O
70,To,O
70,resolve,O
70,the,O
70,challenges,O
70,",",O
70,we,O
70,propose,B
70,a,O
70,novel,B
70,framework,I
70,named,I
70,Multi,I
70,-,I
70,Granularity,I
70,Alignment,I
70,Network,I
70,(,I
70,MGAN,I
70,),I
70,to,O
70,simultaneously,B
70,align,I
70,aspect,B
70,granularity,O
70,and,O
70,aspect-,O
70,specific,O
70,feature,O
70,representations,O
70,across,B
70,domains,B
70,.,O
71,Specifically,O
71,",",O
71,the,O
71,MGAN,B
71,consists,B
71,of,I
71,two,B
71,networks,I
71,for,B
71,learning,I
71,aspect,B
71,-,I
71,specific,I
71,representations,I
71,for,O
71,the,O
71,two,O
71,domains,O
71,",",O
71,respectively,O
71,.,O
72,The,O
72,CFA,B
72,considers,B
72,both,I
72,semantic,B
72,alignment,I
72,by,B
72,maximally,I
72,ensuring,I
72,the,O
72,equivalent,B
72,distributions,B
72,from,B
72,different,B
72,domains,I
72,but,O
72,the,O
72,same,B
72,class,B
72,",",O
72,and,O
72,semantic,O
72,separation,O
72,by,O
72,guaranteeing,O
72,distributions,O
72,from,O
72,both,O
72,different,O
72,classes,O
72,and,O
72,domains,O
72,to,B
72,be,I
72,as,I
72,dissimilar,I
72,as,O
72,possible,O
72,.,O
73,First,O
73,",",O
73,to,B
73,reduce,I
73,the,O
73,task,B
73,discrepancy,I
73,between,B
73,domains,B
73,",",O
73,i.e.,O
74,",",O
74,modeling,B
74,the,O
74,two,B
74,tasks,I
74,at,B
74,the,O
74,same,B
74,fine,I
74,-,I
74,grained,I
74,level,I
74,",",O
74,we,O
74,propose,B
74,a,O
74,novel,B
74,Coarse2,I
74,Fine,O
74,(,O
74,C2F,O
74,),O
74,attention,O
74,module,O
74,to,B
74,help,I
74,the,O
74,source,B
74,task,I
74,automatically,B
74,capture,I
74,the,O
74,corresponding,B
74,aspect,I
74,term,I
74,in,B
74,the,O
74,context,B
74,towards,B
74,the,O
74,given,B
74,aspect,O
74,category,O
74,(,O
74,e.g.,O
75,To,O
75,prevent,O
75,false,B
75,alignment,I
75,",",O
75,we,O
75,adopt,B
75,the,O
75,Contrastive,B
75,Feature,I
75,Alignment,O
75,(,O
75,CFA,O
75,),O
75,(,O
75,Motiian,O
75,et,O
75,al.,O
76,2017,O
76,),O
76,to,B
76,semantically,I
76,align,I
76,aspect,B
76,-,I
76,specific,I
76,representations,I
76,.,O
77,Exploiting,O
77,Coarse,O
77,-,O
77,to,O
77,-,O
77,Fine,O
77,Task,O
77,Transfer,O
77,for,O
77,Aspect,B
77,-,O
77,level,O
77,Sentiment,O
77,Classification,O
78,To,O
78,model,O
78,aspect,B
78,-,I
78,oriented,I
78,sentiment,I
78,analysis,I
78,",",O
78,equipping,O
78,Recurrent,O
78,Neural,O
78,Networks,O
78,(,O
78,RNNs,O
78,),O
78,with,O
78,the,O
78,attention,O
78,Copyright,O
78,c,O
78,2019,O
78,",",O
78,Association,O
78,for,O
78,the,O
78,Advancement,O
78,of,O
78,Artificial,O
78,Intelligence,O
78,(,O
78,www.aaai.org,O
78,),O
78,.,O
79,(,O
79,2,O
79,),O
79,MGAN,B
79,consistently,B
79,outperforms,I
79,the,O
79,MGAN,O
79,w,O
79,/,O
79,o,O
79,C2,O
79,F,O
79,",",O
79,where,B
79,C2F,B
79,module,I
79,of,B
79,the,O
79,source,B
79,network,I
79,is,B
79,removed,B
79,and,I
79,the,O
79,source,O
79,position,O
79,information,O
79,is,O
79,missed,B
79,(,O
79,we,O
79,set,O
79,all,O
79,p,O
79,s,O
79,i,O
79,to,O
79,1,O
79,),O
79,",",O
79,by,B
79,1.41,B
79,%,I
79,",",O
79,1.03,O
79,%,O
79,",",O
79,1.09,O
79,%,O
79,for,B
79,accuracy,B
79,and,O
79,1.79,B
79,%,O
79,",",O
79,3.62,O
79,%,O
79,and,O
79,1.16,O
79,%,O
79,for,O
79,Macro,B
79,-,I
79,F1,I
79,on,O
79,average,O
79,.,O
80,Attention,O
80,Guided,O
80,Graph,O
80,Convolutional,O
80,Networks,O
80,for,O
80,Relation,B
80,Extraction,I
81,The,O
81,MGAN,B
81,w,I
81,/,I
81,o,I
81,PI,I
81,",",O
81,which,O
81,does,B
81,not,I
81,utilize,I
81,the,O
81,position,B
81,information,I
81,",",O
81,performs,B
81,very,B
81,poorly,I
81,.,O
82,SO,B
82,performs,B
82,poorly,B
82,due,O
82,to,O
82,no,O
82,adaptation,O
82,applied,O
82,.,O
83,The,O
83,popular,B
83,technique,I
83,FT,I
83,can,B
83,not,I
83,achieve,I
83,satisfactory,B
83,results,I
83,since,O
83,fine,O
83,-,O
83,tuning,O
83,may,O
83,cause,O
83,the,O
83,oblivion,O
83,of,O
83,useful,O
83,knowledge,O
83,from,O
83,the,O
83,source,O
83,task,O
83,.,O
84,The,O
84,full,B
84,model,I
84,MGAN,I
84,outperforms,B
84,M,I
84,-,I
84,DAN,I
84,and,I
84,M,O
84,-,O
84,MMD,O
84,by,B
84,1.80,B
84,%,I
84,and,O
84,1.33,O
84,%,O
84,for,B
84,accuracy,B
84,and,O
84,1.90,B
84,%,O
84,and,O
84,1.66,O
84,%,O
84,for,O
84,Marco,B
84,-,O
84,F1,O
84,on,O
84,average,O
84,",",O
84,respectively,O
84,.,O
85,Remarkably,O
85,",",O
85,MGAN,B
85,considers,B
85,both,I
85,of,B
85,them,I
85,in,I
85,a,O
85,point,B
85,-,I
85,wise,I
85,surrogate,I
85,",",O
85,which,O
85,altogether,O
85,improves,B
85,the,O
85,performance,B
85,of,O
85,our,B
85,method,I
85,.,O
86,Besides,O
86,",",O
86,MGAN,O
86,outperforms,B
86,its,O
86,ablation,B
86,MGAN,O
86,w/,O
86,o,O
86,SS,O
86,removing,B
86,the,O
86,semantic,B
86,separation,I
86,loss,I
86,of,B
86,the,O
86,CFA,B
86,by,B
86,0.81,B
86,%,I
86,for,B
86,accuracy,B
86,and,O
86,1.00,B
86,%,O
86,for,O
86,Macro,B
86,-,I
86,F1,I
86,on,I
86,average,I
86,",",O
86,which,O
86,implies,O
86,that,O
86,the,O
86,semantic,O
86,separation,O
86,plays,O
86,an,O
86,important,O
86,role,O
86,in,O
86,alleviating,O
86,false,O
86,alignment,O
86,.,O
87,Then,O
87,",",O
87,compared,B
87,with,I
87,MGAN,B
87,w,O
87,/,O
87,o,O
87,C2F,B
87,",",O
87,MGAN,O
87,further,O
87,uses,B
87,C2F,O
87,to,B
87,capture,B
87,more,B
87,specific,I
87,aspect,B
87,terms,I
87,from,B
87,the,O
87,context,B
87,towards,B
87,the,O
87,aspect,O
87,category,O
87,",",O
87,such,O
87,as,O
87,"""",O
87,shells,O
87,"""",O
87,to,O
87,food,O
87,seafood,O
87,sea,O
87,",",O
87,which,O
87,helps,B
87,the,O
87,source,B
87,task,I
87,capture,O
87,more,O
87,fine,O
87,-,O
87,grained,O
87,semantics,O
87,of,B
87,aspect,O
87,category,O
87,and,O
87,detailed,B
87,position,I
87,information,I
87,like,B
87,the,O
87,target,B
87,task,O
87,",",O
87,such,O
87,that,O
87,the,O
87,sentiment,O
87,attention,O
87,can,O
87,be,O
87,positionaware,O
87,and,O
87,identify,O
87,more,O
87,relevant,O
87,sentiment,O
87,features,O
87,towards,O
87,the,O
87,aspect,O
87,.,O
88,While,O
88,MGAN,B
88,w,I
88,/,I
88,o,I
88,C2F,I
88,locates,B
88,wrong,B
88,sentiment,I
88,contexts,I
88,and,O
88,fails,O
88,in,O
88,(,O
88,c,O
88,),O
88,.,O
89,For,B
89,ternary,B
89,relation,I
89,extraction,I
89,(,I
89,first,O
89,two,O
89,columns,O
89,in,O
89,),O
89,",",O
89,our,B
89,AGGCN,I
89,model,I
89,achieves,B
89,accuracies,B
89,of,B
89,87.1,B
89,and,I
89,87.0,I
89,on,B
89,instances,I
89,within,B
89,single,I
89,sentence,I
89,(,O
89,Single,O
89,),O
89,and,O
89,on,O
89,all,B
89,instances,O
89,(,O
89,Cross,O
89,),O
89,",",O
89,respectively,O
89,",",O
89,which,O
89,outperform,B
89,all,O
89,the,O
89,baselines,O
89,.,O
90,As,O
90,such,O
90,",",O
90,benefited,B
90,from,B
90,distilled,B
90,knowledge,I
90,from,O
90,the,O
90,source,B
90,task,I
90,",",O
90,MGAN,B
90,can,B
90,better,I
90,model,I
90,the,O
90,complicated,B
90,relatedness,I
90,between,B
90,the,O
90,context,B
90,and,I
90,aspect,I
90,term,I
90,for,B
90,the,O
90,target,B
90,domain,I
90,L,I
90,",",O
90,but,O
90,MGAN,O
90,w,O
90,/,O
90,o,O
90,C2F,O
90,performs,B
90,poorly,B
90,though,O
90,it,O
90,make,O
90,true,O
90,predictions,O
90,in,O
90,(,O
90,d,O
90,),O
90,and,O
90,(,O
90,e,O
90,),O
90,.,O
91,The,O
91,hyperparameters,O
91,for,O
91,our,O
91,models,O
91,were,O
91,tuned,B
91,on,I
91,the,O
91,development,B
91,set,I
91,for,O
91,each,O
91,task,O
91,.,O
92,We,O
92,initialized,B
92,our,B
92,word,I
92,representations,I
92,using,B
92,publicly,B
92,available,I
92,300,I
92,-,I
92,dimensional,I
92,Glove,I
92,vectors,I
93,For,B
93,the,O
93,sentiment,B
93,classification,I
93,task,I
93,",",O
93,word,B
93,representations,I
93,were,O
93,updated,B
93,during,B
93,training,I
93,with,B
93,a,O
93,learning,B
93,rate,I
93,of,B
93,0.1,B
93,.,O
94,For,O
94,the,O
94,semantic,B
94,relatedness,I
94,task,I
94,",",O
94,word,B
94,representations,I
94,were,O
94,held,B
94,fixed,B
94,as,O
94,we,O
94,did,O
94,not,O
94,observe,O
94,any,O
94,significant,O
94,improvement,O
94,when,O
94,the,O
94,representations,O
94,were,O
94,tuned,O
94,.,O
95,Our,O
95,models,O
95,were,O
95,trained,B
95,using,I
95,AdaGrad,B
95,with,B
95,a,O
95,learning,B
95,rate,I
95,of,B
95,0.05,B
95,and,O
95,a,O
95,minibatch,B
95,size,I
95,of,O
95,25,B
95,.,O
96,The,O
96,model,B
96,parameters,I
96,were,O
96,regularized,B
96,with,I
96,a,O
96,per-minibatch,B
96,L2,I
96,regularization,I
96,strength,I
96,of,B
96,10,B
96,?4,I
96,.,O
97,The,O
97,sentiment,B
97,classifier,I
97,was,O
97,additionally,B
97,regularized,I
97,using,I
97,dropout,B
97,with,B
97,a,O
97,dropout,O
97,rate,O
97,of,B
97,0.5,B
97,.,O
98,In,O
98,this,O
98,paper,O
98,",",O
98,we,O
98,introduce,B
98,a,O
98,generalization,B
98,of,I
98,the,I
98,standard,I
98,LSTM,I
98,architecture,I
98,to,B
98,tree,B
98,-,I
98,structured,I
98,network,I
98,topologies,I
98,and,O
98,show,B
98,its,O
98,superiority,B
98,for,B
98,representing,I
98,sentence,B
98,meaning,I
98,over,B
98,a,O
98,sequential,B
98,LSTM,O
98,.,O
99,While,O
99,the,O
99,standard,O
99,LSTM,O
99,composes,B
99,its,O
99,hidden,B
99,state,B
99,from,B
99,the,O
99,input,B
99,at,O
99,the,O
99,current,O
99,time,O
99,step,O
99,and,O
99,the,O
99,hidden,O
99,state,O
99,of,B
99,the,O
99,LSTM,O
99,unit,O
99,in,O
99,the,O
99,previous,O
99,time,O
99,step,O
99,",",O
99,the,O
99,tree,O
99,-,O
99,structured,O
99,LSTM,O
99,",",O
99,or,O
99,Tree,O
99,-,O
99,LSTM,O
99,",",O
99,composes,O
99,its,O
99,state,O
99,from,O
99,an,O
99,input,O
99,vector,O
99,and,O
99,the,O
99,hidden,O
99,states,O
99,of,O
99,arbitrarily,B
99,many,I
99,child,I
99,units,I
99,.,O
100,For,O
100,binary,B
100,relation,I
100,extraction,I
100,(,O
100,third,O
100,and,O
100,fourth,O
100,columns,O
100,in,O
100,),O
100,",",O
100,AGGCN,B
100,consistently,B
100,outperforms,I
100,GS,B
100,GLSTM,I
100,and,O
100,GCN,B
100,as,O
100,well,O
100,.,O
101,Tree,O
101,-,O
101,LSTMs,O
101,outperform,O
101,all,O
101,existing,O
101,systems,O
101,and,O
101,strong,O
101,LSTM,O
101,baselines,O
101,on,O
101,two,O
101,tasks,O
101,:,O
101,predicting,B
101,the,I
101,semantic,I
101,relatedness,I
101,of,I
101,two,O
101,sentences,O
101,(,O
101,Sem,O
101,Eval,O
101,2014,O
101,",",O
101,Task,O
101,1,O
101,),O
101,and,O
101,sentiment,B
101,classification,I
101,(,O
101,Stanford,O
101,Sentiment,O
101,Treebank,O
101,),O
101,.,O
102,Majority,B
102,assigns,B
102,the,O
102,sentiment,B
102,polarity,I
102,with,B
102,most,B
102,frequent,I
102,occurrences,I
102,in,B
102,the,O
102,training,B
102,set,I
102,to,B
102,each,B
102,sample,I
102,in,O
102,test,B
102,set,O
102,.,O
103,Bi,O
103,-,O
103,LSTM,O
103,and,O
103,Bi,O
103,-,O
103,GRU,O
103,adopt,B
103,a,O
103,Bi,O
103,-,O
103,LSTM,O
103,and,O
103,a,O
103,Bi,O
103,-,O
103,GRU,O
103,network,O
103,to,B
103,model,I
103,the,O
103,sentence,B
103,and,O
103,use,B
103,the,O
103,hidden,B
103,state,I
103,of,B
103,the,O
103,final,B
103,word,I
103,for,B
103,prediction,B
103,respectively,O
103,.,O
104,TD,O
104,-,O
104,LSTM,B
104,adopts,B
104,two,B
104,LSTMs,I
104,to,B
104,model,I
104,the,O
104,left,B
104,context,I
104,with,B
104,target,B
104,and,O
104,the,O
104,right,B
104,context,O
104,with,O
104,target,O
104,respectively,O
104,;,O
104,It,O
104,takes,B
104,the,O
104,hidden,B
104,states,I
104,of,B
104,LSTM,O
104,at,B
104,last,B
104,time,I
104,-,O
104,step,O
104,to,O
104,represent,O
104,the,O
104,sentence,B
104,for,B
104,prediction,B
104,.,O
105,MemNet,B
105,applies,B
105,attention,I
105,multiple,B
105,times,I
105,on,B
105,the,O
105,word,B
105,embeddings,I
105,",",O
105,and,O
105,the,O
105,output,B
105,of,B
105,last,B
105,attention,O
105,is,O
105,fed,B
105,to,I
105,softmax,B
105,for,B
105,prediction,B
105,.,O
106,IAN,B
106,interactively,O
106,learns,B
106,attentions,B
106,in,B
106,the,O
106,contexts,O
106,and,O
106,targets,B
106,",",O
106,and,O
106,generates,B
106,the,O
106,representations,B
106,for,B
106,targets,O
106,and,O
106,contexts,O
106,separately,O
106,.,O
107,RAM,B
107,),O
107,is,B
107,a,O
107,multilayer,B
107,architecture,I
107,where,B
107,each,B
107,layer,I
107,consists,B
107,of,B
107,attention,B
107,-,I
107,based,I
107,aggregation,I
107,of,O
107,word,B
107,features,I
107,and,O
107,a,O
107,GRU,B
107,cell,I
107,to,B
107,learn,I
107,the,O
107,sentence,B
107,representation,I
107,.,O
108,LCR,O
108,-,O
108,Rot,O
108,employs,B
108,three,B
108,Bi-,I
108,LSTMs,I
108,to,B
108,model,I
108,the,O
108,left,B
108,context,I
108,",",O
108,the,O
108,target,B
108,and,O
108,the,O
108,right,B
108,context,O
108,.,O
109,AOA,O
109,-,O
109,LSTM,O
109,introduces,B
109,an,O
109,attention,O
109,-,O
109,over-,O
109,attention,O
109,(,O
109,AOA,O
109,),O
109,based,O
109,network,O
109,to,B
109,model,I
109,aspects,B
109,and,I
109,sentences,I
109,in,B
109,a,O
109,joint,B
109,way,I
109,and,O
109,explicitly,B
109,capture,I
109,the,O
109,interaction,B
109,between,B
109,aspects,O
109,and,O
109,context,O
109,sentences,O
109,.,O
110,BGWA,B
110,:,O
110,Bi,B
110,-,I
110,GRU,I
110,based,I
110,relation,I
110,extraction,I
110,model,I
110,with,B
110,word,B
110,and,I
110,sentence,I
110,level,I
110,attention,I
110,),O
110,.,O
111,More,O
111,specifically,O
111,",",O
111,our,O
111,AG,B
111,-,I
111,GCN,I
111,model,I
111,surpasses,B
111,the,I
111,state,B
111,-,O
111,of,O
111,-,O
111,the,O
111,-,O
111,art,O
111,Graphstructured,O
111,LSTM,O
111,model,O
111,(,O
111,GS,O
111,GLSTM,O
111,),O
111,by,B
111,6.8,B
111,and,I
111,3.8,I
111,points,I
111,for,B
111,the,O
111,Single,B
111,and,O
111,Cross,O
111,settings,O
111,",",O
111,respectively,O
111,.,O
112,We,O
112,use,B
112,300,B
112,-,I
112,dimension,I
112,word,I
112,vectors,I
112,pre-trained,B
112,by,I
112,GloVe,B
112,(,O
112,whose,O
112,vocabulary,O
112,size,O
112,is,O
112,1.9M,O
112,),O
112,for,O
112,our,O
112,experiments,O
112,",",O
112,as,O
112,previous,O
112,works,O
112,did,O
112,.,O
113,All,O
113,out,O
113,-,O
113,of,O
113,-,O
113,vocabulary,O
113,words,O
113,are,O
113,initialized,B
113,as,I
113,zero,B
113,vectors,I
113,",",O
113,and,O
113,all,O
113,biases,O
113,are,O
113,set,B
113,to,I
113,zero,O
113,.,O
114,The,O
114,dimensions,B
114,of,B
114,hidden,B
114,states,I
114,and,I
114,fused,I
114,embeddings,I
114,are,O
114,set,B
114,to,I
114,300,B
114,.,O
115,The,O
115,dimension,B
115,of,B
115,position,B
115,embeddings,I
115,is,O
115,set,B
115,to,I
115,50,B
115,.,O
116,Keras,B
116,is,O
116,used,O
116,for,B
116,implementing,I
116,our,O
116,neural,B
116,network,I
116,model,I
116,.,O
117,The,O
117,paired,B
117,t-,I
117,test,I
117,is,O
117,used,B
117,for,I
117,the,O
117,significance,B
117,testing,I
117,.,O
118,In,B
118,model,B
118,training,I
118,",",O
118,we,O
118,set,B
118,the,O
118,learning,B
118,rate,I
118,to,B
118,0.001,B
118,",",O
118,the,O
118,batch,B
118,size,I
118,to,O
118,64,B
118,",",O
118,and,O
118,dropout,B
118,rate,O
118,to,O
118,0.5,B
118,.,O
119,Based,O
119,on,O
119,the,O
119,analysis,O
119,above,O
119,",",O
119,in,O
119,this,O
119,paper,O
119,",",O
119,we,O
119,propose,B
119,a,O
119,hierarchical,B
119,attention,I
119,based,O
119,positionaware,O
119,network,O
119,(,O
119,HAPN,O
119,),O
119,for,B
119,aspect,B
119,-,I
119,level,I
119,sentiment,I
119,classification,I
119,.,O
120,A,O
120,position,B
120,-,I
120,aware,I
120,encoding,I
120,layer,I
120,is,O
120,introduced,O
120,for,B
120,modelling,I
120,the,O
120,sentence,B
120,to,B
120,achieve,I
120,the,O
120,position,O
120,-,O
120,aware,O
120,abstract,O
120,representation,O
120,of,B
120,each,B
120,word,I
120,.,O
121,On,O
121,this,O
121,basis,O
121,",",O
121,a,O
121,succinct,B
121,fusion,I
121,mechanism,I
121,is,O
121,further,O
121,proposed,B
121,to,I
121,fuse,B
121,the,I
121,information,B
121,of,I
121,aspects,B
121,and,I
121,the,O
121,contexts,O
121,",",O
121,achieving,B
121,the,O
121,final,B
121,sentence,I
121,representation,I
121,.,O
122,AGGCN,B
122,also,O
122,performs,B
122,better,B
122,than,B
122,GCNs,B
122,",",O
122,although,O
122,its,O
122,performance,O
122,can,O
122,be,O
122,boosted,O
122,via,O
122,pruned,O
122,trees,O
122,.,O
123,Finally,O
123,",",O
123,we,O
123,feed,B
123,the,O
123,achieved,B
123,sentence,I
123,representation,I
123,into,B
123,a,O
123,softmax,B
123,layer,I
123,to,B
123,predict,I
123,the,O
123,sentiment,B
123,polarity,I
123,.,O
124,Hierarchical,O
124,Attention,O
124,Based,O
124,Position-aware,O
124,Network,O
124,for,O
124,Aspect-level,B
124,Sentiment,I
124,Analysis,I
125,Aspect,O
125,-,O
125,level,O
125,sentiment,B
125,analysis,I
125,is,O
125,a,O
125,fine,O
125,-,O
125,grained,O
125,task,O
125,in,O
125,sentiment,O
125,analysis,O
125,",",O
125,which,O
125,aims,O
125,to,O
125,identify,O
125,the,O
125,sentiment,O
125,polarity,O
125,(,O
125,i.e.,O
126,(,O
126,2,O
126,),O
126,The,O
126,TD,B
126,-,I
126,LSTM,I
126,model,I
126,",",O
126,which,O
126,has,O
126,been,O
126,shown,B
126,to,I
126,be,I
126,better,I
126,than,I
126,LSTM,O
126,",",O
126,gets,B
126,the,O
126,worst,B
126,performance,I
126,of,B
126,all,B
126,RNN,I
126,based,I
126,models,I
126,and,I
126,the,O
126,accuracy,B
126,achieved,B
126,by,I
126,TD,O
126,-,O
126,LSTM,O
126,is,B
126,2.94,B
126,%,I
126,and,O
126,2.4,O
126,%,O
126,lower,B
126,than,O
126,those,O
126,by,O
126,Bi,B
126,-,O
126,LSTM,O
126,on,O
126,the,O
126,two,O
126,datasets,O
126,respectively,O
126,.,O
127,Our,O
127,method,O
127,achieves,B
127,accuracies,B
127,of,B
127,82.23,B
127,%,I
127,as,I
127,well,I
127,as,O
127,77,O
127,.,O
128,27,O
128,%,O
128,on,B
128,the,O
128,Restaurant,B
128,and,I
128,Laptop,I
128,dataset,I
128,respectively,O
128,",",O
128,which,O
128,are,O
128,0.89,O
128,%,O
128,and,O
128,2.03,O
128,%,O
128,higher,O
128,than,O
128,the,O
128,current,O
128,best,O
128,method,O
128,.,O
129,In,O
129,addition,O
129,",",O
129,another,O
129,observation,O
129,is,O
129,that,O
129,Bi,B
129,-,I
129,GRU,I
129,-,O
129,PW,O
129,performs,B
129,even,B
129,worse,I
129,than,B
129,Bi,O
129,-,O
129,GRU,O
129,.,O
130,The,O
130,accuracy,B
130,achieved,B
130,by,I
130,Bi,B
130,-,I
130,GRU,I
130,-,O
130,PW,O
130,is,B
130,0.72,B
130,%,I
130,as,I
130,well,I
130,as,O
130,1.41,B
130,%,O
130,lower,B
130,than,I
130,that,O
130,by,O
130,Bi,O
130,-,O
130,GRU,O
130,on,B
130,the,O
130,Restaurant,B
130,and,I
130,Laptop,I
130,dataset,I
130,respectively,O
130,.,O
131,HAPN,B
131,achieves,B
131,improvement,B
131,of,B
131,0.35,B
131,%,I
131,and,I
131,0.78,I
131,%,O
131,on,B
131,accuracy,B
131,respectively,O
131,on,O
131,the,O
131,two,O
131,dataset,O
131,.,O
132,(,O
132,1,O
132,),O
132,The,O
132,information,B
132,fusion,I
132,operation,I
132,is,O
132,only,O
132,used,B
132,to,I
132,calculate,B
132,the,O
132,Source2context,B
132,attention,I
132,value,I
132,.,O
133,The,O
133,output,B
133,of,B
133,Source2aspect,B
133,attention,I
133,is,O
133,only,O
133,used,B
133,for,I
133,information,B
133,fusion,I
133,.,O
134,However,O
134,",",O
134,our,B
134,AGGCN,I
134,model,I
134,still,O
134,obtains,B
134,8.0,B
134,and,I
134,5.7,I
134,points,I
134,higher,B
134,than,I
134,the,O
134,GS,B
134,GLSTM,I
134,model,O
134,for,B
134,ternary,B
134,and,O
134,binary,O
134,relations,O
134,",",O
134,respectively,O
134,.,O
135,And,O
135,the,O
135,achieved,O
135,model,O
135,is,O
135,"""",O
135,Bi,B
135,-,I
135,GRU,I
135,-,O
135,PE,O
135,"""",O
135,reported,O
135,in,O
135,the,O
135,",",O
135,achieving,B
135,the,O
135,accuracies,B
135,of,B
135,80.89,B
135,%,I
135,and,O
135,76.02,O
135,%,O
135,on,B
135,the,O
135,two,B
135,datasets,I
135,respectively,O
135,",",O
135,which,O
135,are,O
135,1.34,O
135,%,O
135,and,O
135,1.25,O
135,%,O
135,lower,O
135,than,O
135,the,O
135,proposed,O
135,model,O
135,.,O
136,(,O
136,3,O
136,),O
136,Compared,B
136,with,I
136,the,I
136,state,B
136,-,I
136,of,I
136,-,O
136,the,O
136,-,O
136,art,O
136,methods,O
136,",",O
136,our,B
136,model,I
136,achieves,B
136,the,O
136,best,B
136,performance,I
136,",",O
136,which,O
136,illustrates,O
136,the,O
136,effectiveness,O
136,of,O
136,the,O
136,proposed,O
136,approach,O
136,.,O
137,After,O
137,introducing,B
137,the,O
137,position,B
137,embeddings,I
137,",",O
137,the,O
137,accuracy,B
137,has,B
137,an,I
137,increase,B
137,of,B
137,0.62,B
137,%,I
137,and,I
137,2.67,I
137,%,O
137,on,B
137,two,B
137,datasets,I
137,.,O
138,Because,O
138,of,O
138,advantages,O
138,of,O
138,neural,O
138,networks,O
138,",",O
138,we,O
138,approach,O
138,this,O
138,aspect,O
138,level,O
138,sentiment,O
138,classification,O
138,problem,O
138,based,B
138,on,I
138,long,B
138,short,I
138,-,I
138,term,I
138,memory,I
138,(,I
138,LSTM,I
138,),I
138,neural,O
138,networks,O
138,.,O
139,Previous,O
139,LSTM,O
139,-,O
139,based,O
139,methods,O
139,mainly,O
139,focus,O
139,on,O
139,modeling,O
139,texts,O
139,separately,O
139,",",O
139,while,O
139,our,O
139,approach,O
139,models,B
139,aspects,B
139,and,I
139,texts,O
139,simultaneously,O
139,using,B
139,LSTMs,B
139,.,O
140,Furthermore,O
140,",",O
140,the,O
140,target,B
140,representation,I
140,and,I
140,text,I
140,representation,O
140,generated,B
140,from,I
140,LSTMs,B
140,interact,B
140,with,I
140,each,B
140,other,I
140,by,B
140,an,O
140,attention,O
140,-,O
140,over,O
140,-,O
140,attention,O
140,(,O
140,AOA,O
140,),O
140,module,O
140,.,O
141,AOA,B
141,automatically,B
141,generates,I
141,mutual,B
141,attentions,I
141,not,B
141,only,I
141,from,I
141,aspect,I
141,-,I
141,to,I
141,-,O
141,text,B
141,but,B
141,also,I
141,text,O
141,-,O
141,to,O
141,-,O
141,aspect,O
141,.,O
142,That,O
142,is,O
142,why,O
142,we,O
142,choose,B
142,AOA,B
142,to,B
142,attend,I
142,to,O
142,the,O
142,most,B
142,important,I
142,parts,I
142,in,B
142,both,I
142,aspect,B
142,and,I
142,sentence,I
142,.,O
143,Majority,B
143,is,B
143,a,O
143,basic,B
143,baseline,I
143,method,I
143,",",O
143,which,O
143,assigns,B
143,the,O
143,largest,B
143,sentiment,I
143,polarity,I
143,in,B
143,the,O
143,training,B
143,set,I
143,to,B
143,each,B
143,sample,I
143,in,O
143,the,O
143,test,B
143,set,O
143,.,O
144,LSTM,O
144,uses,B
144,one,B
144,LSTM,O
144,network,O
144,to,B
144,model,I
144,the,O
144,sentence,B
144,",",O
144,and,O
144,the,O
144,last,B
144,hidden,I
144,state,I
144,is,O
144,used,B
144,as,I
144,the,O
144,sentence,O
144,representation,O
144,for,B
144,the,O
144,final,B
144,classification,I
144,.,O
145,We,O
145,also,O
145,notice,O
145,that,O
145,our,B
145,AGGCN,I
145,achieves,B
145,a,O
145,better,B
145,test,I
145,accuracy,I
145,than,B
145,all,B
145,GCN,I
145,models,I
145,",",O
145,which,O
145,further,O
145,demonstrates,O
145,its,O
145,ability,O
145,to,O
145,learn,O
145,better,O
145,representations,O
145,from,O
145,full,O
145,trees,O
145,.,O
146,TD,O
146,-,O
146,LSTM,O
146,uses,B
146,two,B
146,LSTM,O
146,networks,O
146,to,B
146,model,I
146,the,O
146,preceding,B
146,and,I
146,following,I
146,contexts,I
146,surrounding,B
146,the,O
146,aspect,B
146,term,I
146,.,O
147,AT,O
147,-,O
147,LSTM,B
147,first,B
147,models,I
147,the,O
147,sentence,B
147,via,B
147,a,O
147,LSTM,O
147,model,O
147,.,O
148,ATAE,O
148,-,O
148,LSTM,O
148,further,B
148,extends,I
148,AT,B
148,-,O
148,LSTM,O
148,by,B
148,appending,I
148,the,O
148,aspect,B
148,embedding,I
148,into,B
148,each,B
148,word,I
148,vector,I
148,.,O
149,IAN,B
149,uses,B
149,two,B
149,LSTM,I
149,networks,I
149,to,B
149,model,I
149,the,O
149,sentence,B
149,and,I
149,aspect,I
149,term,I
149,respectively,O
149,.,O
150,In,O
150,experiments,O
150,",",O
150,we,O
150,first,O
150,randomly,B
150,select,I
150,20,B
150,%,I
150,of,B
150,training,B
150,data,I
150,as,B
150,validation,B
150,set,I
150,to,B
150,tune,I
150,the,O
150,hyperparameters,B
150,.,O
151,All,O
151,weight,B
151,matrices,I
151,are,O
151,randomly,B
151,initialized,I
151,from,I
151,uniform,B
151,distribution,I
151,U,I
151,(,I
151,?10,I
151,?4,I
151,",",I
151,10,I
151,?4,O
151,),O
151,and,O
151,all,O
151,bias,B
151,terms,I
151,are,O
151,set,B
151,to,I
151,zero,B
151,.,O
152,The,O
152,L,B
152,2,I
152,regularization,I
152,coefficient,I
152,is,O
152,set,B
152,to,I
152,10,O
152,?,O
153,4,O
153,and,O
153,the,O
153,dropout,B
153,keep,I
153,rate,I
153,is,O
153,set,B
153,to,I
153,0.2,B
153,.,O
154,The,O
154,word,B
154,embeddings,I
154,are,O
154,initialized,B
154,with,I
154,300,B
154,-,I
154,dimensional,I
154,Glove,I
154,vectors,I
154,and,O
154,are,O
154,fixed,B
154,during,I
154,training,B
154,.,O
155,The,O
155,dimension,B
155,of,B
155,LSTM,B
155,hidden,I
155,states,I
155,is,O
155,set,B
155,to,I
155,150,B
155,.,O
156,The,O
156,initial,B
156,learning,I
156,rate,I
156,is,B
156,0.01,B
156,for,B
156,the,O
156,Adam,B
156,optimizer,I
156,.,O
157,Our,O
157,C,O
157,-,O
157,AGGCN,O
157,model,O
157,achieves,B
157,an,O
157,F1,B
157,score,I
157,of,B
157,68.2,B
157,",",O
157,which,O
157,outperforms,B
157,the,O
157,state,B
157,-,O
157,ofart,O
157,C,O
157,-,O
157,GCN,O
157,model,O
157,by,B
157,1.8,B
157,points,I
157,.,O
158,If,O
158,the,O
158,training,B
158,loss,I
158,does,B
158,not,I
158,drop,B
158,after,B
158,every,B
158,three,I
158,epochs,I
158,",",O
158,we,O
158,decrease,B
158,the,O
158,learning,B
158,rate,I
158,by,B
158,half,B
158,.,O
159,The,O
159,batch,B
159,size,I
159,is,O
159,set,B
159,as,I
159,25,B
159,.,O
160,For,B
160,the,O
160,out,B
160,of,I
160,vocabulary,I
160,words,I
160,we,O
160,initialize,B
160,them,I
160,randomly,B
160,from,B
160,uniform,O
160,distribution,O
160,U,O
160,(,O
160,?,O
161,In,O
161,our,O
161,implementation,O
161,",",O
161,we,O
161,found,B
161,that,I
161,the,O
161,performance,B
161,fluctuates,I
161,with,B
161,different,B
161,random,I
161,initialization,I
161,",",O
161,which,O
161,is,O
161,a,O
161,well,O
161,-,O
161,known,O
161,issue,O
161,in,O
161,training,O
161,neural,O
161,networks,O
161,.,O
162,On,O
162,average,O
162,",",O
162,our,B
162,algorithm,I
162,is,O
162,better,B
162,than,I
162,these,O
162,baseline,B
162,methods,I
162,and,O
162,our,O
162,best,O
162,trained,O
162,model,O
162,outperforms,B
162,them,I
162,in,I
162,a,O
162,large,B
162,margin,I
162,.,O
163,The,O
163,RNTN,B
163,has,O
163,the,O
163,highest,B
163,reversal,I
163,accuracy,I
163,",",O
163,showing,B
163,its,I
163,ability,I
163,to,I
163,structurally,B
163,learn,I
163,negation,I
163,of,I
163,positive,I
163,sentences,I
163,.,O
164,shows,B
164,a,O
164,typical,B
164,case,I
164,in,B
164,which,I
164,sentiment,B
164,was,O
164,made,B
164,more,B
164,positive,I
164,by,B
164,switching,I
164,the,O
164,main,B
164,class,I
164,from,B
164,negative,B
164,to,I
164,neutral,I
164,even,O
164,though,O
164,both,O
164,not,O
164,and,O
164,dull,O
164,were,O
164,negative,O
164,.,O
165,Therefore,O
165,we,O
165,can,O
165,conclude,B
165,that,O
165,the,O
165,RNTN,B
165,is,O
165,best,B
165,able,I
165,to,I
165,identify,I
165,the,O
165,effect,B
165,of,I
165,negations,I
165,upon,B
165,both,O
165,positive,B
165,and,I
165,negative,I
165,sentiment,I
165,sentences,I
165,.,O
166,The,O
166,performance,B
166,gap,I
166,between,B
166,GCNs,B
166,with,I
166,pruned,I
166,trees,I
166,and,I
166,AGGCNs,I
166,with,O
166,full,O
166,trees,O
166,empirically,B
166,show,I
166,that,O
166,the,O
166,AGGCN,B
166,model,I
166,is,O
166,better,B
166,at,I
166,distinguishing,I
166,relevant,B
166,from,I
166,irrelevant,I
166,information,I
166,for,B
166,learning,I
166,a,O
166,better,O
166,graph,O
166,representation,O
166,.,O
167,We,O
167,compare,B
167,to,I
167,commonly,B
167,used,I
167,methods,I
167,that,B
167,use,I
167,bag,B
167,of,I
167,words,I
167,features,I
167,with,B
167,Naive,B
167,Bayes,I
167,and,I
167,SVMs,I
167,",",O
167,as,O
167,well,O
167,as,O
167,Naive,O
167,Bayes,O
167,with,O
167,bag,O
167,of,O
167,bigram,O
167,features,O
167,.,O
168,We,O
168,also,O
168,compare,O
168,to,O
168,a,O
168,model,B
168,that,O
168,averages,B
168,neural,B
168,word,B
168,vectors,I
168,and,O
168,ignores,B
168,word,O
168,order,O
168,(,O
168,VecAvg,O
168,),O
168,.,O
169,The,O
169,Stanford,B
169,Sentiment,B
169,Treebank,I
169,is,B
169,the,O
169,first,B
169,corpus,I
169,with,B
169,fully,B
169,labeled,I
169,parse,I
169,trees,I
169,that,O
169,allows,B
169,for,I
169,a,O
169,complete,B
169,analysis,I
169,of,B
169,the,O
169,compositional,B
169,effects,I
169,of,O
169,sentiment,O
169,in,O
169,language,O
169,.,O
170,The,O
170,corpus,B
170,is,O
170,based,B
170,on,I
170,the,O
170,dataset,B
170,introduced,O
170,by,O
170,and,O
170,consists,B
170,of,I
170,"11,855",B
170,single,I
170,sentences,I
170,extracted,B
170,from,I
170,movie,B
170,reviews,I
170,.,O
171,It,O
171,was,O
171,parsed,B
171,with,B
171,the,O
171,Stanford,B
171,parser,I
171,and,O
171,includes,O
171,a,O
171,total,B
171,of,I
171,"215,154",B
171,unique,I
171,phrases,I
171,from,B
171,those,O
171,parse,B
171,trees,I
171,",",O
171,each,O
171,annotated,B
171,by,I
171,3,B
171,human,I
171,judges,I
171,.,O
172,This,O
172,new,B
172,dataset,I
172,allows,O
172,us,O
172,to,B
172,analyze,I
172,the,O
172,intricacies,B
172,of,B
172,sentiment,B
172,and,O
172,to,O
172,capture,O
172,complex,B
172,linguistic,I
172,phenomena,I
172,.,O
173,The,O
173,granularity,B
173,and,I
173,size,I
173,of,O
173,this,O
173,dataset,O
173,will,O
173,enable,B
173,the,O
173,community,B
173,to,B
173,train,I
173,compositional,B
173,models,I
173,that,O
173,are,O
173,based,B
173,on,I
173,supervised,B
173,and,O
173,structured,O
173,machine,O
173,learning,O
173,techniques,O
173,.,O
174,Optimal,O
174,performance,O
174,for,B
174,all,B
174,models,I
174,was,O
174,achieved,B
174,at,I
174,word,B
174,vector,I
174,sizes,I
174,between,B
174,25,B
174,and,I
174,35,I
174,dimensions,I
174,and,O
174,batch,B
174,sizes,O
174,between,O
174,20,B
174,and,O
174,30,O
174,.,O
175,The,O
175,RNTN,B
175,would,O
175,usually,B
175,achieve,I
175,its,O
175,best,B
175,performance,I
175,on,B
175,the,O
175,dev,B
175,set,I
175,after,B
175,training,I
175,for,I
175,3,B
175,-,I
175,5,I
175,hours,I
175,.,O
176,The,O
176,sentences,B
176,in,B
176,the,O
176,treebank,B
176,were,B
176,split,I
176,into,I
176,a,O
176,train,B
176,(,I
176,8544,I
176,),I
176,",",I
176,dev,I
176,(,O
176,1101,O
176,),O
176,and,O
176,test,O
176,splits,O
176,(,O
176,2210,O
176,),O
176,and,O
176,these,O
176,splits,O
176,are,O
176,made,O
176,available,O
176,with,O
176,the,O
176,data,O
176,release,O
176,.,O
177,Compared,O
177,to,O
177,GCN,B
177,models,I
177,",",O
177,our,B
177,model,I
177,obtains,B
177,1.3,B
177,and,I
177,1.2,I
177,points,I
177,higher,I
177,than,B
177,the,O
177,best,B
177,performing,I
177,model,O
177,with,B
177,pruned,B
177,tree,I
177,(,I
177,K=1,I
177,),I
177,.,O
178,We,O
178,use,B
178,f,B
178,=,I
178,tanh,I
178,in,B
178,all,B
178,experiments,I
178,.,O
179,In,O
179,order,O
179,to,O
179,capture,O
179,the,O
179,compositional,O
179,effects,O
179,with,O
179,higher,O
179,accuracy,O
179,",",O
179,we,O
179,propose,O
179,a,O
179,new,O
179,model,O
179,called,B
179,the,O
179,Recursive,B
179,Neural,I
179,Tensor,I
179,Network,I
179,(,I
179,RNTN,I
179,),I
179,.,O
180,Recursive,O
180,Neural,O
180,Tensor,O
180,Networks,O
180,take,B
180,as,I
180,input,I
180,phrases,B
180,of,B
180,any,B
180,length,I
180,.,O
181,They,O
181,represent,B
181,a,I
181,phrase,B
181,through,B
181,word,B
181,vectors,B
181,and,I
181,a,O
181,parse,O
181,tree,B
181,and,O
181,then,O
181,compute,B
181,vectors,O
181,for,B
181,higher,B
181,nodes,I
181,in,B
181,the,O
181,tree,O
181,using,B
181,the,O
181,same,B
181,tensor,I
181,-,I
181,based,I
181,composition,I
181,function,I
181,.,O
182,Recursive,O
182,Deep,O
182,Models,O
182,for,O
182,Semantic,O
182,Compositionality,O
182,Over,O
182,a,O
182,Sentiment,B
182,Treebank,I
183,Further,O
183,progress,O
183,towards,O
183,understanding,O
183,compositionality,O
183,in,O
183,tasks,O
183,such,O
183,as,O
183,sentiment,O
183,detection,O
183,requires,O
183,richer,B
183,supervised,I
183,training,I
183,and,I
183,evaluation,I
183,resources,I
183,and,O
183,more,O
183,powerful,O
183,models,O
183,of,O
183,composition,O
183,.,O
184,showed,B
184,that,O
184,a,O
184,fine,B
184,grained,I
184,classification,I
184,into,B
184,5,B
184,classes,I
184,is,B
184,a,O
184,reasonable,B
184,approximation,I
184,to,B
184,capture,I
184,most,B
184,of,I
184,the,I
184,data,I
184,variation,I
184,.,O
185,The,O
185,RNTN,B
185,gets,B
185,the,O
185,highest,B
185,performance,I
185,",",O
185,followed,B
185,by,I
185,the,O
185,MV,B
185,-,I
185,RNN,I
185,and,I
185,RNN,O
185,.,O
186,The,O
186,recursive,B
186,models,I
186,work,B
186,very,B
186,well,B
186,on,B
186,shorter,B
186,phrases,I
186,",",O
186,where,B
186,negation,B
186,and,I
186,composition,I
186,are,B
186,important,B
186,",",O
186,while,O
186,bag,B
186,of,I
186,features,I
186,baselines,I
186,perform,B
186,well,O
186,only,O
186,with,B
186,longer,B
186,sentences,I
186,.,O
187,The,O
187,combination,B
187,of,I
187,the,O
187,new,B
187,sentiment,I
187,treebank,I
187,and,I
187,the,O
187,RNTN,O
187,pushes,B
187,the,O
187,state,B
187,of,O
187,the,O
187,art,O
187,on,B
187,short,B
187,phrases,I
187,up,B
187,to,I
187,85.4,B
187,%,I
187,.,O
188,We,O
188,also,O
188,notice,B
188,that,O
188,AGGCN,O
188,and,O
188,C,O
188,-,O
188,AGGCN,O
188,achieve,B
188,better,B
188,precision,I
188,and,O
188,recall,O
188,scores,O
188,than,B
188,GCN,I
188,and,O
188,C,O
188,-,O
188,GCN,O
188,",",O
188,respectively,O
188,.,O
189,We,O
189,apply,B
189,the,O
189,proposed,B
189,model,I
189,to,B
189,aspect,B
189,-,I
189,level,I
189,sentiment,I
189,classification,I
189,.,O
190,In,B
190,our,B
190,experiments,I
190,",",O
190,all,B
190,word,I
190,vectors,I
190,are,B
190,initialized,B
190,by,B
190,Glove,B
190,1,O
190,.,O
191,The,O
191,word,B
191,embedding,I
191,vectors,I
191,are,O
191,pre-trained,B
191,on,I
191,an,O
191,unlabeled,B
191,corpus,I
191,whose,B
191,size,B
191,is,B
191,about,B
191,840,I
191,billion,I
191,.,O
192,The,O
192,other,B
192,parameters,I
192,are,O
192,initialized,B
192,by,I
192,sampling,B
192,from,B
192,a,O
192,uniform,O
192,distribution,O
192,U,O
192,(??,O
193,The,O
193,dimension,B
193,of,I
193,word,B
193,vectors,I
193,",",O
193,aspect,B
193,embeddings,I
193,and,O
193,the,O
193,size,B
193,of,O
193,hidden,O
193,layer,O
193,are,B
193,300,B
193,.,O
194,The,O
194,length,B
194,of,B
194,attention,B
194,weights,I
194,is,O
194,the,O
194,same,B
194,as,I
194,the,O
194,length,O
194,of,O
194,sentence,B
194,.,O
195,Theano,B
195,is,O
195,used,B
195,for,I
195,implementing,B
195,our,O
195,neural,B
195,network,I
195,models,I
195,.,O
196,We,O
196,trained,B
196,all,B
196,models,I
196,with,B
196,a,O
196,batch,B
196,size,I
196,of,B
196,25,B
196,examples,I
196,",",O
196,and,O
196,a,O
196,momentum,B
196,of,O
196,0.9,B
196,",",O
196,L,B
196,2,I
196,-,I
196,regularization,I
196,weight,I
196,of,O
196,0.001,B
196,and,O
196,initial,B
196,learning,I
196,rate,I
196,of,O
196,0.01,B
196,for,B
196,AdaGrad,B
196,.,O
197,In,O
197,this,O
197,paper,O
197,",",O
197,we,O
197,propose,B
197,an,O
197,attention,B
197,mechanism,I
197,to,B
197,enforce,I
197,the,O
197,model,B
197,to,O
197,attend,O
197,to,O
197,the,O
197,important,B
197,part,I
197,of,I
197,a,I
197,sentence,I
197,",",O
197,in,O
197,response,O
197,to,O
197,a,O
197,specific,O
197,aspect,O
197,.,O
198,We,O
198,design,B
198,an,O
198,aspect,B
198,-,I
198,tosentence,I
198,attention,I
198,mechanism,I
198,that,O
198,can,B
198,concentrate,I
198,on,I
198,the,O
198,key,B
198,part,I
198,of,B
198,a,O
198,sentence,B
198,given,B
198,the,O
198,aspect,O
198,.,O
199,We,O
199,also,O
199,evaluate,O
199,our,O
199,model,O
199,on,B
199,the,O
199,SemEval,B
199,dataset,I
199,under,O
199,the,O
199,same,O
199,settings,O
199,as,O
199,.,O
200,We,O
200,explore,B
200,the,O
200,potential,B
200,correlation,I
200,of,B
200,aspect,B
200,and,I
200,sentiment,I
200,polarity,I
200,in,B
200,aspect,O
200,-,O
200,level,O
200,sentiment,O
200,classification,O
200,.,O
201,In,O
201,order,O
201,to,B
201,capture,I
201,important,B
201,information,I
201,in,O
201,response,O
201,to,O
201,a,O
201,given,B
201,aspect,I
201,",",O
201,we,O
201,design,B
201,an,O
201,attentionbased,B
201,LSTM,I
201,.,O
202,Attention,O
202,-,O
202,based,O
202,LSTM,O
202,for,O
202,Aspect,B
202,-,O
202,level,O
202,Sentiment,O
202,Classification,O
203,Aspect,O
203,-,O
203,level,O
203,sentiment,B
203,classification,O
203,is,O
203,a,O
203,finegrained,O
203,task,O
203,in,O
203,sentiment,O
203,analysis,O
203,.,O
204,In,O
204,this,O
204,paper,O
204,",",O
204,we,O
204,deal,O
204,with,O
204,aspect,B
204,-,I
204,level,I
204,sentiment,I
204,classification,I
204,and,O
204,we,O
204,find,O
204,that,O
204,the,O
204,sentiment,O
204,polarity,O
204,of,O
204,a,O
204,sentence,O
204,is,O
204,highly,O
204,dependent,O
204,on,O
204,both,O
204,content,O
204,and,O
204,aspect,O
204,.,O
205,LSTM,B
205,:,O
205,Standard,O
205,LSTM,O
205,can,B
205,not,I
205,capture,I
205,any,O
205,aspect,B
205,information,I
205,in,B
205,sentence,B
205,",",O
205,so,O
205,it,O
205,must,O
205,get,O
205,the,O
205,same,O
205,(,O
205,a,O
205,),O
205,the,O
205,aspect,O
205,of,O
205,this,O
205,sentence,O
205,:,O
205,service,O
205,(,O
205,b,O
205,),O
205,the,O
205,aspect,O
205,of,O
205,this,O
205,sentence,O
205,:,O
205,food,O
205,:,O
205,Attention,O
205,Visualizations,O
205,.,O
206,Since,O
206,it,O
206,can,B
206,not,I
206,take,I
206,advantage,I
206,of,I
206,the,O
206,aspect,B
206,information,I
206,",",O
206,not,O
206,surprisingly,O
206,the,O
206,model,O
206,has,O
206,worst,B
206,performance,I
206,.,O
207,TD,O
207,-,O
207,LSTM,O
207,:,O
207,TD,O
207,-,O
207,LSTM,O
207,can,B
207,improve,I
207,the,O
207,performance,B
207,of,B
207,sentiment,B
207,classifier,I
207,by,B
207,treating,I
207,an,O
207,aspect,B
207,as,B
207,a,O
207,target,B
207,.,O
208,Since,O
208,there,B
208,is,I
208,no,I
208,attention,B
208,mechanism,I
208,in,B
208,TD,B
208,-,I
208,LSTM,I
208,",",O
208,it,O
208,can,B
208,not,I
208,"""",O
208,know,B
208,"""",O
208,which,B
208,words,B
208,are,B
208,important,B
208,for,B
208,a,O
208,given,B
208,aspect,I
208,.,O
209,It,O
209,is,O
209,worth,O
209,noting,O
209,that,O
209,TC,B
209,-,I
209,LSTM,I
209,performs,B
209,worse,B
209,than,B
209,LSTM,O
209,and,O
209,TD,O
209,-,O
209,LSTM,O
209,in,O
209,.,O
210,Our,O
210,C,B
210,-,I
210,AGGCN,O
210,model,O
210,(,O
210,85.7,O
210,),O
210,consistently,B
210,outperforms,I
210,the,O
210,C,O
210,-,O
210,GCN,O
210,model,O
210,(,O
210,84.8,O
210,),O
210,",",O
210,showing,B
210,the,O
210,good,B
210,generalizability,I
210,.,O
211,ATAE,O
211,-,O
211,LSTM,O
211,not,O
211,only,O
211,addresses,B
211,the,O
211,shortcoming,B
211,of,B
211,the,O
211,unconformity,B
211,between,B
211,word,B
211,vectors,I
211,and,I
211,aspect,I
211,embeddings,I
211,",",O
211,but,O
211,also,O
211,can,O
211,capture,B
211,the,O
211,most,B
211,important,I
211,information,I
211,in,B
211,response,I
211,to,I
211,a,O
211,given,B
211,aspect,O
211,.,O
212,TD,O
212,-,O
212,LSTM,O
212,uses,B
212,two,B
212,LSTM,O
212,networks,O
212,to,B
212,model,I
212,the,O
212,preceding,B
212,and,I
212,following,I
212,contexts,I
212,surrounding,B
212,the,O
212,aspect,B
212,term,I
212,.,O
213,AT,O
213,-,O
213,LSTM,B
213,combines,B
213,the,O
213,sentence,B
213,hidden,I
213,states,I
213,from,B
213,a,O
213,LSTM,O
213,with,B
213,the,O
213,aspect,B
213,term,I
213,embedding,I
213,to,B
213,generate,I
213,the,O
213,attention,B
213,vector,I
213,.,O
214,ATAE,O
214,-,O
214,LSTM,O
214,further,O
214,extends,B
214,AT,B
214,-,O
214,LSTM,O
214,by,B
214,appending,I
214,the,O
214,aspect,B
214,embedding,I
214,into,B
214,each,B
214,word,I
214,vector,I
214,.,O
215,AF,O
215,-,O
215,LSTM,O
215,introduces,B
215,a,O
215,word,B
215,-,O
215,aspect,B
215,fusion,I
215,attention,I
215,to,B
215,learn,I
215,associative,B
215,relationships,I
215,between,B
215,aspect,O
215,and,O
215,context,O
215,words,O
215,.,O
216,CNN,B
216,uses,B
216,the,O
216,architecture,B
216,proposed,O
216,in,O
216,without,B
216,explicitly,I
216,considering,I
216,aspect,B
216,.,O
217,We,O
217,use,B
217,rectifier,B
217,as,B
217,non-linear,B
217,function,I
217,f,I
217,in,B
217,the,O
217,CNN,B
217,g,I
217,",",I
217,CNN,O
217,t,O
217,and,O
217,sigmoid,B
217,in,O
217,the,O
217,CNN,O
217,s,O
217,",",O
217,filter,B
217,window,I
217,sizes,I
217,of,B
217,1,B
217,",",O
217,2,O
217,",",O
217,3,O
217,",",O
217,4,O
217,with,O
217,100,O
217,feature,O
217,maps,O
217,each,O
217,",",O
217,l,B
217,2,O
217,regularization,O
217,term,O
217,of,O
217,0.001,B
217,and,O
217,minibatch,B
217,size,I
217,of,O
217,25,B
217,.,O
218,Parameterized,O
218,filters,O
218,and,O
218,gates,O
218,have,B
218,the,O
218,same,B
218,size,I
218,and,O
218,number,O
218,as,B
218,normal,B
218,filters,O
218,.,O
219,They,O
219,are,O
219,generated,B
219,uniformly,I
219,by,I
219,CNN,B
219,with,B
219,window,B
219,sizes,I
219,of,B
219,1,B
219,",",I
219,2,I
219,",",O
219,3,O
219,",",O
219,4,O
219,",",O
219,eg.,O
220,among,O
220,100,O
220,parameterized,O
220,filters,O
220,with,B
220,size,O
220,3,O
220,",",O
220,25,O
220,of,B
220,them,O
220,are,O
220,generated,O
220,by,O
220,aspect,O
220,CNN,B
220,with,O
220,filter,O
220,size,O
220,1,B
220,",",O
220,2,O
220,",",O
220,3,O
220,",",O
220,4,O
220,respectively,O
220,.,O
221,The,O
221,word,B
221,embeddings,I
221,are,O
221,initialized,B
221,with,I
221,300,B
221,-,I
221,dimensional,I
221,Glove,I
221,vectors,I
221,and,O
221,are,O
221,fixed,B
221,during,I
221,training,B
221,.,O
222,All,O
222,models,O
222,were,O
222,trained,B
222,using,I
222,the,O
222,Adam,B
222,optimizer,I
222,with,B
222,categorical,B
222,crossentropy,I
222,as,B
222,the,O
222,loss,B
222,function,I
222,.,O
223,The,O
223,dropout,B
223,rate,I
223,is,O
223,chosen,B
223,as,I
223,0.3,B
223,.,O
224,Training,B
224,is,O
224,done,B
224,through,I
224,mini-batch,B
224,stochastic,I
224,gradient,I
224,descent,I
224,with,B
224,Adam,B
224,update,I
224,rule,I
224,.,O
225,The,O
225,initial,B
225,learning,I
225,rate,I
225,is,B
225,0.001,B
225,.,O
226,If,O
226,the,O
226,training,B
226,loss,I
226,does,B
226,not,I
226,drop,B
226,after,B
226,every,B
226,three,I
226,epochs,I
226,",",O
226,we,O
226,decrease,B
226,the,O
226,learning,B
226,rate,I
226,by,B
226,half,B
226,.,O
227,For,B
227,the,O
227,out,B
227,of,I
227,vocabulary,I
227,words,I
227,we,O
227,initialize,B
227,them,I
227,randomly,B
227,from,B
227,uniform,O
227,distribution,O
227,U,O
227,(,O
227,?,O
228,We,O
228,apply,B
228,dropout,B
228,on,B
228,the,O
228,final,B
228,classification,I
228,features,I
228,of,B
228,PG,B
228,-,I
228,CNN,I
228,.,O
229,We,O
229,adopt,B
229,early,B
229,stopping,I
229,based,B
229,on,B
229,the,O
229,validation,B
229,loss,I
229,on,O
229,development,B
229,sets,I
229,.,O
230,In,O
230,the,O
230,present,O
230,work,O
230,",",O
230,we,O
230,propose,B
230,two,B
230,simple,I
230,yet,I
230,effective,I
230,convolutional,I
230,neural,I
230,networks,I
230,with,B
230,aspect,B
230,information,I
230,incorporated,O
230,.,O
231,Specifically,O
231,",",O
231,we,O
231,design,B
231,two,B
231,novel,I
231,neural,I
231,units,I
231,that,O
231,take,B
231,target,B
231,aspects,I
231,into,B
231,account,B
231,.,O
232,One,O
232,is,O
232,parameterized,B
232,filter,I
232,",",O
232,the,O
232,other,B
232,is,O
232,parameterized,O
232,gate,O
232,.,O
233,We,O
233,use,B
233,an,O
233,early,B
233,stopping,I
233,criterion,I
233,on,B
233,the,O
233,validation,B
233,data,I
233,to,B
233,determine,I
233,the,O
233,number,B
233,of,I
233,training,I
233,epochs,I
233,.,O
234,These,O
234,units,B
234,both,O
234,are,O
234,generated,B
234,from,I
234,aspect,B
234,-,I
234,specific,I
234,features,I
234,and,O
234,are,O
234,further,O
234,applied,O
234,on,O
234,the,O
234,sentence,O
234,.,O
235,Parameterized,O
235,Convolutional,O
235,Neural,O
235,Networks,O
235,for,O
235,Aspect,B
235,Level,I
235,Sentiment,I
235,Classification,I
236,Continuous,O
236,growing,O
236,of,O
236,user,O
236,generated,O
236,text,O
236,in,O
236,social,O
236,media,O
236,platforms,O
236,such,O
236,as,O
236,Twitter,O
236,drives,O
236,sentiment,B
236,classification,I
236,increasingly,O
236,popular,O
236,.,O
237,Differing,O
237,from,O
237,general,B
237,sentiment,I
237,classification,I
237,",",O
237,aspect,O
237,level,O
237,sentiment,O
237,classification,O
237,identifies,O
237,opinions,O
237,from,O
237,text,O
237,about,O
237,specific,O
237,entities,O
237,and,O
237,their,O
237,aspects,O
237,.,O
238,Our,O
238,two,O
238,models,O
238,achieve,B
238,the,O
238,best,B
238,performance,I
238,when,O
238,compared,B
238,to,I
238,these,O
238,baselines,B
238,as,O
238,shown,O
238,in,O
238,",",O
238,which,O
238,shows,O
238,that,O
238,our,O
238,proposed,O
238,neural,O
238,units,O
238,effectively,O
238,captures,O
238,the,O
238,aspect,O
238,-,O
238,specific,O
238,features,O
238,.,O
239,Surprisingly,O
239,",",O
239,a,O
239,vanilla,B
239,CNN,I
239,works,B
239,quite,B
239,well,I
239,on,O
239,this,O
239,problem,O
239,.,O
240,It,O
240,even,O
240,beats,B
240,these,O
240,welldesigned,B
240,LSTM,I
240,models,I
240,",",O
240,which,O
240,further,O
240,proves,O
240,that,O
240,using,O
240,CNN,O
240,-,O
240,based,O
240,methods,O
240,is,O
240,a,O
240,direction,O
240,worth,O
240,exploring,O
240,.,O
241,Compared,O
241,to,O
241,one,O
241,recently,B
241,proposed,I
241,model,I
241,AF,I
241,-,I
241,LSTM,I
241,",",O
241,our,B
241,method,I
241,achieve,B
241,2,B
241,%,I
241,-,O
241,5,O
241,%,O
241,improvements,O
241,.,O
242,For,B
242,CNNs,B
242,",",O
242,we,O
242,make,B
242,use,I
242,of,B
242,the,O
242,well,B
242,-,I
242,known,I
242,CNN,I
242,-,O
242,non-static,O
242,architecture,O
242,and,O
242,hyperparameters,O
242,proposed,O
242,by,O
242,",",O
242,with,B
242,a,O
242,learning,B
242,rate,I
242,of,O
242,0.0006,B
242,",",O
242,obtained,B
242,by,O
242,tuning,B
242,on,B
242,the,O
242,validation,B
242,data,I
242,.,O
243,For,O
243,our,O
243,DM,B
243,-,I
243,MCNN,I
243,models,I
243,",",O
243,the,O
243,configuration,B
243,of,B
243,the,O
243,convolutional,B
243,module,I
243,is,O
243,the,O
243,same,O
243,as,O
243,for,O
243,CNNs,B
243,",",O
243,and,O
243,the,O
243,remaining,B
243,hyperparameter,I
243,values,I
243,were,O
243,as,O
243,well,O
243,tuned,B
243,on,I
243,the,O
243,validation,B
243,sets,I
243,.,O
244,The,O
244,learning,B
244,rate,I
244,is,O
244,fixed,B
244,to,I
244,0.01,B
244,and,O
244,the,O
244,rest,O
244,of,B
244,the,O
244,optimization,O
244,parameters,O
244,are,O
244,set,O
244,as,O
244,recommended,O
244,in,O
244,:,O
244,?,O
245,The,O
245,training,B
245,is,O
245,performed,B
245,in,I
245,batches,B
245,of,B
245,128,B
245,instances,I
245,.,O
246,For,O
246,greater,B
246,efficiency,I
246,and,I
246,better,I
246,convergence,I
246,properties,I
246,",",O
246,the,O
246,training,B
246,relies,B
246,on,I
246,mini-batches,B
246,.,O
247,Our,O
247,implementation,B
247,considers,B
247,the,O
247,maximal,B
247,sentence,I
247,length,I
247,in,B
247,each,B
247,mini-batch,I
247,and,I
247,zero,B
247,-,I
247,pads,I
247,all,B
247,other,I
247,sentences,I
247,to,B
247,this,B
247,length,O
247,under,B
247,convolutional,B
247,module,I
247,",",O
247,thus,O
247,enabling,B
247,uniform,B
247,and,O
247,fast,O
247,processing,O
247,of,B
247,each,O
247,mini-batch,O
247,.,O
248,All,O
248,neural,B
248,network,I
248,architectures,I
248,are,O
248,implemented,B
248,using,I
248,the,O
248,PyTorch,B
248,framework,O
248,2,O
248,.,O
249,Embeddings,B
249,.,O
250,The,O
250,standard,B
250,pre-trained,I
250,word,I
250,vectors,I
250,used,O
250,for,B
250,English,B
250,are,B
250,the,O
250,GloVe,B
250,ones,I
250,trained,B
250,on,I
250,840,B
250,billion,I
250,tokens,I
250,of,B
250,Common,B
250,Crawl,I
250,data,I
250,1,O
250,",",O
250,while,O
250,for,O
250,other,B
250,languages,I
250,",",O
250,we,O
250,rely,B
250,on,O
250,the,O
250,Facebook,B
250,fastText,I
250,Wikipedia,I
250,embeddings,I
250,as,B
250,input,B
250,representations,I
250,.,O
251,All,O
251,of,O
251,these,O
251,are,B
251,300,B
251,-,I
251,dimensional,I
251,.,O
252,The,O
252,vectors,B
252,are,O
252,either,O
252,fed,B
252,to,I
252,the,O
252,CNN,B
252,",",O
252,or,O
252,to,O
252,the,O
252,convolutional,B
252,module,I
252,of,B
252,the,O
252,DM,B
252,-,I
252,MCNN,I
252,during,B
252,initialization,B
252,",",O
252,while,O
252,unknown,B
252,words,I
252,are,O
252,initialized,B
252,with,I
252,zeros,B
252,.,O
253,All,O
253,words,O
253,",",O
253,including,B
253,the,O
253,unknown,B
253,ones,I
253,",",O
253,are,B
253,fine,B
253,-,I
253,tuned,I
253,during,B
253,the,O
253,training,B
253,process,I
253,.,O
254,For,B
254,our,O
254,transfer,B
254,learning,I
254,approach,I
254,",",O
254,our,O
254,experiments,O
254,rely,B
254,on,I
254,the,O
254,multi-domain,B
254,sentiment,I
254,dataset,I
254,by,O
254,",",O
254,collected,B
254,from,I
254,Amazon,B
254,customers,I
254,reviews,I
254,.,O
255,For,O
255,cross,B
255,-,I
255,lingual,I
255,projection,I
255,",",O
255,we,O
255,extract,B
255,links,B
255,between,B
255,words,B
255,from,B
255,a,O
255,2017,B
255,dump,I
255,of,I
255,the,I
255,English,I
255,edition,I
255,of,O
255,Wiktionary,O
255,.,O
256,We,O
256,apply,B
256,Dropout,B
256,on,I
256,the,O
256,penultimate,B
256,layer,I
256,as,I
256,well,I
256,as,O
256,on,O
256,the,O
256,embeddings,B
256,layer,O
256,with,B
256,a,O
256,probability,B
256,of,B
256,0.5,B
256,.,O
257,Specifically,O
257,",",O
257,we,O
257,train,B
257,linear,B
257,SVMs,I
257,using,B
257,scikit,B
257,-,I
257,learn,I
257,to,B
257,extract,I
257,word,B
257,coefficients,I
257,in,B
257,each,B
257,domain,I
257,and,O
257,also,B
257,for,I
257,the,O
257,union,B
257,of,I
257,all,I
257,domains,I
257,together,O
257,",",O
257,yielding,B
257,a,O
257,26,B
257,-,O
257,dimensional,O
257,sentiment,O
257,embedding,O
257,.,O
258,For,O
258,comparison,O
258,and,O
258,analysis,O
258,",",O
258,we,O
258,also,O
258,consider,B
258,several,B
258,alternative,I
258,forms,I
258,of,B
258,infusing,I
258,external,B
258,cues,I
258,.,O
259,We,O
259,consider,O
259,a,O
259,recent,O
259,sentiment,B
259,lexicon,I
259,called,B
259,VADER,B
259,.,O
260,These,O
260,contain,B
260,separate,B
260,domain,I
260,-,I
260,specific,I
260,scores,I
260,for,B
260,250,B
260,different,I
260,Reddit,I
260,communities,I
260,",",O
260,and,O
260,hence,O
260,result,B
260,in,I
260,250,O
260,-,O
260,dimensional,O
260,embeddings,O
260,.,O
261,We,O
261,restrict,B
261,the,O
261,vocabulary,B
261,link,I
261,set,B
261,to,I
261,include,I
261,the,O
261,languages,B
261,in,O
261,",",O
261,mining,B
261,corresponding,B
261,translation,B
261,",",O
261,synonymy,B
261,",",O
261,derivation,B
261,",",O
261,and,O
261,etymological,B
261,links,I
261,from,O
261,Wiktionary,B
261,.,O
262,In,O
262,this,O
262,paper,O
262,",",O
262,we,O
262,investigate,B
262,how,O
262,extrinsic,B
262,signals,I
262,can,O
262,be,O
262,incorporated,B
262,into,I
262,deep,B
262,neural,I
262,networks,I
262,for,B
262,sentiment,B
262,analysis,I
262,.,O
263,In,O
263,our,O
263,paper,O
263,",",O
263,we,O
263,instead,O
263,consider,B
263,word,B
263,embeddings,I
263,specifically,O
263,specialized,B
263,for,I
263,the,O
263,task,O
263,of,O
263,sentiment,B
263,analysis,I
263,",",O
263,studying,O
263,how,O
263,they,O
263,can,O
263,lead,B
263,to,I
263,stronger,B
263,and,I
263,more,I
263,consistent,I
263,gains,I
263,",",O
263,despite,O
263,the,O
263,fact,O
263,that,O
263,the,O
263,embeddings,O
263,were,O
263,obtained,B
263,using,I
263,out,B
263,-,I
263,of,O
263,-,O
263,domain,O
263,data,O
263,.,O
264,We,O
264,instead,O
264,propose,B
264,a,O
264,bespoke,B
264,convolutional,I
264,neural,I
264,network,I
264,architecture,I
264,with,B
264,a,O
264,separate,B
264,memory,I
264,module,I
264,dedicated,B
264,to,I
264,the,O
264,sentiment,B
264,embeddings,I
264,.,O
265,A,O
265,Helping,O
265,Hand,O
265,:,O
265,Transfer,O
265,Learning,O
265,for,O
265,Deep,B
265,Sentiment,I
265,Analysis,I
266,Over,O
266,the,O
266,past,O
266,decades,O
266,",",O
266,sentiment,B
266,analysis,I
266,has,O
266,grown,O
266,from,O
266,an,O
266,academic,O
266,endeavour,O
266,to,O
266,an,O
266,essential,O
266,analytics,O
266,tool,O
266,.,O
267,We,O
267,choose,B
267,the,O
267,size,O
267,of,B
267,the,O
267,layers,B
267,(,I
267,RNN,I
267,layer,I
267,size,O
267,o,O
267,=,O
267,256,O
267,),O
267,and,O
267,entity,O
267,marker,O
267,embeddings,O
267,(,O
267,d,O
267,=,O
267,3,O
267,),O
267,with,B
267,a,O
267,random,B
267,search,I
267,on,B
267,the,O
267,validation,B
267,set,I
267,.,O
268,In,O
268,recent,O
268,years,O
268,",",O
268,deep,O
268,neural,O
268,architectures,O
268,based,O
268,on,O
268,convolutional,O
268,or,O
268,recurrent,O
268,layers,O
268,have,O
268,become,O
268,established,O
268,as,O
268,the,O
268,preeminent,O
268,models,O
268,for,O
268,supervised,B
268,sentiment,I
268,polarity,I
268,classification,I
268,.,O
269,Comparing,O
269,this,O
269,to,O
269,CNNs,B
269,with,B
269,GloVe,B
269,/,I
269,fastText,B
269,embeddings,I
269,",",O
269,where,B
269,Glo,B
269,Ve,I
269,is,O
269,used,B
269,for,I
269,English,B
269,",",O
269,and,O
269,fastText,O
269,is,O
269,used,O
269,for,O
269,all,O
269,other,O
269,languages,O
269,",",O
269,we,O
269,observe,B
269,substantial,B
269,improvements,I
269,across,B
269,all,O
269,datasets,B
269,.,O
270,This,O
270,shows,B
270,that,B
270,word,I
270,vectors,I
270,do,O
270,tend,B
270,to,B
270,convey,I
270,pertinent,B
270,word,O
270,semantics,O
270,signals,O
270,that,O
270,enable,O
270,models,B
270,to,O
270,generalize,O
270,better,B
270,.,O
271,Note,B
271,also,O
271,that,O
271,the,O
271,accuracy,B
271,using,B
271,GloVe,B
271,on,B
271,the,O
271,English,B
271,movies,I
271,review,I
271,dataset,I
271,is,O
271,consistent,B
271,with,I
271,numbers,B
271,reported,B
271,in,I
271,previous,B
271,work,I
271,.,O
272,Next,O
272,",",O
272,we,O
272,consider,B
272,our,B
272,DM,I
272,-,I
272,MCNNs,I
272,with,B
272,their,O
272,dual,B
272,-,O
272,module,O
272,mechanism,O
272,to,O
272,take,O
272,advantage,O
272,of,O
272,transfer,O
272,learning,O
272,.,O
273,We,O
273,observe,B
273,fairly,B
273,consistent,I
273,and,I
273,sometimes,I
273,quite,I
273,substan,I
273,-,I
273,tial,I
273,gains,I
273,over,B
273,CNNs,B
273,with,B
273,just,I
273,the,O
273,GloVe,B
273,/,I
273,fastText,I
273,vectors,I
273,.,O
274,Although,O
274,the,O
274,automatically,B
274,projected,I
274,cross,I
274,-,I
274,lingual,I
274,embeddings,I
274,are,B
274,very,B
274,noisy,I
274,and,I
274,limited,I
274,in,B
274,their,I
274,coverage,I
274,",",O
274,particularly,B
274,with,I
274,respect,I
274,to,I
274,inflected,B
274,forms,I
274,",",O
274,our,B
274,model,I
274,succeeds,B
274,in,O
274,exploiting,O
274,them,O
274,to,O
274,obtain,O
274,substantial,B
274,gains,I
274,in,O
274,several,B
274,different,I
274,languages,I
274,and,O
274,domains,O
274,.,O
275,The,O
275,best,B
275,performing,I
275,system,I
275,in,B
275,the,O
275,SemEval,B
275,2017,I
275,task,I
275,is,O
275,the,O
275,one,O
275,described,O
275,in,O
275,which,O
275,achieved,O
275,an,O
275,F,O
275,P,O
275,N,O
275,of,O
275,0.61,O
275,.,O
276,For,B
276,the,O
276,ASTD,B
276,",",O
276,the,O
276,best,B
276,reported,I
276,results,I
276,are,O
276,by,B
276,who,O
276,used,O
276,an,O
276,ensemble,B
276,system,I
276,combining,B
276,output,I
276,of,I
276,CNN,B
276,and,I
276,Bi,I
276,-,I
276,LSTM,I
276,architectures,I
276,",",O
276,which,O
276,achieved,O
276,an,O
276,F,O
276,P,O
276,N,O
276,of,O
276,0.71,O
276,.,O
277,In,O
277,this,O
277,paper,O
277,",",O
277,we,O
277,present,B
277,Mazajak,B
277,2,O
277,",",O
277,an,O
277,Online,B
277,Arabic,I
277,sentiment,I
277,analysis,I
277,system,I
277,that,O
277,utilises,B
277,deep,B
277,learning,I
277,and,O
277,massive,B
277,Arabic,O
277,word,O
277,embeddings,O
277,.,O
278,We,O
278,present,B
278,a,O
278,novel,B
278,architecture,I
278,that,O
278,considers,B
278,other,B
278,relations,I
278,in,B
278,the,O
278,sentence,B
278,as,B
278,a,O
278,context,B
278,for,B
278,predicting,I
278,the,O
278,label,B
278,of,B
278,the,O
278,target,B
278,relation,I
278,.,O
279,The,O
279,system,O
279,is,O
279,available,B
279,as,I
279,an,O
279,online,B
279,API,I
279,that,O
279,can,O
279,be,O
279,used,B
279,by,I
279,other,B
279,researchers,I
279,.,O
280,Mazajak,O
280,:,O
280,An,O
280,Online,O
280,Arabic,B
280,Sentiment,I
280,Analyser,I
281,Work,O
281,on,O
281,SA,B
281,started,O
281,in,O
281,early,O
281,2000s,O
281,",",O
281,particularly,O
281,with,O
281,the,O
281,work,O
281,of,O
281,",",O
281,where,O
281,they,O
281,studied,O
281,the,O
281,sentiment,O
281,of,O
281,movies,O
281,',O
281,reviews,O
281,.,O
282,As,O
282,shown,O
282,in,O
282,the,O
282,table,O
282,",",O
282,Mazajak,B
282,model,I
282,outperformed,B
282,the,O
282,current,B
282,state,I
282,-,I
282,of,I
282,-,O
282,the,O
282,-,O
282,art,O
282,models,O
282,on,B
282,the,O
282,SemEval,B
282,and,I
282,ASTD,I
282,datasets,I
282,.,O
283,In,O
283,addition,O
283,",",O
283,it,O
283,achieved,B
283,a,O
283,high,B
283,performance,I
283,on,B
283,the,O
283,ArSAS,B
283,dataset,I
283,.,O
284,Our,O
284,reported,B
284,scores,I
284,are,O
284,higher,B
284,than,I
284,current,B
284,top,I
284,systems,I
284,for,B
284,all,B
284,the,I
284,evaluation,I
284,scores,O
284,",",O
284,including,B
284,average,B
284,recall,I
284,",",O
284,F,O
284,P,O
284,N,O
284,",",O
284,and,O
284,accuracy,O
284,.,O
285,These,O
285,results,O
285,confirm,O
285,that,O
285,our,B
285,model,O
285,choice,O
285,for,B
285,our,O
285,tool,O
285,represents,B
285,the,I
285,current,B
285,state,I
285,-,I
285,of,I
285,-,O
285,the,O
285,-,O
285,art,O
285,for,O
285,Arabic,B
285,SA,I
285,.,O
286,All,O
286,the,O
286,neural,O
286,models,O
286,presented,O
286,in,O
286,this,O
286,paper,O
286,were,O
286,implemented,B
286,using,I
286,the,O
286,Tensor,B
286,Flow,I
286,python,I
286,pack,I
286,-,O
286,.,O
287,Our,O
287,architecture,B
287,uses,B
287,an,O
287,LSTM,B
287,-,I
287,based,I
287,encoder,I
287,to,B
287,jointly,I
287,learn,I
287,representations,B
287,for,B
287,all,B
287,relations,I
287,in,B
287,a,O
287,single,B
287,sentence,I
287,.,O
288,We,O
288,minimize,B
288,the,O
288,crossentropy,B
288,error,I
288,using,B
288,the,O
288,Adam,B
288,optimizer,I
288,and,O
288,L2regularization,B
288,on,B
288,the,O
288,set,B
288,of,I
288,weights,I
288,.,O
289,For,B
289,the,O
289,individual,B
289,models,I
289,(,I
289,before,I
289,joining,I
289,),I
289,",",O
289,we,O
289,use,B
289,200,B
289,training,I
289,epochs,I
289,and,O
289,a,O
289,batch,B
289,size,I
289,of,B
289,100,B
289,.,O
290,Our,O
290,framework,B
290,consists,B
290,of,I
290,three,B
290,main,I
290,sub,I
290,parts,I
290,.,O
291,Given,B
291,a,O
291,segmented,B
291,sentence,I
291,",",O
291,the,O
291,first,B
291,step,I
291,is,O
291,to,B
291,create,I
291,meaningful,B
291,vector,I
291,representations,I
291,for,B
291,all,B
291,the,O
291,EDUs,O
291,.,O
292,Next,O
292,",",O
292,we,O
292,devise,B
292,three,B
292,different,I
292,Recursive,I
292,Neural,I
292,Net,I
292,models,I
292,",",O
292,each,O
292,designed,B
292,for,I
292,one,B
292,of,B
292,discourse,B
292,structure,I
292,prediction,I
292,",",O
292,discourse,O
292,relation,O
292,prediction,O
292,and,O
292,sentiment,B
292,analysis,I
292,.,O
293,Finally,O
293,",",O
293,we,O
293,join,B
293,these,O
293,Neural,B
293,Nets,I
293,in,B
293,two,B
293,different,I
293,ways,I
293,:,O
293,Multitasking,B
293,and,O
293,Pre-training,B
293,.,O
294,Exploring,O
294,Joint,O
294,Neural,O
294,Model,O
294,for,O
294,Sentence,B
294,Level,I
294,Discourse,I
294,Parsing,I
294,and,I
294,Sentiment,I
294,Analysis,I
295,From,O
295,the,O
295,results,O
295,",",O
295,we,O
295,see,B
295,some,B
295,improvement,B
295,on,B
295,Discourse,B
295,Structure,I
295,prediction,I
295,when,B
295,we,O
295,are,O
295,using,O
295,a,O
295,joint,B
295,model,I
295,but,O
295,the,O
295,improvement,O
295,is,B
295,statistically,B
295,significant,I
295,only,B
295,for,I
295,the,O
295,Nuclearity,B
295,and,I
295,Relation,I
295,predictions,I
295,.,O
296,The,O
296,improvements,B
296,on,I
296,the,O
296,Relation,B
296,predictions,I
296,were,O
296,mainly,B
296,on,O
296,the,O
296,Contrastive,B
296,set,I
296,",",O
296,specifically,B
296,the,O
296,class,O
296,of,O
296,Contrast,B
296,",",O
296,Comparison,B
296,and,O
296,Cause,B
296,relations,O
296,as,O
296,.,O
297,In,B
297,the,O
297,fine,B
297,grained,I
297,setting,I
297,we,O
297,compute,B
297,the,O
297,accuracy,B
297,of,B
297,exact,B
297,match,I
297,across,B
297,five,B
297,classes,I
297,.,O
298,The,O
298,representation,B
298,of,I
298,the,O
298,target,B
298,relation,I
298,and,O
298,representations,B
298,of,O
298,the,O
298,context,B
298,relations,I
298,are,B
298,combined,B
298,to,B
298,make,I
298,the,O
298,final,B
298,prediction,I
298,.,O
299,This,O
299,work,O
299,first,B
299,builds,I
299,an,O
299,RRC,B
299,dataset,I
299,called,B
299,ReviewRC,B
299,",",O
299,using,B
299,reviews,B
299,from,B
299,SemEval,B
299,2016,I
299,Task,I
299,5,I
299,2,O
299,",",O
299,which,O
299,is,B
299,a,I
299,popular,B
299,dataset,O
299,for,B
299,aspect,B
299,-,I
299,based,I
299,sentiment,I
299,analysis,I
299,(,I
299,ABSA,I
299,),I
299,in,B
299,the,O
299,domains,B
299,of,I
299,laptop,I
299,and,I
299,restaurant,I
299,.,O
300,We,O
300,adopt,B
300,BERT,B
300,BASE,I
300,(,I
300,uncased,I
300,),I
300,as,B
300,the,O
300,basis,B
300,for,B
300,all,B
300,experiments,I
301,Since,O
301,post,O
301,-,O
301,training,O
301,may,O
301,take,O
301,a,O
301,large,O
301,footprint,O
301,on,O
301,GPU,O
301,memory,O
301,(,O
301,as,O
301,BERT,O
301,pretraining,O
301,),O
301,",",O
301,we,O
301,leverage,B
301,FP16,B
301,computation,I
301,11,O
301,to,B
301,reduce,I
301,the,O
301,size,B
301,of,B
301,both,I
301,the,O
301,model,B
301,and,O
301,hidden,B
301,representations,I
301,of,O
301,data,B
301,.,O
302,We,O
302,set,B
302,a,O
302,static,B
302,loss,I
302,scale,I
302,of,B
302,2,B
302,in,B
302,FP16,O
302,",",O
302,which,O
302,can,O
302,avoid,O
302,any,O
302,over,O
302,/,O
302,under,O
302,-,O
302,flow,O
302,of,O
302,floating,O
302,point,O
302,computation,O
302,.,O
303,The,O
303,maximum,B
303,length,I
303,of,I
303,post,B
303,-training,I
303,is,O
303,set,B
303,to,I
303,320,B
303,with,B
303,a,O
303,batch,B
303,size,I
303,of,O
303,16,B
303,for,B
303,each,I
303,type,I
303,of,O
303,knowledge,B
303,.,O
304,The,O
304,number,B
304,of,B
304,subbatch,I
304,u,I
304,is,O
304,set,B
304,to,I
304,2,B
304,",",O
304,which,O
304,is,O
304,good,B
304,enough,I
304,to,O
304,store,O
304,each,O
304,sub,B
304,-,I
304,batch,I
304,iteration,I
304,into,B
304,a,O
304,GPU,B
304,memory,I
304,of,O
304,11G,B
304,.,O
305,We,O
305,use,B
305,Adam,B
305,optimizer,I
305,and,O
305,set,B
305,the,O
305,learning,B
305,rate,I
305,to,B
305,be,I
305,3e,B
305,-,I
305,5,I
305,.,O
306,We,O
306,train,B
306,"70,000",B
306,steps,I
306,for,B
306,the,O
306,laptop,B
306,domain,I
306,and,O
306,"140,000",B
306,steps,O
306,for,O
306,the,O
306,restaurant,B
306,domain,O
306,",",O
306,which,O
306,roughly,O
306,have,O
306,one,O
306,pass,O
306,over,O
306,the,O
306,preprocessed,O
306,data,O
306,on,O
306,the,O
306,respective,O
306,domain,O
306,.,O
307,This,O
307,work,O
307,adopts,B
307,BERT,B
307,),O
307,as,B
307,the,O
307,base,B
307,model,I
307,as,O
307,it,O
307,achieves,O
307,the,O
307,state,O
307,-,O
307,of,O
307,the,O
307,-,O
307,art,O
307,performance,O
307,on,O
307,MRC,O
307,.,O
308,To,O
308,address,O
308,all,O
308,the,O
308,above,O
308,challenges,O
308,",",O
308,we,O
308,propose,B
308,a,O
308,novel,B
308,joint,I
308,post,I
308,-,I
308,training,I
308,technique,I
308,that,O
308,takes,B
308,BERT,B
308,'s,I
308,pre-trained,I
308,weights,I
308,as,B
308,the,O
308,initialization,B
308,4,O
308,for,B
308,basic,B
308,language,I
308,understanding,I
308,and,I
308,adapt,B
308,BERT,O
308,with,B
308,both,B
308,domain,B
308,knowledge,I
308,and,O
308,task,O
308,(,O
308,MRC,O
308,),O
308,knowledge,O
308,before,B
308,fine,B
308,-,O
308,tuning,O
308,using,B
308,the,O
308,domain,O
308,end,O
308,task,O
308,annotated,O
308,data,O
308,for,O
308,the,O
308,domain,O
308,RRC,O
308,.,O
309,Context,O
309,-,O
309,Aware,O
309,Representations,O
309,for,O
309,Knowledge,B
309,Base,I
309,Relation,I
309,Extraction,I
310,This,O
310,technique,O
310,leverages,B
310,knowledge,B
310,from,B
310,two,B
310,sources,I
310,:,O
310,unsupervised,B
310,domain,I
310,reviews,I
310,and,O
310,supervised,B
310,(,I
310,yet,I
310,out,I
310,-,I
310,of,I
310,-,O
310,domain,O
310,),O
310,MRC,O
310,data,O
310,5,O
310,",",O
310,where,O
310,the,O
310,former,O
310,enhances,O
310,domain,O
310,-,O
310,awareness,O
310,and,O
310,the,O
310,latter,O
310,strengthens,O
310,MRC,O
310,task,O
310,-,O
310,awareness,O
310,.,O
311,BERT,O
311,Post,O
311,-,O
311,Training,O
311,for,O
311,Review,O
311,Reading,O
311,Comprehension,O
311,and,O
311,Aspect,B
311,-,O
311,based,O
311,Sentiment,O
311,Analysis,O
312,To,O
312,show,O
312,the,O
312,generality,O
312,of,O
312,the,O
312,approach,O
312,",",O
312,the,O
312,proposed,O
312,post,O
312,-,O
312,training,O
312,is,O
312,also,O
312,applied,O
312,to,O
312,some,O
312,other,O
312,review,O
312,-,O
312,based,O
312,tasks,O
312,such,O
312,as,O
312,aspect,B
312,extraction,I
312,and,O
312,aspect,O
312,sentiment,O
312,classification,O
312,in,O
312,aspect,O
312,-,O
312,based,O
312,sentiment,O
312,analysis,O
312,.,O
313,To,O
313,answer,O
313,RQ1,O
313,",",O
313,we,O
313,observed,B
313,that,O
313,the,O
313,proposed,B
313,joint,I
313,post,I
313,-,I
313,training,I
313,(,I
313,BERT,I
313,-,O
313,PT,O
313,),O
313,has,O
313,the,O
313,best,B
313,performance,I
313,over,B
313,all,B
313,tasks,I
313,in,B
313,all,O
313,domains,O
313,",",O
313,which,O
313,show,B
313,the,O
313,benefits,B
313,of,I
313,having,I
313,two,B
313,types,I
313,of,O
313,knowledge,O
313,.,O
314,Methods,O
314,EM,O
314,F1,O
314,EM,O
314,F1,O
314,DrQA,O
314,38.26,O
314,50.99,O
314,49.52,O
314,63.73,O
314,DrQA+MRC,O
314,40,O
314,To,O
314,answer,O
314,RQ2,O
314,",",O
314,to,O
314,our,O
314,surprise,O
314,we,O
314,found,B
314,that,I
314,the,O
314,vanilla,B
314,pre-trained,I
314,weights,I
314,of,B
314,BERT,B
314,do,B
314,not,I
314,work,I
314,well,B
314,for,B
314,review,B
314,-,I
314,based,I
314,tasks,I
314,",",O
314,although,O
314,it,O
314,achieves,O
314,state,O
314,-,O
314,of,O
314,-,O
314,the,O
314,-,O
314,art,O
314,results,O
314,on,O
314,many,O
314,other,O
314,NLP,O
314,tasks,O
314,.,O
315,To,O
315,answer,O
315,RQ3,O
315,",",O
315,we,O
315,noticed,B
315,that,I
315,the,O
315,roles,B
315,of,B
315,domain,B
315,knowledge,I
315,and,I
315,task,I
315,knowledge,O
315,vary,B
315,for,I
315,different,B
315,tasks,I
315,and,O
315,domains,O
315,.,O
316,For,B
316,RRC,B
316,",",O
316,we,O
316,found,B
316,that,I
316,the,O
316,performance,B
316,gain,I
316,of,B
316,BERT,B
316,-,I
316,PT,I
316,mostly,B
316,comes,I
316,from,I
316,task,B
316,-,O
316,awareness,O
316,(,O
316,MRC,O
316,),O
316,post,O
316,-training,O
316,(,O
316,as,O
316,indicated,O
316,by,O
316,BERT,O
316,-,O
316,MRC,O
316,),O
316,.,O
317,For,O
317,AE,B
317,",",O
317,we,O
317,found,B
317,that,I
317,great,B
317,performance,I
317,boost,I
317,comes,B
317,mostly,I
317,from,I
317,domain,B
317,knowledge,I
317,posttraining,I
317,",",O
317,which,O
317,indicates,O
317,that,O
317,contextualized,O
317,representations,O
317,of,O
317,domain,O
317,knowledge,O
317,are,O
317,very,O
317,important,O
317,for,O
317,AE,O
317,.,O
318,For,O
318,AE,O
318,",",O
318,errors,B
318,mostly,B
318,come,I
318,from,I
318,annotation,B
318,inconsistency,I
318,and,O
318,boundaries,B
318,of,B
318,aspects,B
318,(,O
318,e.g.,O
319,For,O
319,ASC,B
319,",",O
319,we,O
319,observed,B
319,that,I
319,large,B
319,-,I
319,scale,I
319,annotated,I
319,MRC,I
319,data,I
319,is,B
319,very,B
319,useful,I
319,.,O
320,We,O
320,demonstrate,O
320,that,O
320,for,O
320,sentence,B
320,-,I
320,level,I
320,relation,I
320,extraction,I
320,it,O
320,is,O
320,beneficial,O
320,to,O
320,consider,O
320,other,O
320,relations,O
320,in,O
320,the,O
320,sentential,O
320,context,O
320,while,O
320,predicting,O
320,the,O
320,target,O
320,relation,O
320,.,O
321,We,O
321,further,B
321,investigated,I
321,the,O
321,examples,B
321,improved,I
321,by,O
321,BERT,B
321,-,I
321,MRC,I
321,and,O
321,found,B
321,that,I
321,the,O
321,boundaries,B
321,of,I
321,spans,I
321,(,I
321,especially,I
321,short,I
321,spans,O
321,),O
321,were,B
321,greatly,B
321,improved,O
321,.,O
322,BERT,O
322,-,O
322,MRC,O
322,has,B
322,almost,I
322,no,I
322,improvement,B
322,on,B
322,restaurant,B
322,",",O
322,which,O
322,indicates,O
322,Wikipedia,O
322,may,O
322,have,O
322,no,O
322,knowledge,O
322,about,O
322,aspects,O
322,of,O
322,restaurant,O
322,.,O
323,The,O
323,errors,B
323,on,B
323,RRC,B
323,mainly,O
323,come,B
323,from,I
323,boundaries,B
323,of,B
323,spans,B
323,that,B
323,are,I
323,not,I
323,concise,B
323,enough,I
323,and,O
323,incorrect,B
323,location,I
323,of,O
323,spans,O
323,that,O
323,may,O
323,have,O
323,certain,B
323,nearby,I
323,words,I
323,related,B
323,to,I
323,the,O
323,question,B
323,.,O
324,ASC,B
324,tends,B
324,to,I
324,have,I
324,more,O
324,errors,B
324,as,B
324,the,O
324,decision,B
324,boundary,I
324,between,B
324,the,O
324,negative,B
324,and,I
324,neutral,I
324,examples,I
324,is,B
324,unclear,B
324,(,O
324,e.g.,O
325,Emo2,O
325,Vec,O
325,embedding,O
325,matrix,O
325,and,O
325,the,O
325,CNN,O
325,model,O
325,are,O
325,pre-trained,B
325,using,I
325,hashtag,B
325,corpus,I
325,alone,O
325,.,O
326,Parameters,O
326,of,O
326,T,O
326,and,O
326,CNN,O
326,are,B
326,randomly,B
326,initialized,I
326,and,O
326,Adam,B
326,is,O
326,used,B
326,for,I
326,optimization,B
326,.,O
327,For,B
327,the,O
327,best,B
327,model,I
327,",",I
327,we,O
327,use,B
327,the,O
327,batch,B
327,size,I
327,of,B
327,16,B
327,",",O
327,embedding,B
327,size,O
327,of,O
327,100,B
327,",",O
327,1024,B
327,filters,I
327,and,I
327,filter,B
327,sizes,I
327,are,B
327,1,B
327,",",O
327,3,O
327,",5",O
327,and,O
327,7,O
327,respectively,O
327,.,O
328,We,O
328,tune,B
328,our,B
328,parameters,I
328,of,B
328,learning,B
328,rate,I
328,",",O
328,L2,B
328,regularization,I
328,",",O
328,whether,O
328,to,O
328,pre-train,O
328,our,O
328,model,O
328,and,O
328,batch,O
328,size,O
328,with,O
328,the,O
328,average,O
328,accuracy,O
328,of,O
328,the,O
328,development,O
328,set,O
328,of,O
328,all,O
328,datasets,O
328,.,O
329,In,O
329,this,O
329,paper,O
329,",",O
329,we,O
329,propose,B
329,RESIDE,B
329,",",O
329,a,O
329,novel,B
329,distant,I
329,supervised,I
329,relation,I
329,extraction,I
329,method,I
329,which,O
329,utilizes,B
329,additional,B
329,supervision,I
329,from,B
329,KB,B
329,through,B
329,its,O
329,neural,B
329,network,I
329,based,I
329,architecture,I
329,.,O
330,The,O
330,main,O
330,goal,O
330,of,O
330,relation,B
330,extraction,I
330,is,O
330,to,O
330,determine,O
330,a,O
330,type,O
330,of,O
330,relation,O
330,between,O
330,two,O
330,target,O
330,entities,O
330,that,O
330,appear,O
330,together,O
330,in,O
330,a,O
330,text,O
330,.,O
331,We,O
331,early,B
331,stop,B
331,our,B
331,model,I
331,when,B
331,the,O
331,averaged,B
331,dev,I
331,accuracy,I
331,stop,O
331,increasing,B
331,.,O
332,Our,O
332,best,B
332,model,I
332,uses,B
332,learning,B
332,rate,I
332,of,B
332,0.001,B
332,",",O
332,L2,B
332,regularization,I
332,of,O
332,1.0,B
332,",",O
332,batch,B
332,size,I
332,of,O
332,32,B
332,.,O
333,We,O
333,save,B
333,the,O
333,best,B
333,model,I
333,and,O
333,take,B
333,the,O
333,embedding,B
333,layer,I
333,as,B
333,Emo2Vec,B
333,vectors,I
333,.,O
334,This,O
334,work,O
334,demonstrates,B
334,the,O
334,effectiveness,B
334,of,B
334,incorporating,I
334,sentiment,B
334,labels,I
334,in,B
334,a,O
334,wordlevel,B
334,information,I
334,for,B
334,sentiment,O
334,-,O
334,related,O
334,tasks,O
334,compared,B
334,to,I
334,other,B
334,word,I
334,embeddings,I
334,.,O
335,1,O
335,),O
335,We,O
335,propose,B
335,Emo2Vec,B
335,1,O
335,which,O
335,are,B
335,word,B
335,-,I
335,level,I
335,representations,I
335,that,B
335,encode,I
335,emotional,B
335,semantics,I
335,into,B
335,fixed,B
335,-,O
335,sized,O
335,",",O
335,real,O
335,-,O
335,valued,O
335,vectors,O
335,.,O
336,2,O
336,),O
336,We,O
336,propose,B
336,to,I
336,learn,I
336,Emo2Vec,B
336,with,B
336,a,O
336,multi-task,B
336,learning,I
336,framework,I
336,by,B
336,including,I
336,six,B
336,different,I
336,emotion,I
336,-,I
336,related,I
336,tasks,I
336,.,O
337,Emo2,O
337,Vec,O
337,:,O
337,Learning,B
337,Generalized,I
337,Emotion,I
337,Representation,I
337,by,O
337,Multi-,O
337,task,O
337,Training,O
338,Compared,O
338,with,O
338,CNN,B
338,embedding,I
338,:,O
338,Emo2,B
338,Vec,I
338,works,B
338,better,I
338,than,I
338,CNN,O
338,embedding,O
338,on,B
338,14,B
338,/,I
338,18,I
338,datasets,I
338,",",O
338,giving,B
338,2.6,B
338,%,I
338,absolute,I
338,accuracy,I
338,improvement,I
338,for,B
338,the,O
338,sentiment,B
338,task,I
338,and,O
338,1.6,B
338,%,O
338,absolute,O
338,f1score,O
338,improvement,O
338,on,O
338,the,O
338,other,B
338,tasks,I
338,.,O
339,Compared,O
339,with,O
339,SSWE,O
339,:,O
339,Emo2,O
339,Vec,O
339,works,B
339,much,B
339,better,I
339,on,B
339,all,B
339,datasets,I
339,except,B
339,SS,B
339,-,I
339,T,I
339,datasets,O
339,",",O
339,which,O
339,gives,B
339,3.3,B
339,%,I
339,accuracy,I
339,improvement,I
339,and,I
339,4.7,B
339,%,O
339,f,O
339,1,O
339,score,O
339,improvement,O
339,respectively,O
339,on,O
339,sentiment,B
339,and,O
339,other,O
339,tasks,O
339,.,O
340,Since,O
340,Emo2,O
340,Vec,O
340,is,B
340,not,B
340,trained,I
340,by,I
340,predicting,B
340,contextual,I
340,words,I
340,",",O
340,it,O
340,is,O
340,weak,B
340,on,B
340,capturing,I
340,synthetic,B
340,and,I
340,semantic,I
340,meaning,I
340,.,O
341,In,O
341,this,O
341,paper,O
341,",",O
341,we,O
341,consider,O
341,the,O
341,sentential,B
341,relation,I
341,extraction,I
341,task,O
341,:,O
341,to,O
341,each,O
341,occurrence,O
341,of,O
341,the,O
341,target,O
341,entity,O
341,pair,O
341,e,O
341,1,O
341,",",O
341,e,O
341,2,O
341,in,O
341,some,O
341,sentence,O
341,s,O
341,one,O
341,has,O
341,to,O
341,assign,O
341,a,O
341,relation,O
341,type,O
341,r,O
341,from,O
341,a,O
341,given,O
341,set,O
341,R.,O
341,A,O
341,triple,O
341,e,O
341,1,O
341,",",O
341,r,O
341,",",O
341,e,O
341,2,O
341,is,O
341,called,O
341,a,O
341,relation,O
341,instance,O
341,and,O
341,we,O
341,refer,O
341,to,O
341,the,O
341,relation,O
341,of,O
341,the,O
341,target,O
341,entity,O
341,pair,O
341,as,O
341,target,O
341,relation,O
341,.,O
342,GloVe,O
342,+,O
342,Emo2,O
342,Vec,O
342,achieves,B
342,better,B
342,performances,I
342,on,B
342,SOTA,B
342,results,I
342,on,O
342,three,B
342,datasets,I
342,(,I
342,SE0714,I
342,",",I
342,stress,I
342,and,I
342,tube,I
342,tablet,I
342,),I
342,and,O
342,comparable,B
342,result,I
342,to,B
342,SOTA,O
342,on,O
342,dataset,B
342,Previous,O
342,SOTA,O
342,results,O
343,It,O
343,shows,B
343,multi-task,B
343,training,I
343,helps,B
343,to,I
343,create,I
343,better,B
343,generalized,I
343,word,I
343,emotion,I
343,representations,I
343,than,B
343,just,I
343,using,I
343,a,O
343,single,B
343,task,I
343,.,O
344,On,B
344,average,O
344,",",O
344,it,O
344,gives,B
344,1.3,B
344,%,I
344,improvement,I
344,in,B
344,accuracy,B
344,for,B
344,the,O
344,sentiment,B
344,task,I
344,and,O
344,1.1,B
344,%,O
344,improvement,O
344,of,B
344,f,B
344,1,I
344,-,I
344,score,I
344,on,O
344,the,O
344,other,B
344,tasks,I
344,.,O
345,Here,O
345,",",O
345,we,O
345,want,O
345,to,O
345,highlight,O
345,that,O
345,solely,B
345,using,I
345,a,O
345,simple,B
345,classifier,I
345,with,B
345,good,B
345,word,I
345,representation,I
345,can,B
345,achieve,I
345,promising,B
345,results,I
345,.,O
346,Compared,O
346,with,O
346,GloVe+,B
346,DeepMoji,I
346,",",I
346,GloVe,I
346,+,I
346,Emo2,I
346,Vec,I
346,achieves,B
346,same,B
346,or,I
346,better,I
346,results,I
346,on,B
346,11,B
346,/,I
346,14,I
346,datasets,I
346,",",O
346,which,O
346,on,O
346,average,O
346,gives,O
346,1.0,B
346,%,I
346,improvement,I
346,.,O
347,Thus,O
347,",",O
347,to,O
347,detect,O
347,the,O
347,corresponding,B
347,emotion,I
347,",",O
347,more,B
347,attention,I
347,needs,I
347,to,O
347,be,O
347,paid,O
347,to,O
347,words,B
347,.,O
348,LSTM,B
348,:,O
348,LSTM,O
348,takes,B
348,the,O
348,sentence,B
348,as,B
348,input,B
348,so,O
348,as,O
348,to,B
348,get,I
348,the,O
348,hidden,B
348,representation,I
348,of,B
348,each,B
348,word,I
348,.,O
349,Then,O
349,it,O
349,regards,B
349,the,O
349,average,B
349,value,I
349,of,B
349,all,O
349,hidden,B
349,states,I
349,as,O
349,the,O
349,representation,B
349,of,O
349,sentence,O
349,",",O
349,and,O
349,puts,B
349,it,O
349,into,O
349,softmax,B
349,layer,I
349,to,B
349,predict,I
349,the,O
349,probability,B
349,of,O
349,each,B
349,sentiment,I
349,polarity,I
349,.,O
350,AE,O
350,-,O
350,LSTM,B
350,:,O
350,AE,O
350,-,O
350,LSTM,O
350,first,O
350,models,B
350,the,O
350,words,B
350,in,B
350,sentence,I
350,via,B
350,LSTM,O
350,network,O
350,and,O
350,concatenate,B
350,the,O
350,aspect,B
350,embedding,I
350,to,B
350,the,O
350,hidden,B
350,contextual,I
350,representation,I
350,for,B
350,calculating,I
350,the,O
350,attention,B
350,weights,I
350,",",O
350,which,O
350,are,O
350,employed,B
350,to,O
350,produce,O
350,the,O
350,final,B
350,representation,O
350,for,O
350,the,O
350,input,B
350,sentence,O
350,to,O
350,judge,O
350,the,O
350,sentiment,B
350,polarity,I
350,.,O
351,ATAE,O
351,-,O
351,LSTM,O
351,:,O
351,ATAE,O
351,-,O
351,LSTM,O
351,extended,B
351,AE,B
351,-,O
351,LSTM,O
351,by,B
351,appending,I
351,the,O
351,aspect,B
351,embedding,I
351,to,B
351,each,B
351,word,I
351,embedding,O
351,so,O
351,as,O
351,to,O
351,represent,O
351,the,O
351,input,B
351,sentence,I
351,",",O
351,which,O
351,highlights,O
351,the,O
351,role,O
351,of,O
351,aspect,O
351,embedding,O
351,.,O
352,The,O
352,models,B
352,that,B
352,take,I
352,the,O
352,context,B
352,into,B
352,account,B
352,perform,B
352,similar,B
352,to,B
352,the,O
352,baselines,B
352,at,B
352,the,O
352,smallest,B
352,recall,I
352,numbers,I
352,",",O
352,but,O
352,start,B
352,to,O
352,positively,B
352,deviate,I
352,from,O
352,them,O
352,at,O
352,higher,B
352,recall,O
352,rates,O
352,.,O
353,IAN,B
353,:,O
353,IAN,O
353,considers,B
353,the,O
353,separate,B
353,modeling,I
353,of,B
353,aspect,B
353,terms,I
353,and,I
353,sentences,I
353,respectively,O
353,.,O
354,MemNet,B
354,:,O
354,MemNet,O
354,applies,B
354,attention,B
354,multiple,B
354,times,I
354,on,B
354,the,O
354,word,B
354,embedding,I
354,",",O
354,so,B
354,that,I
354,more,B
354,abstractive,I
354,evidences,I
354,could,B
354,be,I
354,selected,I
354,from,I
354,the,O
354,external,B
354,memory,I
354,.,O
355,In,O
355,our,O
355,experiments,O
355,",",O
355,all,O
355,word,B
355,embedding,I
355,are,O
355,initialized,B
355,by,I
355,the,O
355,pre-trained,B
355,Glove,I
355,vector,I
355,2,O
355,.,O
356,All,O
356,the,O
356,weight,B
356,matrices,I
356,are,B
356,given,B
356,the,O
356,initial,B
356,value,I
356,by,B
356,sampling,B
356,from,B
356,the,O
356,uniform,B
356,distribution,I
356,U,I
356,(,I
356,?0.1,I
356,",",I
356,0.1,I
356,),I
356,",",O
356,and,O
356,all,O
356,the,O
356,biases,B
356,are,O
356,set,O
356,to,O
356,zero,B
356,.,O
357,The,O
357,dimension,B
357,of,B
357,position,B
357,embedding,I
357,is,I
357,set,B
357,to,I
357,100,B
357,",",O
357,which,B
357,is,O
357,randomly,B
357,initialized,I
357,and,I
357,updated,I
357,during,B
357,the,O
357,training,B
357,process,I
357,.,O
358,The,O
358,dimension,O
358,of,O
358,the,O
358,word,B
358,embedding,I
358,and,I
358,aspect,I
358,term,I
358,embedding,O
358,are,O
358,set,B
358,to,I
358,300,B
358,",",O
358,and,O
358,the,O
358,number,O
358,of,O
358,the,O
358,hidden,B
358,units,I
358,are,O
358,set,O
358,to,O
358,200,B
358,.,O
359,We,O
359,use,B
359,Tensorflow,B
359,to,B
359,implement,I
359,our,B
359,proposed,I
359,model,I
359,and,O
359,employ,B
359,the,O
359,Momentum,B
359,as,B
359,the,O
359,training,B
359,method,I
359,",",O
359,whose,B
359,momentum,O
359,parameter,O
359,?,O
360,is,O
360,set,B
360,to,I
360,0.9,B
360,",",O
360,?,O
361,is,O
361,set,B
361,to,I
361,10,O
361,?,O
362,6,O
362,",",O
362,and,O
362,the,O
362,initial,B
362,learning,I
362,rate,I
362,is,O
362,set,B
362,to,I
362,0.01,B
362,.,O
363,Inspired,O
363,by,O
363,this,O
363,",",O
363,we,O
363,go,O
363,one,O
363,step,O
363,further,O
363,and,O
363,propose,B
363,a,O
363,position,B
363,-,I
363,aware,I
363,bidirectional,B
363,attention,I
363,network,I
363,(,I
363,PBAN,I
363,),I
363,based,B
363,on,I
363,bidirectional,O
363,Gated,O
363,Recurrent,O
363,Units,O
363,(,O
363,Bi,O
363,-,O
363,GRU,O
363,),O
363,.,O
364,In,O
364,addition,O
364,to,O
364,utilizing,O
364,the,O
364,position,O
364,information,O
364,",",O
364,PBAN,B
364,also,O
364,mutually,B
364,models,I
364,the,O
364,relationship,B
364,between,B
364,the,O
364,sentence,B
364,and,I
364,different,I
364,words,I
364,in,O
364,the,O
364,aspect,O
364,term,O
364,by,B
364,adopting,I
364,a,O
364,bidirectional,B
364,attention,I
364,mechanism,I
364,.,O
365,1,O
365,),O
365,Obtaining,B
365,position,B
365,information,I
365,of,B
365,each,B
365,word,I
365,in,B
365,corresponding,B
365,sentence,I
365,based,B
365,on,I
365,the,O
365,current,B
365,aspect,I
365,term,I
365,",",O
365,then,O
365,converting,B
365,the,O
365,position,O
365,information,O
365,into,B
365,position,O
365,embedding,O
365,.,O
366,In,O
366,particular,O
366,",",O
366,the,O
366,ContextAtt,B
366,model,I
366,performs,B
366,better,B
366,than,B
366,any,B
366,other,I
366,system,I
366,in,O
366,our,O
366,study,O
366,over,B
366,the,O
366,entire,B
366,recall,I
366,range,I
366,.,O
367,2,O
367,),O
367,The,O
367,PBAN,B
367,composes,B
367,of,I
367,two,B
367,Bi,I
367,-,I
367,GRU,I
367,networks,I
367,focusing,B
367,on,I
367,extracting,I
367,the,O
367,aspectlevel,B
367,features,I
367,and,O
367,sentence,B
367,-,O
367,level,O
367,features,O
367,respectively,O
367,.,O
368,3,O
368,),O
368,Using,O
368,the,O
368,bidirectional,B
368,attention,I
368,mechanism,I
368,to,B
368,model,I
368,the,O
368,mutual,B
368,relation,I
368,between,B
368,aspect,B
368,term,I
368,and,I
368,its,I
368,corresponding,I
368,sentence,I
368,.,O
369,A,O
369,Position,O
369,-,O
369,aware,O
369,Bidirectional,O
369,Attention,O
369,Network,O
369,for,O
369,Aspect,B
369,-,O
369,level,O
369,Sentiment,O
369,Analysis,O
370,shows,O
370,the,O
370,performance,O
370,of,O
370,our,O
370,model,O
370,and,O
370,other,O
370,baseline,O
370,models,O
370,on,B
370,datasets,B
370,Restaurant,I
370,and,O
370,Laptop,O
370,respectively,O
370,.,O
371,We,O
371,can,O
371,observe,B
371,that,O
371,our,B
371,proposed,I
371,PBAN,I
371,model,I
371,achieves,B
371,the,O
371,best,B
371,performance,I
371,among,B
371,all,O
371,methods,B
371,.,O
372,Generally,O
372,speaking,O
372,",",O
372,by,B
372,integrating,I
372,the,I
372,position,B
372,information,I
372,and,I
372,the,O
372,bidirectional,O
372,attention,O
372,mechanism,O
372,",",O
372,PBAN,B
372,achieves,B
372,the,O
372,state,B
372,-,I
372,of,B
372,-,O
372,the,O
372,-,O
372,art,O
372,performances,O
372,",",O
372,and,O
372,it,O
372,can,O
372,effectively,B
372,judge,I
372,the,O
372,sentiment,B
372,polarity,I
372,of,O
372,different,B
372,aspect,I
372,term,I
372,in,B
372,its,O
372,corresponding,B
372,sentence,I
372,so,O
372,as,O
372,to,B
372,improve,I
372,the,O
372,classification,B
372,accuracy,I
372,.,O
373,NRC,O
373,-,O
373,Canada,O
373,is,B
373,the,O
373,top,B
373,method,I
373,in,B
373,SemEval,B
373,2014,I
373,Task,I
373,4,I
373,for,B
373,ACSA,B
373,and,I
373,ATSA,I
373,task,O
373,.,O
374,CNN,B
374,is,O
374,widely,B
374,used,I
374,on,I
374,text,B
374,classification,I
374,task,I
374,.,O
375,TD,O
375,-,O
375,LSTM,O
375,uses,B
375,two,B
375,LSTM,O
375,networks,O
375,to,B
375,model,I
375,the,O
375,preceding,B
375,and,I
375,following,I
375,contexts,I
375,of,B
375,the,O
375,target,B
375,to,O
375,generate,O
375,target,O
375,-,O
375,dependent,O
375,representation,O
375,for,B
375,sentiment,B
375,prediction,I
375,.,O
376,Compared,O
376,to,O
376,the,O
376,competitive,B
376,LSTM,I
376,-,I
376,baseline,I
376,that,O
376,uses,O
376,the,O
376,same,O
376,relation,O
376,encoder,O
376,",",O
376,the,O
376,ContextAtt,B
376,model,I
376,achieves,B
376,a,O
376,24,B
376,%,I
376,reduction,I
376,of,B
376,the,O
376,average,B
376,error,I
376,:,O
376,from,O
376,0.2096,O
376,0.002,O
376,to,O
376,0.1590,O
376,0.002,O
376,.,O
377,ATAE,O
377,-,O
377,LSTM,O
377,is,B
377,an,O
377,attention,B
377,-,O
377,based,O
377,LSTM,O
377,for,B
377,ACSA,B
377,task,I
377,.,O
378,IAN,B
378,stands,B
378,for,B
378,interactive,B
378,attention,I
378,network,I
378,for,O
378,ATSA,B
378,task,I
378,",",O
378,which,O
378,is,O
378,also,O
378,based,B
378,on,I
378,LSTM,B
378,and,I
378,attention,O
378,mechanisms,O
378,.,O
379,RAM,B
379,is,B
379,a,O
379,recurrent,B
379,attention,I
379,network,I
379,for,B
379,ATSA,B
379,task,I
379,",",O
379,which,O
379,uses,B
379,LSTM,B
379,and,I
379,multiple,I
379,attention,O
379,mechanisms,O
379,.,O
380,GCN,B
380,stands,B
380,for,I
380,gated,B
380,convolutional,I
380,neural,I
380,network,I
380,",",O
380,in,B
380,which,I
380,GTRU,B
380,does,B
380,not,I
380,have,I
380,the,O
380,aspect,B
380,embedding,I
380,as,B
380,an,O
380,additional,B
380,input,I
380,.,O
381,In,O
381,our,O
381,experiments,O
381,",",O
381,word,B
381,embedding,I
381,vectors,I
381,are,O
381,initialized,B
381,with,I
381,300,B
381,-,I
381,dimension,I
381,GloVe,I
381,vectors,O
381,which,O
381,are,O
381,pre-trained,B
381,on,I
381,unlabeled,B
381,data,I
381,of,B
381,840,B
381,billion,I
381,tokens,I
381,.,O
382,Words,O
382,out,O
382,of,B
382,the,O
382,vocabulary,O
382,of,O
382,Glo,B
382,Ve,I
382,are,B
382,randomly,B
382,initialized,I
382,with,B
382,a,O
382,uniform,O
382,distribution,O
382,U,O
382,(,O
382,?,O
383,All,O
383,neural,B
383,models,I
383,are,O
383,implemented,B
383,in,I
383,PyTorch,B
383,.,O
384,We,O
384,use,B
384,Adagrad,B
384,with,B
384,a,O
384,batch,B
384,size,I
384,of,B
384,32,B
384,instances,I
384,",",O
384,default,B
384,learning,I
384,rate,I
384,of,O
384,1,O
384,e,O
384,?,O
385,2,O
385,",",O
385,and,O
385,maximal,B
385,epochs,I
385,of,B
385,30,B
385,.,O
386,We,O
386,only,O
386,fine,B
386,tune,I
386,early,B
386,stopping,I
386,with,B
386,5,B
386,-,I
386,fold,I
386,cross,I
386,validation,I
386,on,B
386,training,B
386,datasets,I
386,.,O
387,In,O
387,this,O
387,paper,O
387,",",O
387,we,O
387,propose,B
387,a,O
387,fast,B
387,and,I
387,effective,I
387,neural,I
387,network,I
387,for,B
387,ACSA,B
387,and,O
387,ATSA,O
387,based,B
387,on,I
387,convolutions,B
387,and,O
387,gating,O
387,mechanisms,O
387,",",O
387,which,O
387,has,O
387,much,O
387,less,O
387,training,O
387,time,O
387,than,O
387,LSTM,O
387,based,O
387,networks,O
387,",",O
387,but,O
387,with,O
387,better,O
387,accuracy,O
387,.,O
388,shows,B
388,that,O
388,the,O
388,ContextAtt,B
388,model,I
388,performs,B
388,best,B
388,over,B
388,all,B
388,relation,I
388,types,I
388,.,O
389,For,B
389,ACSA,B
389,task,I
389,",",O
389,our,B
389,model,I
389,has,O
389,two,B
389,separate,I
389,convolutional,I
389,layers,I
389,on,B
389,the,I
389,top,I
389,of,I
389,the,O
389,embedding,B
389,layer,I
389,",",O
389,whose,B
389,outputs,B
389,are,B
389,combined,I
389,by,I
389,novel,B
389,gating,I
389,units,I
389,.,O
390,For,B
390,ATSA,B
390,task,I
390,",",O
390,where,O
390,the,O
390,aspect,O
390,terms,O
390,consist,O
390,of,O
390,multiple,O
390,words,O
390,",",O
390,we,O
390,extend,B
390,our,B
390,model,I
390,to,B
390,include,I
390,another,B
390,convolutional,I
390,layer,I
390,for,O
390,the,O
390,target,B
390,expressions,I
390,.,O
391,The,O
391,proposed,B
391,gating,B
391,units,I
391,have,B
391,two,B
391,nonlinear,I
391,gates,I
391,",",O
391,each,O
391,of,O
391,which,O
391,is,O
391,connected,B
391,to,I
391,one,B
391,convolutional,I
391,layer,I
391,.,O
392,We,O
392,summarize,O
392,previous,O
392,approaches,O
392,into,O
392,two,O
392,subtasks,O
392,:,O
392,aspect,B
392,-,I
392,category,I
392,sentiment,I
392,analysis,I
392,(,I
392,ACSA,I
392,),I
392,and,O
392,aspect,O
392,-,O
392,term,O
392,sentiment,O
392,analysis,O
392,(,O
392,ATSA,O
392,),O
392,.,O
393,A,O
393,number,O
393,of,O
393,models,O
393,have,O
393,been,O
393,developed,O
393,for,O
393,ABSA,B
393,",",O
393,but,O
393,there,O
393,are,O
393,two,O
393,different,O
393,subtasks,O
393,",",O
393,namely,O
393,aspect,O
393,-,O
393,category,O
393,sentiment,O
393,analysis,O
393,(,O
393,ACSA,O
393,),O
393,and,O
393,aspect,O
393,-,O
393,term,O
393,sentiment,O
393,analysis,O
393,(,O
393,ATSA,O
393,),O
393,.,O
394,The,O
394,goal,O
394,of,O
394,ACSA,B
394,is,O
394,to,O
394,predict,O
394,the,O
394,sentiment,O
394,polarity,O
394,with,O
394,regard,O
394,to,O
394,the,O
394,given,O
394,aspect,O
394,",",O
394,which,O
394,is,O
394,one,O
394,of,O
394,a,O
394,few,O
394,predefined,O
394,categories,O
394,.,O
395,On,O
395,the,O
395,other,O
395,hand,O
395,",",O
395,the,O
395,goal,O
395,of,O
395,ATSA,B
395,is,O
395,to,O
395,identify,O
395,the,O
395,sentiment,O
395,polarity,O
395,concerning,O
395,the,O
395,target,O
395,entities,O
395,that,O
395,appear,O
395,in,O
395,the,O
395,text,O
395,instead,O
395,",",O
395,which,O
395,could,O
395,be,O
395,a,O
395,multi-word,O
395,phrase,O
395,or,O
395,a,O
395,single,O
395,word,O
395,.,O
396,LSTM,O
396,based,O
396,model,O
396,ATAE,O
396,-,O
396,LSTM,O
396,has,O
396,the,O
396,worst,B
396,performance,I
396,of,B
396,all,B
396,neural,I
396,networks,I
396,.,O
397,One,O
397,can,O
397,also,O
397,see,B
397,that,I
397,the,O
397,ContextSum,B
397,does,B
397,n't,I
397,universally,I
397,outperforms,I
397,the,O
397,LSTM,B
397,-,I
397,baseline,I
397,.,O
398,GCAE,B
398,improves,B
398,the,O
398,performance,B
398,by,B
398,1.1,B
398,%,I
398,to,I
398,2.5,I
398,%,O
398,compared,B
398,with,I
398,ATAE,B
398,-,I
398,LSTM,I
398,.,O
399,GCAE,B
399,achieves,B
399,4,B
399,%,I
399,higher,I
399,accuracy,I
399,than,B
399,ATAE,B
399,-,I
399,LSTM,I
399,on,I
399,Restaurant,B
399,-,O
399,Large,O
399,and,O
399,5,B
399,%,O
399,higher,O
399,on,O
399,SemEval,B
399,-,O
399,2014,O
399,on,O
399,ACSA,O
399,task,O
399,.,O
400,However,O
400,",",O
400,GCN,B
400,",",O
400,which,O
400,does,O
400,not,O
400,have,O
400,aspect,O
400,modeling,O
400,part,O
400,",",O
400,has,O
400,higher,B
400,score,I
400,than,B
400,GCAE,B
400,on,B
400,the,O
400,original,B
400,restaurant,I
400,dataset,I
400,.,O
401,Without,O
401,the,O
401,large,O
401,amount,O
401,of,O
401,sentiment,B
401,lexicons,I
401,",",O
401,SVM,B
401,perform,B
401,worse,B
401,than,B
401,neural,B
401,methods,I
401,.,O
402,With,O
402,multiple,O
402,sentiment,O
402,lexicons,O
402,",",O
402,the,O
402,performance,B
402,is,O
402,increased,B
402,by,B
402,7.6,B
402,%,I
402,.,O
403,ATSA,B
404,IAN,B
404,has,O
404,better,B
404,performance,I
404,than,B
404,TD,B
404,-,I
404,LSTM,I
404,and,I
404,ATAE,I
404,-,O
404,LSTM,O
404,",",O
404,because,O
404,two,O
404,attention,O
404,layers,O
404,guides,O
404,the,O
404,representation,O
404,learning,O
404,of,O
404,the,O
404,context,O
404,and,O
404,the,O
404,entity,O
404,interactively,O
404,.,O
405,RAM,B
405,also,O
405,achieves,B
405,good,B
405,accuracy,I
405,by,B
405,combining,I
405,multiple,B
405,attentions,I
405,with,B
405,a,O
405,recurrent,B
405,neural,I
405,network,I
405,",",O
405,but,O
405,it,O
405,needs,O
405,more,O
405,training,O
405,time,O
405,as,O
405,shown,O
405,in,O
405,the,O
405,following,O
405,section,O
405,.,O
406,Because,O
406,of,O
406,the,O
406,gating,O
406,mechanisms,O
406,and,O
406,the,O
406,convolutional,O
406,layer,O
406,over,O
406,aspect,O
406,terms,O
406,",",O
406,GCAE,B
406,outperforms,B
406,other,B
406,neural,I
406,models,I
406,and,O
406,basic,O
406,SVM,O
406,.,O
407,On,B
407,the,O
407,hard,B
407,test,I
407,dataset,I
407,",",O
407,GCAE,B
407,has,O
407,1,B
407,%,I
407,higher,I
407,accuracy,I
407,than,B
407,RAM,B
407,on,O
407,restaurant,B
407,data,I
407,and,O
407,1.7,B
407,%,O
407,higher,O
407,on,O
407,laptop,B
407,data,O
407,.,O
408,It,O
408,demonstrates,O
408,again,O
408,that,O
408,using,B
408,attention,B
408,is,O
408,crucial,B
408,to,I
408,extract,I
408,relevant,B
408,information,I
408,from,B
408,the,O
408,context,B
408,relations,I
408,.,O
409,We,O
409,use,B
409,Bi-directional,B
409,GRUs,I
409,having,B
409,300,B
409,neurons,I
409,",",O
409,each,O
409,followed,B
409,by,I
409,a,O
409,dense,B
409,layer,I
409,consisting,B
409,of,I
409,100,B
409,neurons,O
409,.,O
410,Utilizing,B
410,the,I
410,dense,B
410,layer,I
410,",",O
410,we,O
410,project,B
410,the,O
410,input,B
410,features,I
410,of,B
410,all,B
410,the,O
410,three,O
410,modalities,O
410,to,B
410,the,O
410,same,B
410,dimensions,I
410,.,O
411,We,O
411,set,B
411,dropout,B
411,=,B
411,0.5,B
411,(,I
411,MOSI,I
411,),I
411,&,O
411,0.3,B
411,(,O
411,MOSEI,O
411,),O
411,as,B
411,a,I
411,measure,I
411,of,I
411,regularization,B
411,.,O
412,In,O
412,addition,O
412,",",O
412,we,O
412,also,O
412,use,B
412,dropout,B
412,=,B
412,0.4,B
412,(,I
412,MOSI,I
412,),I
412,&,O
412,0.3,B
412,(,O
412,MOSEI,O
412,),O
412,for,B
412,the,O
412,Bi,B
412,-,I
412,GRU,I
412,layers,I
412,.,O
413,We,O
413,employ,B
413,ReLu,B
413,activation,I
413,function,I
413,in,B
413,the,O
413,dense,B
413,layers,I
413,",",O
413,and,O
413,softmax,B
413,activation,O
413,in,O
413,the,O
413,final,B
413,classification,I
413,layer,I
413,.,O
414,For,B
414,training,B
414,the,I
414,network,I
414,we,O
414,set,B
414,the,O
414,batch,B
414,size,I
414,=,B
414,32,B
414,",",O
414,use,B
414,Adam,B
414,optimizer,I
414,with,B
414,cross,B
414,-,I
414,entropy,I
414,loss,I
414,function,I
414,and,O
414,train,O
414,for,O
414,50,B
414,epochs,I
414,.,O
415,In,O
415,this,O
415,paper,O
415,",",O
415,we,O
415,propose,B
415,a,O
415,novel,B
415,method,I
415,that,O
415,employs,B
415,a,O
415,recurrent,B
415,neural,I
415,network,I
415,based,I
415,multimodal,I
415,multi-utterance,I
415,attention,I
415,framework,I
415,for,B
415,sentiment,B
415,prediction,I
415,.,O
416,To,O
416,better,O
416,address,O
416,these,O
416,concerns,O
416,we,O
416,propose,O
416,a,O
416,novel,B
416,fusion,I
416,method,I
416,by,O
416,focusing,B
416,on,I
416,inter-modality,B
416,relations,I
416,computed,B
416,between,I
416,the,O
416,target,B
416,utterance,I
416,and,I
416,its,I
416,context,I
416,.,O
417,The,O
417,attention,B
417,mechanism,I
417,is,O
417,then,O
417,used,O
417,to,O
417,attend,B
417,to,O
417,the,O
417,important,B
417,contextual,I
417,utterances,I
417,having,B
417,higher,B
417,relatedness,I
417,or,I
417,similarity,I
417,(,O
417,computed,O
417,using,O
417,inter-modality,O
417,correlations,O
417,),O
417,with,B
417,the,O
417,target,B
417,utterance,I
417,.,O
418,Unlike,O
418,previous,O
418,approaches,O
418,that,O
418,simply,O
418,apply,O
418,attentions,O
418,over,O
418,the,O
418,contextual,B
418,utterance,I
418,for,O
418,classification,O
418,",",O
418,we,O
418,attend,B
418,over,O
418,the,O
418,contextual,O
418,utterances,O
418,by,B
418,computing,I
418,correlations,B
418,among,B
418,the,O
418,modalities,B
418,of,B
418,the,O
418,target,B
418,utterance,O
418,and,O
418,the,O
418,context,O
418,utterances,O
418,.,O
419,On,B
419,the,O
419,relation,O
419,-,O
419,specific,O
419,results,O
419,we,O
419,observe,B
419,that,O
419,the,O
419,context,B
419,-,O
419,enabled,O
419,model,O
419,demonstrates,B
419,the,O
419,most,B
419,improvement,I
419,on,O
419,precision,B
419,and,O
419,seems,O
419,to,O
419,be,O
419,especially,O
419,useful,B
419,for,I
419,taxonomy,B
419,relations,I
419,(,O
419,see,O
419,SUBCLASS,O
419,OF,O
419,",",O
419,PART,O
419,OF,O
419,),O
419,.,O
420,The,O
420,model,O
420,facilitates,B
420,this,O
420,modality,B
420,selection,I
420,by,O
420,attending,B
420,over,I
420,the,O
420,contextual,B
420,utterances,I
420,and,O
420,thus,O
420,generates,B
420,better,B
420,multimodal,I
420,feature,I
420,representation,I
420,when,B
420,these,O
420,modalities,B
420,from,I
420,the,O
420,context,O
420,are,O
420,combined,B
420,with,I
420,the,O
420,modalities,O
420,of,O
420,the,O
420,target,O
420,utterance,O
420,.,O
421,Contextual,O
421,Inter-modal,O
421,Attention,O
421,for,O
421,Multi-modal,B
421,Sentiment,I
421,Analysis,I
422,Traditionally,O
422,",",O
422,sentiment,B
422,analysis,I
422,has,O
422,been,O
422,applied,O
422,to,O
422,a,O
422,wide,O
422,variety,O
422,of,O
422,texts,O
422,.,O
423,For,B
423,MOSEI,B
423,dataset,I
423,",",O
423,we,O
423,obtain,B
423,better,B
423,performance,I
423,with,B
423,text,B
423,.,O
424,For,O
424,text,B
424,-,I
424,acoustic,I
424,input,I
424,pairs,I
424,",",O
424,we,O
424,obtain,B
424,the,O
424,highest,B
424,accuracies,I
424,with,B
424,79.,O
425,74,O
425,%,O
425,",",O
425,79.60,O
425,%,O
425,and,O
425,79.32,O
425,%,O
425,for,B
425,MMMU,B
425,-,I
425,BA,I
425,",",O
425,MMUU,O
425,-,O
425,SA,O
425,and,O
425,MU,O
425,-,O
425,SA,O
425,frameworks,O
425,",",O
425,respectively,O
425,.,O
426,Finally,O
426,",",O
426,we,O
426,experiment,B
426,with,I
426,tri-modal,B
426,inputs,I
426,and,O
426,observe,B
426,an,O
426,improved,B
426,performance,I
426,of,B
426,79.,O
427,80,O
427,%,O
427,",",O
427,79.76,O
427,%,O
427,and,O
427,79.63,O
427,%,O
427,for,B
427,MMMU,B
427,-,I
427,BA,I
427,",",O
427,MMUU,O
427,-,O
427,SA,O
427,and,O
427,MU,O
427,-,O
427,SA,O
427,frameworks,O
427,",",O
427,respectively,O
427,.,O
428,The,O
428,performance,B
428,improvement,I
428,was,O
428,also,O
428,found,B
428,to,I
428,be,I
428,statistically,B
428,significant,I
428,(,I
428,T-test,I
428,),I
428,than,B
428,the,O
428,bimodality,B
428,and,I
428,uni-modality,I
428,inputs,I
428,.,O
429,Further,O
429,",",O
429,we,O
429,observe,B
429,that,O
429,the,O
429,MMMU,B
429,-,I
429,BA,I
429,framework,I
429,reports,B
429,the,O
429,best,B
429,accuracy,I
429,of,B
429,79,O
429,.,O
430,80,O
430,%,O
430,for,B
430,the,O
430,MOSEI,B
430,dataset,I
430,",",O
430,thus,O
430,supporting,O
430,our,O
430,claim,O
430,that,O
430,multi-modal,O
430,attention,O
430,framework,O
430,(,O
430,i.e.,O
431,We,O
431,use,B
431,librosa,B
431,",",I
431,a,I
431,Python,I
431,library,I
431,",",O
431,to,B
431,process,I
431,the,O
431,audio,B
431,files,I
431,and,O
431,extract,O
431,features,O
431,from,O
431,them,O
431,.,O
432,We,O
432,use,O
432,scikit,B
432,-,I
432,learn,I
432,and,I
432,xgboost,I
432,[,O
432,25,O
432,],O
432,",",O
432,the,O
432,machine,O
432,learning,O
432,libraries,O
432,for,O
432,Python,O
432,",",O
432,to,B
432,implement,I
432,all,B
432,the,O
432,ML,O
432,classifiers,O
432,(,O
432,RF,O
432,",",O
432,XGB,O
432,",",O
432,SVM,O
432,",",O
432,MNB,O
432,",",O
432,and,O
432,LR,O
432,),O
432,and,O
432,the,O
432,MLP,O
432,.,O
433,We,O
433,find,O
433,that,O
433,:,O
433,The,O
433,entity,B
433,representations,I
433,and,I
433,feedforward,I
433,layers,I
433,contribute,B
433,1.0,B
433,F,I
433,1,I
433,.,O
434,We,O
434,use,O
434,PyTorch,B
434,to,B
434,implement,I
434,the,O
434,LSTM,B
434,classifiers,I
434,described,O
434,earlier,O
434,.,O
435,In,O
435,order,O
435,to,B
435,regularize,I
435,the,O
435,hidden,B
435,space,I
435,of,I
435,the,O
435,LSTM,B
435,classifiers,I
435,",",O
435,we,O
435,use,B
435,a,O
435,shut,B
435,-,I
435,off,I
435,mechanism,I
435,",",O
435,called,B
435,dropout,B
435,",",O
435,where,B
435,a,O
435,fraction,B
435,of,O
435,neurons,O
435,are,O
435,not,O
435,used,O
435,for,B
435,final,B
435,prediction,I
435,.,O
436,We,O
436,randomly,B
436,split,I
436,our,B
436,dataset,I
436,into,B
436,a,O
436,train,B
436,(,I
436,80,I
436,%,I
436,),I
436,and,I
436,test,I
436,(,O
436,20,O
436,%,O
436,),O
436,set,O
436,.,O
437,The,O
437,LSTM,B
437,classifiers,I
437,were,O
437,trained,B
437,on,I
437,an,O
437,NVIDIA,B
437,Titan,I
437,X,I
437,GPU,I
437,for,O
437,faster,O
437,processing,O
437,.,O
438,We,O
438,stop,B
438,the,O
438,training,B
438,when,B
438,we,O
438,do,B
438,not,I
438,see,I
438,any,I
438,improvement,I
438,in,B
438,validation,B
438,performance,I
438,for,B
438,>,B
438,10,I
438,epochs,I
438,.,O
439,In,O
439,this,O
439,work,O
439,",",O
439,we,O
439,explore,B
439,the,O
439,implication,B
439,of,B
439,hand,I
439,-,I
439,crafted,I
439,features,I
439,for,B
439,SER,B
439,and,O
439,compare,B
439,the,O
439,performance,B
439,of,O
439,lighter,B
439,machine,I
439,learning,I
439,models,I
439,with,B
439,the,O
439,heavily,B
439,data,I
439,-,O
439,reliant,O
439,deep,O
439,learning,O
439,models,O
439,.,O
440,Furthermore,O
440,",",O
440,we,O
440,also,O
440,combine,B
440,features,B
440,from,B
440,the,O
440,textual,B
440,modality,I
440,to,B
440,understand,I
440,the,O
440,correlation,B
440,between,I
440,different,I
440,modalities,I
440,and,O
440,aid,B
440,ambiguity,B
440,resolution,I
440,.,O
441,For,O
441,both,O
441,the,O
441,approaches,O
441,",",O
441,we,O
441,first,O
441,extract,B
441,handcrafted,B
441,features,I
441,from,B
441,the,O
441,time,B
441,domain,I
441,of,B
441,the,O
441,audio,B
441,signal,I
441,and,O
441,train,B
441,the,O
441,respective,B
441,models,I
441,.,O
442,In,B
442,the,O
442,first,B
442,approach,I
442,",",O
442,we,O
442,train,B
442,traditional,B
442,machine,I
442,learning,I
442,classifiers,I
442,",",O
442,namely,B
442,",",O
442,Random,B
442,Forests,I
442,",",O
442,Gradient,B
442,Boosting,I
442,",",O
442,Support,B
442,Vector,I
442,Machines,I
442,",",O
442,Naive,B
442,-,I
442,Bayes,I
442,and,O
442,Logistic,B
442,Regression,I
442,.,O
443,In,O
443,the,O
443,second,B
443,approach,I
443,",",O
443,we,O
443,build,B
443,a,O
443,Multi,B
443,-,I
443,Layer,I
443,Perceptron,I
443,and,I
443,an,I
443,LSTM,I
443,classifier,I
443,to,B
443,recognize,I
443,emotion,B
443,given,B
443,a,O
443,speech,B
443,signal,I
443,.,O
444,RESIDE,B
444,makes,B
444,principled,B
444,use,I
444,of,B
444,entity,B
444,type,I
444,and,I
444,relation,B
444,alias,I
444,information,I
444,from,B
444,KBs,B
444,",",O
444,to,B
444,impose,I
444,soft,B
444,constraints,I
444,while,B
444,predicting,I
444,the,O
444,relation,O
444,.,O
445,(,O
445,3,O
445,),O
445,F,B
445,1,I
445,drops,B
445,by,I
445,10.3,B
445,when,B
445,we,I
445,remove,I
445,the,O
445,feedforward,B
445,layers,I
445,",",O
445,the,O
445,LSTM,B
445,component,I
445,and,O
445,the,O
445,dependency,B
445,structure,I
445,altogether,O
445,.,O
446,With,O
446,the,O
446,rise,O
446,of,O
446,deep,O
446,learning,O
446,algorithms,O
446,",",O
446,there,O
446,have,O
446,been,O
446,multiple,O
446,attempts,O
446,to,O
446,tackle,O
446,the,O
446,task,O
446,of,O
446,Speech,B
446,Emotion,I
446,Recognition,I
446,(,I
446,SER,I
446,),I
446,as,O
446,in,O
446,[,O
446,2,O
446,],O
446,and,O
446,.,O
447,In,O
447,this,O
447,work,O
447,",",O
447,we,O
447,explore,O
447,the,O
447,implication,O
447,of,O
447,hand,O
447,-,O
447,crafted,O
447,features,O
447,for,O
447,SER,B
447,and,O
447,compare,O
447,the,O
447,performance,O
447,of,O
447,lighter,O
447,machine,O
447,learning,O
447,models,O
447,with,O
447,the,O
447,heavily,O
447,data,O
447,-,O
447,reliant,O
447,deep,O
447,learning,O
447,models,O
447,.,O
448,From,O
448,",",O
448,we,O
448,can,O
448,see,O
448,that,O
448,our,B
448,simpler,I
448,and,I
448,lighter,I
448,ML,I
448,models,I
448,either,B
448,outperform,I
448,or,I
448,are,I
448,comparable,I
448,to,I
448,the,I
448,much,B
448,heavier,I
448,current,I
448,state,I
448,-,I
448,of,I
448,-,O
448,the,O
448,art,O
448,on,O
448,this,O
448,dataset,O
448,.,O
449,Performance,O
449,of,O
449,LSTM,B
449,and,O
449,ARE,O
449,reveals,B
449,that,O
449,deep,B
449,models,I
449,indeed,I
449,need,I
449,a,I
449,lot,I
449,of,O
449,information,O
449,to,O
449,learn,O
449,features,O
449,as,B
449,the,O
449,LSTM,O
449,classifier,O
449,trained,O
449,on,O
449,eight,B
449,-,I
449,dimensional,I
449,features,O
449,achieves,B
449,very,B
449,low,I
449,accuracy,I
449,as,O
449,compared,O
449,to,O
449,the,O
449,end,O
449,-,O
449,to,O
449,-,O
449,end,O
449,trained,O
449,ARE,O
449,.,O
450,We,O
450,observe,B
450,that,O
450,the,O
450,performance,B
450,of,I
450,all,I
450,the,O
450,models,O
450,for,O
450,this,O
450,setting,O
450,is,B
450,similar,B
450,.,O
451,c),O
451,Audio,B
451,+,I
451,Text,I
451,results,I
451,:,O
452,(,O
452,2,O
452,),O
452,When,O
452,we,O
452,remove,B
452,the,O
452,dependency,B
452,structure,I
452,(,O
452,i.e.,O
453,",",O
453,setting,O
453,to,O
453,I,O
453,),O
453,",",O
453,the,O
453,score,B
453,drops,B
453,by,I
453,3.2,B
453,F,I
453,1,I
453,.,O
454,We,O
454,see,O
454,that,O
454,combining,B
454,audio,B
454,and,I
454,text,I
454,features,I
454,gives,B
454,us,O
454,a,O
454,boost,B
454,of,B
454,?,O
455,Overall,O
455,",",O
455,we,O
455,can,O
455,conclude,B
455,that,I
455,our,B
455,simple,I
455,ML,I
455,methods,I
455,are,B
455,very,B
455,robust,I
455,to,B
455,have,I
455,achieved,I
455,comparable,B
455,performance,I
455,even,O
455,though,O
455,they,O
455,are,O
455,modeled,O
455,to,O
455,predict,O
455,six,O
455,-,O
455,classes,O
455,as,O
455,opposed,O
455,to,O
455,four,O
455,in,O
455,previous,O
455,works,O
455,.,O
456,It,O
456,is,O
456,clear,O
456,that,O
456,both,B
456,context,I
456,and,I
456,knowledge,I
456,are,O
456,essential,B
456,to,I
456,the,O
456,strong,B
456,performance,I
456,of,B
456,KET,B
456,on,B
456,all,B
456,datasets,I
456,.,O
457,Note,O
457,that,O
457,removing,B
457,context,B
457,has,O
457,a,O
457,greater,B
457,impact,I
457,on,B
457,long,B
457,conversations,I
457,than,B
457,short,B
457,conversations,O
457,",",O
457,which,O
457,is,O
457,expected,O
457,because,O
457,more,O
457,contextual,O
457,information,O
457,is,O
457,lost,O
457,in,O
457,long,O
457,conversations,O
457,.,O
458,c,O
458,LSTM,O
458,:,O
458,A,O
458,contextual,B
458,LSTM,O
458,model,O
458,.,O
459,An,O
459,utterance,O
459,-,O
459,level,O
459,bidirectional,O
459,LSTM,O
459,is,O
459,used,O
459,to,B
459,encode,I
459,each,B
459,utterance,O
459,.,O
460,A,O
460,context,B
460,-,I
460,level,I
460,unidirectional,I
460,LSTM,I
460,is,O
460,used,O
460,to,B
460,encode,I
460,the,O
460,context,O
460,.,O
461,CNN+cLSTM,B
461,:,O
461,An,O
461,CNN,B
461,is,O
461,used,O
461,to,B
461,extract,I
461,utterance,B
461,features,I
461,.,O
462,An,O
462,c,B
462,LSTM,I
462,is,O
462,then,O
462,applied,B
462,to,I
462,learn,I
462,context,B
462,representations,I
462,.,O
463,(,O
463,4,O
463,),O
463,Removing,B
463,the,O
463,pruning,B
463,(,O
463,i.e.,O
464,",",O
464,using,O
464,full,O
464,trees,O
464,as,O
464,input,O
464,),O
464,further,O
464,hurts,B
464,the,O
464,result,B
464,by,B
464,another,I
464,9.7,B
464,F,I
464,1,I
464,.,O
465,We,O
465,treat,B
465,each,B
465,utterance,I
465,with,B
465,its,O
465,context,B
465,as,B
465,a,O
465,single,B
465,document,I
465,.,O
466,We,O
466,limit,B
466,the,O
466,document,B
466,length,I
466,to,B
466,the,O
466,last,B
466,100,I
466,tokens,I
466,to,O
466,allow,O
466,larger,B
466,batch,I
466,size,I
466,.,O
467,DialogueRNN,B
467,:,O
467,The,O
467,stateof,B
467,-,I
467,the,O
467,-,O
467,art,O
467,model,O
467,for,B
467,emotion,B
467,detection,I
467,in,B
467,textual,B
467,conversations,I
467,.,O
468,It,O
468,models,B
468,both,I
468,context,B
468,and,I
468,speakers,I
468,information,I
468,.,O
469,We,O
469,replace,B
469,the,O
469,hierarchical,B
469,self,I
469,-,I
469,attention,I
469,by,B
469,a,O
469,single,B
469,self,O
469,-,O
469,attention,O
469,layer,O
469,to,B
469,learn,I
469,context,B
469,representations,I
469,.,O
470,Contextual,O
470,utterances,O
470,are,B
470,concatenated,B
470,together,I
470,prior,B
470,to,I
470,the,O
470,single,B
470,self,I
470,-,I
470,attention,I
470,layer,I
470,.,O
471,We,O
471,replace,B
471,the,O
471,dynamic,B
471,contextaware,I
471,affective,I
471,graph,I
471,attention,I
471,by,B
471,the,O
471,standard,B
471,graph,O
471,attention,O
471,.,O
472,We,O
472,preprocessed,B
472,all,B
472,datasets,I
472,by,B
472,lower,B
472,-,I
472,casing,I
472,and,O
472,tokenization,B
472,using,B
472,Spacy,B
472,2,O
472,.,O
473,We,O
473,use,B
473,the,O
473,released,B
473,code,I
473,for,B
473,BERT,B
473,BASE,I
473,and,I
473,DialogueRNN,I
473,.,O
474,We,O
474,use,O
474,Glo,B
474,Ve,I
474,embedding,I
474,for,B
474,initialization,B
474,in,B
474,the,O
474,word,B
474,and,I
474,concept,I
474,embedding,O
474,layers,O
475,For,B
475,each,B
475,dataset,I
475,",",O
475,all,B
475,models,I
475,are,B
475,fine,B
475,-,I
475,tuned,I
475,based,B
475,on,B
475,their,O
475,performance,B
475,on,O
475,the,O
475,validation,B
475,set,I
475,.,O
476,For,O
476,our,B
476,model,I
476,in,B
476,all,B
476,datasets,I
476,",",I
476,we,O
476,use,B
476,Adam,B
476,optimization,I
476,(,I
476,Kingma,I
476,and,I
476,Ba,I
476,",",O
476,2014,O
476,),O
476,with,B
476,a,O
476,batch,B
476,size,I
476,of,B
476,64,B
476,and,O
476,learning,B
476,rate,I
476,of,O
476,0.0001,B
476,throughout,O
476,the,O
476,training,O
476,process,O
476,.,O
477,For,B
477,the,O
477,class,B
477,weights,I
477,in,B
477,cross,B
477,-,I
477,entropy,I
477,loss,I
477,for,O
477,each,B
477,dataset,I
477,",",O
477,we,O
477,set,O
477,them,O
477,as,O
477,the,O
477,ratio,B
477,of,B
477,the,O
477,class,O
477,distribution,O
477,in,O
477,the,O
477,validation,B
477,set,O
477,to,B
477,the,O
477,class,O
477,distribution,O
477,in,O
477,the,O
477,training,B
477,set,O
477,.,O
478,To,O
478,this,O
478,end,O
478,",",O
478,we,O
478,propose,B
478,a,O
478,Knowledge,O
478,-,O
478,Enriched,O
478,Transformer,O
478,(,O
478,KET,O
478,),O
478,to,O
478,effectively,O
478,incorporate,B
478,contextual,B
478,information,I
478,and,I
478,external,I
478,knowledge,O
478,bases,O
478,to,O
478,address,O
478,the,O
478,aforementioned,O
478,challenges,O
478,.,O
479,In,O
479,addition,O
479,",",O
479,we,O
479,propose,O
479,a,O
479,hierarchical,B
479,self,I
479,-,I
479,attention,I
479,mechanism,I
479,allowing,B
479,KET,B
479,to,B
479,model,I
479,the,O
479,hierarchical,O
479,structure,O
479,of,O
479,conversations,O
479,.,O
480,The,O
480,self,B
480,-,I
480,attention,I
480,and,I
480,cross-attention,I
480,modules,I
480,in,O
480,the,O
480,Transformer,B
480,capture,B
480,the,O
480,intra-sentence,B
480,and,O
480,inter-sentence,O
480,correlations,O
480,",",O
480,respectively,O
480,.,O
481,The,O
481,shorter,B
481,path,I
481,of,B
481,information,I
481,flow,I
481,in,O
481,these,O
481,two,O
481,modules,O
481,compared,O
481,to,B
481,gated,O
481,RNNs,O
481,and,O
481,CNNs,O
481,allows,B
481,KET,B
481,to,O
481,model,O
481,contextual,B
481,information,O
481,more,O
481,efficiently,O
481,.,O
482,Our,O
482,model,O
482,separates,B
482,context,B
482,and,I
482,response,I
482,into,B
482,the,O
482,encoder,B
482,and,O
482,decoder,O
482,",",O
482,respectively,O
482,",",O
482,which,O
482,is,O
482,different,O
482,from,O
482,other,O
482,Transformer,O
482,-,O
482,based,O
482,models,O
482,",",O
482,e.g.,O
483,",",O
483,BERT,O
483,",",O
483,which,O
483,directly,O
483,concatenate,O
483,context,B
483,and,I
483,response,I
483,",",O
483,and,O
483,then,O
483,train,O
483,language,O
483,models,O
483,using,O
483,only,O
483,the,O
483,encoder,O
483,part,O
483,.,O
484,(,O
484,1,O
484,),O
484,A,B
484,logistic,I
484,regression,I
484,(,O
484,LR,O
484,),O
484,classifier,O
484,which,O
484,combines,B
484,dependencybased,B
484,features,I
484,with,B
484,other,B
484,lexical,I
484,features,O
484,.,O
485,Moreover,O
485,",",O
485,to,O
485,exploit,B
485,commonsense,B
485,knowledge,I
485,",",O
485,we,O
485,leverage,B
485,external,B
485,knowledge,O
485,bases,O
485,to,O
485,facilitate,O
485,the,O
485,understanding,B
485,of,I
485,each,I
485,word,I
485,in,B
485,the,O
485,utterances,B
485,by,B
485,referring,I
485,to,O
485,related,B
485,knowledge,O
485,entities,O
485,.,O
486,The,O
486,referring,B
486,process,I
486,is,B
486,dynamic,B
486,and,I
486,balances,B
486,between,I
486,relatedness,B
486,and,O
486,affectiveness,O
486,of,B
486,the,O
486,retrieved,B
486,knowledge,I
486,entities,I
486,using,B
486,a,O
486,context,B
486,-,I
486,aware,I
486,affective,I
486,graph,I
486,attention,I
486,mechanism,I
486,.,O
487,Knowledge,O
487,-,O
487,Enriched,O
487,Transformer,O
487,for,O
487,Emotion,B
487,Detection,I
487,in,I
487,Textual,I
487,Conversations,I
488,The,O
488,task,O
488,of,O
488,detecting,B
488,emotions,I
488,in,I
488,textual,I
488,conversations,I
488,leads,O
488,to,O
488,a,O
488,wide,O
488,range,O
488,of,O
488,applications,O
488,such,O
488,as,O
488,opinion,O
488,mining,O
488,in,O
488,social,O
488,networks,O
488,.,O
489,c,O
489,LSTM,O
489,performs,B
489,reasonably,B
489,well,I
489,on,B
489,short,O
489,conversations,O
489,(,O
489,i.e.,O
490,",",O
490,EC,O
490,and,O
490,DailyDialog,O
490,),O
490,",",O
490,but,O
490,the,O
490,worst,B
490,on,B
490,long,O
490,conversations,O
490,(,O
490,i.e.,O
491,BERT,O
491,BASE,O
491,achieves,B
491,very,B
491,competitive,I
491,performance,I
491,on,B
491,all,B
491,datasets,I
491,except,B
491,EC,B
491,due,B
491,to,I
491,its,O
491,strong,B
491,representational,I
491,power,I
491,via,B
491,bi-directional,B
491,context,I
491,modelling,I
491,using,B
491,the,O
491,Transformer,B
491,.,O
492,In,O
492,particular,O
492,",",O
492,DialogueRNN,B
492,performs,B
492,better,I
492,than,I
492,our,B
492,model,I
492,on,B
492,IEMOCAP,B
492,",",O
492,which,O
492,maybe,O
492,attributed,O
492,to,O
492,its,O
492,detailed,O
492,speaker,O
492,information,O
492,for,O
492,modelling,O
492,the,O
492,emotion,O
492,dynamics,O
492,in,O
492,each,O
492,speaker,O
492,as,O
492,the,O
492,conversation,O
492,flows,O
492,.,O
493,Our,O
493,KET,O
493,variants,O
493,KET,O
493,SingleSelfAttn,O
493,and,O
493,KET,O
493,StdAttn,O
493,perform,B
493,comparably,B
493,with,B
493,the,O
493,best,B
493,baselines,I
493,on,B
493,all,B
493,datasets,I
493,except,B
493,IEMOCAP,B
493,.,O
494,However,O
494,",",O
494,both,O
494,variants,O
494,perform,O
494,noticeably,B
494,worse,I
494,than,B
494,KET,B
494,on,B
494,all,B
494,datasets,I
494,except,B
494,EC,B
494,",",O
494,validating,O
494,the,O
494,importance,O
494,of,O
494,our,O
494,proposed,O
494,hierarchical,O
494,self,O
494,-,O
494,attention,O
494,and,O
494,dynamic,O
494,context,O
494,-,O
494,aware,O
494,affective,O
494,graph,O
494,attention,O
494,mechanism,O
494,.,O
495,(,O
495,2,O
495,),O
495,Shortest,B
495,Dependency,B
495,Path,I
495,LSTM,I
495,(,O
495,SDP,O
495,-,O
495,LSTM,O
495,),O
495,",",O
495,which,O
495,applies,B
495,a,O
495,neural,B
495,sequence,I
495,model,I
495,on,B
495,the,O
495,shortest,O
495,path,O
495,between,B
495,the,O
495,subject,B
495,and,I
495,object,I
495,entities,I
495,in,B
495,the,O
495,dependency,O
495,tree,O
495,.,O
496,One,O
496,observation,O
496,worth,O
496,mentioning,O
496,is,O
496,that,O
496,these,O
496,two,O
496,variants,O
496,perform,O
496,on,B
496,a,I
496,par,I
496,with,B
496,the,O
496,KET,B
496,model,I
496,on,O
496,EC,B
496,.,O
497,In,B
497,contrast,O
497,",",O
497,when,B
497,the,O
497,utterance,B
497,-,I
497,level,I
497,LSTM,I
497,in,O
497,c,B
497,LSTM,O
497,is,O
497,replaced,B
497,by,I
497,features,B
497,extracted,B
497,by,O
497,CNN,B
497,",",O
497,i.e.,O
498,",",O
498,the,O
498,CNN,B
498,+,O
498,c,B
498,LSTM,I
498,",",O
498,the,O
498,model,B
498,performs,B
498,significantly,B
498,better,I
498,than,B
498,c,O
498,LSTM,O
498,on,B
498,long,B
498,conversations,I
498,",",O
498,which,O
498,further,O
498,validates,O
498,that,O
498,modelling,O
498,long,O
498,conversations,O
498,using,O
498,only,O
498,RNN,O
498,models,O
498,may,O
498,not,O
498,be,O
498,sufficient,O
498,.,O
499,This,O
499,finding,O
499,indicates,B
499,that,I
499,our,B
499,model,I
499,is,B
499,robust,B
499,across,B
499,datasets,B
499,with,B
499,varying,B
499,training,I
499,sizes,I
499,",",I
499,context,I
499,lengths,I
499,and,I
499,domains,I
499,.,O
500,1,O
500,),O
500,Word,B
500,embeddings,I
500,:,O
501,In,O
501,this,O
501,method,O
501,",",O
501,the,O
501,word,B
501,vectors,I
501,pretrained,B
501,on,I
501,large,B
501,text,I
501,corpus,I
501,such,B
501,as,I
501,Wikipedia,B
501,dump,I
501,are,O
501,averaged,B
501,to,B
501,get,I
501,the,O
501,document,B
501,vector,I
501,",",O
501,which,O
501,is,O
501,then,O
501,fed,B
501,to,O
501,the,O
501,sentiment,B
501,classifier,I
501,to,O
501,compute,O
501,the,O
501,sentiment,O
501,score,O
501,.,O
502,2,O
502,),O
502,Recursive,B
502,networks,I
502,:,O
503,Various,O
503,types,O
503,of,O
503,recursive,O
503,neural,O
503,networks,O
503,(,O
503,RNN,O
503,),O
503,have,O
503,been,O
503,applied,B
503,on,I
503,SST,B
503,.,O
504,3,O
504,),O
504,Recurrent,B
504,networks,I
504,:,O
505,Sophisticated,O
505,recurrent,O
505,networks,O
505,such,B
505,as,I
505,left,B
505,-,I
505,to,I
505,-,O
505,right,O
505,and,O
505,bidrectional,O
505,LSTM,O
505,networks,O
505,have,O
505,also,O
505,been,O
505,applied,B
505,on,I
505,SST,B
505,.,O
506,4,O
506,),O
506,Convolutional,B
506,networks,I
506,:,O
507,Tree,O
507,-,O
507,LSTM,B
507,",",O
507,which,O
507,is,B
507,a,O
507,recursive,B
507,model,I
507,that,O
507,generalizes,B
507,the,O
507,LSTM,O
507,to,B
507,arbitrary,B
507,tree,O
507,structures,O
507,.,O
508,In,O
508,this,O
508,approach,O
508,",",O
508,the,O
508,input,B
508,sequences,I
508,were,O
508,passed,B
508,through,I
508,a,O
508,1,B
508,-,I
508,dimensional,I
508,convolutional,I
508,neural,I
508,network,I
508,as,B
508,feature,B
508,extractors,I
508,.,O
509,In,O
509,this,O
509,paper,O
509,",",O
509,we,O
509,use,B
509,the,O
509,pretrained,B
509,BERT,I
509,model,I
509,and,O
509,finetune,B
509,it,I
509,for,I
509,the,O
509,fine,B
509,-,I
509,grained,I
509,sentiment,I
509,classification,I
509,task,I
509,on,B
509,the,O
509,Stanford,B
509,Sentiment,O
509,Treebank,O
509,(,O
509,SST,O
509,),O
509,dataset,O
509,.,O
510,We,O
510,can,O
510,see,B
510,that,I
510,our,B
510,model,I
510,",",O
510,despite,O
510,being,O
510,a,O
510,simple,O
510,architecture,O
510,",",O
510,performs,B
510,better,B
510,in,B
510,terms,I
510,of,I
510,accuracy,B
510,than,B
510,many,B
510,popular,I
510,and,I
510,sophisticated,I
510,NLP,I
510,models,I
510,.,O
511,There,O
511,are,O
511,two,O
511,versions,O
511,of,B
511,this,O
511,method,O
511,.,O
512,The,O
512,first,B
512,one,I
512,",",O
512,named,B
512,AC,B
512,-,I
512,S,I
512,",",O
512,averages,B
512,the,O
512,word,B
512,vectors,I
512,before,B
512,the,O
512,target,B
512,and,O
512,the,O
512,word,O
512,vectors,O
512,after,B
512,the,O
512,target,O
512,separately,O
512,.,O
513,The,O
513,second,B
513,one,I
513,",",O
513,named,B
513,AC,B
513,",",O
513,averages,B
513,the,O
513,word,O
513,vectors,O
513,of,O
513,the,O
513,full,B
513,context,I
513,.,O
514,SVM,B
514,:,O
514,The,O
514,traditional,O
514,state,O
514,-,O
514,of,O
514,-,O
514,the,O
514,-,O
514,art,O
514,method,O
514,using,O
514,SVMs,O
514,on,B
514,surface,B
514,features,I
514,",",I
514,lexicon,I
514,features,O
514,and,O
514,parsing,O
514,features,O
514,",",O
514,which,O
514,is,O
514,the,O
514,best,O
514,team,O
514,in,O
514,SemEval,O
514,2014,O
514,.,O
515,Rec,O
515,-,O
515,NN,O
515,:,O
515,It,O
515,firstly,B
515,uses,I
515,rules,B
515,to,B
515,transform,I
515,the,O
515,dependency,B
515,tree,I
515,and,O
515,put,B
515,the,O
515,opinion,B
515,target,I
515,at,B
515,the,O
515,root,B
515,",",O
515,and,O
515,then,O
515,performs,B
515,semantic,B
515,composition,I
515,with,B
515,Recursive,B
515,NNs,I
515,for,B
515,sentiment,B
515,prediction,I
515,.,O
516,TD-,O
516,LSTM,O
516,:,O
516,It,O
516,uses,B
516,a,I
516,forward,B
516,LSTM,O
516,and,O
516,a,O
516,backward,O
516,LSTM,O
516,to,B
516,abstract,I
516,the,O
516,information,B
516,before,B
516,and,O
516,after,O
516,the,O
516,target,B
516,.,O
517,TD,O
517,-,O
517,LSTM,O
517,-,O
517,A,O
517,:,O
517,We,O
517,developed,B
517,TD,O
517,-,O
517,LSTM,O
517,to,O
517,make,O
517,it,O
517,have,B
517,one,B
517,attention,I
517,on,B
517,the,O
517,outputs,B
517,of,O
517,3,O
517,https://github.com/svn2github/word2vec,O
518,MemNet,B
518,:,O
518,It,O
518,applies,B
518,attention,I
518,multiple,B
518,times,I
518,on,B
518,the,O
518,word,B
518,embeddings,I
518,",",O
518,and,O
518,the,O
518,last,B
518,attention,O
518,'s,O
518,output,O
518,is,O
518,fed,B
518,to,I
518,softmax,B
518,for,B
518,prediction,B
518,",",O
518,without,O
518,combining,O
518,the,O
518,results,O
518,of,O
518,different,O
518,attentions,O
518,.,O
519,In,B
519,this,O
519,paper,O
519,",",O
519,we,O
519,propose,B
519,a,O
519,novel,B
519,framework,I
519,to,B
519,solve,I
519,the,O
519,above,O
519,problems,B
519,in,O
519,target,B
519,sentiment,I
519,analysis,I
519,.,O
520,Specifically,O
520,",",O
520,our,O
520,framework,B
520,first,B
520,adopts,I
520,a,O
520,bidirectional,B
520,LSTM,I
520,(,I
520,BLSTM,I
520,),I
520,to,B
520,produce,I
520,the,O
520,memory,O
520,(,O
520,i.e.,O
521,the,O
521,states,O
521,of,O
521,time,O
521,steps,O
521,generated,O
521,by,O
521,LSTM,O
521,),O
521,from,B
521,the,O
521,input,B
521,",",O
521,as,O
521,bidirectional,O
521,recurrent,O
521,neural,O
521,networks,O
521,(,O
521,RNNs,O
521,),O
521,were,O
521,found,O
521,effective,O
521,for,O
521,a,O
521,similar,O
521,purpose,O
521,in,O
521,machine,O
521,translation,O
521,.,O
522,The,O
522,memory,B
522,slices,I
522,are,O
522,then,O
522,weighted,B
522,according,I
522,to,B
522,their,O
522,relative,B
522,positions,I
522,to,O
522,the,O
522,target,B
522,",",O
522,so,O
522,that,O
522,different,O
522,targets,O
522,from,O
522,the,O
522,same,O
522,sentence,O
522,have,O
522,their,O
522,own,O
522,tailor,O
522,-,O
522,made,O
522,memories,O
522,.,O
523,Our,O
523,framework,O
523,introduces,B
523,a,O
523,novel,B
523,way,I
523,of,B
523,applying,I
523,multiple,B
523,-,I
523,attention,I
523,mechanism,I
523,to,B
523,synthesize,I
523,important,B
523,features,I
523,in,B
523,difficult,B
523,sentence,I
523,structures,I
523,.,O
524,After,O
524,that,O
524,",",O
524,we,O
524,pay,B
524,multiple,B
524,attentions,I
524,on,B
524,the,O
524,position,B
524,-,I
524,weighted,I
524,memory,I
524,and,O
524,nonlinearly,B
524,combine,I
524,the,O
524,attention,B
524,results,I
524,with,B
524,a,O
524,recurrent,O
524,network,O
524,",",O
524,i.e.,O
525,Finally,O
525,",",O
525,we,O
525,apply,B
525,softmax,B
525,on,B
525,the,O
525,output,B
525,of,B
525,the,O
525,GRU,B
525,network,I
525,to,B
525,predict,I
525,the,O
525,sentiment,B
525,on,O
525,the,O
525,target,B
525,.,O
526,Our,O
526,group,O
526,presented,O
526,a,O
526,competitive,B
526,sequence,I
526,model,I
526,that,O
526,employs,B
526,a,O
526,position,B
526,-,I
526,aware,I
526,attention,I
526,mechanism,I
526,over,B
526,LSTM,I
526,outputs,I
526,(,I
526,PA,I
526,-,O
526,LSTM,O
526,),O
526,",",O
526,and,O
526,showed,O
526,that,O
526,it,O
526,outperforms,O
526,several,O
526,CNN,O
526,and,O
526,dependency,O
526,-,O
526,based,O
526,models,O
526,by,O
526,a,O
526,substantial,O
526,margin,O
526,.,O
527,Recurrent,O
527,Attention,O
527,Network,O
527,on,O
527,Memory,O
527,for,O
527,Aspect,B
527,Sentiment,I
527,Analysis,I
528,As,O
528,shown,O
528,by,O
528,the,O
528,results,O
528,in,O
528,",",O
528,our,B
528,RAM,I
528,consistently,B
528,outperforms,I
528,all,O
528,compared,B
528,methods,I
528,on,O
528,these,O
528,four,O
528,datasets,O
528,.,O
529,AC,O
529,and,O
529,AC,O
529,-,O
529,S,O
529,perform,B
529,poorly,B
529,",",O
529,because,O
529,averaging,O
529,context,O
529,is,O
529,equivalent,O
529,to,O
529,paying,O
529,identical,O
529,attention,O
529,to,O
529,each,O
529,word,O
529,which,O
529,would,O
529,hide,O
529,the,O
529,true,O
529,sentiment,O
529,word,O
529,.,O
530,Rec,O
530,-,O
530,NN,O
530,is,O
530,better,B
530,than,I
530,TD,B
530,-,O
530,LSTM,O
530,but,O
530,not,B
530,as,I
530,good,I
530,as,O
530,our,B
530,method,I
530,.,O
531,TD,O
531,-,O
531,LSTM,O
531,performs,B
531,less,B
531,competitive,I
531,than,B
531,our,B
531,method,I
531,on,O
531,all,O
531,the,O
531,datasets,O
531,",",O
531,particularly,O
531,on,O
531,the,O
531,tweet,O
531,dataset,O
531,",",O
531,because,O
531,in,O
531,this,O
531,dataset,O
531,sentiment,O
531,words,O
531,are,O
531,usually,O
531,far,O
531,from,O
531,person,O
531,names,O
531,",",O
531,for,O
531,which,O
531,case,O
531,the,O
531,multiple,O
531,-,O
531,attention,O
531,mechanism,O
531,is,O
531,designed,O
531,to,O
531,work,O
531,.,O
532,TD,O
532,-,O
532,LSTM,O
532,-,O
532,A,O
532,also,O
532,performs,B
532,worse,B
532,than,B
532,our,B
532,method,I
532,",",O
532,because,O
532,it,O
532,s,O
532,two,O
532,attentions,O
532,",",O
532,i.e.,O
533,one,O
533,for,O
533,the,O
533,text,O
533,before,O
533,the,O
533,target,O
533,and,O
533,the,O
533,other,O
533,for,O
533,the,O
533,after,O
533,",",O
533,can,O
533,not,O
533,tackle,O
533,some,O
533,cases,O
533,where,O
533,more,O
533,than,B
533,one,O
533,features,O
533,being,O
533,attended,O
533,are,O
533,at,O
533,the,O
533,same,O
533,side,O
533,of,O
533,the,O
533,target,O
533,.,O
534,MemNet,B
534,adopts,B
534,multiple,B
534,attentions,I
534,in,B
534,order,I
534,to,I
534,improve,I
534,the,O
534,attention,B
534,results,I
534,",",O
534,given,O
534,the,O
534,assumption,O
534,that,O
534,the,O
534,result,O
534,of,O
534,an,O
534,attention,O
534,at,O
534,a,O
534,later,O
534,hop,O
534,should,O
534,be,O
534,better,O
534,than,O
534,that,O
534,at,O
534,the,O
534,beginning,O
534,.,O
535,Grid,O
535,search,O
535,was,O
535,performed,B
535,using,I
535,20,B
535,%,I
535,of,I
535,the,I
535,training,I
535,data,I
535,as,B
535,a,O
535,validation,B
535,set,I
535,in,O
535,order,O
535,to,B
535,determine,I
535,the,O
535,optimal,B
535,hyperparameters,I
535,as,O
535,well,O
535,as,O
535,whether,O
535,to,O
535,use,O
535,a,O
535,constant,B
535,learning,I
535,rate,I
535,or,I
535,learning,O
535,rate,O
535,annealing,O
535,.,O
536,The,O
536,optimal,B
536,learning,I
536,rate,I
536,in,B
536,the,O
536,case,O
536,of,O
536,cosine,B
536,similarity,I
536,is,B
536,extremely,B
536,small,I
536,",",O
536,suggesting,B
536,a,O
536,chaotic,B
536,error,I
536,surface,I
536,.,O
537,The,O
537,weights,B
537,of,B
537,the,O
537,networks,B
537,were,B
537,initialized,B
537,from,B
537,a,O
537,uniform,B
537,distribution,I
537,in,B
537,the,O
537,range,B
537,of,O
537,[,B
537,-,I
537,0.001,I
537,",",I
537,0.001,O
537,],O
537,.,O
538,In,O
538,this,O
538,work,O
538,",",O
538,we,O
538,propose,B
538,a,O
538,novel,B
538,extension,I
538,of,I
538,the,I
538,graph,I
538,convolutional,I
538,network,I
538,),O
538,that,O
538,is,O
538,tailored,B
538,for,I
538,relation,B
538,extraction,I
538,.,O
539,We,O
539,did,O
539,however,O
539,tune,B
539,the,O
539,number,B
539,of,I
539,iterations,I
539,from,B
539,",",I
539,learning,B
539,rate,I
539,from,O
539,[,B
539,0.25,I
539,",",O
539,0.025,O
539,",",O
539,0.0025,O
539,",",O
539,0.001,O
539,],O
539,and,O
539,?,O
540,from,B
540,.,O
541,In,O
541,the,O
541,case,O
541,of,O
541,using,B
541,L2,B
541,regularized,I
541,dot,I
541,product,I
541,",",O
541,?,O
542,(,O
542,regularization,O
542,strength,O
542,),O
542,was,O
542,chosen,B
542,from,I
542,[,B
542,1,I
542,",",I
542,0.1,I
542,",",O
542,0.01,O
542,],O
542,.,O
543,The,O
543,model,O
543,in,O
543,turn,O
543,requires,B
543,a,O
543,larger,B
543,number,I
543,of,I
543,epochs,I
543,for,B
543,convergence,B
543,.,O
544,For,B
544,the,O
544,distribution,O
544,for,O
544,sampling,B
544,negative,I
544,words,I
544,",",O
544,we,O
544,used,B
544,the,O
544,n-gram,B
544,distribution,O
544,raised,B
544,to,I
544,the,O
544,3,B
544,/,I
544,4,I
544,th,I
544,power,I
544,in,O
544,accordance,O
544,with,O
544,.,O
545,This,O
545,paper,O
545,aims,B
545,to,I
545,improve,I
545,existing,O
545,document,B
545,embedding,I
545,models,I
545,by,B
545,training,I
545,document,O
545,embeddings,O
545,using,B
545,cosine,B
545,similarity,I
545,instead,O
545,of,O
545,dot,O
545,product,O
545,.,O
546,For,O
546,example,O
546,",",O
546,in,B
546,the,O
546,basic,O
546,model,O
546,of,O
546,trying,B
546,to,I
546,predict,B
546,given,B
546,a,O
546,document,B
546,-,I
546,the,O
546,words,B
546,/,I
546,n,I
546,-,O
546,grams,O
546,in,O
546,the,O
546,document,O
546,",",O
546,instead,O
546,of,O
546,trying,O
546,to,O
546,maximize,B
546,the,O
546,dot,O
546,product,O
546,between,O
546,a,O
546,document,O
546,vector,O
546,and,O
546,vectors,O
546,of,O
546,the,O
546,words,O
546,/,O
546,n,O
546,-,O
546,grams,O
546,in,O
546,the,O
546,document,O
546,over,O
546,the,O
546,training,O
546,set,O
546,",",O
546,we,O
546,'ll,O
546,be,O
546,trying,O
546,to,O
546,maximize,O
546,the,O
546,cosine,B
546,similarity,I
546,instead,O
546,.,O
547,In,O
547,document,B
547,-,I
547,level,I
547,sentiment,I
547,classification,I
547,",",O
547,each,O
547,document,O
547,must,O
547,be,O
547,mapped,O
547,to,O
547,a,O
547,fixed,O
547,length,O
547,vector,O
547,.,O
548,In,O
548,document,O
548,classification,O
548,tasks,O
548,such,O
548,as,O
548,sentiment,O
548,classification,O
548,(,O
548,in,O
548,this,O
548,paper,O
548,we,O
548,focus,O
548,on,O
548,binary,B
548,sentiment,O
548,classification,O
548,of,O
548,long,O
548,movie,O
548,reviews,O
548,",",O
548,i.e.,O
549,From,O
549,here,O
549,we,O
549,see,B
549,that,I
549,using,I
549,cosine,B
549,similarity,I
549,instead,B
549,of,I
549,dot,B
549,product,I
549,improves,B
549,accuracy,B
549,across,O
549,the,O
549,board,O
549,.,O
550,It,O
550,uses,B
550,encoded,B
550,syntactic,I
550,information,I
550,obtained,B
550,from,I
550,Graph,B
550,Convolution,I
550,Networks,I
550,(,I
550,GCN,I
550,),I
550,",",O
550,along,B
550,with,I
550,embedded,B
550,side,I
550,information,O
550,",",O
550,to,B
550,improve,I
550,neural,B
550,relation,I
550,extraction,I
550,.,O
551,Our,O
551,model,O
551,encodes,B
551,the,O
551,dependency,B
551,structure,I
551,over,B
551,the,O
551,input,B
551,sentence,I
551,with,B
551,efficient,B
551,graph,I
551,convolution,I
551,operations,I
551,",",O
551,then,O
551,extracts,B
551,entity,B
551,-,I
551,centric,I
551,representations,I
551,to,B
551,make,I
551,robust,B
551,relation,I
551,predictions,I
551,.,O
552,However,O
552,it,O
552,is,O
552,not,O
552,to,B
552,suggest,B
552,that,I
552,switching,B
552,from,B
552,dot,B
552,product,I
552,to,O
552,cosine,B
552,similarity,I
552,alone,O
552,improves,B
552,accuracy,B
552,as,O
552,other,O
552,minor,O
552,ad,O
552,-,O
552,justments,O
552,and,O
552,hyperparameter,O
552,tuning,O
552,as,O
552,explained,O
552,was,O
552,done,O
552,.,O
553,As,O
553,seen,O
553,during,B
553,grid,B
553,search,I
553,",",O
553,whenever,O
553,the,O
553,initial,B
553,learning,I
553,rate,I
553,was,B
553,0.25,B
553,",",O
553,accuracy,O
553,was,O
553,always,O
553,poor,O
553,.,O
554,Introducing,B
554,L2,B
554,regularization,I
554,to,B
554,dot,B
554,product,I
554,improves,B
554,accuracy,B
554,for,B
554,all,B
554,cases,I
554,except,B
554,a,O
554,depreciation,B
554,in,B
554,the,I
554,case,I
554,of,I
554,using,I
554,unigrams,B
554,only,O
554,",",O
554,lucikily,O
554,cosine,O
554,similarity,O
554,does,O
554,not,O
554,suffer,O
554,from,O
554,this,O
554,same,O
554,depreciation,O
554,.,O
555,We,O
555,propose,B
555,two,B
555,novel,I
555,approaches,I
555,for,B
555,improving,I
555,the,O
555,effectiveness,B
555,of,I
555,attention,I
555,models,I
555,.,O
556,The,O
556,first,B
556,approach,I
556,is,O
556,a,O
556,new,O
556,way,O
556,of,B
556,encoding,O
556,a,O
556,target,O
556,which,O
556,better,O
556,captures,O
556,the,O
556,aspect,O
556,semantics,O
556,of,O
556,the,O
556,target,O
556,expression,O
556,.,O
557,To,O
557,address,O
557,this,O
557,problem,O
557,",",O
557,inspired,O
557,by,O
557,",",O
557,we,O
557,instead,O
557,model,B
557,each,B
557,target,I
557,as,B
557,a,O
557,mixture,B
557,of,O
557,K,B
557,aspect,I
557,embeddings,I
557,where,O
557,we,O
557,would,O
557,like,O
557,each,O
557,embedded,O
557,aspect,O
557,to,O
557,represent,O
557,a,O
557,cluster,O
557,of,O
557,closely,O
557,related,O
557,targets,O
557,.,O
558,We,O
558,use,B
558,an,O
558,autoencoder,B
558,structure,I
558,to,B
558,learn,I
558,both,B
558,the,I
558,aspect,B
558,embeddings,I
558,as,B
558,well,I
558,as,O
558,the,O
558,representation,O
558,of,B
558,the,O
558,target,O
558,as,O
558,a,O
558,weighted,B
558,combination,I
558,of,O
558,the,O
558,aspect,O
558,embeddings,O
558,.,O
559,The,O
559,autoencoder,B
559,structure,I
559,is,O
559,jointly,B
559,trained,I
559,with,I
559,a,O
559,neural,B
559,attention,I
559,-,I
559,based,I
559,sentiment,I
559,classifier,I
559,to,B
559,provide,I
559,a,O
559,good,B
559,target,I
559,representation,I
559,as,I
559,well,I
559,as,O
559,a,O
559,high,B
559,accuracy,I
559,on,B
559,the,O
559,predicted,B
559,sentiment,O
559,.,O
560,Our,O
560,second,B
560,approach,I
560,exploits,B
560,syntactic,B
560,information,I
560,to,B
560,construct,I
560,a,O
560,syntax,B
560,-,I
560,based,I
560,attention,I
560,model,I
560,.,O
561,Instead,O
561,",",O
561,our,O
561,syntax,B
561,-,I
561,based,I
561,attention,I
561,mechanism,I
561,selectively,B
561,focuses,I
561,on,B
561,a,I
561,small,B
561,subset,I
561,of,I
561,context,I
561,words,I
561,that,O
561,are,O
561,close,B
561,to,I
561,the,O
561,target,B
561,on,O
561,the,O
561,syntactic,B
561,path,I
561,which,O
561,is,O
561,obtained,B
561,by,I
561,applying,B
561,a,O
561,dependency,O
561,parser,O
561,on,O
561,the,O
561,review,B
561,sentence,I
561,.,O
562,We,O
562,also,O
562,apply,B
562,a,O
562,novel,B
562,path,I
562,-,I
562,centric,I
562,pruning,I
562,technique,I
562,to,B
562,remove,I
562,irrelevant,B
562,information,I
562,from,B
562,the,B
562,tree,I
562,while,O
562,maximally,B
562,keeping,I
562,relevant,B
562,content,I
562,",",O
562,which,O
562,further,O
562,improves,O
562,the,O
562,performance,O
562,of,O
562,several,O
562,dependencybased,O
562,models,O
562,including,O
562,ours,O
562,.,O
563,(,O
563,1,O
563,),O
563,Feature,B
563,-,I
563,based,I
563,SVM,I
563,:,O
564,We,O
564,compare,B
564,with,I
564,the,O
564,reported,B
564,results,I
564,of,B
564,a,O
564,top,B
564,system,I
564,in,B
564,SemEval,B
564,2014,I
564,.,O
565,(,O
565,2,O
565,),O
565,LSTM,B
565,:,O
565,An,O
565,LSTM,O
565,network,O
565,is,O
565,built,B
565,on,I
565,top,B
565,of,I
565,word,I
565,embeddings,I
565,.,O
566,Effective,O
566,Attention,O
566,Modeling,O
566,for,O
566,Aspect,B
566,-,I
566,Level,I
566,Sentiment,I
566,Classification,I
567,Aspect,O
567,-,O
567,level,O
567,sentiment,O
567,classification,O
567,is,O
567,an,O
567,important,O
567,task,O
567,in,O
567,fine,B
567,-,O
567,grained,O
567,sentiment,O
567,analysis,O
567,.,O
568,1,O
568,),O
568,Feature,O
568,-,O
568,based,O
568,SVM,O
568,is,O
568,still,O
568,a,O
568,strong,O
568,baseline,O
568,",",O
568,our,B
568,best,I
568,model,I
568,achieves,B
568,competitive,B
568,results,I
568,on,I
568,D1,B
568,and,I
568,D2,I
568,without,B
568,relying,I
568,on,O
568,so,B
568,many,I
568,manually,I
568,-,O
568,designed,O
568,features,O
568,and,O
568,external,O
568,resources,O
568,.,O
569,4,O
569,),O
569,The,O
569,integrated,B
569,full,I
569,model,I
569,over,I
569,all,I
569,achieves,B
569,the,O
569,best,B
569,performance,I
569,compared,B
569,to,I
569,using,I
569,only,B
569,one,I
569,of,I
569,the,O
569,two,O
569,proposed,O
569,approaches,O
569,.,O
570,5,O
570,),O
570,The,O
570,proposed,B
570,target,I
570,representation,I
570,is,B
570,more,B
570,helpful,I
570,on,B
570,restaurant,B
570,domain,I
570,(,I
570,D1,I
570,",",I
570,D3,I
570,",",O
570,and,O
570,D4,O
570,),O
570,than,B
570,laptop,B
570,domain,O
570,(,O
570,D2,O
570,),O
570,.,O
571,2,O
571,),O
571,Compared,B
571,with,I
571,all,B
571,other,I
571,neural,I
571,baselines,I
571,",",I
571,our,B
571,full,I
571,model,I
571,achieves,B
571,statistically,B
571,significant,I
571,improvements,I
571,(,I
571,p,I
571,<,I
571,0.05,I
571,),O
571,on,B
571,both,B
571,accuracies,I
571,and,I
571,macro,I
571,-,I
571,F1,I
571,scores,I
571,for,B
571,D1,B
571,",",O
571,D3,O
571,",",O
571,D4,O
571,.,O
572,3,O
572,),O
572,Compared,O
572,with,O
572,LSTM,B
572,+,I
572,ATT,I
572,",",O
572,all,B
572,three,I
572,settings,I
572,of,B
572,our,B
572,model,I
572,are,B
572,able,I
572,to,I
572,achieve,I
572,statistically,B
572,significant,I
572,improvements,I
572,(,I
572,p,I
572,<,I
572,0.05,I
572,),O
572,on,B
572,all,O
572,datasets,O
572,.,O
573,Graph,O
573,Convolution,O
573,over,O
573,Pruned,O
573,Dependency,O
573,Trees,O
573,Improves,O
573,Relation,B
573,Extraction,I
574,In,O
574,pursuit,O
574,of,O
574,this,O
574,goal,O
574,",",O
574,we,O
574,develop,B
574,deep,B
574,memory,I
574,network,I
574,for,B
574,aspect,B
574,level,I
574,sentiment,I
574,classification,I
574,",",O
574,which,O
574,is,O
574,inspired,O
574,by,O
574,the,O
574,recent,O
574,success,O
574,of,O
574,computational,O
574,models,O
574,with,O
574,attention,O
574,mechanism,O
574,and,O
574,explicit,O
574,memory,O
574,.,O
575,Our,O
575,approach,O
575,is,B
575,data,B
575,-,I
575,driven,I
575,",",O
575,computationally,B
575,efficient,I
575,and,O
575,does,O
575,not,O
575,rely,O
575,on,O
575,syntactic,O
575,parser,O
575,or,O
575,sentiment,O
575,lexicon,O
575,.,O
576,The,O
576,approach,O
576,consists,B
576,of,I
576,multiple,B
576,computational,I
576,layers,I
576,with,B
576,shared,B
576,parameters,I
576,.,O
577,Each,O
577,layer,O
577,is,B
577,a,O
577,content,B
577,-,I
577,and,I
577,location,I
577,-,O
577,based,O
577,attention,O
577,model,O
577,",",O
577,which,O
577,first,B
577,learns,I
577,the,O
577,importance,B
577,/,I
577,weight,I
577,of,B
577,each,O
577,context,O
577,word,O
577,and,O
577,then,O
577,utilizes,B
577,this,O
577,information,B
577,to,B
577,calculate,I
577,continuous,B
577,text,I
577,representation,I
577,.,O
578,The,O
578,text,B
578,representation,I
578,in,B
578,the,O
578,last,B
578,layer,I
578,is,O
578,regarded,B
578,as,I
578,the,O
578,feature,B
578,for,B
578,sentiment,B
578,classification,I
578,.,O
579,As,O
579,every,B
579,component,I
579,is,B
579,differentiable,B
579,",",O
579,the,O
579,entire,B
579,model,I
579,could,B
579,be,I
579,efficiently,I
579,trained,I
579,end,B
579,-,I
579,toend,I
579,with,B
579,gradient,B
579,descent,I
579,",",O
579,where,B
579,the,O
579,loss,B
579,function,I
579,is,O
579,the,O
579,cross,B
579,-,O
579,entropy,O
579,error,O
579,of,B
579,sentiment,B
579,classification,I
579,.,O
580,(,O
580,1,O
580,),O
580,Majority,B
580,is,B
580,a,O
580,basic,B
580,baseline,I
580,method,I
580,",",O
580,which,O
580,assigns,B
580,the,O
580,majority,O
580,sentiment,O
580,label,O
580,in,B
580,training,B
580,set,I
580,to,B
580,each,I
580,instance,B
580,in,O
580,the,O
580,test,B
580,set,O
580,.,O
581,(,O
581,2,O
581,),O
581,Feature,B
581,-,I
581,based,I
581,SVM,I
581,performs,B
581,state,B
581,-,O
581,of,O
581,-,O
581,the,O
581,-,O
581,art,O
581,on,B
581,aspect,B
581,level,I
581,sentiment,I
581,classification,I
581,.,O
582,(,O
582,3,O
582,),O
582,We,O
582,compare,O
582,with,O
582,three,B
582,LSTM,I
582,models,I
582,(,O
582,Tang,O
582,et,O
582,al.,O
583,In,B
583,LSTM,B
583,",",O
583,a,O
583,LSTM,O
583,based,O
583,recurrent,O
583,model,O
583,is,O
583,applied,B
583,from,I
583,the,O
583,start,B
583,to,B
583,the,O
583,end,B
583,of,B
583,a,O
583,sentence,B
583,",",O
583,and,O
583,the,O
583,last,B
583,hidden,I
583,vector,I
583,is,O
583,used,B
583,as,I
583,the,O
583,sentence,O
583,representation,O
583,.,O
584,Results,O
584,on,B
584,the,O
584,TACRED,B
584,Dataset,I
585,TDLSTM,B
585,extends,B
585,LSTM,I
585,by,B
585,taking,I
585,into,I
585,account,I
585,of,O
585,the,O
585,aspect,B
585,",",O
585,and,O
585,uses,B
585,two,B
585,LSTM,O
585,networks,O
585,",",O
585,a,O
585,forward,B
585,one,I
585,and,O
585,a,O
585,backward,O
585,one,O
585,",",O
585,towards,B
585,the,O
585,aspect,O
585,.,O
586,TDLSTM,B
586,+,O
586,ATT,O
586,extends,B
586,TDLSTM,O
586,by,B
586,incorporating,I
586,an,O
586,attention,B
586,mechanism,I
586,(,O
586,Bahdanau,O
586,et,O
586,al.,O
587,",",O
587,2015,O
587,),O
587,over,B
587,the,O
587,hidden,B
587,vectors,I
587,.,O
588,We,O
588,use,B
588,the,O
588,same,B
588,Glove,I
588,word,I
588,vectors,I
588,for,B
588,fair,B
588,comparison,I
588,.,O
589,(,O
589,4,O
589,),O
589,We,O
589,also,O
589,implement,B
589,ContextAVG,B
589,",",O
589,a,O
589,simplistic,B
589,version,I
589,of,B
589,our,B
589,approach,I
589,.,O
590,Aspect,O
590,level,O
590,sentiment,B
590,classification,O
590,is,O
590,a,O
590,fundamental,O
590,task,O
590,in,O
590,the,O
590,field,O
590,of,O
590,sentiment,O
590,analysis,O
590,.,O
591,We,O
591,can,O
591,find,B
591,that,I
591,feature,B
591,-,I
591,based,I
591,SVM,I
591,is,B
591,an,O
591,extremely,B
591,strong,I
591,performer,I
591,and,O
591,substantially,B
591,outperforms,I
591,other,B
591,baseline,I
591,methods,I
591,",",O
591,which,O
591,demonstrates,O
591,the,O
591,importance,O
591,of,O
591,a,O
591,powerful,O
591,feature,O
591,representation,O
591,for,O
591,aspect,O
591,level,O
591,sentiment,O
591,classification,O
591,.,O
592,We,O
592,can,O
592,also,O
592,find,O
592,that,O
592,the,O
592,performance,B
592,of,B
592,Contex,B
592,-,I
592,tAVG,I
592,is,B
592,very,B
592,poor,I
592,",",O
592,which,O
592,means,O
592,that,O
592,assigning,O
592,the,O
592,same,O
592,weight,O
592,/,O
592,importance,O
592,to,O
592,all,O
592,the,O
592,context,O
592,words,O
592,is,O
592,not,O
592,an,O
592,effective,O
592,way,O
592,.,O
593,We,O
593,can,O
593,find,O
593,that,O
593,using,O
593,multiple,B
593,computational,I
593,layers,I
593,could,O
593,consistently,B
593,improve,I
593,the,O
593,classification,B
593,accuracy,I
593,in,B
593,all,B
593,these,I
593,models,I
593,.,O
594,Among,B
594,three,B
594,recurrent,I
594,models,I
594,",",O
594,TDLSTM,B
594,performs,B
594,better,B
594,than,B
594,LSTM,B
594,",",O
594,which,O
594,indicates,O
594,that,O
594,taking,O
594,into,O
594,account,O
594,of,O
594,the,O
594,aspect,O
594,information,O
594,is,O
594,helpful,O
594,.,O
595,We,O
595,observe,B
595,that,O
595,our,O
595,GCN,B
595,model,I
595,Our,O
595,Model,O
595,(,O
595,C,O
595,-,O
595,GCN,O
595,),O
595,84.8,O
595,*,O
595,76.5,O
595,*,O
595,outperforms,B
595,all,B
595,dependency,I
595,-,O
595,based,O
595,models,O
595,by,B
595,at,B
595,least,I
595,1.6,I
595,F,I
595,1,I
595,.,O
596,Among,O
596,all,O
596,our,O
596,models,O
596,from,O
596,single,O
596,hop,O
596,to,O
596,nine,O
596,hops,O
596,",",O
596,we,O
596,can,O
596,observe,B
596,that,I
596,using,B
596,more,B
596,computational,I
596,layers,I
596,could,O
596,generally,O
596,lead,B
596,to,O
596,better,B
596,performance,I
596,",",O
596,especially,B
596,when,I
596,the,O
596,number,B
596,of,I
596,hops,O
596,is,B
596,less,B
596,than,I
596,six,I
596,.,O
597,We,O
597,consider,B
597,that,O
597,each,B
597,hidden,I
597,vector,I
597,of,B
597,TDLSTM,B
597,encodes,B
597,the,O
597,semantics,B
597,of,O
597,word,B
597,sequence,I
597,until,B
597,the,O
597,current,B
597,position,I
597,.,O
598,The,O
598,best,B
598,performances,I
598,are,O
598,achieved,B
598,when,I
598,the,O
598,model,B
598,contains,B
598,seven,B
598,and,I
598,nine,I
598,hops,I
598,",",O
598,respectively,O
598,.,O
599,All,O
599,these,O
599,models,O
599,perform,B
599,comparably,B
599,when,B
599,the,O
599,number,B
599,of,I
599,hops,I
599,is,B
599,larger,B
599,than,I
599,five,I
599,.,O
600,On,B
600,both,B
600,datasets,I
600,",",O
600,the,O
600,proposed,B
600,approach,I
600,could,B
600,obtain,I
600,comparable,B
600,accuracy,I
600,compared,B
600,to,I
600,the,O
600,state,B
600,-,I
600,of,I
600,-,O
600,art,O
600,feature,O
600,-,O
600,based,O
600,SVM,O
600,system,O
600,.,O
601,We,O
601,initialise,B
601,our,B
601,model,I
601,with,B
601,GloVe,B
601,(,O
601,300,B
601,-,I
601,D,I
601,",",I
601,trained,B
601,on,I
601,42B,B
601,tokens,I
601,",",O
601,1.9,O
601,M,O
601,vocab,O
601,",",O
601,not,B
601,updated,I
601,during,I
601,training,B
601,:,O
601,),O
601,4,O
601,and,O
601,pre-process,B
601,the,O
601,corpus,B
601,with,O
601,tokenisation,B
601,using,B
601,NLTK,B
601,),O
601,and,O
601,case,B
601,folding,I
601,.,O
602,Training,B
602,is,O
602,carried,B
602,out,I
602,over,I
602,800,B
602,epochs,I
602,with,B
602,the,O
602,FTRL,B
602,optimiser,I
602,and,O
602,a,O
602,batch,B
602,size,I
602,of,B
602,128,B
602,and,O
602,learning,B
602,rate,I
602,of,O
602,0.05,B
602,.,O
603,Dropout,B
603,is,O
603,applied,B
603,to,I
603,the,O
603,output,B
603,of,B
603,?,O
604,in,B
604,the,O
604,final,B
604,classifier,I
604,(,O
604,Equation,O
604,),O
604,with,B
604,a,O
604,rate,B
604,of,B
604,0.2,B
604,.,O
605,We,O
605,use,B
605,the,O
605,following,B
605,hyper,I
605,-,I
605,parameters,I
605,for,B
605,weight,B
605,matrices,I
605,in,B
605,both,B
605,directions,I
605,:,O
605,R,O
605,?,O
606,R,O
606,3003,O
606,",",O
606,H,O
606,",",O
606,U,O
606,",",O
606,V,O
606,",",O
606,Ware,O
606,all,O
606,matrices,O
606,of,B
606,size,O
606,R,O
606,300300,O
606,",",O
606,v,O
606,?,O
607,R,O
607,300,B
607,",",O
607,and,O
607,hidden,B
607,size,I
607,of,B
607,the,O
607,GRU,B
607,in,B
607,Equation,O
607,is,B
607,300,O
607,.,O
608,Lastly,O
608,",",O
608,to,B
608,curb,I
608,overfitting,B
608,",",O
608,we,O
608,regularise,B
608,the,O
608,last,B
608,layer,I
608,(,O
608,Equation,O
608,),O
608,with,B
608,an,O
608,L,B
608,2,I
608,penalty,I
608,on,B
608,its,O
608,weights,B
608,:,O
608,?,O
609,By,B
609,using,B
609,contextualized,B
609,word,I
609,representations,I
609,",",O
609,the,O
609,C,B
609,-,I
609,GCN,I
609,model,I
609,further,O
609,outperforms,B
609,the,O
609,strong,B
609,PA,I
609,-,O
609,LSTM,O
609,model,O
609,by,O
609,1.3,B
609,F,I
609,1,I
609,",",O
609,and,O
609,achieves,B
609,a,O
609,new,B
609,state,I
609,of,I
609,the,O
609,art,O
609,.,O
610,We,O
610,empirically,B
610,set,B
610,the,O
610,number,B
610,of,I
610,memory,I
610,chains,I
610,to,I
610,6,B
610,",",O
610,with,B
610,the,O
610,keys,B
610,of,O
610,two,O
610,of,O
610,them,O
610,set,O
610,to,O
610,the,O
610,same,B
610,embeddings,I
610,as,B
610,the,O
610,target,B
610,words,I
610,LOC1,I
610,and,I
610,LOC2,I
610,",",O
610,resp.,O
611,",",O
611,and,O
611,the,O
611,other,O
611,4,O
611,chains,O
611,with,B
611,free,O
611,key,O
611,embeddings,O
611,which,O
611,are,O
611,updated,O
611,during,O
611,training,O
611,",",O
611,and,O
611,therefore,O
611,free,O
611,to,B
611,capture,O
611,any,O
611,entities,O
611,.,O
612,In,O
612,this,O
612,work,O
612,",",O
612,we,O
612,propose,B
612,a,O
612,novel,B
612,model,I
612,architecture,I
612,for,B
612,TABSA,B
612,",",O
612,augmented,B
612,with,I
612,multiple,B
612,"""",I
612,memory,I
612,chains,I
612,"""",O
612,",",O
612,and,O
612,equipped,B
612,with,O
612,a,O
612,delayed,B
612,memory,O
612,update,O
612,mechanism,O
612,",",O
612,to,B
612,keep,I
612,track,I
612,of,I
612,numerous,B
612,entities,I
612,independently,I
612,.,O
613,Recurrent,O
613,Entity,O
613,Networks,O
613,with,O
613,Delayed,O
613,Memory,O
613,Update,O
613,for,O
613,Targeted,B
613,Aspect,I
613,-,I
613,based,I
613,Sentiment,I
613,Analysis,I
614,While,O
614,neural,O
614,networks,O
614,have,O
614,been,O
614,shown,O
614,to,O
614,achieve,O
614,impressive,O
614,results,O
614,for,O
614,sentence,O
614,-,O
614,level,O
614,sentiment,O
614,analysis,O
614,",",O
614,targeted,B
614,aspect,I
614,-,O
614,based,O
614,sentiment,O
614,analysis,O
614,(,O
614,TABSA,O
614,),O
614,-,O
614,extraction,O
614,of,O
614,finegrained,O
614,opinion,O
614,polarity,O
614,w.r.t.,O
615,Our,O
615,model,O
615,achieves,B
615,state,B
615,-,I
615,of,I
615,-,O
615,the,O
615,-,O
615,art,O
615,results,O
615,for,B
615,both,I
615,aspect,B
615,detection,I
615,and,O
615,sentiment,B
615,classification,I
615,.,O
616,It,O
616,is,O
616,impressive,O
616,that,O
616,the,O
616,proposed,B
616,model,I
616,",",O
616,equipped,B
616,only,I
616,with,I
616,domainindependent,B
616,general,I
616,-,I
616,purpose,I
616,GloVe,I
616,embeddings,I
616,",",O
616,outperforms,B
616,Sentic,B
616,LSTM,I
616,",",O
616,an,O
616,approach,O
616,heavily,B
616,reliant,I
616,on,I
616,external,B
616,knowledge,I
616,bases,I
616,and,I
616,domainspecific,I
616,embeddings,O
616,.,O
617,We,O
617,see,B
617,consistent,B
617,performance,I
617,gains,I
617,for,B
617,our,B
617,model,I
617,in,B
617,both,I
617,aspect,B
617,detection,I
617,and,I
617,sentiment,I
617,classification,I
617,",",O
617,compared,B
617,to,I
617,EntNet,B
617,",",O
617,esp.,O
618,for,B
618,aspect,O
618,detection,O
618,",",O
618,underlining,O
618,the,O
618,benefit,O
618,of,O
618,delayed,O
618,update,O
618,gate,O
618,activation,O
618,.,O
619,We,O
619,focus,O
619,in,O
619,on,O
619,the,O
619,task,O
619,of,O
619,sentiment,B
619,analysis,I
619,and,O
619,attempt,B
619,to,I
619,learn,I
619,an,O
619,unsupervised,B
619,representation,I
619,that,O
619,accurately,B
619,contains,I
619,this,O
619,concept,O
619,.,O
620,As,O
620,an,O
620,approach,O
620,",",O
620,we,O
620,consider,B
620,the,O
620,popular,O
620,research,B
620,benchmark,I
620,of,I
620,byte,I
620,(,I
620,character,I
620,),I
620,level,I
620,language,I
620,modelling,I
620,due,B
620,to,I
620,its,B
620,further,I
620,simplicity,I
620,and,I
620,generality,I
620,.,O
621,In,B
621,addition,O
621,",",O
621,we,O
621,find,B
621,our,B
621,model,I
621,improves,B
621,upon,I
621,other,B
621,dependencybased,I
621,models,I
621,in,O
621,both,B
621,precision,I
621,and,I
621,recall,I
621,.,O
622,We,O
622,train,B
622,on,I
622,a,O
622,very,B
622,large,I
622,corpus,I
622,picked,B
622,to,I
622,have,I
622,a,O
622,similar,B
622,distribution,I
622,as,B
622,our,B
622,task,I
622,of,I
622,interest,I
622,.,O
623,The,O
623,representation,O
623,learned,O
623,by,B
623,our,O
623,model,O
623,achieves,B
623,91.8,B
623,%,I
623,significantly,B
623,outperforming,I
623,the,O
623,state,B
623,of,B
623,the,O
623,art,O
623,of,O
623,90.2,B
623,%,O
623,by,O
623,a,O
623,30,B
623,model,O
623,ensemble,O
623,.,O
624,It,O
624,matches,B
624,the,O
624,performance,B
624,of,B
624,baselines,B
624,using,B
624,as,O
624,few,B
624,as,O
624,a,O
624,dozen,B
624,labeled,I
624,examples,I
624,and,O
624,outperforms,B
624,all,B
624,previous,I
624,results,I
624,with,B
624,only,O
624,a,O
624,few,O
624,hundred,O
624,labeled,O
624,examples,O
624,.,O
625,Confusingly,O
625,",",O
625,despite,O
625,a,O
625,16,O
625,%,O
625,relative,O
625,error,O
625,reduction,O
625,on,B
625,the,I
625,binary,O
625,subtask,O
625,",",O
625,it,O
625,does,B
625,not,I
625,reach,I
625,the,O
625,state,B
625,of,B
625,the,O
625,art,O
625,of,O
625,53.6,B
625,%,O
625,on,O
625,the,O
625,fine,B
625,-,I
625,grained,I
625,subtask,O
625,",",O
625,achieving,B
625,52.9,B
625,%,O
625,.,O
626,Fitting,B
626,a,O
626,threshold,B
626,to,O
626,this,O
626,single,O
626,unit,O
626,achieves,B
626,a,O
626,test,B
626,accuracy,I
626,of,B
626,92.30,B
626,%,I
626,which,O
626,outperforms,B
626,a,O
626,strong,B
626,supervised,I
626,results,I
626,on,O
626,the,O
626,dataset,O
626,",",O
626,the,O
626,91.87,B
626,%,O
626,of,O
626,NB,B
626,-,I
626,SVM,I
626,trigram,I
626,",",O
626,but,O
626,is,O
626,still,B
626,below,I
626,the,O
626,semi-supervised,B
626,state,I
626,of,O
626,the,O
626,art,O
626,of,O
626,94.09,B
626,%,O
626,.,O
627,Using,B
627,the,O
627,full,B
627,4096,I
627,unit,I
627,representation,I
627,achieves,B
627,92.88,B
627,%,I
627,.,O
628,As,O
628,we,O
628,will,O
628,show,O
628,in,O
628,Section,O
628,6.2,O
628,",",O
628,we,O
628,find,O
628,that,O
628,our,B
628,GCN,I
628,models,I
628,have,B
628,complementary,B
628,strengths,I
628,when,B
628,compared,I
628,to,I
628,the,O
628,PA,B
628,-,I
628,LSTM,I
628,.,O
629,We,O
629,try,B
629,our,O
629,approach,B
629,on,B
629,the,O
629,binary,B
629,version,I
629,of,B
629,the,O
629,Yelp,B
629,Dataset,I
629,Challenge,I
629,in,I
629,2015,I
629,as,O
629,introduced,O
629,in,O
629,.,O
630,Using,B
630,the,O
630,full,B
630,dataset,I
630,",",O
630,we,O
630,achieve,B
630,95,O
630,.,O
631,The,O
631,observed,B
631,capacity,B
631,ceiling,I
631,is,B
631,an,O
631,interesting,B
631,phenomena,I
631,and,I
631,stumbling,I
631,point,I
631,for,B
631,scaling,B
631,our,I
631,unsupervised,I
631,representations,I
631,.,O
632,Additionally,O
632,",",O
632,there,B
632,is,I
632,a,O
632,notable,B
632,drop,I
632,in,B
632,the,O
632,relative,B
632,performance,I
632,of,B
632,our,B
632,approach,I
632,transitioning,B
632,from,I
632,sentence,B
632,to,I
632,document,I
632,datasets,I
632,.,O
633,Finally,O
633,",",O
633,as,O
633,the,O
633,amount,O
633,of,O
633,labeled,B
633,data,I
633,increases,B
633,",",O
633,the,O
633,performance,B
633,of,O
633,the,O
633,simple,B
633,linear,I
633,model,I
633,we,O
633,train,B
633,on,I
633,top,I
633,of,O
633,our,O
633,static,B
633,representation,I
633,will,B
633,eventually,I
633,saturate,B
633,.,O
634,Compared,O
634,to,O
634,the,O
634,dual,B
634,-,I
634,history,I
634,variants,I
634,(,I
634,variants,O
634,3,O
634,",",O
634,5,O
634,",",O
634,and,O
634,7,O
634,),O
634,",",O
634,these,B
634,models,I
634,provide,B
634,lesser,B
634,performance,I
634,.,O
635,DGIM,B
635,prevents,B
635,the,O
635,storage,B
635,of,I
635,dynamic,I
635,influences,I
635,between,B
635,speakers,B
635,at,B
635,each,I
635,historical,B
635,time,I
635,step,I
635,and,O
635,leads,B
635,to,I
635,performance,B
635,deterioration,I
635,.,O
636,Multi,O
636,-,O
636,hop,O
636,vs,O
636,No,O
636,-,O
636,hop,O
636,:,O
636,Variants,O
636,2,O
636,and,O
636,3,O
636,represent,O
636,cases,O
636,where,O
636,multi-hop,B
636,is,O
636,omitted,O
636,",",O
636,i.e.,O
637,Performance,O
637,for,O
637,them,O
637,are,O
637,poorer,O
637,than,B
637,variants,O
637,having,O
637,multi-hop,B
637,mechanism,O
637,(,O
637,variants,O
637,4,O
637,-,O
637,7,O
637,),O
637,.,O
638,Also,O
638,",",O
638,removal,B
638,of,I
638,multi-hop,O
638,leads,B
638,to,I
638,worse,B
638,performance,I
638,than,O
638,the,O
638,removal,O
638,of,O
638,DGIM,O
638,.,O
639,Comparing,B
639,the,O
639,C,B
639,-,I
639,GCN,B
639,model,I
639,with,B
639,the,O
639,GCN,O
639,model,O
639,",",O
639,we,O
639,find,B
639,that,I
639,the,O
639,gain,B
639,mainly,B
639,comes,I
639,from,I
639,improved,B
639,recall,I
639,.,O
640,However,O
640,",",O
640,best,B
640,performance,I
640,is,O
640,achieved,B
640,by,I
640,variant,B
640,6,I
640,which,B
640,contains,I
640,all,B
640,the,I
640,proposed,I
640,modules,I
640,in,B
640,its,B
640,pipeline,I
640,.,O
641,memnet,B
641,is,B
641,an,O
641,end,B
641,-,I
641,toend,I
641,memory,I
641,network,I
641,.,O
642,cLSTM,B
642,4,O
642,classifies,B
642,utterances,I
642,using,B
642,neighboring,B
642,utterances,O
642,(,O
642,of,O
642,same,O
642,speaker,O
642,),O
642,as,B
642,context,B
642,.,O
643,TFN,B
643,5,O
643,models,B
643,intra-and,B
643,intermodality,I
643,dynamics,I
643,by,B
643,explicitly,I
643,aggregating,I
643,uni,B
643,-,I
643,",",I
643,bi-,I
643,and,I
643,trimodal,I
643,interactions,I
643,.,O
644,MFN,B
644,performs,B
644,multi-view,B
644,learning,I
644,by,B
644,using,I
644,Delta,B
644,-,I
644,memory,I
644,Attention,I
644,Network,I
644,",",O
644,a,O
644,fusion,B
644,mechanism,I
644,to,B
644,learn,I
644,cross,B
644,-,O
644,view,O
644,interactions,O
644,.,O
645,CMN,O
645,models,O
645,separate,B
645,contexts,B
645,for,B
645,both,O
645,speaker,B
645,and,I
645,listener,I
645,to,B
645,an,I
645,utterance,B
645,.,O
646,20,O
646,%,O
646,of,O
646,the,O
646,training,O
646,set,O
646,is,O
646,used,B
646,as,I
646,validation,B
646,set,O
646,for,B
646,hyper,B
646,-,I
646,parameter,I
646,tuning,I
646,.,O
647,Termination,B
647,of,B
647,the,O
647,training,B
647,-,I
647,phase,I
647,is,O
647,decided,B
647,by,I
647,early,B
647,-,O
647,stopping,O
647,with,B
647,a,O
647,patience,B
647,of,O
647,10,B
647,d,I
647,=,I
647,100,I
647,dv,I
647,=,O
647,512,O
647,dem,O
647,=,O
647,100,O
647,K,O
647,=,O
647,40,O
647,R,O
647,=,O
647,3,O
647,epochs,O
647,.,O
648,The,O
648,network,B
648,is,O
648,subjected,B
648,to,I
648,regularization,B
648,in,B
648,the,O
648,form,O
648,of,B
648,Dropout,B
648,and,I
648,Gradient,I
648,-,I
648,clipping,I
648,for,B
648,a,O
648,norm,B
648,of,O
648,40,B
648,.,O
649,Finally,O
649,",",O
649,the,O
649,best,B
649,hyper,I
649,-,I
649,parameters,I
649,are,O
649,decided,B
649,using,I
649,a,O
649,gridsearch,B
649,.,O
650,This,O
650,simple,B
650,interpolation,I
650,between,B
650,a,I
650,GCN,B
650,and,I
650,a,O
650,PA,O
650,-,O
650,LSTM,O
650,achieves,B
650,an,O
650,F,O
650,1,O
650,score,O
650,of,B
650,67.1,B
650,",",O
650,outperforming,B
650,each,B
650,model,I
650,alone,I
650,by,B
650,at,B
650,least,I
650,2.0,I
650,F,O
650,1,O
650,.,O
651,We,O
651,use,B
651,the,O
651,Adam,B
651,optimizer,I
651,(,I
651,Kingma,I
651,and,I
651,Ba,I
651,",",I
651,2014,I
651,),I
651,for,B
651,training,B
651,the,O
651,parameters,B
651,starting,B
651,with,I
651,an,O
651,initial,B
651,learning,I
651,rate,I
651,of,B
651,0.001,B
651,.,O
652,For,B
652,multimodal,B
652,feature,I
652,extraction,I
652,",",O
652,we,O
652,explore,B
652,different,B
652,designs,I
652,for,O
652,the,O
652,employed,B
652,CNNs,I
652,.,O
653,For,O
653,text,B
653,",",O
653,we,O
653,find,B
653,the,O
653,single,B
653,layer,I
653,CNN,I
653,to,B
653,perform,I
653,at,I
653,par,I
653,with,I
653,deeper,B
653,variants,I
653,.,O
654,For,O
654,visual,B
654,features,I
654,",",O
654,however,O
654,",",O
654,a,O
654,deeper,B
654,CNN,I
654,provides,B
654,better,B
654,representations,I
654,.,O
655,We,O
655,also,O
655,find,B
655,that,O
655,contextually,B
655,conditioned,I
655,features,I
655,perform,B
655,better,I
655,than,I
655,context,B
655,-,I
655,less,I
655,features,O
655,.,O
656,We,O
656,propose,B
656,Interactive,B
656,COnversational,I
656,memory,I
656,Network,I
656,(,I
656,ICON,I
656,),I
656,",",O
656,a,O
656,multimodal,B
656,network,O
656,for,B
656,identifying,I
656,emotions,B
656,in,B
656,utterance,B
656,-,I
656,videos,I
656,.,O
657,First,O
657,",",O
657,it,O
657,extracts,B
657,multimodal,B
657,features,I
657,from,B
657,all,B
657,utterancevideos,I
657,.,O
658,Next,O
658,",",O
658,given,B
658,a,O
658,test,B
658,utterance,I
658,to,B
658,be,I
658,classified,B
658,",",O
658,ICON,B
658,considers,B
658,the,O
658,preceding,B
658,utterances,I
658,of,B
658,both,B
658,speakers,I
658,falling,B
658,within,I
658,a,O
658,context,B
658,-,I
658,window,I
658,and,O
658,models,B
658,their,O
658,self,B
658,-,O
658,emotional,O
658,influences,O
658,using,B
658,local,B
658,gated,I
658,recurrent,I
658,units,I
658,.,O
659,Furthermore,O
659,",",O
659,to,B
659,incorporate,I
659,inter,B
659,-speaker,I
659,influences,I
659,",",O
659,a,O
659,global,B
659,representation,I
659,is,B
659,generated,B
659,using,B
659,a,O
659,GRU,B
659,that,O
659,intakes,B
659,output,B
659,of,B
659,the,O
659,local,B
659,GRUs,I
659,.,O
660,For,B
660,each,B
660,instance,I
660,in,B
660,the,O
660,context,B
660,-,I
660,window,I
660,",",O
660,the,O
660,output,B
660,of,B
660,this,O
660,global,B
660,GRU,I
660,is,O
660,stored,B
660,as,I
660,a,O
660,memory,B
660,cell,I
660,.,O
661,RESIDE,O
661,:,O
661,Improving,O
661,Distantly,B
661,-,I
661,Supervised,I
661,Neural,I
661,Relation,I
661,Extraction,I
661,using,O
661,Side,O
661,Information,O
662,An,O
662,interpolation,B
662,between,B
662,a,I
662,C,B
662,-,I
662,GCN,I
662,and,I
662,a,O
662,PA,O
662,-,O
662,LSTM,O
662,further,B
662,improves,I
662,the,O
662,result,B
662,to,B
662,68.2,B
662,.,O
663,These,O
663,memories,B
663,are,O
663,then,O
663,subjected,B
663,to,I
663,multiple,B
663,read,I
663,/,I
663,write,I
663,cycles,I
663,that,B
663,include,I
663,attention,B
663,mechanism,I
663,for,B
663,generating,I
663,contextual,B
663,summaries,I
663,of,B
663,the,O
663,conversational,B
663,history,I
663,.,O
664,At,B
664,each,B
664,iteration,I
664,",",O
664,the,O
664,representation,O
664,of,O
664,the,O
664,test,O
664,utterance,O
664,is,O
664,improved,B
664,with,I
664,this,O
664,summary,B
664,representation,O
664,and,O
664,finally,O
664,used,B
664,for,I
664,prediction,B
664,.,O
665,ICON,O
665,:,O
665,Interactive,O
665,Conversational,O
665,Memory,O
665,Network,O
665,for,O
665,Multimodal,B
665,Emotion,I
665,Detection,I
666,ICON,B
666,performs,B
666,better,I
666,than,I
666,the,O
666,compared,B
666,models,I
666,with,B
666,significant,B
666,performance,I
666,increase,I
666,in,B
666,emotions,O
666,(,O
666,?,O
667,Also,O
667,",",O
667,ICON,O
667,manages,B
667,to,I
667,correctly,B
667,identify,B
667,the,O
667,relatively,B
667,similar,I
667,excitement,I
667,emotion,I
667,by,B
667,a,O
667,large,B
667,margin,I
667,.,O
668,As,O
668,seen,O
668,",",O
668,the,O
668,trimodal,B
668,network,I
668,provides,B
668,the,O
668,best,B
668,performance,I
668,which,O
668,is,O
668,preceded,B
668,by,I
668,the,O
668,bimodal,B
668,variants,I
668,.,O
669,Interestingly,O
669,",",O
669,the,O
669,audio,B
669,and,I
669,visual,I
669,modality,I
669,",",O
669,on,O
669,their,O
669,own,O
669,",",O
669,do,O
669,not,O
669,provide,O
669,good,O
669,performance,O
669,",",O
669,but,O
669,when,B
669,used,I
669,with,I
669,text,B
669,",",O
669,complementary,B
669,data,I
669,is,O
669,shared,B
669,to,B
669,improve,I
669,over,B
669,all,I
669,performance,O
669,.,O
670,For,B
670,each,B
670,emotion,I
670,",",O
670,ICON,B
670,outperforms,B
670,all,B
670,the,I
670,compared,I
670,models,I
670,except,O
670,for,O
670,happiness,B
670,emotion,O
670,.,O
671,Results,O
671,on,O
671,the,O
671,SemEval,B
671,Dataset,I
672,However,O
672,",",O
672,its,O
672,performance,B
672,is,O
672,still,O
672,at,B
672,par,I
672,with,I
672,c,B
672,LSTM,I
672,without,B
672,a,O
672,significant,B
672,gap,I
672,.,O
673,In,B
673,all,O
673,the,O
673,labels,B
673,",",O
673,ICON,B
673,attains,B
673,improved,B
673,performance,I
673,over,B
673,its,O
673,counterparts,B
673,",",O
673,suggesting,O
673,the,O
673,efficacy,O
673,of,O
673,its,O
673,context,O
673,-,O
673,modeling,O
673,scheme,O
673,.,O
674,presents,B
674,the,O
674,results,O
674,for,O
674,different,B
674,combinations,I
674,of,I
674,modes,I
674,used,B
674,by,I
674,ICON,B
674,on,B
674,IEMOCAP,B
674,.,O
675,Among,B
675,unimodals,B
675,",",O
675,language,B
675,modality,I
675,performs,B
675,the,O
675,best,B
675,",",O
675,reaffirming,O
675,its,O
675,significance,O
675,in,O
675,multimodal,O
675,systems,O
675,.,O
676,We,O
676,first,O
676,study,B
676,the,O
676,effect,B
676,of,I
676,distilling,I
676,from,I
676,unlabeled,I
676,source,I
676,words,I
676,",",O
676,as,O
676,shown,O
676,in,O
676,.,O
677,It,O
677,can,O
677,be,O
677,seen,O
677,that,O
677,unlabeled,O
677,source,O
677,words,O
677,can,O
677,boost,B
677,the,I
677,accuracy,B
677,by,I
677,nearly,B
677,1,I
677,%,I
677,WER,I
677,",",O
677,demonstrating,B
677,the,O
677,effectiveness,O
677,by,O
677,introducing,B
677,abundant,I
677,unlabeled,O
677,data,O
677,into,B
677,knowledge,B
677,distillation,I
677,.,O
678,Furthermore,O
678,",",O
678,we,O
678,study,O
678,the,O
678,effect,B
678,of,I
678,ensemble,I
678,teacher,I
678,model,I
678,in,I
678,knowledge,I
678,distillation,I
678,.,O
679,As,O
679,shown,O
679,in,O
679,",",O
679,the,O
679,ensemble,O
679,teacher,O
679,model,O
679,can,O
679,boost,B
679,the,O
679,accuracy,B
679,by,B
679,more,B
679,than,I
679,1,I
679,%,I
679,WER,I
679,",",O
679,compared,B
679,with,I
679,the,O
679,single,B
679,teacher,O
679,model,O
679,(,O
679,a,O
679,Transformer,O
679,model,O
679,with,O
679,6,O
679,-,O
679,layer,O
679,encoder,O
679,and,O
679,6,O
679,-,O
679,layer,O
679,decoder,O
679,),O
679,",",O
679,which,O
679,demonstrates,O
679,the,O
679,strong,O
679,ensemble,O
679,teacher,O
679,model,O
679,is,O
679,essential,O
679,to,O
679,guarantee,O
679,the,O
679,performance,O
679,of,O
679,student,O
679,model,O
679,in,O
679,knowledge,O
679,distillation,O
679,.,O
680,At,O
680,last,O
680,",",O
680,we,O
680,compare,B
680,Transformer,B
680,with,B
680,RNN,B
680,and,I
680,CNN,I
680,based,I
680,models,I
680,",",O
680,without,B
680,using,I
680,knowledge,B
680,distillation,I
680,and,O
680,unlabeled,O
680,data,O
680,",",O
680,as,O
680,shown,O
680,in,O
680,.,O
681,We,O
681,can,O
681,see,O
681,that,O
681,Transformer,O
681,model,O
681,outperforms,B
681,the,O
681,RNN,B
681,and,I
681,CNN,I
681,based,I
681,models,I
681,used,O
681,in,O
681,previous,O
681,works,O
681,",",O
681,demonstrating,O
681,the,O
681,advantage,O
681,of,O
681,Transformer,O
681,model,O
681,.,O
682,We,O
682,find,B
682,that,I
682,under,I
682,the,O
682,conventional,B
682,with-,I
682,entity,I
682,evaluation,I
682,",",O
682,our,B
682,C,I
682,-,I
682,GCN,I
682,model,I
682,outperforms,B
682,all,B
682,existing,I
682,dependency,I
682,-,O
682,based,O
682,neural,O
682,models,O
682,on,O
682,this,O
682,sep,O
682,-,O
682,arate,O
682,dataset,O
682,.,O
683,Inspired,O
683,by,O
683,the,O
683,knowledge,O
683,distillation,O
683,in,O
683,computer,O
683,vision,O
683,and,O
683,natural,O
683,language,O
683,processing,O
683,",",O
683,in,O
683,this,O
683,work,O
683,",",O
683,we,O
683,propose,B
683,the,O
683,token,B
683,-,I
683,level,I
683,ensemble,I
683,distillation,O
683,for,B
683,G2P,B
683,conversion,I
683,",",O
683,to,O
683,address,O
683,the,O
683,practical,O
683,problems,O
683,mentioned,O
683,above,O
683,.,O
684,First,O
684,",",O
684,we,O
684,use,B
684,knowledge,B
684,distillation,I
684,to,B
684,leverage,I
684,the,O
684,large,B
684,amount,I
684,of,I
684,unlabeled,I
684,words,I
684,.,O
685,Specifically,O
685,",",O
685,we,O
685,train,B
685,a,O
685,teacher,B
685,model,I
685,to,B
685,generate,I
685,the,O
685,phoneme,B
685,sequence,I
685,as,I
685,well,I
685,as,O
685,its,O
685,probability,B
685,distribution,I
685,given,B
685,unlabeled,B
685,grapheme,I
685,sequence,O
685,",",O
685,and,O
685,regard,O
685,the,O
685,unlabeled,O
685,grapheme,O
685,sequence,O
685,and,O
685,the,O
685,generated,O
685,phoneme,O
685,sequence,O
685,as,O
685,pseudo,O
685,labeled,O
685,data,O
685,",",O
685,and,O
685,add,O
685,them,O
685,into,O
685,the,O
685,original,O
685,training,O
685,data,O
685,.,O
686,Second,O
686,",",O
686,we,O
686,train,B
686,a,O
686,variety,B
686,of,I
686,models,I
686,(,I
686,CNN,I
686,",",O
686,RNN,O
686,and,O
686,Transformer,O
686,),O
686,for,O
686,ensemble,O
686,to,B
686,get,I
686,higher,B
686,accuracy,I
686,",",O
686,and,O
686,transfer,B
686,the,I
686,knowledge,B
686,of,O
686,the,O
686,ensemble,O
686,models,O
686,to,O
686,a,O
686,light,B
686,-,I
686,weight,I
686,model,I
686,that,O
686,is,O
686,suitable,B
686,for,O
686,online,B
686,deployment,I
686,",",O
686,again,O
686,by,O
686,knowledge,O
686,distillation,O
686,.,O
687,Besides,O
687,",",O
687,we,O
687,adopt,B
687,Transformer,B
687,instead,B
687,of,I
687,RNN,B
687,or,I
687,CNN,I
687,as,B
687,the,O
687,basic,B
687,encoder,I
687,-,I
687,decoder,I
687,model,I
687,structure,I
687,",",O
687,since,O
687,it,O
687,demonstrates,O
687,advantages,O
687,in,O
687,a,O
687,variety,O
687,of,O
687,sequence,O
687,to,O
687,sequence,O
687,tasks,O
687,",",O
687,such,O
687,as,O
687,neural,O
687,machine,O
687,translation,O
687,",",O
687,text,O
687,summarization,O
687,",",O
687,automatic,O
687,speech,O
687,recognition,O
687,.,O
688,We,O
688,use,B
688,4,B
688,Transformer,I
688,models,I
688,",",O
688,3,B
688,CNN,I
688,models,O
688,and,O
688,3,O
688,Bi,O
688,-,O
688,LSTM,O
688,models,O
688,with,O
688,different,O
688,hyperparameters,O
688,for,O
688,ensemble,O
688,",",O
688,which,O
688,give,O
688,the,O
688,best,O
688,performance,O
688,on,O
688,the,O
688,validation,O
688,set,O
688,.,O
689,The,O
689,4,B
689,Transformer,I
689,models,I
689,share,B
689,the,O
689,same,B
689,hidden,I
689,size,I
689,(,I
689,256,I
689,),I
689,but,O
689,vary,B
689,in,I
689,the,O
689,number,B
689,of,I
689,the,O
689,encoder,O
689,-,O
689,decoder,O
689,layers,O
689,.,O
690,For,O
690,the,O
690,3,O
690,CNN,O
690,models,O
690,",",O
690,they,O
690,share,B
690,the,O
690,same,B
690,hidden,I
690,size,I
690,(,I
690,256,I
690,),I
690,but,O
690,vary,B
690,in,I
690,the,O
690,number,B
690,of,I
690,encoder,I
690,-,I
690,decoder,I
690,layers,I
690,(,O
690,10,O
690,-,O
690,10,O
690,",",O
690,10,O
690,-,O
690,10,O
690,",",O
690,8,O
690,-,O
690,8,O
690,),O
690,and,O
690,convolutional,O
690,kernel,O
690,widths,O
690,(,O
690,3,O
690,",",O
690,2,O
690,",",O
690,2,O
690,),O
690,respectively,O
690,.,O
691,For,O
691,the,O
691,3,B
691,Bi,I
691,-,I
691,LSTM,I
691,models,I
691,",",I
691,they,O
691,share,B
691,the,O
691,same,B
691,number,I
691,of,I
691,encoder,I
691,-,O
691,decoder,O
691,layers,O
691,(,O
691,1,O
691,-,O
691,1,O
691,),O
691,",",O
691,but,O
691,with,B
691,different,I
691,hidden,B
691,sizes,I
691,(,O
691,256,O
691,",",O
691,384,O
691,and,O
691,512,O
691,),O
691,.,O
692,Notably,O
692,",",O
692,by,B
692,properly,I
692,incorporating,I
692,off,B
692,-,I
692,path,I
692,information,I
692,",",O
692,our,B
692,model,I
692,outperforms,B
692,the,O
692,previous,B
692,shortest,I
692,dependency,I
692,path,O
692,-,O
692,based,O
692,model,O
692,(,O
692,SDP,O
692,-,O
692,LSTM,O
692,),O
692,.,O
693,We,O
693,choose,B
693,Transformer,B
693,as,O
693,the,O
693,student,O
693,model,O
693,and,O
693,use,B
693,the,O
693,default,B
693,configurations,I
693,(,I
693,256,I
693,hidden,I
693,size,I
693,and,O
693,6,O
693,-,O
693,6,O
693,layers,O
693,of,O
693,encoder,O
693,-,O
693,decoder,O
693,),O
693,unless,O
693,otherwise,O
693,stated,O
693,.,O
694,We,O
694,implement,B
694,experiments,I
694,with,I
694,the,O
694,fairseq,B
694,-,I
694,py,I
694,4,I
694,library,I
694,in,I
694,Py-Torch,I
694,.,O
695,We,O
695,use,B
695,Adam,B
695,optimizer,I
695,for,B
695,all,B
695,models,I
695,and,O
695,follow,B
695,the,O
695,learning,B
695,rate,I
695,schedule,I
695,in,O
695,.,O
696,We,O
696,use,O
696,beam,B
696,search,I
696,during,B
696,inference,B
696,and,O
696,set,B
696,beam,O
696,size,O
696,to,O
696,10,O
696,.,O
697,We,O
697,use,O
697,WER,B
697,(,I
697,word,I
697,error,I
697,rate,I
697,),I
697,and,I
697,PER,I
697,(,O
697,phoneme,O
697,error,O
697,rate,O
697,),O
697,to,B
697,measure,I
697,the,O
697,accuracy,B
697,of,I
697,G2P,I
697,conversion,I
697,.,O
698,The,O
698,dropout,O
698,is,B
698,0.3,B
698,for,B
698,Bi,B
698,-,I
698,LSTM,I
698,and,I
698,CNN,I
698,models,I
698,",",I
698,while,O
698,the,O
698,residual,B
698,dropout,O
698,",",O
698,attention,O
698,dropout,O
698,and,O
698,ReLU,O
698,dropout,O
698,for,O
698,Transformer,B
698,models,O
698,is,O
698,0.2,B
698,",",O
698,0.4,O
698,",",O
698,0.4,O
698,respectively,O
698,.,O
699,We,O
699,train,B
699,each,B
699,model,I
699,on,B
699,8,B
699,NVIDIA,I
699,M40,I
699,GPUs,I
699,.,O
700,Each,O
700,GPU,O
700,contains,B
700,roughly,B
700,4000,I
700,tokens,I
700,in,B
700,one,B
700,mini-batch,I
700,.,O
701,Token,O
701,-,O
701,Level,O
701,Ensemble,O
701,Distillation,O
701,for,O
701,Grapheme,B
701,-,O
701,to,O
701,-,O
701,Phoneme,O
701,Conversion,O
702,Under,B
702,the,O
702,mask,B
702,-,I
702,entity,I
702,evaluation,I
702,",",O
702,our,B
702,C,I
702,-,O
702,GCN,O
702,model,O
702,also,O
702,outperforms,B
702,PA,B
702,-,O
702,LSTM,O
702,by,B
702,a,O
702,substantial,B
702,margin,I
702,",",O
702,suggesting,O
702,its,O
702,generalizability,O
702,even,O
702,when,O
702,entities,O
702,are,O
702,not,O
702,seen,O
702,.,O
703,We,O
703,first,O
703,compare,O
703,our,O
703,method,O
703,with,O
703,previous,O
703,works,O
703,on,B
703,CMUDict,B
703,0.7,O
703,b,O
703,dataset,O
703,",",O
703,as,O
703,shown,O
703,in,O
703,.,O
704,It,O
704,can,B
704,be,I
704,seen,I
704,that,O
704,our,B
704,method,I
704,on,I
704,6,I
704,-,I
704,layer,I
704,encoder,I
704,and,I
704,6,O
704,-,O
704,layer,O
704,decoder,O
704,Transformer,O
704,achieves,B
704,the,I
704,new,B
704,state,I
704,-,O
704,of,B
704,-,O
704,the,O
704,-,O
704,art,O
704,result,O
704,of,O
704,19.88,B
704,%,I
704,WER,I
704,",",O
704,outperforming,B
704,NSGD,B
704,by,B
704,4.22,B
704,%,O
704,WER,O
704,.,O
705,We,O
705,compare,O
705,our,O
705,method,O
705,with,O
705,the,O
705,previous,O
705,state,O
705,-,O
705,of,O
705,-,O
705,the,O
705,-,O
705,art,O
705,CNN,B
705,with,O
705,NSGD,O
705,(,O
705,which,O
705,is,O
705,reproduced,O
705,by,B
705,ourself,O
705,),O
705,on,O
705,our,O
705,internal,B
705,dataset,I
705,",",O
705,as,O
705,shown,O
705,in,O
705,.,O
706,Our,O
706,method,O
706,outperforms,B
706,CNN,O
706,with,O
706,NSGD,O
706,by,O
706,3.52,B
706,%,I
706,WER,I
706,",",O
706,which,O
706,demonstrates,B
706,the,O
706,effectiveness,B
706,of,I
706,our,O
706,method,O
706,for,B
706,G2P,B
706,conversion,I
706,.,O
707,We,O
707,propose,O
707,to,O
707,replace,B
707,the,O
707,original,B
707,fully,I
707,connected,I
707,layer,I
707,(,O
707,adopted,O
707,in,O
707,Transformer,O
707,),O
707,with,O
707,1D,O
707,convolution,O
707,in,O
707,FFT,O
707,block,O
707,",",O
707,as,O
707,described,O
707,in,O
707,Section,O
707,3.1,O
707,.,O
708,As,O
708,shown,O
708,in,O
708,",",O
708,replacing,O
708,1D,O
708,convolution,O
708,with,O
708,fully,O
708,connected,O
708,layer,O
708,results,B
708,in,O
708,-,B
708,0.113,I
708,CMOS,I
708,",",O
708,which,O
708,demonstrates,O
708,the,O
708,effectiveness,O
708,of,O
708,1D,O
708,convolution,O
708,.,O
709,We,O
709,find,O
709,that,O
709,removing,B
709,sequence,B
709,-,B
709,level,I
709,knowledge,I
709,distillation,I
709,results,B
709,in,I
709,-,O
709,0.325,O
709,CMOS,O
709,",",O
709,which,O
709,demonstrates,O
709,the,O
709,effectiveness,O
709,of,O
709,sequence,O
709,-,O
709,level,O
709,knowledge,O
709,distillation,O
709,.,O
710,To,O
710,show,B
710,the,I
710,effectiveness,B
710,of,B
710,path,B
710,-,I
710,centric,I
710,pruning,I
710,",",O
710,we,O
710,compare,B
710,the,O
710,two,B
710,GCN,I
710,models,I
710,and,I
710,the,O
710,Tree,O
710,-,O
710,LSTM,O
710,when,B
710,the,O
710,pruning,O
710,distance,O
710,K,O
710,is,O
710,varied,O
710,.,O
711,We,O
711,first,O
711,train,B
711,the,O
711,autoregressive,B
711,Transformer,I
711,TTS,I
711,model,I
711,on,B
711,4,B
711,NVIDIA,I
711,V100,I
711,GPUs,I
711,",",O
711,with,B
711,batchsize,B
711,of,I
711,16,I
711,sentences,I
711,on,O
711,each,O
711,GPU,O
711,.,O
712,We,O
712,use,B
712,the,O
712,Adam,B
712,optimizer,I
712,with,B
712,?,O
713,In,O
713,addition,O
713,",",O
713,we,O
713,also,O
713,leverage,B
713,sequence,B
713,-,I
713,level,I
713,knowledge,I
713,distillation,I
713,that,O
713,has,O
713,achieved,O
713,good,O
713,performance,O
713,in,O
713,non-autoregressive,O
713,machine,O
713,translation,O
713,to,O
713,transfer,O
713,the,O
713,knowledge,O
713,from,O
713,the,O
713,teacher,O
713,model,O
713,to,O
713,the,O
713,student,O
713,model,O
713,.,O
714,In,O
714,the,O
714,inference,O
714,process,O
714,",",O
714,the,O
714,output,B
714,mel-spectrograms,I
714,of,O
714,our,O
714,FastSpeech,O
714,model,O
714,are,O
714,transformed,B
714,into,I
714,audio,B
714,samples,I
714,using,I
714,the,O
714,pretrained,O
714,WaveGlow,O
714,[,O
714,20,O
714,],O
714,5,O
714,.,O
715,Considering,O
715,the,O
715,monotonous,O
715,alignment,O
715,between,O
715,text,B
715,and,O
715,speech,O
715,",",O
715,to,O
715,speedup,O
715,mel-,O
715,spectrogram,O
715,generation,O
715,",",O
715,in,O
715,this,O
715,work,O
715,",",O
715,we,O
715,propose,B
715,a,O
715,novel,O
715,model,O
715,",",O
715,FastSpeech,B
715,",",O
715,which,O
715,takes,B
715,a,O
715,text,O
715,(,O
715,phoneme,O
715,),O
715,sequence,O
715,as,O
715,input,O
715,and,O
715,generates,B
715,mel-spectrograms,B
715,non-autoregressively,I
715,.,O
716,It,O
716,adopts,B
716,a,O
716,feed,B
716,-,I
716,forward,I
716,network,I
716,based,B
716,on,I
716,the,O
716,self,B
716,-,O
716,attention,O
716,in,O
716,Transformer,O
716,and,O
716,1D,O
716,convolution,O
716,.,O
717,Since,O
717,a,O
717,mel-spectrogram,O
717,sequence,O
717,is,O
717,much,O
717,longer,O
717,than,O
717,its,O
717,corresponding,O
717,phoneme,O
717,sequence,O
717,",",O
717,in,O
717,order,O
717,to,O
717,solve,O
717,the,O
717,problem,O
717,of,O
717,length,B
717,mismatch,O
717,between,O
717,the,O
717,two,O
717,sequences,O
717,",",O
717,FastSpeech,O
717,adopts,O
717,a,O
717,length,O
717,regulator,O
717,that,O
717,up,B
717,-,I
717,samples,I
717,the,O
717,phoneme,O
717,sequence,O
717,according,O
717,to,O
717,the,O
717,phoneme,O
717,duration,O
717,(,O
717,i.e.,O
718,",",O
718,the,O
718,number,O
718,of,O
718,mel-,O
718,spectrograms,O
718,that,O
718,each,O
718,phoneme,O
718,corresponds,O
718,to,B
718,),O
718,to,O
718,match,O
718,the,O
718,length,B
718,of,O
718,the,O
718,mel-spectrogram,O
718,sequence,O
718,.,O
719,The,O
719,regulator,O
719,is,O
719,built,B
719,on,I
719,a,O
719,phoneme,O
719,duration,B
719,predictor,I
719,",",O
719,which,O
719,predicts,B
719,the,O
719,duration,O
719,of,O
719,each,O
719,phoneme,O
719,.,O
720,FastSpeech,O
720,:,O
720,Fast,O
720,",",O
720,Robust,O
720,and,O
720,Controllable,O
720,Text,B
720,to,I
720,Speech,I
721,As,O
721,shown,O
721,in,O
721,",",O
721,the,O
721,performance,B
721,of,O
721,all,O
721,three,O
721,models,O
721,peaks,B
721,when,O
721,K,O
721,=,O
721,1,O
721,",",O
721,outperforming,B
721,their,O
721,respective,B
721,dependency,I
721,path,I
721,-,I
721,based,I
721,counterpart,I
721,(,I
721,K,O
721,=,O
721,0,O
721,),O
721,.,O
722,We,O
722,conduct,B
722,the,O
722,MOS,B
722,(,I
722,mean,I
722,opinion,I
722,score,I
722,),I
722,evaluation,I
722,on,B
722,the,O
722,test,B
722,set,I
722,to,B
722,measure,I
722,the,O
722,audio,B
722,quality,I
722,.,O
723,Robustness,B
724,It,O
724,can,B
724,be,I
724,seen,I
724,that,I
724,Transformer,B
724,TTS,I
724,is,O
724,not,B
724,robust,I
724,to,B
724,these,O
724,hard,B
724,cases,I
724,and,I
724,gets,B
724,34,B
724,%,I
724,error,I
724,rate,I
724,",",O
724,while,O
724,FastSpeech,B
724,can,O
724,effectively,B
724,eliminate,I
724,word,B
724,repeating,I
724,and,O
724,skipping,O
724,to,O
724,improve,O
724,intelligibility,B
724,.,O
725,As,O
725,demonstrated,B
725,by,I
725,the,I
725,samples,B
725,",",O
725,FastSpeech,B
725,can,B
725,adjust,I
725,the,O
725,voice,O
725,speed,O
725,from,B
725,0.5x,I
725,to,I
725,1.5,I
725,x,I
725,smoothly,I
725,",",O
725,with,B
725,stable,B
725,and,I
725,almost,I
725,unchanged,I
725,pitch,I
725,.,O
726,Our,O
726,approach,O
726,is,O
726,to,B
726,decouple,I
726,speaker,I
726,modeling,I
726,from,B
726,speech,B
726,synthesis,I
726,by,I
726,independently,I
726,training,B
726,a,O
726,speaker,O
726,-,O
726,discriminative,O
726,embedding,O
726,network,O
726,that,O
726,captures,B
726,the,I
726,space,B
726,of,I
726,speaker,O
726,characteristics,O
726,and,O
726,training,O
726,a,O
726,high,B
726,quality,I
726,TTS,I
726,model,I
726,on,I
726,a,O
726,smaller,B
726,dataset,I
726,conditioned,B
726,on,O
726,the,O
726,representation,B
726,learned,I
726,by,O
726,the,O
726,first,O
726,network,O
726,.,O
727,We,O
727,train,B
727,the,I
727,speaker,I
727,embedding,I
727,network,I
727,on,B
727,a,O
727,speaker,O
727,verification,O
727,task,O
727,to,B
727,determine,I
727,if,O
727,two,B
727,different,I
727,utterances,I
727,were,I
727,spoken,I
727,by,I
727,the,O
727,same,O
727,speaker,O
727,.,O
728,We,O
728,find,B
728,that,I
728,all,B
728,three,I
728,models,I
728,are,B
728,less,B
728,effective,I
728,when,B
728,the,O
728,entire,B
728,dependency,I
728,tree,I
728,is,B
728,present,B
728,",",O
728,indicating,O
728,that,O
728,including,O
728,extra,O
728,information,O
728,hurts,O
728,performance,O
728,.,O
729,In,O
729,contrast,O
729,to,O
729,the,O
729,subsequent,O
729,TTS,O
729,model,O
729,",",O
729,this,O
729,network,O
729,is,O
729,trained,B
729,on,I
729,untranscribed,B
729,speech,I
729,containing,B
729,reverberation,B
729,and,I
729,background,I
729,noise,I
729,from,B
729,a,O
729,large,B
729,number,I
729,of,I
729,speakers,I
729,.,O
730,Transfer,O
730,Learning,O
730,from,O
730,Speaker,O
730,Verification,O
730,to,O
730,Multispeaker,O
730,Text,B
730,-,I
730,To,O
730,-,O
730,Speech,O
730,Synthesis,O
731,We,O
731,describe,O
731,a,O
731,neural,O
731,network,O
731,-,O
731,based,O
731,system,O
731,for,O
731,text,B
731,-,O
731,to,O
731,-,O
731,speech,O
731,(,O
731,TTS,O
731,),O
731,synthesis,O
731,that,O
731,is,O
731,able,O
731,to,O
731,generate,O
731,speech,O
731,audio,O
731,in,O
731,the,O
731,voice,O
731,of,O
731,different,O
731,speakers,O
731,",",O
731,including,O
731,those,O
731,unseen,O
731,during,O
731,training,O
731,.,O
732,The,O
732,goal,O
732,of,O
732,this,O
732,work,O
732,is,O
732,to,O
732,build,B
732,a,I
732,TTS,I
732,system,I
732,which,O
732,can,O
732,generate,O
732,natural,O
732,speech,O
732,for,O
732,a,O
732,variety,O
732,of,O
732,speakers,O
732,in,O
732,a,O
732,data,O
732,efficient,O
732,manner,O
732,.,O
733,The,O
733,proposed,B
733,model,I
733,achieved,B
733,about,B
733,4.0,I
733,MOS,I
733,in,B
733,all,B
733,datasets,I
733,",",O
733,with,O
733,the,O
733,VCTK,O
733,model,O
733,obtaining,O
733,a,O
733,MOS,O
733,about,O
733,0.2,O
733,points,O
733,higher,O
733,than,O
733,the,O
733,LibriSpeech,O
733,model,O
733,when,O
733,evaluated,O
733,on,O
733,seen,O
733,speakers,O
733,.,O
734,Most,O
734,importantly,O
734,",",O
734,the,O
734,audio,B
734,generated,B
734,by,O
734,our,O
734,model,O
734,for,O
734,unseen,B
734,speakers,I
734,is,B
734,deemed,I
734,to,I
734,be,I
734,at,I
734,least,I
734,as,I
734,natural,I
734,as,O
734,that,O
734,generated,O
734,for,O
734,seen,O
734,speakers,O
734,.,O
735,Surprisingly,O
735,",",O
735,the,O
735,MOS,B
735,on,B
735,unseen,I
735,speakers,I
735,is,B
735,higher,I
735,than,I
735,that,O
735,of,O
735,seen,B
735,speakers,O
735,",",O
735,by,B
735,as,I
735,much,I
735,as,O
735,0.2,B
735,points,I
735,on,O
735,LibriSpeech,B
735,.,O
736,The,O
736,scores,B
736,for,I
736,the,O
736,VCTK,B
736,model,I
736,tend,B
736,to,I
736,be,I
736,higher,I
736,than,I
736,those,I
736,for,O
736,LibriSpeech,B
736,",",O
736,reflecting,B
736,the,O
736,cleaner,B
736,nature,I
736,of,I
736,the,O
736,dataset,O
736,.,O
737,Finally,O
737,",",O
737,we,O
737,note,O
737,that,O
737,contextualizing,B
737,the,O
737,GCN,B
737,makes,B
737,it,I
737,less,B
737,sensitive,I
737,to,B
737,changes,B
737,in,B
737,the,O
737,tree,B
737,structures,I
737,provided,O
737,",",O
737,presumably,O
737,because,O
737,the,O
737,model,O
737,can,O
737,use,O
737,word,O
737,sequence,O
737,information,O
737,in,O
737,the,O
737,LSTM,O
737,layer,O
737,to,O
737,recover,O
737,any,O
737,off,O
737,-,O
737,path,O
737,information,O
737,that,O
737,it,O
737,needs,O
737,for,O
737,correct,O
737,relation,O
737,extraction,O
737,.,O
738,For,O
738,seen,B
738,speakers,I
738,on,I
738,VCTK,I
738,",",O
738,the,O
738,proposed,B
738,model,I
738,performs,B
738,about,I
738,as,I
738,well,I
738,as,O
738,the,O
738,baseline,B
738,which,O
738,uses,B
738,an,O
738,embedding,B
738,lookup,I
738,table,I
738,for,O
738,speaker,O
738,conditioning,O
738,.,O
739,As,O
739,shown,O
739,in,O
739,",",O
739,as,O
739,long,O
739,as,O
739,the,O
739,synthesizer,O
739,was,O
739,trained,B
739,on,I
739,a,O
739,sufficiently,O
739,large,O
739,set,O
739,of,O
739,speakers,O
739,",",O
739,i.e.,O
740,on,O
740,LibriSpeech,B
740,",",O
740,the,O
740,synthesized,B
740,speech,I
740,is,O
740,typically,O
740,most,B
740,similar,I
740,to,I
740,the,O
740,ground,B
740,truth,I
740,voices,I
740,.,O
741,On,B
741,this,O
741,20,B
741,voice,I
741,discrimination,I
741,task,I
741,we,O
741,obtain,B
741,an,O
741,EER,B
741,of,I
741,2.86,I
741,%,I
741,",",O
741,demonstrating,O
741,that,O
741,",",O
741,while,O
741,the,O
741,synthetic,O
741,speech,O
741,tends,O
741,to,O
741,be,O
741,close,O
741,to,O
741,the,O
741,target,O
741,speaker,O
741,(,O
741,cosine,O
741,similarity,O
741,>,O
741,0.6,O
741,",",O
741,and,O
741,as,O
741,in,O
741,),O
741,",",O
741,it,O
741,is,O
741,nearly,O
741,always,O
741,even,O
741,closer,O
741,to,O
741,other,O
741,synthetic,O
741,utterances,O
741,for,O
741,the,O
741,same,O
741,speaker,O
741,(,O
741,similarity,O
741,>,O
741,0.7,O
741,),O
741,.,O
742,The,O
742,PCA,B
742,visualization,I
742,(,O
742,left,O
742,),O
742,shows,B
742,that,O
742,synthesized,B
742,utterances,I
742,tend,B
742,to,I
742,lie,I
742,very,I
742,close,I
742,to,O
742,real,B
742,speech,I
742,from,I
742,the,O
742,same,O
742,speaker,O
742,in,B
742,the,O
742,embedding,B
742,space,I
742,.,O
743,However,O
743,",",O
743,synthetic,O
743,utterances,O
743,are,O
743,still,O
743,easily,B
743,distinguishable,I
743,from,B
743,the,O
743,real,O
743,human,O
743,speech,O
743,as,O
743,demonstrated,B
743,by,O
743,the,O
743,t,B
743,-,I
743,SNE,I
743,visualization,I
743,(,O
743,right,O
743,),O
743,where,B
743,utterances,O
743,from,O
743,each,B
743,synthetic,O
743,speaker,O
743,form,O
743,a,O
743,distinct,B
743,cluster,B
743,adjacent,B
743,to,I
743,a,O
743,cluster,O
743,of,O
743,real,O
743,utterances,O
743,from,O
743,the,O
743,corresponding,B
743,speaker,O
743,.,O
744,As,B
744,the,O
744,number,B
744,of,I
744,training,I
744,speakers,I
744,increases,B
744,",",O
744,both,B
744,naturalness,I
744,and,I
744,similarity,I
744,improve,B
744,significantly,I
744,.,O
745,In,O
745,this,O
745,paper,O
745,",",O
745,we,O
745,propose,B
745,a,O
745,novel,B
745,word,I
745,-,I
745,level,I
745,approach,I
745,for,B
745,distant,B
745,supervised,I
745,relation,I
745,extraction,I
745,by,B
745,reducing,I
745,inner-sentence,B
745,noise,I
745,and,O
745,improving,B
745,robustness,B
745,against,B
745,noisy,B
745,words,I
745,.,O
746,Bypassing,B
746,the,O
746,speaker,B
746,encoder,I
746,network,I
746,and,O
746,conditioning,B
746,the,O
746,synthesizer,B
746,on,B
746,random,B
746,points,I
746,in,B
746,the,O
746,speaker,O
746,embedding,O
746,space,O
746,results,O
746,in,O
746,speech,O
746,from,B
746,fictitious,O
746,speakers,O
746,which,O
746,are,O
746,not,O
746,present,O
746,in,O
746,the,O
746,train,O
746,or,O
746,test,O
746,sets,O
746,of,O
746,either,O
746,the,O
746,synthesizer,O
746,or,O
746,the,O
746,speaker,O
746,encoder,O
746,.,O
747,All,O
747,experiments,O
747,discussed,O
747,in,O
747,this,O
747,work,O
747,have,O
747,been,O
747,done,B
747,on,I
747,the,O
747,Google,B
747,Colab,I
747,7,I
747,environment,I
747,using,B
747,Tesla,B
747,T4,I
747,GPU,I
747,accelerator,I
747,with,O
747,the,O
747,following,O
747,hyperparameters,O
747,:,O
748,We,O
748,then,O
748,build,B
748,a,O
748,neural,B
748,network,I
748,model,I
748,with,B
748,four,B
748,components,I
748,.,O
749,The,O
749,model,O
749,uses,B
749,ELMo,B
749,(,I
749,which,I
749,stands,I
749,for,I
749,Embeddings,I
749,from,I
749,Language,I
749,Models,I
749,),I
749,pre-trained,I
749,contextual,I
749,embeddings,O
749,as,B
749,an,O
749,input,B
749,and,O
749,builds,B
749,sequence,B
749,representation,I
749,vectors,I
749,that,O
749,are,O
749,used,O
749,to,B
749,predict,I
749,the,O
749,relation,B
749,between,I
749,the,O
749,question,O
749,pairs,O
749,.,O
750,Tha3aroon,O
750,at,O
750,NSURL,O
750,-,O
750,2019,O
750,Task,O
750,8,O
750,:,O
750,Semantic,B
750,Question,I
750,Similarity,I
750,in,I
750,Arabic,I
751,In,O
751,this,O
751,paper,O
751,",",O
751,we,O
751,describe,O
751,our,O
751,team,O
751,'s,O
751,effort,O
751,on,O
751,the,O
751,semantic,B
751,text,I
751,question,I
751,similarity,I
751,task,O
751,of,O
751,NSURL,O
751,2019,O
751,.,O
752,For,O
752,example,O
752,",",O
752,in,O
752,the,O
752,paraphrase,O
752,identification,O
752,task,O
752,",",O
752,STS,B
752,is,O
752,used,O
752,to,O
752,predict,O
752,if,O
752,one,O
752,sentence,O
752,is,O
752,a,O
752,paraphrase,O
752,of,O
752,the,O
752,other,O
752,or,O
752,not,O
752,.,O
753,A,O
753,new,O
753,task,O
753,has,O
753,been,O
753,proposed,O
753,by,O
753,Mawdoo3,O
753,1,O
753,company,O
753,with,O
753,a,O
753,new,O
753,dataset,O
753,provided,O
753,by,O
753,their,O
753,data,O
753,annotation,O
753,team,O
753,for,O
753,Semantic,B
753,Question,I
753,Similarity,I
753,(,I
753,SQS,I
753,),I
753,for,O
753,the,O
753,Arabic,O
753,language,O
753,.,O
754,SQS,B
754,is,O
754,a,O
754,variant,O
754,of,O
754,STS,O
754,",",O
754,which,O
754,aims,O
754,to,O
754,compare,O
754,a,O
754,pair,O
754,of,O
754,questions,O
754,and,O
754,determine,O
754,whether,O
754,they,O
754,have,O
754,the,O
754,same,O
754,meaning,O
754,or,O
754,not,O
754,.,O
755,To,O
755,reduce,O
755,innersentence,B
755,noise,I
755,",",O
755,we,O
755,utilize,B
755,a,O
755,novel,B
755,Sub,I
755,-,I
755,Tree,I
755,Parse,I
755,(,I
755,STP,I
755,),I
755,method,I
755,to,O
755,remove,O
755,irrelevant,B
755,words,I
755,by,B
755,intercepting,I
755,a,O
755,subtree,B
755,under,B
755,the,O
755,parent,B
755,of,I
755,entities,I
755,',I
755,lowest,I
755,common,I
755,ancestor,I
755,.,O
756,The,O
756,tables,O
756,show,O
756,that,O
756,while,O
756,GRU,B
756,cells,I
756,are,B
756,the,O
756,most,B
756,efficient,I
756,",",O
756,the,O
756,ON,B
756,-,I
756,LSTM,I
756,cells,O
756,(,O
756,with,B
756,chunk,B
756,size,I
756,8,I
756,),O
756,are,O
756,the,O
756,most,O
756,effective,O
756,(,O
756,in,B
756,terms,I
756,of,I
756,all,B
756,considered,I
756,measures,I
756,),O
756,.,O
757,The,O
757,tables,O
757,show,B
757,that,O
757,each,B
757,augmentation,I
757,step,I
757,affects,B
757,the,O
757,model,B
757,'s,I
757,efficiency,I
757,negatively,B
757,.,O
758,On,B
758,the,O
758,other,O
758,hand,O
758,",",O
758,not,B
758,each,B
758,increment,I
758,step,I
758,has,O
758,a,O
758,positive,B
758,effect,I
758,on,O
758,the,O
758,model,B
758,'s,I
758,effectiveness,I
758,.,O
759,However,O
759,",",O
759,the,O
759,sequence,B
759,weighted,I
759,attention,I
759,gives,B
759,better,B
759,results,I
759,by,B
759,about,B
759,1,I
759,point,I
759,of,B
759,the,O
759,F1-score,B
759,.,O
760,For,O
760,example,O
760,",",O
760,using,B
760,pre-trained,B
760,FastText,I
760,embeddings,I
760,as,B
760,an,O
760,input,B
760,to,B
760,our,B
760,model,I
760,yields,B
760,worse,B
760,F1score,I
760,on,B
760,both,O
760,public,B
760,and,I
760,private,I
760,leaderboards,I
760,with,I
760,94.254,B
760,and,O
760,93.118,O
760,",",O
760,respectively,O
760,",",O
760,compared,B
760,with,O
760,the,O
760,ELMo,B
760,contextual,I
760,embeddings,O
760,model,O
760,.,O
761,Moreover,O
761,",",O
761,an,O
761,attempt,O
761,to,B
761,overcome,B
761,the,O
761,weakness,B
761,of,B
761,the,O
761,Arabic,B
761,ELMo,I
761,model,I
761,is,O
761,done,O
761,by,B
761,translating,I
761,the,O
761,data,B
761,to,O
761,English,B
761,using,B
761,Google,B
761,Translate,I
761,8,O
761,and,O
761,treating,B
761,the,O
761,problem,O
761,as,B
761,an,O
761,English,O
761,SQS,O
761,problem,O
761,instead,O
761,",",O
761,but,O
761,the,O
761,results,B
761,are,I
761,much,B
761,worse,I
761,with,B
761,88.868,B
761,and,O
761,87.504,O
761,F1,O
761,-,O
761,scores,O
761,on,B
761,public,B
761,and,O
761,private,O
761,leaderboards,O
761,",",O
761,respectively,O
761,.,O
762,The,O
762,answer,B
762,position,I
762,indicator,I
762,",",O
762,as,O
762,expected,O
762,",",O
762,plays,B
762,a,O
762,crucial,B
762,role,I
762,in,B
762,answer,O
762,focused,O
762,question,O
762,generation,O
762,as,O
762,shown,O
762,in,O
762,the,O
762,NQG,O
762,?,O
763,NER,O
763,",",O
763,show,B
763,that,I
763,word,B
763,case,I
763,",",O
763,POS,O
763,and,O
763,NER,O
763,tag,O
763,features,O
763,contributes,B
763,to,I
763,question,B
763,generation,I
763,.,O
764,Furthermore,O
764,",",O
764,the,O
764,entity,B
764,-,I
764,wise,I
764,attention,I
764,is,O
764,adopted,O
764,to,B
764,alleviate,I
764,the,O
764,influence,B
764,of,I
764,noisy,I
764,words,I
764,in,B
764,the,O
764,subtree,B
764,and,O
764,emphasize,B
764,the,O
764,task,B
764,-,O
764,relevant,O
764,features,O
764,.,O
765,The,O
765,rule,B
765,-,I
765,based,I
765,system,I
765,1,O
765,modified,O
765,on,O
765,the,O
765,code,O
765,released,O
765,by,O
765,.,O
766,We,O
766,implement,B
766,a,O
766,seq2seq,B
766,with,I
766,attention,I
766,as,O
766,the,O
766,baseline,O
766,method,O
766,.,O
767,NQG,B
768,We,O
768,extend,B
768,the,O
768,s,B
768,2s+,I
768,att,I
768,with,B
768,our,O
768,feature,B
768,-,I
768,rich,I
768,encoder,I
768,to,B
768,build,I
768,the,O
768,NQG,B
768,system,I
768,.,O
769,NQG,O
769,+,O
769,Based,O
769,on,O
769,NQG,O
769,",",O
769,we,O
769,incorporate,B
769,copy,B
769,mechanism,I
769,to,O
769,deal,B
769,with,I
769,rare,B
769,words,I
769,problem,I
769,.,O
770,NQG,O
770,+,O
770,Pretrain,O
770,Based,B
770,on,I
770,NQG,O
770,+,O
770,",",O
770,we,O
770,initialize,B
770,the,O
770,word,B
770,embedding,I
770,matrix,I
770,with,B
770,pre-trained,B
770,GloVe,I
770,vectors,I
770,.,O
771,NQG,O
771,+,O
771,STshare,O
771,Based,B
771,on,I
771,NQG,O
771,+,O
771,",",O
771,we,O
771,make,B
771,the,O
771,encoder,B
771,and,I
771,decoder,I
771,share,B
771,the,O
771,same,B
771,embedding,I
771,matrix,I
771,.,O
772,Based,O
772,on,O
772,NQG,B
772,+,I
772,",",O
772,we,O
772,use,B
772,both,O
772,pre-train,B
772,word,I
772,embedding,I
772,and,I
772,STshare,I
772,methods,I
772,",",O
772,to,B
772,further,I
772,improve,I
772,the,O
772,performance,B
772,.,O
773,To,O
773,tackle,O
773,the,O
773,second,O
773,challenge,O
773,",",O
773,we,O
773,initialize,B
773,our,O
773,model,B
773,parameters,I
773,with,B
773,a,B
773,priori,I
773,knowledge,I
773,learned,B
773,from,I
773,the,O
773,entity,B
773,type,I
773,classification,I
773,task,I
773,by,B
773,transfer,B
773,learning,I
773,.,O
774,In,O
774,this,O
774,work,O
774,we,O
774,conduct,O
774,a,O
774,preliminary,O
774,study,O
774,on,O
774,question,O
774,generation,O
774,from,O
774,text,O
774,with,O
774,neural,B
774,networks,O
774,",",O
774,which,O
774,is,O
774,denoted,B
774,as,I
774,the,O
774,Neural,O
774,Question,O
774,Generation,O
774,(,O
774,NQG,O
774,),O
774,framework,O
774,",",O
774,to,B
774,generate,I
774,natural,B
774,language,I
774,questions,I
774,from,O
774,text,O
774,without,B
774,pre-defined,B
774,rules,I
774,.,O
775,The,O
775,Neural,B
775,Question,I
775,Generation,I
775,framework,I
775,extends,B
775,the,O
775,sequence,O
775,-,O
775,to,B
775,-,O
775,sequence,O
775,models,O
775,by,B
775,enriching,I
775,the,O
775,encoder,B
775,with,B
775,answer,B
775,and,O
775,lexical,B
775,features,I
775,to,O
775,generate,O
775,answer,O
775,focused,O
775,questions,O
775,.,O
776,Concretely,O
776,",",O
776,the,O
776,encoder,B
776,reads,B
776,not,O
776,only,O
776,the,O
776,input,B
776,sentence,I
776,",",O
776,but,O
776,also,O
776,the,O
776,answer,B
776,position,I
776,indicator,I
776,and,O
776,lexical,B
776,features,I
776,.,O
777,The,O
777,answer,B
777,position,I
777,feature,I
777,denotes,B
777,the,O
777,answer,O
777,span,O
777,in,B
777,the,O
777,input,B
777,sentence,I
777,",",O
777,which,O
777,is,O
777,essential,O
777,to,O
777,generate,O
777,answer,O
777,relevant,O
777,questions,O
777,.,O
778,The,O
778,lexical,B
778,features,I
778,include,B
778,part,B
778,-,I
778,of,I
778,-,O
778,speech,O
778,(,O
778,POS,O
778,),O
778,and,O
778,named,B
778,entity,I
778,(,O
778,NER,O
778,),O
778,tags,O
778,to,B
778,help,I
778,produce,I
778,better,B
778,sentence,I
778,encoding,I
778,.,O
779,Lastly,O
779,",",O
779,the,O
779,decoder,B
779,with,B
779,attention,B
779,mechanism,I
779,generates,B
779,an,O
779,answer,B
779,specific,I
779,question,I
779,of,B
779,the,O
779,sentence,B
779,.,O
780,As,O
780,the,O
780,reverse,O
780,task,O
780,of,O
780,question,B
780,answering,O
780,",",O
780,question,O
780,generation,O
780,also,O
780,has,O
780,the,O
780,potential,O
780,for,O
780,providing,O
780,a,O
780,large,O
780,scale,O
780,corpus,O
780,of,O
780,question,O
780,-,O
780,answer,O
780,pairs,O
780,.,O
781,Mintz,B
781,proposes,B
781,the,O
781,humandesigned,B
781,feature,I
781,model,I
781,.,O
782,Our,O
782,NQG,B
782,framework,I
782,outperforms,B
782,the,O
782,PCFG,B
782,-,I
782,Trans,I
782,and,I
782,s,I
782,2s,I
782,+,I
782,att,I
782,baselines,I
782,by,B
782,a,O
782,large,B
782,margin,I
782,.,O
783,The,O
783,extended,O
783,version,O
783,",",O
783,NQG,B
783,++,I
783,",",O
783,has,O
783,1.11,B
783,BLEU,I
783,score,I
783,gain,I
783,over,B
783,NQG,O
783,+,O
783,",",O
783,which,O
783,shows,O
783,that,O
783,initializing,O
783,with,O
783,pre-trained,O
783,word,O
783,vectors,O
783,and,O
783,sharing,O
783,them,O
783,between,O
783,encoder,O
783,and,O
783,decoder,O
783,help,O
783,learn,O
783,better,O
783,word,O
783,representation,O
783,.,O
784,With,O
784,the,O
784,help,O
784,of,O
784,copy,B
784,mechanism,I
784,",",O
784,NQG,B
784,+,I
784,has,O
784,a,O
784,2.05,B
784,BLEU,I
784,improvement,I
784,since,O
784,it,O
784,solves,O
784,the,O
784,rare,O
784,words,O
784,problem,O
784,.,O
785,To,O
785,solve,O
785,this,O
785,problem,O
785,",",O
785,we,O
785,use,B
785,the,O
785,context,B
785,obtained,O
785,by,B
785,considering,I
785,exemplars,I
785,",",O
785,specifically,O
785,we,O
785,use,O
785,the,O
785,difference,B
785,between,B
785,relevant,B
785,and,I
785,irrelevant,I
785,exemplars,O
785,.,O
786,We,O
786,consider,B
786,different,B
786,contexts,I
786,in,B
786,the,I
786,form,I
786,of,I
786,Location,B
786,",",I
786,Caption,I
786,",",O
786,and,O
786,Part,O
786,of,O
786,Speech,O
786,tags,O
786,.,O
787,Our,O
787,method,O
787,implicitly,O
787,uses,B
787,a,O
787,differential,B
787,context,I
787,obtained,B
787,through,I
787,supporting,B
787,and,I
787,contrasting,I
787,exemplars,I
787,to,B
787,obtain,I
787,a,O
787,differentiable,B
787,embedding,I
787,.,O
788,This,O
788,embedding,O
788,is,O
788,used,B
788,by,I
788,a,O
788,question,O
788,decoder,O
788,to,B
788,decode,I
788,the,O
788,appropriate,B
788,question,O
788,.,O
789,To,O
789,summarize,O
789,",",O
789,we,O
789,propose,B
789,a,O
789,multimodal,B
789,differential,I
789,network,I
789,to,O
789,solve,O
789,the,O
789,task,B
789,of,B
789,visual,B
789,question,I
789,generation,I
789,.,O
790,Multimodal,O
790,Differential,O
790,Network,O
790,for,O
790,Visual,B
790,Question,I
790,Generation,I
791,MultiR,B
791,puts,B
791,forward,I
791,a,O
791,graphical,B
791,model,I
791,.,O
792,Here,O
792,the,O
792,au-thors,O
792,have,O
792,proposed,O
792,the,O
792,challenging,O
792,task,O
792,of,O
792,generating,B
792,natural,I
792,questions,I
792,for,I
792,an,I
792,image,I
792,.,O
793,Baselines,O
793,for,B
793,LCSTS,B
793,are,B
793,introduced,O
793,in,O
793,the,O
793,following,O
793,.,O
794,RNN,O
794,and,O
794,RNN,O
794,-,O
794,context,O
794,are,O
794,the,O
794,RNNbased,B
794,seq2seq,I
794,models,I
794,",",O
794,without,B
794,and,O
794,with,O
794,attention,B
794,mechanism,I
794,respectively,O
794,.,O
795,Copy,O
795,-,O
795,Net,O
795,is,B
795,the,O
795,attention,B
795,-,O
795,based,O
795,seq2seq,O
795,model,O
795,with,B
795,the,O
795,copy,O
795,mechanism,O
795,.,O
796,SRB,B
796,is,O
796,a,O
796,model,O
796,that,O
796,improves,B
796,semantic,B
796,relevance,I
796,between,B
796,source,B
796,text,I
796,and,I
796,summary,I
796,.,O
797,DRGD,B
797,is,B
797,the,O
797,conventional,B
797,seq2seq,I
797,with,B
797,a,O
797,deep,B
797,recurrent,I
797,generative,I
797,decoder,I
797,.,O
798,As,O
798,to,O
798,the,O
798,baselines,O
798,for,O
798,Gigaword,B
798,",",O
798,ABS,O
798,and,O
798,ABS,O
798,+,O
798,are,B
798,the,O
798,models,B
798,with,B
798,local,B
798,attention,I
798,and,O
798,handcrafted,O
798,features,O
798,.,O
799,Feats,B
799,is,B
799,a,O
799,fully,B
799,RNN,I
799,seq2seq,I
799,model,I
799,with,B
799,some,B
799,specific,I
799,methods,I
799,to,B
799,control,I
799,the,O
799,vocabulary,B
799,size,I
799,.,O
800,RAS,O
800,-,O
800,LSTM,B
800,and,O
800,RAS,O
800,-,O
800,Elman,B
800,are,B
800,seq2seq,B
800,models,I
800,with,B
800,a,O
800,convolutional,B
800,encoder,I
800,and,O
800,an,O
800,LSTM,O
800,decoder,O
800,and,O
800,an,O
800,Elman,O
800,RNN,O
800,decoder,O
800,respectively,O
800,.,O
801,SEASS,B
801,is,B
801,a,I
801,seq2seq,B
801,model,I
801,with,B
801,a,O
801,selective,B
801,gate,I
801,mechanism,I
801,.,O
802,MIML,B
802,proposes,B
802,a,O
802,multi,B
802,-instance,I
802,multi-label,I
802,model,I
802,.,O
803,DRGD,B
803,is,O
803,also,O
803,a,O
803,baseline,B
803,for,I
803,Gigaword,B
803,.,O
804,We,O
804,implement,B
804,our,B
804,experiments,I
804,in,B
804,PyTorch,B
804,on,I
804,an,I
804,NVIDIA,I
804,1080,I
804,Ti,I
804,GPU,I
804,.,O
805,The,O
805,word,B
805,embedding,I
805,dimension,I
805,and,I
805,the,O
805,number,O
805,of,O
805,hidden,O
805,units,O
805,are,O
805,both,O
805,512,B
805,.,O
806,In,O
806,both,O
806,experiments,O
806,",",O
806,the,O
806,batch,B
806,size,I
806,is,O
806,set,B
806,to,I
806,64,B
806,.,O
807,The,O
807,learning,B
807,rate,I
807,is,O
807,halved,B
807,every,B
807,epoch,I
807,.,O
808,Gradient,O
808,clipping,O
808,is,O
808,applied,B
808,with,I
808,range,B
808,[,I
808,-,I
808,10,I
808,",",I
808,10,O
808,],O
808,.,O
809,We,O
809,use,B
809,Adam,B
809,optimizer,I
809,(,I
809,Kingma,I
809,and,I
809,Ba,I
809,",",I
809,2014,I
809,),I
809,with,B
809,the,O
809,default,O
809,setting,O
809,?,O
810,To,O
810,tackle,O
810,this,O
810,problem,O
810,",",O
810,we,O
810,propose,O
810,a,O
810,model,O
810,of,B
810,global,B
810,encoding,I
810,for,B
810,abstractive,B
810,summarization,I
810,.,O
811,We,O
811,set,B
811,a,O
811,convolutional,B
811,gated,I
811,unit,I
811,to,B
811,perform,I
811,global,B
811,encoding,I
811,on,B
811,the,O
811,source,B
811,context,I
811,.,O
812,The,O
812,gate,B
812,based,B
812,on,I
812,convolutional,B
812,neural,I
812,network,I
812,(,I
812,CNN,I
812,),I
812,filters,B
812,each,B
812,encoder,I
812,output,I
812,based,O
812,on,O
812,the,O
812,global,B
812,context,I
812,due,B
812,to,I
812,the,O
812,parameter,B
812,sharing,I
812,",",O
812,so,O
812,that,O
812,the,O
812,representations,O
812,at,O
812,each,O
812,time,O
812,step,O
812,are,O
812,refined,O
812,with,O
812,consideration,O
812,of,O
812,the,O
812,global,O
812,context,O
812,.,O
813,PCNN,B
813,puts,B
813,forward,I
813,a,O
813,piecewise,B
813,CNN,I
813,for,I
813,relation,I
813,extraction,I
813,.,O
814,Global,O
814,Encoding,O
814,for,O
814,Abstractive,B
814,Summarization,I
815,Therefore,O
815,",",O
815,sequence,O
815,-,O
815,to,O
815,-,O
815,sequence,O
815,learning,O
815,can,O
815,be,O
815,applied,O
815,to,O
815,neural,B
815,abstractive,I
815,summarization,I
815,",",O
815,whose,O
815,model,O
815,consists,O
815,of,O
815,an,O
815,encoder,O
815,and,O
815,a,O
815,decoder,O
815,.,O
816,In,O
816,the,O
816,experiments,O
816,on,B
816,the,O
816,two,B
816,datasets,I
816,",",O
816,our,B
816,model,I
816,achieves,B
816,advantages,B
816,of,B
816,ROUGE,B
816,score,I
816,over,B
816,the,O
816,baselines,B
816,",",O
816,and,O
816,the,O
816,advantages,O
816,of,O
816,ROUGE,O
816,score,O
816,on,O
816,the,O
816,LCSTS,B
816,are,B
816,significant,B
816,.,O
817,Compared,O
817,with,O
817,the,O
817,conventional,B
817,seq2seq,I
817,model,I
817,",",O
817,our,B
817,model,O
817,owns,B
817,an,I
817,advantage,I
817,of,B
817,ROUGE,B
817,-,I
817,2,I
817,score,I
817,3.7,I
817,and,I
817,1.5,I
817,on,B
817,the,O
817,LCSTS,B
817,and,O
817,Gigaword,O
817,respectively,O
817,.,O
818,4.2,O
818,",",O
818,we,O
818,choose,B
818,soft,B
818,-,I
818,sharing,I
818,over,B
818,hard,B
818,-,O
818,sharing,O
818,because,B
818,of,I
818,the,O
818,more,B
818,expressive,I
818,parameter,I
818,sharing,O
818,it,O
818,provides,O
818,to,O
818,the,O
818,model,O
818,.,O
819,Empirical,O
819,results,O
819,in,B
819,8,O
819,prove,B
819,that,O
819,soft,B
819,-,I
819,sharing,I
819,method,I
819,is,B
819,statistically,I
819,significantly,I
819,better,I
819,than,I
819,hard,B
819,-,O
819,sharing,O
819,with,B
819,p,B
819,<,I
819,0.001,I
819,in,O
819,all,B
819,metrics,I
819,.,O
820,We,O
820,found,B
820,that,O
820,our,B
820,2,I
820,-,I
820,way,I
820,MTL,I
820,model,I
820,with,B
820,entailment,B
820,generation,I
820,reduces,B
820,this,O
820,extraneous,B
820,count,I
820,by,B
820,17.2,O
820,%,O
820,w.r.t.,O
821,PCNN,B
821,+,O
821,ATT,O
821,proposes,B
821,the,O
821,selective,B
821,attention,I
821,mechanism,I
821,with,B
821,PCNN,O
821,.,O
822,The,O
822,results,B
822,are,I
822,shown,O
822,in,O
822,Table,O
822,10,O
822,",",O
822,where,O
822,the,O
822,2,B
822,-,I
822,way,I
822,-,O
822,QG,O
822,MTL,O
822,model,O
822,(,O
822,with,O
822,question,O
822,generation,O
822,),O
822,versus,B
822,baseline,B
822,improvement,I
822,is,B
822,stat.,O
823,Qualitative,O
823,Examples,O
823,on,O
823,Entailment,O
823,and,O
823,Saliency,O
823,Improvements,O
823,presents,O
823,an,O
823,example,O
823,of,O
823,output,O
823,summaries,B
823,generated,O
823,by,O
823,",",O
823,our,O
823,baseline,O
823,",",O
823,and,O
823,our,O
823,3,O
823,-,O
823,way,O
823,multitask,O
823,model,O
823,.,O
824,Hence,O
824,",",O
824,our,O
824,3,B
824,-,I
824,way,I
824,multi-task,I
824,model,I
824,generates,B
824,summaries,O
824,that,O
824,are,B
824,both,I
824,better,I
824,at,I
824,logical,B
824,entailment,I
824,and,O
824,contain,B
824,more,I
824,salient,I
824,information,I
824,.,O
825,Further,O
825,",",O
825,we,O
825,also,O
825,present,B
825,novel,B
825,multi-task,I
825,learning,I
825,architectures,I
825,based,B
825,on,I
825,multi-layered,B
825,encoder,I
825,and,I
825,decoder,I
825,models,I
825,",",O
825,where,O
825,we,O
825,empirically,B
825,show,I
825,that,O
825,it,O
825,is,O
825,substantially,B
825,better,I
825,to,B
825,share,I
825,the,O
825,higherlevel,B
825,semantic,I
825,layers,I
825,between,B
825,the,O
825,three,B
825,aforementioned,I
825,tasks,I
825,",",O
825,while,O
825,keeping,B
825,the,O
825,lower,B
825,-,I
825,level,I
825,(,I
825,lexico-,I
825,syntactic,I
825,),I
825,layers,O
825,unshared,O
825,.,O
826,Soft,O
826,Layer,O
826,-,O
826,Specific,O
826,Multi,B
826,-,O
826,Task,O
826,Summarization,O
826,with,O
826,Entailment,O
826,and,O
826,Question,O
826,Generation,O
827,We,O
827,improve,O
827,these,O
827,important,O
827,aspects,O
827,of,O
827,abstractive,B
827,summarization,I
827,via,O
827,multi-task,O
827,learning,O
827,with,O
827,the,O
827,auxiliary,O
827,tasks,O
827,of,O
827,question,O
827,generation,O
827,and,O
827,entailment,O
827,generation,O
827,",",O
827,where,O
827,the,O
827,former,O
827,teaches,O
827,the,O
827,summarization,O
827,model,O
827,how,O
827,to,O
827,look,O
827,for,O
827,salient,O
827,questioning,O
827,-,O
827,worthy,O
827,details,O
827,",",O
827,and,O
827,the,O
827,latter,O
827,teaches,O
827,the,O
827,model,O
827,how,O
827,to,O
827,rewrite,O
827,a,O
827,summary,O
827,which,O
827,is,O
827,a,O
827,directed,O
827,-,O
827,logical,O
827,subset,O
827,of,O
827,the,O
827,input,O
827,document,O
827,.,O
828,In,O
828,this,O
828,work,O
828,",",O
828,we,O
828,improve,O
828,abstractive,B
828,text,I
828,summarization,I
828,via,O
828,soft,O
828,",",O
828,high,O
828,-,O
828,level,O
828,(,O
828,semantic,O
828,),O
828,layerspecific,O
828,multi-task,O
828,learning,O
828,with,O
828,two,O
828,relevant,O
828,auxiliary,O
828,tasks,O
828,.,O
829,4,O
829,On,B
829,Gigaword,B
829,dataset,I
829,",",O
829,our,O
829,baseline,B
829,model,I
829,(,O
829,with,O
829,pointer,O
829,only,O
829,",",O
829,since,O
829,coverage,O
829,not,O
829,needed,O
829,for,O
829,this,O
829,single,O
829,-,O
829,sentence,O
829,summarization,O
829,task,O
829,),O
829,performs,B
829,better,I
829,than,I
829,all,B
829,previous,I
829,works,I
829,",",O
829,as,O
829,shown,O
829,in,O
829,.,O
830,BGRU,B
830,proposes,B
830,a,O
830,BGRU,O
830,with,B
830,the,O
830,word,B
830,-,I
830,level,I
830,attention,I
830,mechanism,I
830,.,O
831,shows,B
831,that,O
831,this,O
831,multi-task,B
831,setting,I
831,is,O
831,better,B
831,than,I
831,our,B
831,strong,I
831,baseline,I
831,models,I
831,and,O
831,the,O
831,improvements,O
831,are,O
831,statistically,O
831,significant,O
831,on,O
831,all,O
831,metrics,O
831,5,O
831,on,O
831,both,O
831,CNN,O
831,/,O
831,DailyMail,O
831,(,O
831,p,O
831,<,O
831,0.01,O
831,in,O
831,ROUGE,O
831,-,O
831,1,O
831,/,O
831,ROUGE,O
831,-,O
831,L,O
831,/,O
831,METEOR,O
831,and,O
831,p,O
831,<,O
831,0.05,O
831,in,O
831,ROUGE,O
831,-,O
831,2,O
831,),O
831,and,O
831,Gigaword,O
831,(,O
831,p,O
831,<,O
831,0.01,O
831,on,O
831,all,O
831,metrics,O
831,),O
831,datasets,O
831,",",O
831,showing,O
831,that,O
831,entailment,O
831,generation,O
831,task,O
831,is,O
831,inducing,O
831,useful,O
831,inference,O
831,skills,O
831,to,O
831,the,O
831,summarization,O
831,task,O
831,(,O
831,also,O
831,see,O
831,analysis,O
831,examples,O
831,in,O
831,Sec.,O
832,For,B
832,multi-task,B
832,learning,I
832,with,I
832,question,I
832,generation,I
832,",",O
832,the,O
832,improvements,B
832,are,O
832,statistically,B
832,significant,I
832,in,B
832,ROUGE,B
832,-,I
832,1,I
832,(,I
832,p,I
832,<,I
832,0.01,I
832,),I
832,",",O
832,ROUGE,O
832,-,O
832,L,O
832,(,O
832,p,O
832,<,O
832,0.05,O
832,),O
832,",",O
832,and,O
832,METEOR,B
832,(,O
832,p,O
832,<,O
832,0.01,O
832,),O
832,for,O
832,CNN,B
832,/,I
832,DailyMail,I
832,and,O
832,in,O
832,all,B
832,metrics,I
832,(,O
832,p,O
832,<,O
832,0.01,O
832,),O
832,for,O
832,Gigaword,B
832,",",O
832,compared,O
832,to,O
832,the,O
832,respective,O
832,baseline,O
832,models,O
832,.,O
833,We,O
833,implemented,B
833,our,B
833,models,I
833,in,B
833,the,O
833,Torch,B
833,library,I
833,(,O
833,http://torch.ch/),O
834,To,O
834,optimize,B
834,our,B
834,loss,I
834,(,O
834,Equation,O
834,5,O
834,),O
834,we,O
834,used,B
834,stochastic,B
834,gradient,I
834,descent,I
834,with,B
834,mini-batches,B
834,of,B
834,size,I
834,32,B
834,.,O
835,During,B
835,training,B
835,we,O
835,measure,B
835,the,O
835,perplexity,B
835,of,B
835,the,O
835,summaries,B
835,in,B
835,the,O
835,validation,B
835,set,I
835,and,O
835,adjust,B
835,our,O
835,hyper,B
835,-,I
835,parameters,I
835,",",O
835,such,B
835,as,I
835,the,O
835,learning,B
835,rate,I
835,",",O
835,based,O
835,on,O
835,this,O
835,number,O
835,.,O
836,For,B
836,the,O
836,decoder,B
836,we,O
836,experimented,B
836,with,I
836,both,O
836,the,O
836,Elman,B
836,RNN,I
836,and,O
836,the,O
836,Long,B
836,-,I
836,Short,I
836,Term,I
836,Memory,I
836,(,I
836,LSTM,I
836,),I
836,architecture,I
836,(,O
836,as,O
836,discussed,O
836,in,O
836,3.1,O
836,),O
836,.,O
837,We,O
837,chose,B
837,hyper,B
837,-,I
837,parameters,I
837,based,B
837,on,B
837,a,O
837,grid,B
837,search,I
837,and,O
837,picked,B
837,the,I
837,one,I
837,which,I
837,gave,I
837,the,O
837,best,B
837,perplexity,I
837,on,O
837,the,O
837,validation,B
837,set,I
837,.,O
838,Our,O
838,final,B
838,Elman,I
838,architecture,I
838,(,I
838,RAS,I
838,-,I
838,Elman,O
838,),O
838,uses,B
838,a,O
838,single,B
838,layer,I
838,with,B
838,H,O
838,=,O
838,512,O
838,",",O
838,?,O
839,The,O
839,LSTM,O
839,model,O
839,(,O
839,RAS,O
839,-,O
839,LSTM,O
839,),O
839,also,O
839,has,O
839,a,O
839,single,B
839,layer,I
839,with,B
839,H,O
839,=,O
839,512,O
839,",",O
839,?,O
840,Inspired,O
840,by,O
840,the,O
840,recently,O
840,proposed,O
840,architectures,O
840,for,O
840,machine,O
840,translation,O
840,",",O
840,our,O
840,model,O
840,consists,B
840,of,B
840,a,O
840,conditional,B
840,recurrent,I
840,neural,I
840,network,I
840,",",O
840,which,O
840,acts,B
840,as,I
840,a,O
840,decoder,B
840,to,B
840,generate,I
840,the,O
840,summary,B
840,of,O
840,an,O
840,input,B
840,sentence,I
840,",",O
840,much,O
840,like,O
840,a,O
840,standard,O
840,recurrent,O
840,language,O
840,model,O
840,.,O
841,In,O
841,the,O
841,experiment,O
841,",",O
841,we,O
841,utilize,B
841,word2vec,B
841,2,O
841,to,B
841,train,I
841,word,B
841,embeddings,I
841,on,B
841,NYT,B
841,corpus,I
841,.,O
842,In,O
842,addition,O
842,",",O
842,at,B
842,every,B
842,time,I
842,step,I
842,the,O
842,decoder,B
842,also,O
842,takes,B
842,a,O
842,conditioning,B
842,input,I
842,which,O
842,is,O
842,the,O
842,output,B
842,of,I
842,an,O
842,encoder,B
842,module,I
842,.,O
843,Depending,O
843,on,O
843,the,O
843,current,O
843,state,O
843,of,O
843,the,O
843,RNN,O
843,",",O
843,the,O
843,encoder,B
843,computes,B
843,scores,I
843,over,I
843,the,O
843,words,B
843,in,B
843,the,O
843,input,B
843,sentence,I
843,.,O
844,Lastly,O
844,",",O
844,our,O
844,encoder,O
844,uses,B
844,a,O
844,convolutional,B
844,network,I
844,to,B
844,encode,I
844,input,B
844,words,I
844,.,O
845,Both,O
845,the,O
845,decoder,B
845,and,I
845,encoder,I
845,are,O
845,jointly,B
845,trained,I
845,on,I
845,a,O
845,data,B
845,set,I
845,consisting,B
845,of,I
845,sentence,B
845,-,I
845,summary,I
845,pairs,I
845,.,O
846,Generating,O
846,a,O
846,condensed,O
846,version,O
846,of,O
846,a,O
846,passage,O
846,while,O
846,preserving,O
846,its,O
846,meaning,O
846,is,O
846,known,O
846,as,O
846,text,B
846,summarization,I
846,.,O
847,shows,B
847,that,O
847,both,O
847,our,O
847,RAS,O
847,-,O
847,Elman,O
847,and,O
847,RAS,O
847,-,O
847,LSTM,O
847,models,O
847,achieve,B
847,lower,B
847,perplexity,I
847,than,B
847,ABS,B
847,as,O
847,well,O
847,as,O
847,other,O
847,models,O
847,reported,O
847,in,O
847,.,O
848,The,O
848,RAS,B
848,-,I
848,LSTM,I
848,performs,B
848,slightly,I
848,worse,I
848,than,I
848,RAS,O
848,-,O
848,Elman,O
848,",",O
848,most,O
848,likely,O
848,due,O
848,to,O
848,over-fitting,O
848,.,O
849,The,O
849,ROUGE,B
849,results,I
849,show,B
849,that,O
849,our,B
849,models,I
849,comfortably,B
849,outperform,I
849,both,O
849,ABS,O
849,and,O
849,ABS,O
849,+,O
849,by,B
849,a,O
849,wide,B
849,margin,I
849,on,B
849,all,B
849,metrics,I
849,.,O
850,On,B
850,DUC,B
850,-,I
850,2004,I
850,we,O
850,report,O
850,recall,O
850,ROUGE,O
850,as,O
850,is,O
850,customary,O
850,on,O
850,this,O
850,dataset,O
850,.,O
851,The,O
851,grid,B
851,search,I
851,approach,I
851,is,O
851,used,O
851,to,B
851,select,I
851,optimal,B
851,learning,I
851,rate,I
851,lr,I
851,for,B
851,Adam,B
851,optimizer,I
851,among,B
851,{,O
851,0.1,B
851,",",I
851,0.001,I
851,",",O
851,0.0005,O
851,",",O
851,0.0001,O
851,},O
851,",",O
851,GRU,B
851,size,I
851,m,I
851,?,I
852,{,O
852,100,B
852,",",I
852,160,I
852,",",O
852,230,O
852,",",O
852,400,O
852,},O
852,",",O
852,position,B
852,embedding,I
852,size,I
852,l,I
852,?,I
853,shows,O
853,all,O
853,parameters,O
853,for,B
853,our,O
853,task,O
853,.,O
854,The,O
854,results,O
854,(,O
854,Table,O
854,3,O
854,),O
854,show,B
854,that,O
854,our,B
854,models,I
854,are,O
854,better,B
854,than,I
854,ABS,B
854,+,I
854,.,O
855,The,O
855,discriminator,B
855,provides,B
855,the,O
855,scalar,B
855,training,I
855,signal,I
855,L,I
855,g,I
855,c,I
855,for,B
855,generator,B
855,training,O
855,and,O
855,the,O
855,feature,B
855,vector,I
855,F,I
855,(,I
855,m,I
855,t,I
855,),I
855,for,O
855,goal,B
855,tracker,I
855,.,O
856,Consequently,O
856,",",O
856,there,O
856,is,O
856,an,O
856,increment,B
856,of,I
856,17.51,B
856,%,I
856,from,B
856,RASG,I
856,w,I
856,/,I
856,o,I
856,GTD,I
856,to,I
856,RASG,O
856,w,O
856,/,O
856,o,O
856,GT,O
856,in,B
856,terms,I
856,of,O
856,ROUGE,B
856,-,I
856,L,I
856,",",O
856,which,O
856,demonstrates,O
856,the,O
856,effectiveness,O
856,of,O
856,discriminator,O
856,.,O
857,As,O
857,for,O
857,the,O
857,effectiveness,O
857,of,O
857,goal,B
857,tracker,I
857,",",O
857,compared,B
857,with,I
857,RASG,B
857,and,I
857,RASG,O
857,w,O
857,/,O
857,o,O
857,GT,O
857,",",O
857,RASG,O
857,w/,O
857,o,O
857,GTD,O
857,offers,B
857,a,O
857,decrease,B
857,of,O
857,45.,O
858,23,O
858,%,O
858,and,O
858,17.88,O
858,%,O
858,in,B
858,terms,I
858,of,I
858,ROUGE,B
858,-,I
858,1,I
858,",",O
858,respectively,O
858,.,O
859,Finally,O
859,",",O
859,RASG,B
859,w/o,I
859,DM,I
859,offers,B
859,a,I
859,decrease,I
859,of,I
859,10,O
859,.,O
860,22,O
860,%,O
860,compared,B
860,with,I
860,RASG,B
860,in,B
860,terms,I
860,of,I
860,ROUGE,B
860,-,I
860,L,I
860,",",O
860,which,O
860,demonstrates,O
860,the,O
860,effectiveness,O
860,of,O
860,denoising,O
860,module,O
860,.,O
861,(,O
861,1,O
861,),O
861,S2S,B
861,:,O
861,Sequence,O
861,-,O
861,to,O
861,-,O
861,sequence,O
861,framework,O
861,has,O
861,been,O
861,proposed,O
861,for,O
861,language,O
861,generation,O
861,task,O
861,.,O
862,(,O
862,2,O
862,),O
862,S2SR,B
862,:,O
862,We,O
862,simply,O
862,add,B
862,the,O
862,reader,O
862,attention,O
862,on,O
862,attention,O
862,distribution,O
862,?,O
863,t,O
863,",",O
863,in,B
863,each,O
863,decoding,B
863,step,I
863,.,O
864,(,O
864,3,O
864,),O
864,CGU,B
864,:,O
864,propose,B
864,to,I
864,use,I
864,the,O
864,convolutional,B
864,gated,I
864,unit,I
864,to,O
864,refine,O
864,the,O
864,source,O
864,representation,O
864,",",O
864,which,O
864,achieves,O
864,the,O
864,state,O
864,-,O
864,of,O
864,-,O
864,the,O
864,-,O
864,art,O
864,performance,O
864,on,O
864,social,O
864,media,O
864,text,O
864,summarization,O
864,dataset,O
864,.,O
865,(,O
865,4,O
865,),O
865,LEAD1,B
865,:,O
865,LEAD1,O
865,is,O
865,a,O
865,commonly,O
865,used,O
865,baseline,O
865,",",O
865,which,O
865,selects,B
865,the,I
865,first,B
865,sentence,I
865,of,I
865,document,I
865,as,I
865,the,O
865,summary,O
865,.,O
866,(,O
866,5,O
866,),O
866,TextRank,B
866,:,O
866,propose,B
866,to,B
866,build,I
866,a,O
866,graph,B
866,",",O
866,then,O
866,add,B
866,each,B
866,sentence,I
866,as,B
866,a,O
866,vertex,B
866,and,O
866,use,B
866,link,B
866,to,O
866,represent,O
866,semantic,B
866,similarity,I
866,.,O
867,GRU,O
867,size,O
867,m,O
867,230,B
868,We,O
868,implement,B
868,our,B
868,experiments,I
868,in,B
868,TensorFlow,B
868,),O
868,on,B
868,an,O
868,NVIDIA,B
868,P40,I
868,GPU,I
868,.,O
869,The,O
869,word,B
869,embedding,I
869,dimension,I
869,is,O
869,set,B
869,to,I
869,256,B
869,and,O
869,the,O
869,number,B
869,of,I
869,hidden,I
869,units,I
869,is,O
869,512,B
869,.,O
870,We,O
870,use,B
870,Adagrad,B
870,optimizer,I
870,as,B
870,our,O
870,optimizing,B
870,algorithm,I
870,.,O
871,We,O
871,employ,B
871,beam,B
871,search,I
871,with,B
871,beam,O
871,size,O
871,5,O
871,to,B
871,generate,I
871,more,B
871,fluency,I
871,summary,I
871,sentence,I
871,.,O
872,In,O
872,this,O
872,paper,O
872,",",O
872,we,O
872,propose,B
872,a,O
872,summarization,B
872,framework,I
872,named,B
872,reader,B
872,-,I
872,aware,I
872,summary,I
872,generator,I
872,(,I
872,RASG,I
872,),I
872,that,O
872,incorporates,B
872,reader,O
872,comments,O
872,to,B
872,improve,I
872,the,O
872,summarization,O
872,performance,O
872,.,O
873,Specifically,O
873,",",O
873,a,O
873,seq2seq,B
873,architecture,I
873,with,I
873,attention,I
873,mechanism,I
873,is,O
873,employed,B
873,as,B
873,the,O
873,basic,B
873,summary,I
873,generator,I
873,.,O
874,We,O
874,first,O
874,calculate,B
874,alignment,I
874,between,I
874,the,O
874,reader,B
874,comments,I
874,words,I
874,and,I
874,document,I
874,words,O
874,",",O
874,and,O
874,this,O
874,alignment,O
874,information,O
874,is,O
874,regarded,B
874,as,I
874,reader,O
874,attention,O
874,representing,B
874,the,O
874,"""",O
874,reader,O
874,focused,O
874,aspect,O
874,"""",O
874,.,O
875,Then,O
875,",",O
875,we,O
875,treat,B
875,the,I
875,decoder,B
875,attention,I
875,weights,I
875,as,B
875,the,O
875,focused,B
875,aspect,I
875,of,I
875,the,O
875,generated,O
875,summary,O
875,",",O
875,a.k.a.,B
876,",",O
876,"""",O
876,decoder,B
876,focused,I
876,aspect,I
876,"""",O
876,.,O
877,After,B
877,each,B
877,decoding,I
877,step,I
877,",",O
877,a,O
877,supervisor,B
877,is,O
877,designed,B
877,to,B
877,measure,I
877,the,I
877,distance,B
877,between,B
877,the,O
877,reader,B
877,focused,I
877,aspect,I
877,and,I
877,the,O
877,decoder,O
877,focused,O
877,aspect,O
877,.,O
878,The,O
878,training,B
878,of,I
878,our,O
878,framework,B
878,RASG,I
878,is,O
878,conducted,B
878,in,I
878,an,O
878,adversarial,B
878,way,I
878,.,O
879,Word,O
879,embedding,O
879,dimension,O
879,k,O
879,50,B
879,POS,B
879,embedding,O
879,dimension,O
879,l,O
879,5,B
879,Batch,B
879,size,I
879,n,I
879,50,O
879,Entity,B
879,-,I
879,Task,I
879,weights,I
879,(,O
879,?,O
880,In,O
880,neural,B
880,abstractive,I
880,summarization,I
880,field,O
880,",",O
880,conventional,O
880,sequence,O
880,-,O
880,to,O
880,-,O
880,sequence,O
880,based,O
880,models,O
880,often,O
880,suffer,O
880,from,O
880,summarizing,O
880,the,O
880,wrong,O
880,aspect,O
880,of,O
880,the,O
880,document,O
880,with,O
880,respect,O
880,to,O
880,the,O
880,main,O
880,aspect,O
880,.,O
881,To,O
881,tackle,O
881,this,O
881,problem,O
881,",",O
881,we,O
881,propose,O
881,the,O
881,task,O
881,of,O
881,reader,B
881,-,I
881,aware,I
881,abstractive,I
881,summary,I
881,generation,I
881,",",O
881,which,O
881,utilizes,O
881,the,O
881,reader,O
881,comments,O
881,to,O
881,help,O
881,the,O
881,model,O
881,produce,O
881,better,O
881,summary,O
881,about,O
881,the,O
881,main,O
881,aspect,O
881,.,O
882,Unlike,O
882,traditional,O
882,abstractive,B
882,summarization,I
882,task,O
882,",",O
882,reader,O
882,-,O
882,aware,O
882,summarization,O
882,confronts,O
882,two,O
882,main,O
882,challenges,O
882,:,O
883,We,O
883,see,B
883,that,I
883,RASG,B
883,achieves,B
883,a,O
883,11.0,B
883,%,I
883,",",I
883,9.1,I
883,%,O
883,and,O
883,6.6,O
883,%,O
883,increment,O
883,over,B
883,the,I
883,state,B
883,-,I
883,of,I
883,-,O
883,the,O
883,-,O
883,art,O
883,method,O
883,CGU,O
883,in,B
883,terms,I
883,of,O
883,ROUGE,O
883,-,O
883,1,O
883,",",O
883,ROUGE,O
883,-,O
883,2,O
883,and,O
883,ROUGE,O
883,-,O
883,L,O
883,respectively,O
883,.,O
884,It,O
884,is,O
884,worth,B
884,noticing,I
884,that,O
884,the,O
884,baseline,B
884,model,I
884,S2SR,I
884,achieves,B
884,better,I
884,performance,I
884,than,I
884,S2S,B
884,which,O
884,demonstrates,O
884,the,O
884,effectiveness,O
884,of,O
884,incorporating,O
884,reader,O
884,focused,O
884,aspect,O
884,in,O
884,summary,O
884,generation,O
884,.,O
885,ABS,O
885,+,O
885,Based,B
885,on,I
885,ABS,O
885,model,O
885,",",O
885,further,B
885,with,B
885,two,B
885,-,I
885,layer,I
885,LSTMs,I
885,for,B
885,the,O
885,encoder,B
885,-,O
885,decoder,O
885,with,O
885,500,B
885,hidden,I
885,units,I
885,in,B
885,each,B
885,layer,O
885,implemented,O
885,in,O
885,.,O
886,We,O
886,also,O
886,implement,B
886,a,O
886,sequence,O
886,-,O
886,to,O
886,sequence,O
886,model,O
886,with,B
886,attention,B
886,as,O
886,our,O
886,baseline,O
886,and,O
886,denote,O
886,it,O
886,as,O
886,"""",O
886,s2,O
886,s,O
886,+,O
886,att,O
886,"""",O
886,.,O
887,We,O
887,initialize,B
887,model,B
887,parameters,I
887,randomly,I
887,using,B
887,a,O
887,Gaussian,B
887,distribution,I
887,with,B
887,Xavier,B
887,scheme,I
887,.,O
888,tail,O
888,),O
888,"0.5,0.5",O
888,Entity,B
888,-,I
888,Relation,I
888,Task,I
888,weight,I
888,?,O
889,We,O
889,use,B
889,Adam,B
889,as,B
889,our,O
889,optimizing,B
889,algorithm,I
889,.,O
890,For,O
890,the,O
890,hyperparameters,O
890,of,O
890,Adam,O
890,optimizer,O
890,",",O
890,we,O
890,set,O
890,the,O
890,learning,B
890,rate,I
890,?,O
891,=,O
891,0.001,B
891,",",O
891,two,B
891,momentum,I
891,parameters,I
891,?,O
892,To,O
892,both,O
892,speedup,O
892,the,O
892,training,B
892,and,I
892,converge,I
892,quickly,I
892,",",O
892,we,O
892,use,O
892,mini-batch,B
892,size,I
892,64,I
892,by,B
892,grid,B
892,search,I
892,.,O
893,During,B
893,training,B
893,",",O
893,we,O
893,test,B
893,the,O
893,model,B
893,performance,I
893,(,I
893,ROUGE,I
893,-,I
893,2,I
893,F1,I
893,),I
893,on,B
893,development,B
893,set,I
893,for,B
893,every,B
893,"2,000",I
893,batches,I
893,.,O
894,We,O
894,also,O
894,apply,B
894,gradient,B
894,clipping,I
894,with,B
894,range,O
894,[,O
894,?,O
895,5,O
895,",",O
895,5,O
895,],O
895,during,B
895,training,B
895,.,O
896,In,O
896,this,O
896,paper,O
896,we,O
896,propose,B
896,Selective,B
896,Encoding,I
896,for,I
896,Abstractive,I
896,Sentence,I
896,Summarization,I
896,(,I
896,SEASS,I
896,),I
896,.,O
897,We,O
897,treat,B
897,the,O
897,sentence,B
897,summarization,I
897,as,B
897,a,I
897,threephase,B
897,task,I
897,:,O
897,encoding,B
897,",",O
897,selection,B
897,",",O
897,and,O
897,decoding,B
897,.,O
898,It,O
898,consists,B
898,of,I
898,a,O
898,sentence,B
898,encoder,I
898,",",O
898,a,O
898,selective,B
898,gate,I
898,network,I
898,",",O
898,and,O
898,a,O
898,summary,B
898,decoder,I
898,.,O
899,First,B
899,",",O
899,the,O
899,sentence,B
899,encoder,I
899,reads,B
899,the,O
899,input,B
899,words,I
899,through,B
899,an,O
899,RNN,B
899,unit,I
899,to,B
899,construct,I
899,the,O
899,first,O
899,level,O
899,sentence,O
899,representation,O
899,.,O
900,Then,O
900,the,O
900,selective,B
900,gate,I
900,network,I
900,selects,B
900,the,O
900,encoded,B
900,information,I
900,to,B
900,construct,I
900,the,O
900,second,B
900,level,I
900,sentence,I
900,representation,I
900,.,O
901,0.3,B
901,Learning,B
901,rate,I
901,lr,I
901,0.001,B
901,Dropout,B
901,probability,I
901,p,I
901,0.5,B
901,l,B
901,2,I
901,penalty,I
901,?,O
902,The,O
902,selective,B
902,mechanism,I
902,controls,B
902,the,O
902,information,O
902,flow,O
902,from,B
902,encoder,B
902,to,I
902,decoder,I
902,by,B
902,applying,I
902,a,O
902,gate,B
902,network,I
902,according,B
902,to,O
902,the,O
902,sentence,B
902,information,O
902,",",O
902,which,O
902,helps,O
902,improve,O
902,encoding,O
902,effectiveness,O
902,and,O
902,release,O
902,the,O
902,burden,O
902,of,O
902,the,O
902,decoder,O
902,.,O
903,Finally,O
903,",",O
903,the,O
903,attention,B
903,-,I
903,equipped,I
903,decoder,I
903,generates,B
903,the,O
903,summary,B
903,using,B
903,the,O
903,second,B
903,level,I
903,sentence,I
903,representation,I
903,.,O
904,Selective,O
904,Encoding,O
904,for,O
904,Abstractive,B
904,Sentence,I
904,Summarization,I
905,The,O
905,second,O
905,level,O
905,representation,O
905,is,O
905,tailored,O
905,for,O
905,sentence,B
905,summarization,I
905,task,O
905,",",O
905,which,O
905,leads,O
905,to,O
905,better,O
905,performance,O
905,.,O
906,Our,O
906,SEASS,B
906,model,I
906,with,B
906,beam,B
906,search,I
906,outperforms,B
906,all,B
906,baseline,I
906,models,I
906,by,B
906,a,O
906,large,B
906,margin,I
906,.,O
907,Even,O
907,for,O
907,greedy,B
907,search,I
907,",",O
907,our,O
907,model,O
907,still,B
907,performs,I
907,better,I
907,than,I
907,other,B
907,methods,I
907,which,O
907,used,O
907,beam,O
907,search,O
907,.,O
908,For,O
908,the,O
908,popular,O
908,ROUGE,B
908,-,I
908,2,I
908,metric,I
908,",",O
908,our,O
908,SEASS,O
908,model,O
908,achieves,B
908,17.54,B
908,F1,I
908,score,I
908,and,O
908,performs,B
908,better,I
908,than,I
908,the,O
908,previous,B
908,works,I
908,.,O
909,Compared,O
909,to,O
909,the,O
909,ABS,B
909,model,I
909,",",O
909,our,O
909,model,O
909,has,O
909,a,O
909,6.22,B
909,ROUGE,I
909,-,I
909,2,I
909,F1,I
909,relative,I
909,gain,I
909,.,O
910,Compared,O
910,to,O
910,the,O
910,highest,B
910,CAs,I
910,2s,I
910,baseline,I
910,",",O
910,our,O
910,model,O
910,achieves,B
910,1.57,B
910,ROUGE,I
910,-,I
910,2,I
910,F1,I
910,improvement,I
910,and,O
910,passes,B
910,the,O
910,significant,B
910,test,I
910,according,B
910,to,O
910,the,O
910,official,B
910,ROUGE,O
910,script,O
910,.,O
911,0.0001,B
912,As,O
912,summarized,O
912,in,O
912,",",O
912,our,O
912,SEASS,B
912,outperforms,B
912,all,B
912,the,I
912,baseline,I
912,methods,I
912,and,I
912,achieves,B
912,29.21,B
912,",",O
912,9.56,O
912,and,O
912,25.51,O
912,for,B
912,ROUGE,B
912,1,I
912,",",O
912,2,O
912,and,O
912,L,O
912,recall,O
912,.,O
913,Compared,O
913,to,O
913,the,O
913,ABS,B
913,+,I
913,model,I
913,which,O
913,is,O
913,tuned,B
913,using,I
913,DUC,B
913,2003,I
913,data,I
913,",",O
913,our,B
913,model,O
913,performs,B
913,significantly,B
913,better,I
913,by,B
913,1.07,B
913,ROUGE,I
913,-,I
913,2,I
913,recall,I
913,score,I
913,and,O
913,is,O
913,trained,O
913,only,O
913,with,O
913,English,B
913,Gigaword,I
913,sentence,O
913,-,O
913,summary,O
913,data,O
913,without,O
913,being,O
913,tuned,O
913,using,O
913,DUC,O
913,data,O
913,.,O
914,TOPIARY,B
914,is,O
914,the,O
914,best,O
914,on,O
914,DUC2004,O
914,Task,O
914,-,O
914,1,O
914,for,B
914,compressive,B
914,text,I
914,summarization,I
914,.,O
915,It,O
915,combines,B
915,a,O
915,system,B
915,using,I
915,linguistic,I
915,based,I
915,transformations,I
915,and,O
915,an,B
915,unsupervised,I
915,topic,I
915,detection,I
915,algorithm,I
915,for,O
915,compressive,O
915,text,O
915,summarization,O
915,.,O
916,MOSES,O
916,+,O
916,uses,B
916,a,O
916,phrasebased,B
916,statistical,I
916,machine,I
916,translation,I
916,system,I
916,trained,B
916,on,I
916,Gigaword,B
916,to,B
916,produce,I
916,summaries,B
916,.,O
917,ABS,O
917,and,O
917,ABS,O
917,+,O
917,are,O
917,both,O
917,the,O
917,neural,O
917,network,O
917,based,O
917,models,O
917,with,B
917,local,B
917,attention,I
917,modeling,I
917,for,B
917,abstractive,B
917,sentence,I
917,summarization,I
917,.,O
918,ABS,O
918,+,O
918,is,O
918,trained,B
918,on,I
918,the,O
918,Gigaword,B
918,corpus,I
918,",",O
918,but,O
918,combined,B
918,with,B
918,an,O
918,additional,B
918,log,I
918,-,I
918,linear,I
918,extractive,I
918,summarization,I
918,model,I
918,with,O
918,handcrafted,B
918,features,I
918,.,O
919,RNN,O
919,and,O
919,RNN,O
919,-,O
919,context,O
919,are,B
919,two,B
919,seq2seq,I
919,architectures,I
919,.,O
920,Copy,O
920,Net,O
920,integrates,B
920,a,O
920,copying,B
920,mechanism,I
920,into,B
920,the,O
920,sequence,O
920,-,O
920,to,O
920,sequence,O
920,framework,O
920,.,O
921,RNN,O
921,-,O
921,distract,O
921,uses,B
921,a,O
921,new,B
921,attention,I
921,mechanism,I
921,by,B
921,distracting,I
921,the,O
921,historical,B
921,attention,O
921,in,B
921,the,O
921,decoding,B
921,steps,I
921,.,O
922,RAS,O
922,-,O
922,LSTM,O
922,and,O
922,RAS,O
922,-,O
922,Elman,O
922,both,O
922,consider,B
922,words,B
922,and,O
922,word,O
922,positions,O
922,as,B
922,input,B
922,and,O
922,use,B
922,convolutional,B
922,encoders,I
922,to,B
922,handle,I
922,the,O
922,source,B
922,information,I
922,.,O
923,LenEmb,B
923,uses,O
923,a,O
923,mechanism,O
923,to,O
923,control,B
923,the,O
923,summary,B
923,length,B
923,by,B
923,considering,I
923,the,O
923,length,O
923,embedding,O
923,vector,O
923,as,B
923,the,O
923,input,B
923,.,O
924,ASC+,O
924,FSC,O
924,1,O
924,),O
924,uses,B
924,a,O
924,generative,B
924,model,I
924,with,B
924,attention,B
924,mechanism,I
924,to,B
924,conduct,I
924,the,O
924,sentence,B
924,compression,I
924,problem,I
924,.,O
925,lvt2k,O
925,-,O
925,1sent,O
925,and,O
925,lvt5k,O
925,-,O
925,1sent,O
925,utilize,B
925,a,O
925,trick,B
925,to,B
925,control,I
925,the,O
925,vocabulary,B
925,size,I
925,to,O
925,improve,O
925,the,O
925,training,B
925,efficiency,I
925,.,O
926,For,O
926,the,O
926,experiments,O
926,on,B
926,the,O
926,English,B
926,dataset,I
926,Gigawords,I
926,",",O
926,we,O
926,set,B
926,the,O
926,dimension,B
926,of,B
926,word,B
926,embeddings,I
926,to,B
926,300,B
926,",",O
926,and,O
926,the,O
926,dimension,O
926,of,O
926,hidden,B
926,states,I
926,and,O
926,latent,O
926,variables,O
926,to,O
926,500,B
926,.,O
927,The,O
927,maximum,B
927,length,I
927,of,I
927,documents,B
927,and,I
927,summaries,I
927,is,B
927,100,B
927,and,O
927,50,O
927,respectively,O
927,.,O
928,The,O
928,batch,B
928,size,I
928,of,O
928,mini-batch,B
928,training,I
928,is,B
928,256,B
928,.,O
929,For,B
929,DUC,B
929,-,I
929,2004,I
929,",",O
929,the,O
929,maximum,B
929,length,I
929,of,I
929,summaries,B
929,is,B
929,75,B
929,bytes,I
929,.,O
930,For,O
930,the,O
930,dataset,B
930,of,I
930,LCSTS,I
930,",",O
930,the,O
930,dimension,B
930,of,O
930,word,B
930,embeddings,I
930,is,B
930,350,B
930,.,O
931,We,O
931,also,O
931,set,O
931,the,O
931,dimension,O
931,of,O
931,hidden,B
931,states,I
931,and,I
931,latent,I
931,variables,I
931,to,B
931,500,B
931,.,O
932,The,O
932,maximum,B
932,length,I
932,of,I
932,documents,B
932,and,I
932,summaries,I
932,is,B
932,120,B
932,and,O
932,25,O
932,respectively,O
932,",",O
932,and,O
932,the,O
932,batch,O
932,size,O
932,is,O
932,also,O
932,256,O
932,.,O
933,The,O
933,beam,B
933,size,I
933,of,I
933,the,O
933,decoder,B
933,was,O
933,set,B
933,to,I
933,be,O
933,10,B
933,.,O
934,Adadelta,B
934,with,B
934,hyperparameter,O
934,?,O
935,6,O
935,is,O
935,used,B
935,for,I
935,gradient,B
935,based,I
935,optimization,I
935,.,O
936,Our,O
936,neural,B
936,network,I
936,based,I
936,framework,I
936,is,O
936,implemented,B
936,using,I
936,Theano,B
936,(,O
936,Theano,O
936,Development,O
936,Team,O
936,",",O
936,2016,O
936,),O
936,.,O
937,To,O
937,tackle,O
937,the,O
937,above,O
937,mentioned,O
937,problems,O
937,",",O
937,we,O
937,design,B
937,a,O
937,new,B
937,framework,I
937,based,B
937,on,I
937,sequence,I
937,to,O
937,-,O
937,sequence,O
937,oriented,O
937,encoder,O
937,-,O
937,decoder,O
937,model,O
937,equipped,B
937,with,I
937,a,O
937,latent,B
937,structure,I
937,modeling,I
937,component,I
937,.,O
938,We,O
938,employ,B
938,Variational,B
938,Auto,I
938,-,I
938,Encoders,I
938,(,I
938,VAEs,I
938,),I
938,as,B
938,the,O
938,base,B
938,model,I
938,for,B
938,our,B
938,generative,I
938,framework,I
938,which,O
938,can,B
938,handle,I
938,the,O
938,inference,B
938,problem,I
938,associated,B
938,with,I
938,complex,B
938,generative,O
938,modeling,O
938,.,O
939,Inspired,O
939,by,O
939,",",O
939,we,O
939,add,B
939,historical,B
939,dependencies,I
939,on,B
939,the,O
939,latent,B
939,variables,I
939,of,B
939,VAEs,B
939,and,O
939,propose,B
939,a,O
939,deep,B
939,recurrent,I
939,generative,I
939,decoder,I
939,(,I
939,DRGD,I
939,),I
939,for,B
939,latent,O
939,structure,O
939,modeling,O
939,.,O
940,Then,O
940,the,O
940,standard,B
940,discriminative,I
940,deterministic,I
940,decoder,I
940,and,I
940,the,O
940,recurrent,O
940,generative,O
940,decoder,O
940,are,O
940,integrated,B
940,into,B
940,a,O
940,unified,B
940,decoding,I
940,framework,I
940,.,O
941,The,O
941,target,B
941,summaries,I
941,will,O
941,be,O
941,decoded,B
941,based,B
941,on,I
941,both,I
941,the,O
941,discriminative,B
941,deterministic,I
941,variables,I
941,and,O
941,the,O
941,generative,B
941,latent,I
941,structural,I
941,information,I
941,.,O
942,Deep,O
942,Recurrent,O
942,Generative,O
942,Decoder,O
942,for,O
942,Abstractive,B
942,Text,I
942,Summarization,I
943,In,O
943,this,O
943,paper,O
943,",",O
943,we,O
943,propose,O
943,a,O
943,novel,O
943,word,O
943,-,O
943,level,O
943,approach,O
943,for,O
943,distant,B
943,supervised,I
943,relation,I
943,extraction,I
943,by,O
943,reducing,O
943,inner-sentence,O
943,noise,O
943,and,O
943,improving,O
943,robustness,O
943,against,O
943,noisy,O
943,words,O
943,.,O
944,The,O
944,results,O
944,on,B
944,the,O
944,Chinese,B
944,dataset,I
944,LCSTS,I
944,are,O
944,shown,O
944,in,O
944,.,O
945,Our,O
945,model,O
945,DRGD,O
945,also,O
945,achieves,B
945,the,O
945,best,B
945,performance,I
945,.,O
946,Due,O
946,to,O
946,the,O
946,strong,O
946,rewriting,O
946,ability,O
946,of,O
946,the,O
946,seq2seq,B
946,framework,O
946,",",O
946,in,O
946,this,O
946,paper,O
946,",",O
946,we,O
946,propose,O
946,to,O
946,combine,B
946,the,O
946,seq2seq,O
946,and,O
946,template,O
946,based,O
946,summarization,O
946,approaches,O
946,.,O
947,We,O
947,call,B
947,our,O
947,summarization,B
947,system,I
947,Re,B
947,3,I
947,Sum,I
947,",",O
947,which,O
947,consists,B
947,of,I
947,three,B
947,modules,I
947,:,O
947,Retrieve,B
947,",",O
947,Rerank,B
947,and,O
947,Rewrite,B
947,.,O
948,We,O
948,utilize,B
948,a,O
948,widely,B
948,-,I
948,used,I
948,Information,I
948,Retrieval,I
948,(,I
948,IR,I
948,),I
948,platform,I
948,to,B
948,find,I
948,out,I
948,candidate,B
948,soft,I
948,templates,I
948,from,B
948,the,O
948,training,B
948,corpus,I
948,.,O
949,Then,O
949,",",O
949,we,O
949,extend,B
949,the,O
949,seq2seq,B
949,model,I
949,to,B
949,jointly,I
949,learn,I
949,template,B
949,saliency,I
949,measurement,I
949,(,I
949,Rerank,I
949,),I
949,and,O
949,final,B
949,summary,I
949,generation,I
949,(,O
949,Rewrite,O
949,),O
949,.,O
950,Specifically,O
950,",",O
950,a,O
950,Recurrent,B
950,Neural,I
950,Network,I
950,(,I
950,RNN,I
950,),I
950,encoder,I
950,is,O
950,applied,B
950,to,I
950,convert,B
950,the,O
950,input,B
950,sentence,I
950,and,O
950,each,B
950,candidate,I
950,template,I
950,into,B
950,hidden,B
950,states,I
950,.,O
951,In,B
951,Rerank,B
951,",",O
951,we,O
951,measure,B
951,the,O
951,informativeness,B
951,of,B
951,a,O
951,candidate,B
951,template,I
951,according,B
951,to,B
951,its,O
951,hidden,B
951,state,I
951,relevance,I
951,to,O
951,the,O
951,input,B
951,sentence,I
951,.,O
952,From,O
952,",",O
952,we,O
952,can,O
952,observe,B
952,that,O
952,the,O
952,model,O
952,with,B
952,the,O
952,STP,B
952,performs,B
952,best,B
952,",",O
952,and,O
952,the,O
952,SDP,B
952,model,O
952,obtains,B
952,an,O
952,even,B
952,worse,I
952,result,I
952,than,B
952,the,O
952,pure,B
952,one,I
952,.,O
953,The,O
953,candidate,O
953,template,O
953,with,B
953,the,O
953,highest,B
953,predicted,I
953,informativeness,I
953,is,B
953,regarded,I
953,as,I
953,the,O
953,actual,B
953,soft,I
953,template,O
953,.,O
954,In,O
954,Rewrite,B
954,",",O
954,the,O
954,summary,B
954,is,O
954,generated,B
954,according,B
954,to,I
954,the,O
954,hidden,B
954,states,I
954,of,B
954,both,I
954,the,O
954,sentence,B
954,and,I
954,template,I
954,.,O
955,OpenNMT,B
956,We,O
956,also,O
956,implement,B
956,the,O
956,standard,B
956,attentional,I
956,seq2seq,I
956,model,I
956,with,O
956,OpenNMT,O
956,.,O
957,FTSum,B
957,encoded,B
957,the,O
957,facts,B
957,extracted,B
957,from,I
957,the,O
957,source,B
957,sentence,I
957,to,B
957,improve,I
957,both,B
957,the,O
957,faithfulness,B
957,and,O
957,informativeness,B
957,of,O
957,generated,B
957,summaries,I
957,.,O
958,In,O
958,addition,O
958,",",O
958,to,O
958,evaluate,O
958,the,O
958,effectiveness,O
958,of,O
958,our,O
958,joint,O
958,learning,O
958,framework,O
958,",",O
958,we,O
958,develop,O
958,a,O
958,baseline,O
958,named,O
958,"""",O
958,PIPELINE,B
958,"""",O
958,.,O
959,However,O
959,",",O
959,it,O
959,trains,B
959,the,O
959,Rerank,B
959,module,I
959,and,O
959,Rewrite,B
959,module,O
959,in,O
959,pipeline,O
959,.,O
960,Code,O
960,and,O
960,results,O
960,can,O
960,be,O
960,found,O
960,at,O
960,http://www4.comp.polyu.edu.hk/cszqcao/,B
961,We,O
961,use,B
961,the,O
961,popular,B
961,seq2seq,I
961,framework,I
961,Open,B
961,-,I
961,NMT,I
961,5,O
961,as,O
961,the,O
961,starting,O
961,point,O
961,.,O
962,To,O
962,make,O
962,our,O
962,model,O
962,more,O
962,general,O
962,",",O
962,we,O
962,retain,B
962,the,O
962,default,B
962,settings,I
962,of,B
962,Open,B
962,NMT,I
962,to,O
962,build,O
962,the,O
962,network,B
962,architecture,I
962,.,O
963,RE,B
963,models,O
963,usually,O
963,ignore,O
963,such,O
963,readily,O
963,available,O
963,side,O
963,information,O
963,.,O
964,The,O
964,PR,B
964,curve,I
964,areas,I
964,of,B
964,BGRU,B
964,+,I
964,SDP,I
964,and,I
964,BGRU,O
964,are,B
964,about,I
964,0.332,B
964,and,O
964,0.337,O
964,respectively,O
964,",",O
964,while,O
964,BGRU,O
964,+,O
964,STP,O
964,increases,B
964,it,I
964,to,I
964,0.366,B
964,.,O
965,Specifically,O
965,",",O
965,the,O
965,dimensions,B
965,of,O
965,word,B
965,embeddings,I
965,and,I
965,RNN,I
965,are,B
965,both,I
965,500,B
965,",",O
965,and,O
965,the,O
965,encoder,B
965,and,O
965,decoder,O
965,structures,O
965,are,O
965,two,B
965,-,I
965,layer,I
965,bidirectional,I
965,Long,I
965,Short,I
965,Term,I
965,Memory,I
965,Networks,I
965,(,I
965,LSTMs,I
965,),I
965,.,O
966,On,B
966,our,B
966,computer,I
966,(,O
966,GPU,B
966,:,O
966,GTX,B
966,1080,I
966,",",O
966,Memory,B
966,:,O
966,16G,B
966,",",O
966,CPU,B
966,:,O
966,i7-7700,B
966,K,I
966,),O
966,",",O
966,the,O
966,training,B
966,spends,I
966,about,B
966,2,I
966,days,I
966,.,O
967,During,O
967,test,O
967,",",O
967,we,O
967,use,O
967,beam,B
967,search,I
967,of,B
967,size,I
967,5,B
967,to,B
967,generate,I
967,summaries,B
967,.,O
968,We,O
968,add,B
968,the,O
968,argument,B
968,"""",O
968,replace,O
968,unk,O
968,"""",O
968,to,B
968,replace,O
968,the,O
968,generated,B
968,unknown,I
968,words,I
968,with,B
968,the,O
968,source,B
968,word,I
968,that,B
968,holds,I
968,the,O
968,highest,B
968,attention,I
968,weight,I
968,.,O
969,Since,O
969,the,O
969,generated,O
969,summaries,O
969,are,O
969,often,O
969,shorter,O
969,than,O
969,the,O
969,actual,O
969,ones,O
969,",",O
969,we,O
969,introduce,B
969,an,O
969,additional,B
969,length,I
969,penalty,I
969,argument,I
969,"""",O
969,alpha,B
969,1,I
969,"""",O
969,to,B
969,encourage,I
969,longer,B
969,generation,I
969,",",O
969,like,O
969,.,O
970,Retrieve,O
970,",",O
970,Rerank,O
970,and,O
970,Rewrite,O
970,:,O
970,Soft,O
970,Template,O
970,Based,O
970,Neural,B
970,Summarization,I
971,",",O
971,abstractive,B
971,sentence,I
971,summarization,I
971,",",O
971,which,O
971,generates,O
971,a,O
971,shorter,O
971,version,O
971,of,O
971,a,O
971,given,O
971,sentence,O
971,while,O
971,attempting,O
971,to,O
971,preserve,O
971,its,O
971,original,O
971,meaning,O
971,.,O
972,We,O
972,also,O
972,examine,B
972,the,O
972,performance,B
972,of,B
972,directly,I
972,regarding,I
972,soft,B
972,templates,I
972,as,B
972,output,B
972,summaries,I
972,.,O
973,We,O
973,introduce,B
973,five,B
973,types,I
973,of,I
973,different,I
973,soft,I
973,templates,I
973,:,O
974,As,O
974,shown,O
974,in,O
974,",",O
974,the,O
974,performance,B
974,of,I
974,Random,B
974,is,B
974,terrible,B
974,",",O
974,indicating,O
974,it,O
974,is,O
974,impossible,O
974,to,O
974,use,O
974,one,O
974,summary,O
974,template,O
974,to,O
974,fit,O
974,various,O
974,actual,O
974,summaries,O
974,.,O
975,The,O
975,result,O
975,indicates,O
975,:,O
975,(,O
975,1,O
975,),O
975,Our,B
975,STP,I
975,can,O
975,get,B
975,rid,I
975,of,I
975,irrelevant,B
975,words,I
975,in,B
975,each,B
975,instance,I
975,and,O
975,obtain,B
975,more,B
975,precise,I
975,sentence,I
975,representation,I
975,for,O
975,relation,O
975,extraction,O
975,.,O
976,Rerank,B
976,largely,B
976,outperforms,I
976,First,B
976,",",O
976,which,O
976,verifies,O
976,the,O
976,effectiveness,O
976,of,O
976,the,O
976,Rerank,O
976,module,O
976,.,O
977,Notice,O
977,that,O
977,Optimal,B
977,greatly,B
977,exceeds,I
977,all,B
977,the,I
977,state,I
977,-,I
977,of,I
977,-,O
977,the,O
977,-,O
977,art,O
977,approaches,O
977,.,O
978,Likewise,O
978,",",O
978,comparing,B
978,Max,B
978,and,I
978,First,I
978,",",O
978,we,O
978,observe,B
978,that,I
978,the,O
978,improving,B
978,capacity,I
978,of,B
978,the,O
978,Retrieve,B
978,module,I
978,is,B
978,high,B
978,.,O
979,We,O
979,also,O
979,measure,B
979,the,O
979,linguistic,B
979,quality,I
979,of,B
979,generated,B
979,summaries,I
979,from,O
979,various,O
979,aspects,O
979,",",O
979,and,O
979,the,O
979,results,O
979,are,O
979,present,O
979,in,O
979,.,O
980,As,O
980,can,O
980,be,O
980,seen,O
980,from,O
980,the,O
980,rows,O
980,"""",O
980,LEN,O
980,DIF,O
980,"""",O
980,and,O
980,"""",O
980,LESS,O
980,3,O
980,"""",O
980,",",O
980,the,O
980,performance,B
980,of,I
980,Re,B
980,3,O
980,Sum,O
980,is,O
980,almost,O
980,the,O
980,same,O
980,as,O
980,that,O
980,of,O
980,soft,B
980,templates,I
980,.,O
981,In,O
981,this,O
981,section,O
981,",",O
981,we,O
981,investigate,B
981,how,O
981,soft,B
981,templates,I
981,affect,B
981,our,B
981,model,I
981,.,O
982,As,O
982,illustrated,O
982,in,O
982,",",O
982,the,O
982,more,B
982,high,I
982,-,I
982,quality,I
982,templates,I
982,are,O
982,provided,B
982,",",O
982,the,O
982,higher,B
982,ROUGE,I
982,scores,I
982,are,O
982,achieved,B
982,.,O
983,Next,O
983,",",O
983,we,O
983,manually,B
983,inspect,I
983,the,O
983,summaries,B
983,generated,B
983,by,I
983,different,B
983,methods,I
983,.,O
984,We,O
984,find,B
984,the,O
984,outputs,B
984,of,I
984,Re,I
984,3,I
984,Sum,I
984,are,O
984,usually,O
984,longer,B
984,and,I
984,more,I
984,flu,I
984,-,I
984,ent,I
984,than,I
984,the,O
984,outputs,O
984,of,O
984,OpenNMT,O
984,.,O
985,As,O
985,can,O
985,be,O
985,seen,O
985,",",O
985,with,B
985,different,B
985,templates,I
985,given,I
985,",",O
985,our,B
985,model,I
985,is,O
985,likely,B
985,to,I
985,generate,I
985,dissimilar,B
985,summaries,I
985,.,O
986,(,O
986,2,O
986,),O
986,The,O
986,SDP,B
986,method,I
986,is,O
986,not,B
986,appropriate,I
986,to,I
986,handle,I
986,low,B
986,-,I
986,quality,I
986,sentences,I
986,where,B
986,key,B
986,relation,I
986,words,I
986,are,O
986,not,O
986,in,O
986,the,O
986,SDP,O
986,.,O
987,The,O
987,basic,O
987,idea,O
987,of,B
987,our,O
987,method,O
987,is,O
987,to,O
987,jointly,B
987,estimate,I
987,the,O
987,upper-bound,B
987,frequency,I
987,of,O
987,each,B
987,target,I
987,vocabulary,I
987,that,B
987,can,I
987,occur,I
987,in,B
987,a,O
987,summary,B
987,during,B
987,the,O
987,encoding,B
987,process,I
987,and,O
987,exploit,O
987,the,O
987,estimation,O
987,to,O
987,control,B
987,the,O
987,output,B
987,words,I
987,in,O
987,each,O
987,decoding,O
987,step,O
987,.,O
988,We,O
988,refer,O
988,to,O
988,our,O
988,additional,B
988,component,I
988,as,O
988,a,O
988,wordfrequency,B
988,estimation,I
988,(,I
988,WFE,I
988,),I
988,sub-model,I
988,.,O
989,The,O
989,WFE,B
989,sub-model,I
989,explicitly,B
989,manages,I
989,how,B
989,many,I
989,times,I
989,each,I
989,word,I
989,has,I
989,been,I
989,generated,I
989,so,I
989,far,I
989,and,O
989,might,B
989,be,I
989,generated,O
989,in,O
989,the,O
989,future,O
989,during,O
989,the,O
989,decoding,O
989,process,O
989,.,O
990,Cutting,O
990,-,O
990,off,O
990,Redundant,O
990,Repeating,O
990,Generations,O
990,for,O
990,Neural,B
990,Abstractive,I
990,Summarization,I
991,",",O
991,machine,O
991,translation,O
991,(,O
991,MT,O
991,),O
991,and,O
991,abstractive,B
991,summarization,I
991,(,O
991,ABS,O
991,),O
991,.,O
992,This,O
992,baseline,O
992,keeps,B
992,K,B
992,hypotheses,I
992,with,B
992,highest,B
992,log-probability,I
992,scores,I
992,at,B
992,each,B
992,decoding,I
992,step,I
992,.,O
993,This,O
993,baseline,O
993,randomly,B
993,samples,I
993,words,B
993,from,B
993,top,B
993,-,I
993,10,I
993,candidates,I
993,of,B
993,the,O
993,distribution,B
993,at,B
993,the,O
993,decoding,B
993,step,I
993,.,O
994,From,O
994,and,O
994,",",O
994,we,O
994,can,O
994,obtain,O
994,:,O
994,(,O
994,1,O
994,),O
994,Regardless,O
994,of,O
994,the,O
994,dataset,O
994,that,O
994,we,O
994,employ,O
994,",",O
994,BGRU,B
994,-,I
994,WLA,I
994,(,O
994,+,O
994,STP,O
994,),O
994,+,O
994,EWA,O
994,outperforms,B
994,BGRU,O
994,(+,O
994,STP,O
994,),O
994,.,O
995,This,O
995,baseline,O
995,constructs,B
995,a,O
995,hard,B
995,-,I
995,MoE,I
995,of,I
995,K,I
995,decoders,I
995,with,B
995,uniform,B
995,mixing,I
995,coefficient,I
995,(,O
995,referred,O
995,as,O
995,hMup,O
995,in,O
995,),O
995,and,O
995,conducts,B
995,parallel,B
995,greedy,I
995,decoding,I
995,.,O
996,We,O
996,construct,B
996,a,O
996,hard,B
996,-,I
996,MoE,I
996,of,I
996,K,B
996,SELECTORs,I
996,with,B
996,uniform,B
996,mixing,I
996,coefficient,I
996,that,O
996,infers,B
996,K,O
996,different,O
996,focus,O
996,from,O
996,source,O
996,sequence,O
996,.,O
997,For,O
997,all,O
997,experiments,O
997,",",O
997,we,O
997,tie,B
997,the,O
997,weights,B
997,of,B
997,the,O
997,encoder,B
997,embedding,I
997,",",O
997,the,O
997,decoder,B
997,embedding,O
997,",",O
997,and,O
997,the,O
997,decoder,O
997,output,O
997,layers,O
997,.,O
998,We,O
998,train,B
998,up,B
998,to,I
998,20,I
998,epochs,I
998,and,O
998,select,B
998,the,O
998,checkpoint,B
998,with,B
998,the,O
998,best,B
998,oracle,I
998,metric,I
998,.,O
999,We,O
999,use,B
999,Adam,B
999,(,I
999,Kingma,I
999,and,I
999,Ba,I
999,",",I
999,2015,I
999,),I
999,optimizer,I
999,with,B
999,learning,B
999,rate,I
999,0.001,I
999,and,O
999,momentum,O
999,parmeters,O
999,?,O
1000,Minibatch,O
1000,size,O
1000,is,B
1000,64,B
1000,and,I
1000,32,I
1000,for,B
1000,question,B
1000,generation,I
1000,and,O
1000,abstractive,O
1000,summarization,O
1000,.,O
1001,All,O
1001,models,O
1001,are,O
1001,implemented,B
1001,in,I
1001,PyTorch,B
1001,and,O
1001,trained,B
1001,on,I
1001,single,B
1001,Tesla,I
1001,P40,I
1001,GPU,I
1001,",",O
1001,based,B
1001,on,O
1001,NAVER,B
1001,Smart,I
1001,Machine,I
1001,Learning,I
1001,(,I
1001,NSML,I
1001,),I
1001,platform,I
1001,.,O
1002,In,O
1002,this,O
1002,paper,O
1002,",",O
1002,we,O
1002,present,O
1002,a,O
1002,method,O
1002,for,O
1002,diverse,O
1002,generation,O
1002,that,O
1002,separates,B
1002,diversification,B
1002,and,I
1002,generation,O
1002,stages,O
1002,.,O
1003,The,O
1003,diversification,B
1003,stage,I
1003,leverages,B
1003,content,B
1003,selection,I
1003,to,I
1003,map,B
1003,the,O
1003,source,B
1003,to,O
1003,multiple,O
1003,sequences,O
1003,",",O
1003,where,O
1003,each,O
1003,mapping,O
1003,is,O
1003,modeled,O
1003,by,O
1003,focusing,O
1003,on,O
1003,different,O
1003,tokens,O
1003,in,O
1003,the,O
1003,source,O
1003,(,O
1003,oneto,O
1003,-,O
1003,many,O
1003,mapping,O
1003,),O
1003,.,O
1004,To,O
1004,be,O
1004,more,O
1004,specific,O
1004,",",O
1004,the,O
1004,PR,B
1004,curve,I
1004,area,I
1004,has,O
1004,a,O
1004,relative,B
1004,improvement,I
1004,of,B
1004,over,B
1004,2.3,I
1004,%,I
1004,",",O
1004,which,O
1004,demonstrates,O
1004,that,O
1004,entity,O
1004,-,O
1004,wise,O
1004,hidden,O
1004,states,O
1004,in,O
1004,the,O
1004,BGRU,O
1004,present,O
1004,more,O
1004,precise,O
1004,relational,O
1004,features,O
1004,than,O
1004,other,O
1004,word,O
1004,states,O
1004,.,O
1005,The,O
1005,generation,B
1005,stage,I
1005,uses,B
1005,a,O
1005,standard,B
1005,encoder,I
1005,-,I
1005,decoder,I
1005,model,I
1005,to,O
1005,generate,B
1005,a,O
1005,target,B
1005,sequence,I
1005,given,I
1005,each,I
1005,selected,I
1005,content,I
1005,from,I
1005,the,O
1005,source,O
1005,(,O
1005,one,O
1005,-,O
1005,to,O
1005,-,O
1005,one,O
1005,mapping,O
1005,),O
1005,.,O
1006,We,O
1006,present,B
1006,a,O
1006,generic,B
1006,module,I
1006,called,B
1006,SELECTOR,B
1006,that,O
1006,is,O
1006,specialized,B
1006,for,I
1006,diversification,B
1006,.,O
1007,This,O
1007,module,O
1007,can,O
1007,be,O
1007,used,B
1007,as,I
1007,a,O
1007,plug,B
1007,-,I
1007,and,I
1007,-,O
1007,play,O
1007,to,B
1007,an,O
1007,arbitrary,B
1007,encoder,I
1007,-,O
1007,decoder,O
1007,model,O
1007,for,B
1007,generation,B
1007,without,I
1007,architecture,I
1007,change,I
1007,.,O
1008,Mixture,O
1008,Content,O
1008,Selection,O
1008,for,O
1008,Diverse,B
1008,Sequence,I
1008,Generation,I
1009,Encoder,O
1009,-,O
1009,decoder,O
1009,models,O
1009,are,O
1009,widely,O
1009,used,O
1009,for,O
1009,sequence,B
1009,generation,I
1009,",",O
1009,most,O
1009,notably,O
1009,in,O
1009,machine,O
1009,translation,O
1009,where,O
1009,neural,O
1009,models,O
1009,are,O
1009,now,O
1009,often,O
1009,almost,O
1009,as,O
1009,good,O
1009,as,O
1009,human,O
1009,translators,O
1009,in,O
1009,some,O
1009,language,O
1009,pairs,O
1009,.,O
1010,Accuracy,O
1010,Trade,O
1010,-,O
1010,off,O
1010,compare,O
1010,our,O
1010,method,O
1010,with,O
1010,different,O
1010,diversitypromoting,O
1010,techniques,O
1010,in,B
1010,question,O
1010,generation,O
1010,and,O
1010,abstractive,O
1010,summarization,O
1010,.,O
1011,The,O
1011,tables,O
1011,show,B
1011,that,O
1011,our,O
1011,mixture,B
1011,SELECTOR,I
1011,method,I
1011,outperforms,B
1011,all,B
1011,baselines,I
1011,in,O
1011,Top,B
1011,-,I
1011,1,I
1011,and,I
1011,oracle,I
1011,metrics,I
1011,and,O
1011,achieves,B
1011,the,O
1011,best,B
1011,trade,I
1011,-,O
1011,off,O
1011,between,B
1011,diversity,B
1011,and,O
1011,accuracy,O
1011,.,O
1012,Notably,O
1012,",",O
1012,our,B
1012,method,I
1012,scores,B
1012,state,B
1012,-,I
1012,of,I
1012,-,O
1012,the,O
1012,-,O
1012,art,O
1012,BLEU,O
1012,-,O
1012,4,O
1012,in,O
1012,question,B
1012,generation,I
1012,on,B
1012,SQuAD,B
1012,and,I
1012,ROUGE,I
1012,comparable,O
1012,to,O
1012,state,O
1012,-,O
1012,of,O
1012,-,O
1012,the,O
1012,-,O
1012,art,O
1012,methods,O
1012,in,O
1012,abstractive,B
1012,summarization,I
1012,in,O
1012,CNN,O
1012,-,O
1012,DM,O
1012,(,O
1012,See,O
1012,also,O
1012,for,O
1012,state,O
1012,-,O
1012,of,O
1012,-,O
1012,the,O
1012,-,O
1012,art,O
1012,results,O
1012,in,O
1012,CNN,O
1012,-,O
1012,DM,O
1012,),O
1012,.,O
1013,EWA,B
1013,achieves,B
1013,further,B
1013,improvements,I
1013,and,O
1013,outperforms,B
1013,the,O
1013,baseline,B
1013,by,B
1013,over,I
1013,4.6,B
1013,%,I
1013,",",O
1013,because,O
1013,it,O
1013,considers,O
1013,more,O
1013,information,O
1013,than,O
1013,entity,O
1013,or,O
1013,relational,O
1013,words,O
1013,alone,O
1013,.,O
1014,Here,O
1014,we,O
1014,compare,B
1014,the,O
1014,effect,B
1014,of,I
1014,number,I
1014,of,O
1014,mixtures,O
1014,in,B
1014,our,O
1014,SELECTOR,B
1014,and,I
1014,Mixture,I
1014,Decoder,I
1014,.,O
1015,show,B
1015,that,O
1015,pairwise,B
1015,similarity,I
1015,increases,I
1015,(,I
1015,diversity,I
1015,?),I
1016,when,B
1016,the,O
1016,number,B
1016,of,I
1016,mixtures,I
1016,increases,I
1016,for,B
1016,Mixture,B
1016,Decoder,I
1016,.,O
1017,We,O
1017,compute,B
1017,the,O
1017,entropy,B
1017,numbers,I
1017,by,B
1017,averaging,I
1017,over,B
1017,all,I
1017,generated,I
1017,words,I
1017,in,B
1017,the,O
1017,validation,B
1017,set,I
1017,.,O
1018,We,O
1018,note,B
1018,that,O
1018,the,O
1018,entropy,B
1018,of,I
1018,C2F,I
1018,is,B
1018,very,B
1018,low,I
1018,(,O
1018,before,O
1018,taking,O
1018,the,O
1018,argmax,O
1018,at,O
1018,test,O
1018,time,O
1018,),O
1018,.,O
1019,This,O
1019,is,O
1019,exactly,O
1019,what,O
1019,we,O
1019,had,O
1019,hoped,O
1019,for,O
1019,-,O
1019,we,O
1019,will,O
1019,see,O
1019,that,O
1019,the,O
1019,model,B
1019,in,O
1019,fact,O
1019,learns,B
1019,to,I
1019,focus,I
1019,on,I
1019,only,O
1019,a,O
1019,few,B
1019,top,I
1019,-,O
1019,level,O
1019,chunks,O
1019,of,O
1019,the,O
1019,document,B
1019,over,B
1019,the,O
1019,course,B
1019,of,O
1019,generation,O
1019,.,O
1020,In,B
1020,HIER,B
1020,",",O
1020,we,O
1020,observe,B
1020,that,O
1020,the,O
1020,attention,B
1020,becomes,I
1020,washed,I
1020,out,I
1020,(,O
1020,in,O
1020,accord,O
1020,with,O
1020,its,O
1020,high,O
1020,entropy,O
1020,),O
1020,and,O
1020,is,O
1020,essentially,O
1020,averaging,B
1020,all,B
1020,of,I
1020,the,O
1020,encoder,O
1020,hidden,O
1020,states,O
1020,.,O
1021,In,O
1021,C2,B
1021,F,I
1021,",",O
1021,we,O
1021,see,O
1021,that,O
1021,we,O
1021,get,B
1021,very,B
1021,sharp,I
1021,attention,I
1021,on,B
1021,some,B
1021,rows,I
1021,as,O
1021,we,O
1021,had,O
1021,hoped,O
1021,.,O
1022,(,O
1022,1,O
1022,),O
1022,Regardless,O
1022,of,O
1022,the,O
1022,dataset,O
1022,that,O
1022,we,O
1022,use,O
1022,",",O
1022,models,B
1022,with,I
1022,TL,I
1022,achieve,B
1022,better,B
1022,performance,I
1022,",",O
1022,which,O
1022,improve,B
1022,the,O
1022,PR,B
1022,curve,I
1022,area,I
1022,by,B
1022,over,B
1022,4.7,I
1022,%,I
1022,.,O
1023,Therefore,O
1023,",",O
1023,in,O
1023,order,O
1023,to,B
1023,scale,I
1023,attention,B
1023,models,I
1023,for,O
1023,this,O
1023,problem,O
1023,",",O
1023,we,O
1023,aim,O
1023,to,O
1023,prune,B
1023,down,I
1023,the,I
1023,length,B
1023,of,I
1023,the,O
1023,source,O
1023,sequence,O
1023,in,O
1023,an,O
1023,intelligent,O
1023,way,O
1023,.,O
1024,Instead,O
1024,of,B
1024,naively,B
1024,attending,I
1024,to,I
1024,all,I
1024,the,I
1024,words,I
1024,of,O
1024,the,O
1024,source,B
1024,at,O
1024,once,O
1024,",",O
1024,our,O
1024,solution,O
1024,is,O
1024,to,O
1024,use,O
1024,a,O
1024,two,B
1024,-,I
1024,layer,I
1024,hierarchical,I
1024,attention,I
1024,.,O
1025,For,B
1025,document,I
1025,summarization,I
1025,",",O
1025,this,O
1025,means,B
1025,dividing,B
1025,the,I
1025,document,O
1025,into,B
1025,chunks,I
1025,of,I
1025,text,I
1025,",",O
1025,sparsely,B
1025,attending,I
1025,to,I
1025,one,B
1025,or,I
1025,a,I
1025,few,I
1025,chunks,O
1025,at,O
1025,a,O
1025,time,O
1025,using,B
1025,hard,B
1025,attention,I
1025,",",O
1025,then,O
1025,applying,B
1025,the,O
1025,usual,B
1025,full,I
1025,attention,O
1025,over,B
1025,those,B
1025,chunks,O
1025,-,O
1025,we,O
1025,call,B
1025,this,O
1025,method,O
1025,coarse,B
1025,-,O
1025,to,O
1025,-,O
1025,fine,O
1025,attention,O
1025,.,O
1026,We,O
1026,train,B
1026,with,B
1026,minibatch,B
1026,stochastic,I
1026,gradient,I
1026,descent,I
1026,(,I
1026,SGD,I
1026,),I
1026,with,O
1026,batch,B
1026,size,I
1026,20,B
1026,for,B
1026,20,O
1026,epochs,O
1026,",",O
1026,renormalizing,B
1026,gradients,I
1026,below,B
1026,norm,I
1026,5,I
1026,.,O
1027,We,O
1027,initialize,B
1027,the,I
1027,learning,B
1027,rate,I
1027,to,B
1027,0.1,B
1027,for,B
1027,the,O
1027,top,B
1027,-,I
1027,level,I
1027,encoder,I
1027,and,O
1027,1,B
1027,for,O
1027,the,O
1027,rest,B
1027,of,I
1027,the,O
1027,model,O
1027,",",O
1027,and,O
1027,begin,B
1027,decaying,I
1027,it,I
1027,by,I
1027,a,B
1027,factor,I
1027,of,O
1027,0.5,O
1027,each,O
1027,epoch,O
1027,after,B
1027,the,O
1027,validation,B
1027,perplexity,I
1027,stops,B
1027,decreasing,B
1027,.,O
1028,We,O
1028,initialize,O
1028,all,B
1028,other,I
1028,parameters,I
1028,as,B
1028,uniform,I
1028,in,I
1028,the,O
1028,interval,O
1028,[,O
1028,?,O
1029,We,O
1029,use,B
1029,2,B
1029,layer,I
1029,LSTMs,I
1029,with,B
1029,500,B
1029,hidden,I
1029,units,I
1029,",",O
1029,and,O
1029,we,O
1029,initialize,O
1029,word,B
1029,embeddings,I
1029,with,O
1029,300,B
1029,dimensional,I
1029,word2vec,I
1029,embeddings,O
1029,.,O
1030,We,O
1030,use,O
1030,dropout,B
1030,between,B
1030,stacked,B
1030,LSTM,I
1030,hidden,I
1030,states,I
1030,and,I
1030,before,I
1030,the,I
1030,final,I
1030,word,I
1030,generator,I
1030,layer,I
1030,to,B
1030,regularize,I
1030,(,O
1030,with,O
1030,dropout,O
1030,probability,O
1030,0.3,O
1030,),O
1030,.,O
1031,For,B
1031,convolutional,B
1031,layers,I
1031,",",O
1031,we,O
1031,use,B
1031,a,O
1031,kernel,B
1031,width,I
1031,of,B
1031,6,B
1031,and,I
1031,600,I
1031,filters,I
1031,.,O
1032,Positional,O
1032,embeddings,O
1032,have,B
1032,dimension,B
1032,25,I
1032,.,O
1033,(,O
1033,2,O
1033,),O
1033,BGRU,B
1033,+,I
1033,STP,I
1033,+,O
1033,TL,O
1033,achieves,B
1033,the,O
1033,best,B
1033,performance,I
1033,and,O
1033,increases,B
1033,the,O
1033,area,B
1033,to,B
1033,0.383,B
1033,",",O
1033,while,O
1033,areas,O
1033,of,O
1033,BGRU,O
1033,",",O
1033,BGRU,O
1033,+,O
1033,STP,O
1033,and,O
1033,BGRU,O
1033,+,O
1033,TL,O
1033,are,O
1033,0.337,O
1033,",",O
1033,0.366,O
1033,and,O
1033,0.372,O
1033,respectively,O
1033,.,O
1034,At,B
1034,test,B
1034,time,I
1034,",",O
1034,we,O
1034,run,B
1034,beam,B
1034,search,I
1034,to,B
1034,produce,I
1034,the,O
1034,summary,B
1034,with,B
1034,a,O
1034,beam,O
1034,size,O
1034,of,O
1034,5,O
1034,.,O
1035,Our,O
1035,models,O
1035,are,O
1035,implemented,B
1035,using,I
1035,Torch,B
1035,based,B
1035,on,I
1035,a,O
1035,past,B
1035,version,I
1035,of,I
1035,the,I
1035,Open,I
1035,NMT,I
1035,system,I
1036,We,O
1036,ran,B
1036,our,B
1036,experiments,I
1036,on,B
1036,a,O
1036,12GB,B
1036,Geforce,I
1036,GTX,I
1036,Titan,I
1036,X,I
1036,GPU,I
1036,.,O
1037,Coarse-to-Fine,O
1037,Attention,O
1037,Models,O
1037,for,O
1037,Document,B
1037,Summarization,I
1038,The,O
1038,ILP,B
1038,model,I
1038,ROUGE,B
1038,scores,I
1038,are,O
1038,surprisingly,B
1038,low,I
1038,.,O
1039,C2,O
1039,F,O
1039,results,O
1039,are,O
1039,significantly,B
1039,worse,I
1039,than,I
1039,soft,B
1039,attention,I
1039,results,O
1039,.,O
1040,For,B
1040,the,O
1040,test,B
1040,set,I
1040,of,O
1040,",",O
1040,the,O
1040,average,B
1040,entailment,B
1040,score,I
1040,for,O
1040,the,O
1040,reference,B
1040,is,I
1040,0.72,B
1040,",",O
1040,while,O
1040,for,O
1040,the,O
1040,basic,B
1040,seq2seq,I
1040,model,I
1040,",",O
1040,the,O
1040,entailment,O
1040,score,O
1040,is,O
1040,only,O
1040,0.46,B
1040,.,O
1041,When,O
1041,we,O
1041,adopt,B
1041,entailmentbased,B
1041,strategies,I
1041,",",O
1041,the,O
1041,entailment,B
1041,score,I
1041,rises,B
1041,to,I
1041,0.63,B
1041,for,B
1041,seq2seq,B
1041,model,I
1041,.,O
1042,Note,B
1042,that,O
1042,the,O
1042,entailment,B
1042,score,I
1042,is,B
1042,0.57,B
1042,for,B
1042,seq2seq,B
1042,model,I
1042,with,B
1042,selective,B
1042,encoding,I
1042,",",O
1042,and,O
1042,we,O
1042,believe,O
1042,that,O
1042,the,O
1042,selective,O
1042,mechanism,O
1042,can,O
1042,filter,B
1042,out,I
1042,secondary,B
1042,information,I
1042,in,B
1042,the,O
1042,input,B
1042,",",O
1042,which,O
1042,will,O
1042,reduce,O
1042,the,O
1042,possibility,O
1042,to,O
1042,generate,O
1042,irrelevant,O
1042,information,O
1042,.,O
1043,We,O
1043,conduct,O
1043,experiments,O
1043,on,O
1043,two,O
1043,SRL,O
1043,tasks,O
1043,:,O
1043,and,O
1043,the,O
1043,predicate,B
1043,indicator,I
1043,embedding,I
1043,size,I
1043,is,B
1043,10,B
1043,.,O
1044,Entailment,O
1044,-,O
1044,aware,O
1044,selective,O
1044,model,O
1044,achieves,B
1044,a,O
1044,high,B
1044,entailment,O
1044,reward,O
1044,of,B
1044,0.71,B
1044,.,O
1045,In,O
1045,part,O
1045,at,O
1045,least,O
1045,",",O
1045,we,O
1045,can,O
1045,conclude,B
1045,that,O
1045,our,B
1045,model,I
1045,has,O
1045,successfully,B
1045,learned,I
1045,entailment,B
1045,knowledge,I
1045,.,O
1046,shows,O
1046,that,O
1046,the,O
1046,seq2seq,B
1046,model,I
1046,produces,B
1046,more,B
1046,novel,I
1046,words,I
1046,(,O
1046,i.e.,O
1047,",",O
1047,words,O
1047,that,O
1047,do,O
1047,not,O
1047,appear,O
1047,in,O
1047,the,O
1047,article,O
1047,),O
1047,than,B
1047,our,B
1047,model,I
1047,",",O
1047,indicating,B
1047,a,O
1047,lower,B
1047,degree,I
1047,of,I
1047,abstraction,I
1047,for,O
1047,our,O
1047,model,O
1047,.,O
1048,However,O
1048,",",O
1048,when,O
1048,we,O
1048,exclude,B
1048,all,B
1048,the,I
1048,words,I
1048,not,I
1048,in,I
1048,the,O
1048,reference,O
1048,(,O
1048,these,O
1048,words,O
1048,may,O
1048,lead,O
1048,to,O
1048,wrong,O
1048,information,O
1048,),O
1048,",",O
1048,our,B
1048,model,I
1048,generates,B
1048,more,B
1048,novel,I
1048,words,O
1048,",",O
1048,suggesting,B
1048,that,I
1048,our,O
1048,model,O
1048,provides,B
1048,a,O
1048,compromise,B
1048,solution,I
1048,for,B
1048,informativeness,B
1048,and,I
1048,correctness,I
1048,.,O
1049,6.6.3,O
1049,Could,B
1049,the,I
1049,entailment,I
1049,recognition,I
1049,also,I
1049,be,I
1049,improved,I
1049,?,I
1050,shows,B
1050,that,O
1050,our,B
1050,summarization,I
1050,model,I
1050,with,B
1050,MTL,B
1050,outperforms,B
1050,basic,B
1050,seq2seq,I
1050,model,O
1050,.,O
1051,increases,O
1051,",",O
1051,the,O
1051,accuracy,B
1051,of,B
1051,entailment,B
1051,recognition,I
1051,improves,O
1051,and,O
1051,finally,O
1051,exceeds,O
1051,that,O
1051,of,O
1051,the,O
1051,model,O
1051,without,O
1051,MTL,O
1051,",",O
1051,which,O
1051,reveals,O
1051,the,O
1051,advantage,O
1051,of,O
1051,MTL,O
1051,framework,O
1051,.,O
1052,ABS,B
1052,.,O
1053,first,O
1053,apply,B
1053,the,O
1053,seq2seq,B
1053,model,I
1053,to,B
1053,abstractive,B
1053,sentence,I
1053,summarization,I
1053,.,O
1054,propose,B
1054,a,O
1054,neural,B
1054,machine,I
1054,translation,I
1054,model,I
1054,with,B
1054,two,B
1054,-,I
1054,layer,I
1054,LSTMs,I
1054,for,B
1054,the,O
1054,encoder,B
1054,-,O
1054,decoder,O
1054,.,O
1055,The,O
1055,learning,B
1055,rate,I
1055,is,O
1055,5,B
1055,10,I
1055,?5,I
1055,.,O
1056,BERT,O
1056,base,O
1056,-,O
1056,cased,O
1056,and,O
1056,large,O
1056,-,O
1056,cased,O
1056,models,O
1056,are,O
1056,used,B
1056,in,I
1056,our,B
1056,experiments,I
1056,.,O
1057,Seq2seq,B
1057,.,O
1058,This,O
1058,is,B
1058,a,I
1058,standard,B
1058,seq2seq,I
1058,model,I
1058,with,B
1058,attention,B
1058,mechanism,I
1058,.,O
1059,This,O
1059,is,O
1059,our,O
1059,proposed,O
1059,model,O
1059,with,B
1059,entailment,B
1059,-,I
1059,aware,I
1059,encoder,I
1059,",",O
1059,which,O
1059,applies,B
1059,a,O
1059,multi-task,B
1059,learning,I
1059,(,I
1059,MTL,I
1059,),I
1059,framework,I
1059,to,B
1059,seq2seq,B
1059,model,O
1059,.,O
1060,propose,B
1060,a,O
1060,multi,B
1060,-,I
1060,task,I
1060,learning,I
1060,(,I
1060,MTL,I
1060,),I
1060,framework,I
1060,in,B
1060,which,I
1060,the,O
1060,decoder,B
1060,is,B
1060,shared,I
1060,for,I
1060,summarization,B
1060,generation,I
1060,and,I
1060,entailment,I
1060,generation,O
1060,task,O
1060,.,O
1061,This,O
1061,is,O
1061,our,O
1061,proposed,O
1061,model,O
1061,with,B
1061,entailment,B
1061,-,I
1061,aware,I
1061,decoder,I
1061,",",O
1061,which,O
1061,conducts,B
1061,an,O
1061,Entailment,O
1061,Reward,O
1061,Augmented,O
1061,Maximum,O
1061,Likelihood,O
1061,(,O
1061,ERAML,O
1061,),O
1061,training,O
1061,framework,O
1061,.,O
1062,We,O
1062,apply,B
1062,ROUGE,B
1062,-,I
1062,2,I
1062,RAML,I
1062,training,I
1062,for,B
1062,seq2seq,B
1062,model,I
1062,.,O
1063,Further,O
1063,",",O
1063,the,O
1063,improvement,O
1063,from,O
1063,side,B
1063,information,I
1063,shows,O
1063,that,O
1063,it,O
1063,is,O
1063,complementary,O
1063,to,O
1063,the,O
1063,features,O
1063,extracted,O
1063,from,O
1063,text,O
1063,",",O
1063,thus,O
1063,validating,O
1063,the,O
1063,central,O
1063,thesis,O
1063,of,O
1063,this,O
1063,paper,O
1063,",",O
1063,that,O
1063,inducing,B
1063,side,O
1063,information,O
1063,leads,B
1063,to,O
1063,improved,B
1063,relation,I
1063,extraction,I
1063,.,O
1064,Overall,O
1064,",",O
1064,we,O
1064,find,B
1064,that,I
1064,RESIDE,B
1064,achieves,B
1064,higher,B
1064,precision,I
1064,over,B
1064,the,I
1064,entire,B
1064,recall,I
1064,range,I
1064,on,B
1064,both,B
1064,the,O
1064,datasets,O
1064,.,O
1065,The,O
1065,position,B
1065,embeddings,I
1065,are,B
1065,randomly,B
1065,initialized,I
1065,and,I
1065,fine,I
1065,-,I
1065,tuned,I
1065,during,B
1065,the,O
1065,training,B
1065,process,I
1065,.,O
1066,We,O
1066,implement,B
1066,Reinforcement,B
1066,Learning,I
1066,(,I
1066,RL,I
1066,),I
1066,models,I
1066,(,O
1066,policy,O
1066,gradient,O
1066,),O
1066,with,B
1066,reward,B
1066,metrics,I
1066,of,B
1066,Entailment,B
1066,and,I
1066,ROUGE,I
1066,-,I
1066,2,I
1066,.,O
1067,employ,B
1067,a,O
1067,selective,B
1067,encoding,I
1067,model,I
1067,to,I
1067,control,I
1067,the,O
1067,information,B
1067,flow,I
1067,from,B
1067,encoder,B
1067,to,O
1067,decoder,O
1067,.,O
1068,To,O
1068,incorporate,O
1068,entailment,B
1068,knowledge,O
1068,into,O
1068,abstractive,O
1068,summarization,O
1068,models,O
1068,",",O
1068,we,O
1068,propose,B
1068,in,O
1068,this,O
1068,work,O
1068,an,O
1068,entailment,O
1068,-,O
1068,aware,O
1068,encoder,O
1068,and,O
1068,an,O
1068,entailment,O
1068,-,O
1068,aware,O
1068,decoder,O
1068,.,O
1069,Furthermore,O
1069,",",O
1069,we,O
1069,propose,O
1069,an,O
1069,entailment,B
1069,Reward,I
1069,Augmented,I
1069,Maximum,I
1069,Likelihood,I
1069,(,I
1069,RAML,I
1069,),I
1069,training,I
1069,that,O
1069,encourages,B
1069,the,I
1069,decoder,B
1069,of,I
1069,the,O
1069,summarization,O
1069,system,O
1069,to,B
1069,produce,I
1069,summary,B
1069,entailed,B
1069,by,I
1069,the,O
1069,source,B
1069,.,O
1070,We,O
1070,share,B
1070,the,O
1070,encoder,B
1070,of,B
1070,the,O
1070,summarization,B
1070,generation,I
1070,system,I
1070,with,B
1070,the,O
1070,entailment,B
1070,recognition,I
1070,system,O
1070,",",O
1070,so,O
1070,that,O
1070,the,O
1070,encoder,O
1070,can,O
1070,grasp,O
1070,both,O
1070,the,O
1070,gist,O
1070,of,O
1070,the,O
1070,source,O
1070,sentence,O
1070,and,O
1070,be,O
1070,aware,O
1070,of,O
1070,entailment,O
1070,relationships,O
1070,.,O
1071,Ensure,O
1071,the,O
1071,Correctness,O
1071,of,O
1071,the,O
1071,Summary,O
1071,:,O
1071,Incorporate,O
1071,Entailment,O
1071,Knowledge,O
1071,into,O
1071,Abstractive,B
1071,Sentence,I
1071,Summarization,I
1072,In,O
1072,this,O
1072,paper,O
1072,",",O
1072,we,O
1072,investigate,O
1072,the,O
1072,sentence,B
1072,summarization,I
1072,task,O
1072,that,O
1072,produces,O
1072,a,O
1072,summary,O
1072,from,O
1072,a,O
1072,source,O
1072,sentence,O
1072,.,O
1073,Experimental,O
1073,Results,O
1073,:,O
1073,Gigaword,B
1073,Corpus,I
1074,We,O
1074,show,B
1074,that,O
1074,simple,B
1074,neural,I
1074,architectures,I
1074,built,B
1074,on,B
1074,top,I
1074,of,I
1074,BERT,B
1074,yields,B
1074,state,B
1074,-,I
1074,of,O
1074,-,O
1074,the,O
1074,-,O
1074,art,O
1074,performance,O
1074,on,O
1074,a,O
1074,variety,B
1074,of,O
1074,benchmark,O
1074,datasets,O
1074,for,O
1074,these,O
1074,two,O
1074,tasks,O
1074,.,O
1075,Our,O
1075,model,O
1075,performs,B
1075,better,I
1075,than,I
1075,the,O
1075,previous,B
1075,works,I
1075,.,O
1076,Experimental,O
1076,Results,O
1076,:,O
1076,DUC,B
1076,2004,I
1077,In,O
1077,",",O
1077,experimental,O
1077,results,O
1077,also,O
1077,show,B
1077,our,O
1077,Seq2seq,B
1077,+,I
1077,selective,I
1077,+,O
1077,MTL,O
1077,+,O
1077,ERAML,O
1077,model,O
1077,achieves,B
1077,significant,B
1077,improvements,I
1077,over,B
1077,baseline,B
1077,models,I
1077,",",O
1077,surpassing,B
1077,Feats2s,B
1077,by,B
1077,0.98,B
1077,%,I
1077,ROUGE,I
1077,-,I
1077,1,I
1077,",",O
1077,0.78,O
1077,%,O
1077,ROUGE,O
1077,-,O
1077,2,O
1077,and,O
1077,0.65,O
1077,%,O
1077,ROUGE,O
1077,-,O
1077,L,O
1077,without,B
1077,fine,B
1077,-,O
1077,tuning,O
1077,on,B
1077,DUC,O
1077,data,O
1077,.,O
1078,In,B
1078,this,O
1078,paper,O
1078,we,O
1078,seek,O
1078,to,B
1078,address,O
1078,this,O
1078,problem,O
1078,by,O
1078,incorporating,B
1078,source,I
1078,syntactic,I
1078,structure,I
1078,in,O
1078,neural,B
1078,sentence,I
1078,summarization,I
1078,to,O
1078,help,O
1078,the,O
1078,system,B
1078,identify,B
1078,summary,B
1078,-,I
1078,worthy,I
1078,content,I
1078,and,O
1078,compose,B
1078,summaries,B
1078,that,B
1078,preserve,I
1078,the,O
1078,important,B
1078,meaning,I
1078,of,I
1078,the,O
1078,source,O
1078,texts,O
1078,.,O
1079,We,O
1079,present,B
1079,structure,B
1079,-,I
1079,infused,I
1079,copy,I
1079,mechanisms,I
1079,to,B
1079,facilitate,I
1079,copying,I
1079,source,B
1079,words,I
1079,and,I
1079,relations,I
1079,to,O
1079,the,O
1079,summary,B
1079,based,B
1079,on,I
1079,their,O
1079,semantic,B
1079,and,O
1079,structural,O
1079,importance,O
1079,in,B
1079,the,O
1079,source,O
1079,sentences,O
1079,.,O
1080,Structure,O
1080,-,O
1080,Infused,O
1080,Copy,O
1080,Mechanisms,O
1080,for,O
1080,Abstractive,B
1080,Summarization,I
1081,Seq2seq,O
1081,learning,O
1081,has,O
1081,produced,O
1081,promising,O
1081,results,O
1081,on,O
1081,summarization,B
1081,.,O
1082,We,O
1082,first,O
1082,report,O
1082,results,O
1082,on,B
1082,the,O
1082,Gigaword,B
1082,valid,I
1082,-,I
1082,2000,I
1082,dataset,I
1082,in,O
1082,.,O
1083,We,O
1083,present,B
1083,R,I
1083,-,I
1083,1,I
1083,",",I
1083,R,O
1083,-,O
1083,2,O
1083,",",O
1083,and,O
1083,R,O
1083,-,O
1083,L,O
1083,scores,O
1083,),O
1083,that,O
1083,respectively,O
1083,measures,B
1083,the,O
1083,overlapped,B
1083,unigrams,I
1083,",",O
1083,bigrams,O
1083,",",O
1083,and,O
1083,longest,O
1083,common,O
1083,subsequences,O
1083,between,B
1083,the,O
1083,system,B
1083,and,O
1083,reference,O
1083,summaries,O
1083,3,O
1083,.,O
1084,Overall,O
1084,",",O
1084,we,O
1084,observe,B
1084,that,O
1084,models,B
1084,equipped,O
1084,with,B
1084,the,O
1084,structure,B
1084,-,I
1084,infused,I
1084,copy,I
1084,mechanisms,I
1084,are,O
1084,superior,B
1084,to,I
1084,the,O
1084,baseline,B
1084,",",O
1084,suggesting,O
1084,that,O
1084,combining,O
1084,source,O
1084,syntactic,O
1084,structure,O
1084,with,O
1084,the,O
1084,copy,O
1084,mechanism,O
1084,is,O
1084,effective,O
1084,.,O
1085,Simple,O
1085,BERT,O
1085,Models,O
1085,for,O
1085,Relation,B
1085,Extraction,I
1085,and,O
1085,Semantic,B
1085,Role,I
1085,Labeling,I
1086,We,O
1086,found,B
1086,that,O
1086,the,O
1086,"""",O
1086,Struct,O
1086,+,O
1086,Hidden,O
1086,"""",O
1086,architecture,O
1086,",",O
1086,which,O
1086,directly,B
1086,concatenates,I
1086,structural,B
1086,embeddings,I
1086,with,B
1086,the,O
1086,encoder,B
1086,hidden,O
1086,states,O
1086,",",O
1086,outperforms,B
1086,"""",O
1086,Struct,O
1086,+,O
1086,Input,O
1086,"""",O
1086,despite,O
1086,that,O
1086,the,O
1086,latter,O
1086,requires,O
1086,more,O
1086,parameters,O
1086,.,O
1087,"""",O
1087,Struct,B
1087,+,I
1087,2,I
1087,Way,I
1087,+,O
1087,Word,O
1087,"""",O
1087,also,O
1087,demonstrates,B
1087,strong,B
1087,performance,I
1087,",",O
1087,achieving,B
1087,43.21,O
1087,%,O
1087,",",O
1087,21.,O
1088,84,O
1088,%,O
1088,",",O
1088,and,O
1088,40.86,O
1088,%,O
1088,F,O
1088,1,O
1088,scores,O
1088,",",O
1088,for,B
1088,R,I
1088,-,I
1088,1,O
1088,",",O
1088,R,O
1088,-,O
1088,2,O
1088,",",O
1088,and,O
1088,R,O
1088,-,O
1088,L,O
1088,respectively,O
1088,.,O
1089,Motivated,O
1089,by,O
1089,this,O
1089,approach,O
1089,",",O
1089,we,O
1089,consider,B
1089,bottom,B
1089,-,I
1089,up,I
1089,attention,I
1089,for,O
1089,neural,O
1089,abstractive,O
1089,summarization,O
1089,.,O
1090,Our,O
1090,approach,O
1090,first,B
1090,selects,I
1090,a,I
1090,selection,B
1090,mask,I
1090,for,B
1090,the,O
1090,source,B
1090,document,I
1090,and,O
1090,then,O
1090,constrains,B
1090,a,O
1090,standard,O
1090,neural,O
1090,model,O
1090,by,B
1090,this,I
1090,mask,O
1090,.,O
1091,Our,O
1091,full,O
1091,model,O
1091,incorporates,B
1091,a,O
1091,separate,B
1091,content,I
1091,selection,I
1091,system,I
1091,to,B
1091,decide,I
1091,on,O
1091,relevant,B
1091,aspects,I
1091,of,B
1091,the,O
1091,source,B
1091,document,I
1091,.,O
1092,We,O
1092,frame,B
1092,this,O
1092,selection,B
1092,task,I
1092,as,B
1092,a,I
1092,sequence,B
1092,-,I
1092,tagging,I
1092,problem,I
1092,",",O
1092,with,B
1092,the,I
1092,objective,I
1092,of,I
1092,identifying,B
1092,tokens,I
1092,from,B
1092,a,O
1092,document,B
1092,that,O
1092,are,O
1092,part,B
1092,of,O
1092,its,O
1092,summary,B
1092,.,O
1093,To,B
1093,incorporate,O
1093,bottom,O
1093,-,O
1093,up,O
1093,attention,O
1093,into,O
1093,abstractive,O
1093,summarization,O
1093,models,O
1093,",",O
1093,we,O
1093,employ,B
1093,masking,B
1093,to,O
1093,constrain,O
1093,copying,B
1093,words,I
1093,to,O
1093,the,O
1093,selected,B
1093,parts,I
1093,of,B
1093,the,O
1093,text,B
1093,",",O
1093,which,O
1093,produces,B
1093,grammatical,B
1093,outputs,I
1093,.,O
1094,All,O
1094,inference,B
1094,parameters,I
1094,are,O
1094,tuned,B
1094,on,I
1094,a,O
1094,200,B
1094,example,I
1094,subset,I
1094,of,O
1094,the,O
1094,validation,O
1094,set,O
1094,.,O
1095,and,O
1095,copy,B
1095,mask,I
1095,differ,O
1095,across,O
1095,models,O
1095,",",O
1095,with,O
1095,?,O
1096,ranging,O
1096,from,O
1096,0.6,B
1096,to,I
1096,1.4,I
1096,",",O
1096,and,O
1096,ranging,O
1096,from,O
1096,0.1,B
1096,to,O
1096,0.2,O
1096,.,O
1097,The,O
1097,coverage,B
1097,penalty,I
1097,parameter,I
1097,?,O
1098,is,O
1098,set,B
1098,to,B
1098,10,B
1098,",",O
1098,and,O
1098,the,O
1098,copy,B
1098,attention,I
1098,normalization,I
1098,parameter,I
1098,?,O
1099,to,B
1099,2,B
1099,for,O
1099,both,O
1099,approaches,O
1099,.,O
1100,Relation,O
1100,extraction,O
1100,and,O
1100,semantic,B
1100,role,I
1100,labeling,I
1100,(,I
1100,SRL,I
1100,),I
1100,are,O
1100,two,O
1100,fundamental,O
1100,tasks,O
1100,in,O
1100,natural,O
1100,language,O
1100,understanding,O
1100,.,O
1101,The,O
1101,minimum,B
1101,length,I
1101,of,I
1101,the,O
1101,generated,B
1101,summary,I
1101,is,B
1101,set,I
1101,to,I
1101,35,B
1101,for,B
1101,CNN,B
1101,-,I
1101,DM,I
1101,and,O
1101,6,B
1101,for,O
1101,NYT,B
1101,.,O
1102,We,O
1102,use,B
1102,AllenNLP,B
1102,for,B
1102,the,O
1102,content,B
1102,selector,I
1102,",",O
1102,and,O
1102,Open,B
1102,NMT,I
1102,-,I
1102,py,I
1102,for,O
1102,the,O
1102,abstractive,B
1102,models,I
1102,.,O
1103,Bottom,O
1103,-,O
1103,Up,O
1103,Abstractive,B
1103,Summarization,I
1104,Current,O
1104,state,O
1104,-,O
1104,of,O
1104,-,O
1104,the,O
1104,-,O
1104,art,O
1104,neural,B
1104,abstractive,I
1104,summarization,I
1104,models,O
1104,combine,O
1104,extractive,O
1104,and,O
1104,abstractive,O
1104,techniques,O
1104,by,O
1104,using,O
1104,pointergenerator,O
1104,style,O
1104,models,O
1104,which,O
1104,can,O
1104,copy,O
1104,words,O
1104,from,O
1104,the,O
1104,source,O
1104,document,O
1104,.,O
1105,shows,O
1105,our,O
1105,main,O
1105,results,O
1105,on,B
1105,the,O
1105,CNN,B
1105,-,I
1105,DM,I
1105,corpus,I
1105,",",O
1105,with,O
1105,abstractive,O
1105,models,O
1105,shown,O
1105,in,O
1105,the,O
1105,top,O
1105,",",O
1105,and,O
1105,bottom,O
1105,-,O
1105,up,O
1105,attention,O
1105,methods,O
1105,at,O
1105,the,O
1105,bottom,O
1105,.,O
1106,We,O
1106,first,O
1106,observe,O
1106,that,O
1106,using,B
1106,a,I
1106,coverage,I
1106,inference,I
1106,penalty,I
1106,scores,B
1106,the,B
1106,same,I
1106,as,B
1106,a,O
1106,full,B
1106,coverage,O
1106,mechanism,O
1106,",",O
1106,without,B
1106,requiring,I
1106,any,O
1106,additional,B
1106,model,B
1106,parameters,I
1106,or,O
1106,model,O
1106,fine,O
1106,-,O
1106,tuning,O
1106,.,O
1107,The,O
1107,results,O
1107,with,O
1107,the,O
1107,CopyTransformer,O
1107,and,O
1107,coverage,O
1107,penalty,O
1107,indicate,B
1107,a,O
1107,slight,B
1107,improvement,I
1107,across,B
1107,all,B
1107,three,I
1107,scores,I
1107,",",O
1107,but,O
1107,we,O
1107,observe,B
1107,no,B
1107,significant,I
1107,difference,I
1107,between,B
1107,Pointer,B
1107,-,I
1107,Generator,I
1107,and,O
1107,CopyTransformer,O
1107,with,O
1107,bottom,O
1107,-,O
1107,up,O
1107,attention,O
1107,.,O
1108,ABS,O
1108,+,O
1108,is,B
1108,a,I
1108,tuned,B
1108,ABS,O
1108,model,O
1108,with,O
1108,additional,O
1108,features,O
1108,.,O
1109,RAS,O
1109,-,O
1109,Elman,B
1109,),O
1109,is,B
1109,a,I
1109,convolution,B
1109,encoder,I
1109,and,O
1109,an,O
1109,Elman,O
1109,RNN,O
1109,decoder,O
1109,with,B
1109,attention,B
1109,.,O
1110,For,O
1110,SRL,B
1110,",",O
1110,the,O
1110,task,O
1110,is,O
1110,to,O
1110,extract,O
1110,the,O
1110,predicate,O
1110,-,O
1110,argument,O
1110,structure,O
1110,of,O
1110,a,O
1110,sentence,O
1110,",",O
1110,determining,O
1110,"""",O
1110,who,O
1110,did,O
1110,what,O
1110,to,O
1110,whom,O
1110,"""",O
1110,",",O
1110,"""",O
1110,when,O
1110,"""",O
1110,",",O
1110,"""",O
1110,where,O
1110,"""",O
1110,",",O
1110,etc,O
1110,.,O
1111,Seq2seq,O
1111,+,O
1111,att,O
1111,is,B
1111,two,B
1111,-,I
1111,layer,I
1111,BiLSTM,I
1111,encoder,I
1111,and,O
1111,one,B
1111,-,O
1111,layer,O
1111,LSTM,O
1111,decoder,O
1111,equipped,B
1111,with,I
1111,attention,B
1111,.,O
1112,lvt5,O
1112,k,O
1112,-,O
1112,lsent,O
1112,uses,B
1112,temporal,B
1112,attention,I
1112,to,B
1112,keep,I
1112,track,I
1112,of,B
1112,the,O
1112,past,B
1112,attentive,I
1112,weights,I
1112,of,O
1112,the,O
1112,decoder,B
1112,and,O
1112,restrains,B
1112,the,O
1112,repetition,B
1112,in,B
1112,later,B
1112,sequences,I
1112,.,O
1113,SEASS,B
1113,includes,B
1113,an,O
1113,additional,B
1113,selective,I
1113,gate,I
1113,to,B
1113,control,I
1113,information,B
1113,flow,I
1113,from,B
1113,the,O
1113,encoder,B
1113,to,O
1113,the,O
1113,decoder,B
1113,.,O
1114,Pointer,O
1114,-,O
1114,generator,O
1114,is,B
1114,an,O
1114,integrated,B
1114,pointer,O
1114,network,O
1114,and,O
1114,seq2seq,B
1114,model,I
1114,.,O
1115,CGU,B
1115,),O
1115,sets,B
1115,a,O
1115,convolutional,B
1115,gated,I
1115,unit,I
1115,and,O
1115,self,B
1115,-,I
1115,attention,I
1115,for,B
1115,global,B
1115,encoding,I
1115,.,O
1116,Our,O
1116,code,O
1116,is,O
1116,available,O
1116,on,O
1116,https,B
1116,://,I
1116,github.com/wprojectsn/codes,I
1116,",",O
1116,and,O
1116,the,O
1116,vocabularies,O
1116,and,O
1116,candidate,O
1116,concepts,O
1116,are,O
1116,also,O
1116,included,O
1116,.,O
1117,We,O
1117,initialize,B
1117,word,B
1117,embeddings,I
1117,with,O
1117,128,B
1117,-,I
1117,d,I
1117,vectors,I
1117,and,O
1117,fine,B
1117,-,O
1117,tune,O
1117,them,O
1117,during,B
1117,training,I
1117,.,O
1118,The,O
1118,vocabulary,B
1118,size,I
1118,was,O
1118,set,B
1118,to,I
1118,150,B
1118,k,I
1118,for,B
1118,both,B
1118,the,O
1118,source,O
1118,and,O
1118,target,O
1118,text,O
1118,.,O
1119,The,O
1119,hidden,B
1119,state,I
1119,size,I
1119,was,O
1119,set,B
1119,to,I
1119,256,B
1119,.,O
1120,We,O
1120,trained,O
1120,our,O
1120,models,B
1120,on,B
1120,a,O
1120,single,B
1120,GTX,I
1120,TI,I
1120,-,I
1120,TAN,I
1120,GPU,I
1120,machine,I
1120,.,O
1121,We,O
1121,see,B
1121,that,O
1121,the,O
1121,BERT,B
1121,-,I
1121,LSTM,I
1121,-,O
1121,large,O
1121,model,O
1121,achieves,B
1121,the,O
1121,state,B
1121,-,O
1121,of,O
1121,-,O
1121,the,O
1121,-,O
1121,art,O
1121,F,O
1121,1,O
1121,score,O
1121,among,B
1121,single,B
1121,models,I
1121,and,I
1121,outperforms,B
1121,the,O
1121,ensemble,B
1121,model,O
1121,on,B
1121,the,O
1121,CoNLL,B
1121,2005,I
1121,in,B
1121,-,O
1121,domain,O
1121,and,O
1121,out,O
1121,-,O
1121,of,O
1121,-,O
1121,domain,O
1121,tests,O
1121,.,O
1122,We,O
1122,used,B
1122,the,O
1122,Adagrad,B
1122,optimizer,I
1122,with,B
1122,a,O
1122,batch,B
1122,size,I
1122,of,I
1122,64,I
1122,to,B
1122,minimize,I
1122,the,O
1122,loss,B
1122,.,O
1123,We,O
1123,used,O
1123,gradient,O
1123,clipping,O
1123,with,B
1123,a,O
1123,maximum,B
1123,gradient,O
1123,norm,O
1123,of,B
1123,2,B
1123,.,O
1124,The,O
1124,initial,B
1124,learning,I
1124,rate,I
1124,and,O
1124,the,O
1124,accumulator,B
1124,value,I
1124,were,O
1124,set,B
1124,to,I
1124,0.15,B
1124,and,O
1124,0.1,B
1124,",",O
1124,respectively,O
1124,.,O
1125,We,O
1125,trained,B
1125,our,O
1125,concept,B
1125,pointer,I
1125,generator,I
1125,for,B
1125,450,B
1125,k,I
1125,iterations,I
1125,yielded,B
1125,the,O
1125,best,B
1125,performance,I
1125,",",O
1125,then,O
1125,took,O
1125,the,O
1125,optimization,B
1125,using,I
1125,RL,B
1125,rewards,I
1125,for,O
1125,RG,B
1125,-,I
1125,L,I
1125,at,B
1125,95,B
1125,K,O
1125,iterations,O
1125,on,B
1125,DUC,B
1125,-,O
1125,2004,O
1125,and,O
1125,at,O
1125,50,B
1125,K,O
1125,iterations,O
1125,on,O
1125,Gigaword,B
1125,.,O
1126,We,O
1126,took,B
1126,the,O
1126,distancesupervised,B
1126,training,I
1126,at,B
1126,5,B
1126,K,I
1126,iterations,I
1126,on,B
1126,DUC,B
1126,-,I
1126,2004,I
1126,and,O
1126,at,O
1126,6.5,B
1126,K,O
1126,iterations,O
1126,on,O
1126,Gigaword,B
1126,.,O
1127,Hence,O
1127,",",O
1127,in,O
1127,this,O
1127,paper,O
1127,",",O
1127,we,O
1127,propose,B
1127,a,O
1127,novel,B
1127,model,I
1127,based,B
1127,on,I
1127,a,O
1127,concept,B
1127,pointer,I
1127,generator,I
1127,that,O
1127,encourages,B
1127,the,I
1127,generation,I
1127,of,I
1127,conceptual,B
1127,and,I
1127,abstract,I
1127,words,I
1127,.,O
1128,As,O
1128,a,O
1128,hidden,O
1128,benefit,O
1128,",",O
1128,the,O
1128,model,O
1128,also,O
1128,alleviates,B
1128,the,O
1128,OOV,B
1128,problems,I
1128,.,O
1129,Our,O
1129,model,O
1129,uses,B
1129,pointer,I
1129,network,I
1129,to,I
1129,capture,I
1129,the,O
1129,salient,B
1129,information,I
1129,from,B
1129,a,O
1129,source,B
1129,text,I
1129,",",O
1129,and,O
1129,then,O
1129,employs,B
1129,another,B
1129,pointer,O
1129,to,O
1129,generalize,O
1129,the,O
1129,detailed,B
1129,words,I
1129,according,B
1129,to,O
1129,their,O
1129,upper,B
1129,level,I
1129,of,I
1129,expressions,I
1129,.,O
1130,The,O
1130,optimization,B
1130,function,I
1130,is,O
1130,adaptive,B
1130,so,I
1130,as,I
1130,to,I
1130,cater,I
1130,for,I
1130,different,B
1130,datasets,I
1130,with,B
1130,distantly,B
1130,-,I
1130,supervised,I
1130,training,I
1130,.,O
1131,The,O
1131,network,B
1131,is,O
1131,then,O
1131,optimized,B
1131,end,I
1131,-,I
1131,to,I
1131,-,O
1131,end,O
1131,using,B
1131,reinforcement,B
1131,learning,I
1131,",",O
1131,with,B
1131,the,O
1131,distant,B
1131,-,O
1131,supervision,O
1131,strategy,O
1131,as,O
1131,a,O
1131,complement,O
1131,to,O
1131,further,O
1131,improve,O
1131,the,O
1131,summary,O
1131,.,O
1132,However,O
1132,",",O
1132,it,O
1132,falls,B
1132,short,I
1132,on,I
1132,the,O
1132,CoNLL,B
1132,2012,I
1132,benchmark,I
1132,because,O
1132,the,O
1132,model,O
1132,of,O
1132,obtains,O
1132,very,O
1132,high,O
1132,precision,O
1132,.,O
1133,Concept,O
1133,Pointer,O
1133,Network,O
1133,for,O
1133,Abstractive,B
1133,Summarization,I
1134,We,O
1134,observe,B
1134,that,O
1134,our,O
1134,model,B
1134,outperformed,O
1134,all,O
1134,the,O
1134,strong,O
1134,state,O
1134,of,O
1134,-,O
1134,the,O
1134,-,O
1134,art,O
1134,models,O
1134,on,O
1134,both,O
1134,datasets,O
1134,in,O
1134,all,O
1134,metrics,O
1134,except,O
1134,for,O
1134,RG,O
1134,-,O
1134,2,O
1134,on,O
1134,Gigaword,O
1134,.,O
1135,In,O
1135,terms,O
1135,of,O
1135,the,O
1135,pointer,O
1135,generator,O
1135,performance,O
1135,",",O
1135,the,O
1135,improvements,B
1135,made,I
1135,by,O
1135,our,O
1135,concept,B
1135,pointer,O
1135,are,O
1135,statistically,B
1135,significant,I
1135,(,I
1135,p,I
1135,<,I
1135,0.01,I
1135,),I
1135,across,B
1135,all,B
1135,metrics,I
1135,.,O
1136,For,B
1136,the,O
1136,Gigaword,B
1136,dataset,I
1136,",",O
1136,we,O
1136,compare,B
1136,our,I
1136,models,I
1136,with,I
1136,the,O
1136,following,O
1136,abstractive,O
1136,baselines,O
1136,:,O
1137,ABS,O
1137,+,O
1137,is,B
1137,a,I
1137,fine,O
1137,tuned,O
1137,version,O
1137,of,O
1137,ABS,O
1137,which,O
1137,uses,B
1137,an,O
1137,attentive,B
1137,CNN,I
1137,encoder,I
1137,and,O
1137,an,O
1137,NNLM,B
1137,decoder,I
1137,",",O
1137,Feat2s,B
1137,(,O
1137,Nallapati,O
1137,et,O
1137,al.,O
1138,",",O
1138,2016,O
1138,),O
1138,is,B
1138,an,I
1138,RNN,I
1138,sequence,I
1138,-,I
1138,to,I
1138,-,O
1138,sequence,O
1138,model,O
1138,with,B
1138,lexical,B
1138,and,I
1138,statistical,I
1138,features,I
1138,in,B
1138,the,O
1138,encoder,O
1138,",",O
1138,Luong,B
1138,-,O
1138,NMT,O
1138,is,O
1138,a,O
1138,two,B
1138,-,O
1138,layer,O
1138,LSTM,O
1138,encoder,O
1138,-,O
1138,decoder,O
1138,model,O
1138,",",O
1138,RAS,B
1138,-,O
1138,Elman,B
1138,uses,B
1138,an,O
1138,attentive,B
1138,CNN,I
1138,encoder,O
1138,and,O
1138,an,O
1138,Elman,O
1138,RNN,O
1138,decoder,O
1138,",",O
1138,and,O
1138,SEASS,B
1138,uses,O
1138,BiGRU,B
1138,encoders,I
1138,and,O
1138,GRU,B
1138,decoders,I
1138,with,O
1138,selective,B
1138,encoding,I
1138,.,O
1139,For,O
1139,the,O
1139,CNN,B
1139,dataset,I
1139,",",O
1139,we,O
1139,compare,B
1139,our,I
1139,models,I
1139,with,I
1139,the,O
1139,following,O
1139,extractive,O
1139,and,O
1139,abstractive,O
1139,baselines,O
1139,:,O
1140,Lead,O
1140,-,O
1140,3,O
1140,is,B
1140,a,I
1140,strong,O
1140,baseline,O
1140,that,O
1140,extracts,B
1140,the,I
1140,first,B
1140,three,I
1140,sentences,I
1140,of,I
1140,the,O
1140,document,O
1140,as,B
1140,summary,B
1140,",",O
1140,LexRank,B
1140,extracts,O
1140,texts,B
1140,using,B
1140,LexRank,O
1140,",",O
1140,Bi,B
1140,-,O
1140,GRU,O
1140,is,O
1140,a,O
1140,non-hierarchical,B
1140,one,I
1140,-,O
1140,layer,O
1140,sequence,O
1140,-,O
1140,to,O
1140,-,O
1140,sequence,O
1140,abstractive,O
1140,baseline,O
1140,",",O
1140,Distraction,B
1140,-,O
1140,M3,O
1140,uses,B
1140,a,O
1140,sequence,O
1140,-,O
1140,to,O
1140,-,O
1140,sequence,O
1140,abstractive,O
1140,model,O
1140,with,B
1140,distraction,O
1140,-,O
1140,based,O
1140,networks,O
1140,",",O
1140,and,O
1140,GBA,B
1140,is,O
1140,a,O
1140,graph,B
1140,-,O
1140,based,O
1140,attentional,O
1140,neural,O
1140,abstractive,O
1140,model,O
1140,.,O
1141,For,O
1141,both,O
1141,datasets,O
1141,",",O
1141,we,O
1141,further,O
1141,reduce,B
1141,the,I
1141,size,B
1141,of,I
1141,the,O
1141,input,O
1141,",",O
1141,output,O
1141,",",O
1141,and,O
1141,entity,O
1141,vocabularies,O
1141,to,B
1141,at,B
1141,most,I
1141,50,I
1141,K,I
1141,as,O
1141,suggested,O
1141,in,O
1141,and,O
1141,replace,B
1141,less,B
1141,frequent,I
1141,words,I
1141,to,O
1141,"""",O
1141,<,B
1141,unk,I
1141,>,I
1141,"""",O
1141,.,O
1142,We,O
1142,use,B
1142,300D,B
1142,Glove,I
1142,6,O
1142,and,O
1142,1000D,B
1142,wiki2vec,I
1142,7,O
1142,pre-trained,B
1142,vectors,I
1142,to,O
1142,initialize,B
1142,our,O
1142,word,B
1142,and,O
1142,entity,O
1142,vectors,O
1142,.,O
1143,First,O
1143,",",O
1143,we,O
1143,study,B
1143,the,I
1143,ability,I
1143,of,I
1143,the,O
1143,Transformer,B
1143,neural,I
1143,network,I
1143,architecture,I
1143,to,B
1143,encode,I
1143,relations,B
1143,between,B
1143,entity,B
1143,pairs,I
1143,",",O
1143,and,O
1143,we,O
1143,identify,B
1143,a,O
1143,method,O
1143,of,O
1143,representation,B
1143,that,B
1143,outperforms,I
1143,previous,B
1143,work,I
1143,in,B
1143,supervised,B
1143,relation,I
1143,extraction,I
1143,.,O
1144,For,B
1144,GRUs,B
1144,",",O
1144,we,O
1144,set,B
1144,the,O
1144,state,B
1144,size,I
1144,to,B
1144,500,B
1144,.,O
1145,For,O
1145,CNN,B
1145,",",I
1145,we,O
1145,set,B
1145,h,B
1145,=,I
1145,3,I
1145,",",O
1145,4,O
1145,",",O
1145,5,O
1145,with,B
1145,400,B
1145,",",O
1145,300,O
1145,",",O
1145,300,O
1145,feature,O
1145,maps,O
1145,",",O
1145,respectively,O
1145,.,O
1146,For,O
1146,firm,B
1146,attention,I
1146,",",O
1146,k,B
1146,is,O
1146,tuned,B
1146,by,B
1146,calculating,I
1146,the,O
1146,perplexity,B
1146,of,B
1146,the,O
1146,model,B
1146,starting,B
1146,with,I
1146,smaller,O
1146,values,O
1146,(,O
1146,i.e.,O
1147,k,B
1147,=,O
1147,1,O
1147,",",O
1147,2,O
1147,",",O
1147,5,O
1147,",",O
1147,10,O
1147,",",O
1147,20,O
1147,",",O
1147,...,O
1147,),O
1147,and,O
1147,stopping,B
1147,when,I
1147,the,I
1147,perplexity,B
1147,of,I
1147,the,O
1147,model,O
1147,becomes,O
1147,worse,O
1147,than,B
1147,the,O
1147,previous,B
1147,model,O
1147,.,O
1148,We,O
1148,use,B
1148,dropout,B
1148,on,B
1148,all,B
1148,non-linear,I
1148,connections,I
1148,with,B
1148,a,O
1148,dropout,O
1148,rate,O
1148,of,O
1148,0.5,O
1148,.,O
1149,We,O
1149,use,O
1149,beam,B
1149,search,I
1149,of,B
1149,size,I
1149,10,B
1149,to,B
1149,generate,I
1149,the,O
1149,summary,B
1149,.,O
1150,We,O
1150,set,B
1150,the,O
1150,batch,B
1150,sizes,I
1150,of,B
1150,Gigaword,B
1150,and,I
1150,CNN,I
1150,datasets,I
1150,to,B
1150,80,B
1150,and,O
1150,10,O
1150,",",O
1150,respectively,O
1150,.,O
1151,Training,O
1151,is,O
1151,done,O
1151,via,O
1151,stochastic,B
1151,gradient,I
1151,descent,I
1151,over,B
1151,shuffled,B
1151,mini-batches,I
1151,with,B
1151,the,O
1151,Adadelta,B
1151,update,I
1151,rule,I
1151,",",O
1151,with,O
1151,l,O
1151,2,O
1151,constraint,O
1151,(,O
1151,Hinton,O
1151,et,O
1151,al.,O
1152,We,O
1152,perform,B
1152,early,B
1152,stopping,I
1152,using,B
1152,a,O
1152,subset,B
1152,of,I
1152,the,I
1152,given,I
1152,development,I
1152,dataset,I
1152,.,O
1153,To,O
1153,this,O
1153,end,O
1153,",",O
1153,we,O
1153,present,O
1153,a,O
1153,method,B
1153,to,O
1153,effectively,B
1153,apply,I
1153,linked,I
1153,entities,I
1153,in,B
1153,sequence,B
1153,-,I
1153,tosequence,I
1153,models,I
1153,",",O
1153,called,B
1153,Entity2Topic,B
1153,(,I
1153,E2T,I
1153,),I
1153,.,O
1154,E2T,B
1154,is,O
1154,a,O
1154,module,B
1154,that,O
1154,can,O
1154,be,O
1154,easily,O
1154,attached,O
1154,to,O
1154,any,O
1154,sequence,O
1154,-,O
1154,to,O
1154,-,O
1154,sequence,O
1154,based,O
1154,summarization,O
1154,model,O
1154,.,O
1155,Then,O
1155,",",O
1155,we,O
1155,present,B
1155,a,O
1155,method,B
1155,of,B
1155,training,B
1155,this,O
1155,relation,B
1155,representation,I
1155,without,B
1155,any,B
1155,supervision,I
1155,from,B
1155,a,O
1155,knowledge,B
1155,graph,I
1155,or,I
1155,human,I
1155,annotators,I
1155,by,B
1155,matching,I
1155,the,O
1155,blanks,B
1155,.,O
1156,The,O
1156,module,O
1156,encodes,B
1156,the,O
1156,entities,B
1156,extracted,I
1156,from,I
1156,the,O
1156,original,O
1156,text,O
1156,by,B
1156,an,O
1156,entity,B
1156,linking,I
1156,system,I
1156,(,I
1156,ELS,I
1156,),I
1156,",",O
1156,constructs,B
1156,a,O
1156,vector,O
1156,representing,B
1156,the,O
1156,topic,O
1156,of,B
1156,the,O
1156,summary,B
1156,to,I
1156,be,I
1156,generated,I
1156,",",O
1156,and,O
1156,informs,B
1156,the,O
1156,decoder,B
1156,about,B
1156,the,O
1156,constructed,B
1156,topic,O
1156,vector,O
1156,.,O
1157,We,O
1157,solve,O
1157,this,O
1157,issue,O
1157,by,O
1157,using,B
1157,entity,B
1157,encoders,I
1157,with,B
1157,selective,B
1157,disambiguation,I
1157,and,O
1157,by,O
1157,constructing,B
1157,topic,B
1157,vectors,I
1157,using,O
1157,firm,B
1157,attention,I
1157,.,O
1158,Entity,O
1158,Commonsense,O
1158,Representation,O
1158,for,O
1158,Neural,O
1158,Abstractive,B
1158,Summarization,I
1159,In,B
1159,Gigaword,B
1159,dataset,I
1159,where,B
1159,the,I
1159,texts,B
1159,are,I
1159,short,I
1159,",",O
1159,our,B
1159,best,I
1159,model,I
1159,achieves,B
1159,a,O
1159,comparable,B
1159,performance,I
1159,with,B
1159,the,O
1159,current,B
1159,state,I
1159,-,I
1159,of,I
1159,-,O
1159,the,O
1159,-,O
1159,art,O
1159,.,O
1160,In,O
1160,CNN,B
1160,dataset,I
1160,where,B
1160,the,I
1160,texts,B
1160,are,I
1160,longer,I
1160,",",O
1160,our,B
1160,best,I
1160,model,I
1160,outperforms,B
1160,all,B
1160,the,O
1160,previous,O
1160,models,O
1160,.,O
1161,Overall,O
1161,",",O
1161,E2T,B
1161,achieves,B
1161,a,O
1161,significant,B
1161,improvement,I
1161,over,B
1161,the,O
1161,baseline,B
1161,model,I
1161,BASE,I
1161,",",O
1161,with,B
1161,at,B
1161,least,I
1161,2,I
1161,ROUGE,I
1161,-,O
1161,1,B
1161,points,I
1161,increase,I
1161,in,B
1161,the,O
1161,Gigaword,B
1161,dataset,I
1161,and,O
1161,6,B
1161,ROUGE,O
1161,-,O
1161,1,O
1161,points,O
1161,increase,O
1161,in,O
1161,the,O
1161,CNN,B
1161,dataset,O
1161,.,O
1162,Among,B
1162,the,O
1162,model,B
1162,variants,I
1162,",",O
1162,the,O
1162,CNN,B
1162,-,I
1162,based,I
1162,encoder,I
1162,with,B
1162,selective,B
1162,disambiguation,I
1162,and,O
1162,firm,B
1162,attention,I
1162,performs,B
1162,the,O
1162,best,B
1162,.,O
1163,Code,O
1163,to,O
1163,reproduce,O
1163,our,O
1163,results,O
1163,is,O
1163,provided,O
1163,at,O
1163,https://github.com/NLPrinceton/,B
1164,In,O
1164,this,O
1164,work,O
1164,",",O
1164,we,O
1164,make,B
1164,available,I
1164,the,O
1164,first,B
1164,corpus,I
1164,1,O
1164,for,B
1164,sarcasm,B
1164,detection,I
1164,that,O
1164,has,O
1164,both,O
1164,unbalanced,B
1164,and,I
1164,self,I
1164,-,I
1164,annotated,I
1164,labels,I
1164,and,O
1164,does,O
1164,not,O
1164,consist,O
1164,of,O
1164,short,O
1164,text,O
1164,snippets,O
1164,from,O
1164,Twitter,O
1164,2,O
1164,.,O
1165,Matching,O
1165,the,O
1165,Blanks,O
1165,:,O
1165,Distributional,O
1165,Similarity,O
1165,for,O
1165,Relation,B
1165,Learning,I
1166,With,B
1166,more,B
1166,than,I
1166,a,I
1166,million,I
1166,examples,I
1166,of,I
1166,sarcastic,B
1166,statements,I
1166,",",I
1166,each,O
1166,provided,O
1166,with,O
1166,author,B
1166,",",O
1166,topic,O
1166,",",O
1166,and,O
1166,contex,O
1166,information,O
1166,",",O
1166,the,O
1166,dataset,O
1166,exceeds,B
1166,all,O
1166,previous,B
1166,sarcasm,I
1166,corpora,I
1166,by,B
1166,an,B
1166,order,I
1166,of,O
1166,magnitude,O
1166,in,O
1166,size,O
1166,.,O
1167,We,O
1167,introduce,O
1167,the,O
1167,Self,O
1167,-,O
1167,Annotated,O
1167,Reddit,O
1167,Corpus,O
1167,(,O
1167,SARC,O
1167,),O
1167,",",O
1167,a,O
1167,large,O
1167,corpus,O
1167,for,O
1167,sarcasm,B
1167,research,O
1167,and,O
1167,for,O
1167,training,O
1167,and,O
1167,evaluating,O
1167,systems,O
1167,for,O
1167,sarcasm,O
1167,detection,O
1167,.,O
1168,There,O
1168,is,O
1168,clear,B
1168,scope,I
1168,for,B
1168,improvement,B
1168,for,O
1168,machine,B
1168,learning,I
1168,methods,I
1168,",",O
1168,starting,O
1168,with,O
1168,the,O
1168,use,O
1168,of,O
1168,context,O
1168,provided,O
1168,to,O
1168,make,O
1168,better,O
1168,decisions,O
1168,about,O
1168,sarcasm,O
1168,.,O
1169,First,O
1169,",",O
1169,we,O
1169,test,B
1169,performance,B
1169,for,B
1169,the,O
1169,content,B
1169,-,I
1169,based,I
1169,CNN,I
1169,only,I
1169,(,O
1169,row,O
1169,1,O
1169,),O
1169,.,O
1170,This,O
1170,setting,O
1170,provides,B
1170,the,O
1170,worst,B
1170,relative,I
1170,performance,I
1170,with,B
1170,almost,B
1170,10,I
1170,%,I
1170,lesser,I
1170,accuracy,I
1170,than,B
1170,optimal,B
1170,.,O
1171,Next,O
1171,",",O
1171,we,O
1171,include,B
1171,contextual,B
1171,features,I
1171,to,O
1171,this,O
1171,network,O
1171,.,O
1172,Here,O
1172,",",O
1172,the,O
1172,effect,B
1172,of,B
1172,discourse,B
1172,features,I
1172,is,O
1172,primarily,B
1172,seen,I
1172,in,I
1172,the,O
1172,Pol,B
1172,dataset,I
1172,getting,B
1172,an,O
1172,increase,B
1172,of,O
1172,3,B
1172,%,I
1172,in,O
1172,F1,O
1172,(,O
1172,row,O
1172,2,O
1172,),O
1172,.,O
1173,A,O
1173,major,B
1173,boost,I
1173,in,B
1173,performance,B
1173,is,O
1173,observed,B
1173,(,O
1173,8,O
1173,?,O
1174,12,O
1174,%,O
1174,accuracy,O
1174,and,O
1174,F1,O
1174,),O
1174,when,O
1174,user,B
1174,embeddings,I
1174,are,O
1174,introduced,B
1174,(,O
1174,row,O
1174,5,O
1174,),O
1174,.,O
1175,Overall,O
1175,",",O
1175,CASCADE,B
1175,consisting,B
1175,of,I
1175,CNN,B
1175,with,B
1175,user,B
1175,embeddings,I
1175,and,I
1175,contextual,I
1175,discourse,I
1175,features,I
1175,provide,B
1175,the,O
1175,best,B
1175,performance,I
1175,in,B
1175,all,B
1175,three,I
1175,datasets,I
1175,(,O
1175,row,O
1175,6,O
1175,),O
1175,.,O
1176,We,O
1176,challenge,O
1176,the,O
1176,use,B
1176,of,B
1176,CCA,B
1176,for,B
1176,the,O
1176,generation,B
1176,of,O
1176,user,B
1176,embeddings,I
1176,and,O
1176,thus,O
1176,replace,B
1176,it,I
1176,with,I
1176,simple,B
1176,concatenation,I
1176,.,O
1177,All,O
1177,the,O
1177,non-neural,B
1177,baselines,I
1177,could,B
1177,not,I
1177,perform,I
1177,well,B
1177,as,O
1177,the,O
1177,features,O
1177,used,O
1177,by,O
1177,them,O
1177,are,O
1177,mostly,O
1177,derived,O
1177,from,O
1177,NLP,O
1177,tools,O
1177,which,O
1177,can,O
1177,be,O
1177,erroneous,O
1177,.,O
1178,Reading,O
1178,text,O
1178,to,O
1178,identify,B
1178,and,I
1178,extract,I
1178,relations,I
1178,between,I
1178,entities,I
1178,has,O
1178,been,O
1178,along,O
1178,standing,O
1178,goal,O
1178,in,O
1178,natural,O
1178,language,O
1178,processing,O
1178,.,O
1179,This,O
1179,however,O
1179,causes,B
1179,a,O
1179,significant,B
1179,drop,I
1179,in,B
1179,performance,B
1179,(,O
1179,row,O
1179,3,O
1179,),O
1179,.,O
1180,This,O
1180,model,O
1180,uses,B
1180,a,O
1180,comment,B
1180,'s,I
1180,word,B
1180,-,I
1180,counts,I
1180,as,B
1180,features,B
1180,in,B
1180,a,O
1180,vector,B
1180,.,O
1181,CNN,O
1181,:,O
1181,We,O
1181,compare,O
1181,our,O
1181,model,O
1181,with,O
1181,this,O
1181,individual,B
1181,CNN,O
1181,version,O
1181,.,O
1182,This,O
1182,model,O
1182,proposed,O
1182,by,O
1182,consists,B
1182,of,I
1182,a,O
1182,CNN,B
1182,for,B
1182,content,B
1182,modeling,I
1182,and,I
1182,other,B
1182,pre-trained,I
1182,CNNs,I
1182,for,O
1182,extracting,O
1182,sentiment,B
1182,",",I
1182,emotion,I
1182,and,O
1182,personality,O
1182,features,O
1182,from,B
1182,the,O
1182,given,B
1182,comment,I
1182,.,O
1183,This,O
1183,method,B
1183,proposed,O
1183,by,O
1183,also,O
1183,models,B
1183,user,B
1183,embeddings,I
1183,with,O
1183,a,O
1183,method,O
1183,akin,O
1183,to,O
1183,ParagraphVector,B
1183,.,O
1184,We,O
1184,holdout,B
1184,10,B
1184,%,I
1184,of,B
1184,the,O
1184,training,B
1184,data,I
1184,for,B
1184,validation,B
1184,.,O
1185,To,O
1185,optimize,O
1185,the,O
1185,parameters,B
1185,",",O
1185,Adam,B
1185,optimizer,I
1185,(,O
1185,Kingma,O
1185,and,O
1185,Ba,O
1185,",",O
1185,2014,O
1185,),O
1185,is,O
1185,used,O
1185,",",O
1185,starting,B
1185,with,I
1185,an,O
1185,initial,B
1185,learning,I
1185,rate,I
1185,of,B
1185,1e,O
1185,?,O
1186,Typically,O
1186,efforts,O
1186,in,O
1186,relation,B
1186,extraction,I
1186,fall,O
1186,into,O
1186,one,O
1186,of,O
1186,three,O
1186,groups,O
1186,.,O
1187,Training,O
1187,termination,O
1187,is,O
1187,decided,B
1187,using,I
1187,early,B
1187,stopping,I
1187,technique,I
1187,with,B
1187,a,O
1187,patience,B
1187,of,B
1187,12,B
1187,.,O
1188,For,B
1188,the,O
1188,batched,B
1188,-,I
1188,modeling,I
1188,of,B
1188,comments,B
1188,in,B
1188,CNNs,B
1188,",",O
1188,each,B
1188,comment,I
1188,is,B
1188,either,O
1188,restricted,B
1188,or,I
1188,padded,I
1188,to,B
1188,100,B
1188,words,I
1188,for,O
1188,uniformity,B
1188,.,O
1189,Particularly,O
1189,",",O
1189,we,O
1189,propose,B
1189,a,O
1189,hybrid,B
1189,network,I
1189,",",O
1189,named,B
1189,CASCADE,B
1189,",",O
1189,that,O
1189,utilizes,B
1189,both,O
1189,content,B
1189,and,I
1189,contextual,I
1189,-,I
1189,information,I
1189,required,B
1189,for,I
1189,sarcasm,B
1189,detection,I
1189,.,O
1190,First,O
1190,",",O
1190,it,O
1190,performs,B
1190,user,B
1190,profiling,I
1190,to,B
1190,create,I
1190,user,O
1190,embeddings,O
1190,that,B
1190,capture,I
1190,indicative,B
1190,behavioral,I
1190,traits,I
1190,for,B
1190,sarcasm,B
1190,.,O
1191,It,O
1191,performs,O
1191,content,B
1191,-,I
1191,modeling,I
1191,using,B
1191,a,O
1191,Convolutional,B
1191,Neural,I
1191,Network,I
1191,(,I
1191,CNN,I
1191,),I
1191,to,B
1191,extract,I
1191,its,O
1191,syntactic,B
1191,features,I
1191,.,O
1192,It,O
1192,makes,B
1192,use,I
1192,of,I
1192,users,B
1192,',I
1192,historical,I
1192,posts,I
1192,to,B
1192,model,I
1192,their,O
1192,writing,B
1192,style,I
1192,(,I
1192,stylometry,I
1192,),I
1192,and,I
1192,personality,I
1192,indicators,I
1192,",",O
1192,which,O
1192,are,O
1192,then,O
1192,fused,B
1192,into,I
1192,comprehensive,B
1192,user,I
1192,embeddings,I
1192,using,B
1192,a,O
1192,multi-view,B
1192,fusion,I
1192,approach,I
1192,",",O
1192,Canonical,B
1192,Correlation,I
1192,Analysis,I
1192,(,O
1192,CCA,O
1192,),O
1192,.,O
1193,Second,O
1193,",",O
1193,it,O
1193,extracts,B
1193,contextual,B
1193,information,I
1193,from,B
1193,the,O
1193,discourse,B
1193,of,B
1193,comments,B
1193,in,B
1193,the,O
1193,discussion,B
1193,forums,I
1193,.,O
1194,This,O
1194,is,O
1194,done,B
1194,by,I
1194,document,B
1194,modeling,I
1194,of,B
1194,these,O
1194,consolidated,B
1194,comments,I
1194,belonging,B
1194,to,I
1194,the,O
1194,same,B
1194,forum,I
1194,.,O
1195,After,B
1195,the,O
1195,contextual,B
1195,modeling,I
1195,phase,I
1195,",",O
1195,CASCADE,B
1195,is,O
1195,provided,B
1195,with,I
1195,a,O
1195,comment,B
1195,for,B
1195,sarcasm,B
1195,detection,I
1195,.,O
1196,This,O
1196,CNN,B
1196,representation,I
1196,is,O
1196,then,O
1196,concatenated,B
1196,with,I
1196,the,O
1196,relevant,B
1196,user,I
1196,embedding,I
1196,and,I
1196,discourse,I
1196,features,I
1196,to,B
1196,get,I
1196,the,O
1196,final,B
1196,representation,O
1196,which,O
1196,is,O
1196,used,B
1196,for,I
1196,classification,B
1196,.,O
1197,shows,O
1197,that,O
1197,the,O
1197,task,O
1197,agnostic,O
1197,BERT,O
1197,EM,O
1197,and,O
1197,BERT,O
1197,EM,O
1197,+,O
1197,MTB,O
1197,models,O
1197,outperform,B
1197,the,O
1197,previous,B
1197,published,I
1197,state,I
1197,of,I
1197,the,O
1197,art,O
1197,on,B
1197,FewRel,I
1197,task,O
1197,even,O
1197,when,B
1197,they,I
1197,have,I
1197,not,I
1197,seen,I
1197,any,B
1197,FewRel,O
1197,training,O
1197,data,O
1197,.,O
1198,CASCADE,O
1198,:,O
1198,Contextual,B
1198,Sarcasm,I
1198,Detection,I
1198,in,O
1198,Online,O
1198,Discussion,O
1198,Forums,O
1199,The,O
1199,literature,O
1199,in,O
1199,automated,B
1199,sarcasm,I
1199,detection,I
1199,has,O
1199,mainly,O
1199,focused,O
1199,on,O
1199,lexical,O
1199,",",O
1199,syntactic,O
1199,and,O
1199,semantic,O
1199,-,O
1199,level,O
1199,analysis,O
1199,of,O
1199,text,O
1199,.,O
1200,In,O
1200,this,O
1200,paper,O
1200,",",O
1200,we,O
1200,propose,O
1200,CASCADE,O
1200,(,O
1200,a,O
1200,ContextuAl,O
1200,SarCasm,B
1200,DEtector,O
1200,),O
1200,that,O
1200,adopts,O
1200,a,O
1200,hybrid,O
1200,approach,O
1200,of,O
1200,both,O
1200,content,O
1200,and,O
1200,context,O
1200,-,O
1200,driven,O
1200,modeling,O
1200,for,O
1200,sarcasm,O
1200,detection,O
1200,in,O
1200,online,O
1200,social,O
1200,media,O
1200,discussions,O
1200,.,O
1201,CASCADE,B
1201,manages,O
1201,to,O
1201,achieve,B
1201,major,B
1201,improvement,I
1201,across,B
1201,all,B
1201,datasets,I
1201,with,B
1201,statistical,B
1201,significance,I
1201,.,O
1202,CASCADE,O
1202,comfortably,B
1202,beats,I
1202,the,I
1202,state,B
1202,-,I
1202,of,I
1202,-,O
1202,the,O
1202,-,O
1202,art,O
1202,neural,O
1202,models,O
1202,CNN,O
1202,-,O
1202,SVM,O
1202,and,O
1202,CUE,B
1202,-,O
1202,CNN,O
1202,.,O
1203,The,O
1203,lowest,B
1203,performance,I
1203,is,O
1203,obtained,B
1203,by,I
1203,the,O
1203,Bag,B
1203,-,I
1203,of,I
1203,-,O
1203,words,O
1203,approach,O
1203,whereas,O
1203,all,O
1203,neural,O
1203,architectures,O
1203,outperform,O
1203,it,O
1203,.,O
1204,Its,O
1204,improved,B
1204,performance,I
1204,on,B
1204,the,O
1204,Main,B
1204,imbalanced,I
1204,dataset,I
1204,also,O
1204,reflects,B
1204,its,O
1204,robustness,B
1204,towards,B
1204,class,B
1204,imbalance,I
1204,and,O
1204,establishes,B
1204,it,I
1204,as,I
1204,a,O
1204,real,B
1204,-,I
1204,world,I
1204,deployable,I
1204,network,I
1204,.,O
1205,Since,O
1205,CUE,B
1205,-,I
1205,CNN,I
1205,generates,B
1205,its,O
1205,user,B
1205,embeddings,I
1205,using,B
1205,a,O
1205,method,B
1205,similar,B
1205,to,I
1205,the,O
1205,ParagraphVector,B
1205,",",O
1205,we,O
1205,test,O
1205,the,O
1205,importance,O
1205,of,O
1205,personality,O
1205,features,O
1205,being,O
1205,included,O
1205,in,O
1205,our,O
1205,user,O
1205,profiling,O
1205,.,O
1206,Amongst,B
1206,the,O
1206,neural,B
1206,networks,I
1206,",",O
1206,the,O
1206,CNN,B
1206,baseline,I
1206,receives,B
1206,the,O
1206,least,B
1206,performance,I
1206,.,O
1207,The,O
1207,additional,B
1207,MTB,I
1207,based,I
1207,training,I
1207,further,B
1207,increases,I
1207,F,B
1207,1,I
1207,scores,I
1207,for,B
1207,all,B
1207,tasks,I
1207,.,O
1208,To,O
1208,address,O
1208,the,O
1208,need,O
1208,for,B
1208,a,O
1208,large,O
1208,and,O
1208,high,O
1208,-,O
1208,quality,O
1208,dataset,O
1208,for,O
1208,a,O
1208,new,B
1208,complex,I
1208,and,O
1208,cross-domain,O
1208,semantic,O
1208,parsing,O
1208,task,O
1208,",",O
1208,we,O
1208,introduce,B
1208,Spider,B
1208,",",O
1208,which,O
1208,consists,B
1208,of,I
1208,200,B
1208,databases,I
1208,with,B
1208,multiple,B
1208,tables,I
1208,",",O
1208,"10,181",B
1208,questions,I
1208,",",O
1208,and,O
1208,"5,693",B
1208,corresponding,I
1208,complex,O
1208,SQL,O
1208,queries,O
1208,",",O
1208,all,O
1208,written,O
1208,by,O
1208,11,O
1208,college,O
1208,students,O
1208,spending,O
1208,a,O
1208,total,O
1208,of,O
1208,"1,000",O
1208,man-hours,O
1208,.,O
1209,As,O
1209,illustrates,O
1209,",",O
1209,given,O
1209,a,O
1209,database,O
1209,with,O
1209,multiple,O
1209,tables,O
1209,including,B
1209,foreign,O
1209,keys,O
1209,",",O
1209,our,O
1209,corpus,O
1209,creates,B
1209,and,I
1209,annotates,I
1209,complex,O
1209,questions,B
1209,and,O
1209,SQL,O
1209,queries,O
1209,including,O
1209,different,B
1209,SQL,O
1209,clauses,O
1209,such,O
1209,as,O
1209,joining,B
1209,and,O
1209,nested,O
1209,query,O
1209,.,O
1210,Spider,O
1210,:,O
1210,A,O
1210,Large,O
1210,-,O
1210,Scale,O
1210,Human,O
1210,-,O
1210,Labeled,O
1210,Dataset,O
1210,for,O
1210,Complex,B
1210,and,I
1210,Cross,I
1210,-,O
1210,Domain,O
1210,Semantic,O
1210,Parsing,O
1210,and,O
1210,Text,B
1210,-,O
1210,to,O
1210,-,O
1210,SQL,O
1210,Task,O
1211,Existing,O
1211,datasets,O
1211,for,O
1211,SP,B
1211,have,O
1211,two,O
1211,shortcomings,O
1211,.,O
1212,The,O
1212,performances,B
1212,of,B
1212,the,O
1212,Seq2Seq,B
1212,-,I
1212,based,I
1212,basic,I
1212,models,I
1212,including,B
1212,Seq2Seq,O
1212,",",O
1212,Seq2Seq,O
1212,+,O
1212,Attention,O
1212,",",O
1212,and,O
1212,Seq2Seq,O
1212,+,O
1212,Copying,O
1212,are,B
1212,very,B
1212,low,I
1212,.,O
1213,In,O
1213,contrast,O
1213,",",O
1213,SQLNet,B
1213,and,I
1213,TypeSQL,I
1213,that,O
1213,utilize,B
1213,SQL,B
1213,structure,I
1213,information,I
1213,to,B
1213,guide,I
1213,the,O
1213,SQL,O
1213,generation,O
1213,process,O
1213,significantly,B
1213,outperform,I
1213,other,B
1213,Seq2Seq,I
1213,models,I
1213,.,O
1214,As,O
1214,Component,O
1214,Matching,O
1214,results,O
1214,in,O
1214,shows,O
1214,",",O
1214,all,B
1214,models,I
1214,struggle,B
1214,with,I
1214,WHERE,B
1214,clause,I
1214,prediction,I
1214,the,O
1214,most,O
1214,.,O
1215,In,O
1215,general,O
1215,",",O
1215,the,O
1215,over,B
1215,all,B
1215,performances,I
1215,of,B
1215,all,O
1215,models,O
1215,are,B
1215,low,B
1215,",",O
1215,indicating,O
1215,that,O
1215,our,O
1215,task,O
1215,is,O
1215,challenging,O
1215,and,O
1215,there,O
1215,is,O
1215,still,O
1215,a,O
1215,large,O
1215,room,O
1215,for,O
1215,improvement,O
1215,.,O
1216,Inspired,O
1216,by,O
1216,this,O
1216,existing,O
1216,research,O
1216,",",O
1216,we,O
1216,have,O
1216,developed,B
1216,TRANX,B
1216,",",O
1216,a,O
1216,TRANsition,B
1216,-,I
1216,based,I
1216,abstract,I
1216,syntaX,I
1216,parser,I
1216,for,B
1216,semantic,B
1216,parsing,I
1216,and,I
1216,code,I
1216,generation,I
1216,.,O
1217,For,B
1217,BERT,B
1217,EM,I
1217,+,I
1217,MTB,I
1217,",",O
1217,the,O
1217,increase,B
1217,over,O
1217,'s,O
1217,supervised,O
1217,approach,O
1217,is,O
1217,very,B
1217,significant,I
1217,-,I
1217,8.8,B
1217,%,I
1217,on,B
1217,the,O
1217,5,B
1217,-,O
1217,way,O
1217,-,O
1217,1,O
1217,-,O
1217,shot,O
1217,task,O
1217,and,O
1217,12.7,B
1217,%,O
1217,on,O
1217,the,O
1217,10,B
1217,-,O
1217,way,O
1217,-,O
1217,1,O
1217,-,O
1217,shot,O
1217,task,O
1217,.,O
1218,TRANX,B
1218,is,O
1218,designed,B
1218,with,I
1218,the,O
1218,following,B
1218,principles,I
1218,in,O
1218,mind,O
1218,:,O
1219,Generalization,O
1219,ability,O
1219,TRANX,O
1219,employs,B
1219,ASTs,B
1219,as,B
1219,a,O
1219,general,B
1219,-,I
1219,purpose,I
1219,intermediate,I
1219,meaning,I
1219,representation,I
1219,",",O
1219,and,O
1219,the,O
1219,task,B
1219,-,O
1219,dependent,O
1219,grammar,O
1219,is,O
1219,provided,B
1219,to,B
1219,the,O
1219,system,B
1219,as,O
1219,external,B
1219,knowledge,I
1219,to,O
1219,guide,O
1219,the,O
1219,parsing,B
1219,process,I
1219,",",O
1219,therefore,O
1219,decoupling,O
1219,the,O
1219,semantic,O
1219,parsing,O
1219,procedure,O
1219,with,O
1219,specificities,O
1219,of,O
1219,grammars,O
1219,.,O
1220,Extensibility,B
1220,TRANX,O
1220,uses,B
1220,a,O
1220,simple,B
1220,transition,I
1220,system,I
1220,to,B
1220,parse,I
1220,NL,B
1220,utterances,I
1220,into,O
1220,tree,O
1220,-,O
1221,Effectiveness,B
1222,We,O
1222,test,B
1222,TRANX,B
1222,on,B
1222,four,O
1222,semantic,B
1222,parsing,I
1222,(,O
1222,ATIS,B
1222,",",O
1222,GEO,B
1222,),O
1222,and,O
1222,code,B
1222,generation,I
1222,(,O
1222,DJANGO,B
1222,",",O
1222,WIKISQL,B
1222,),O
1222,tasks,O
1222,",",O
1222,and,O
1222,demonstrate,O
1222,that,O
1222,TRANX,O
1222,is,O
1222,capable,O
1222,of,O
1222,generalizing,O
1222,to,O
1222,different,O
1222,domains,O
1222,while,O
1222,registering,O
1222,strong,O
1222,performance,O
1222,",",O
1222,out,O
1222,-,O
1222,performing,O
1222,existing,O
1222,neural,O
1222,networkbased,O
1222,approaches,O
1222,on,O
1222,three,O
1222,of,O
1222,the,O
1222,four,O
1222,datasets,O
1222,(,O
1222,GEO,O
1222,",",O
1222,ATIS,O
1222,",",O
1222,DJANGO,O
1222,),O
1222,.,O
1223,TRANX,O
1223,:,O
1223,A,O
1223,Transition,O
1223,-,O
1223,based,O
1223,Neural,O
1223,Abstract,O
1223,Syntax,O
1223,Parser,O
1223,for,O
1223,Semantic,B
1223,Parsing,I
1223,and,I
1223,Code,I
1223,Generation,I
1224,Our,O
1224,system,O
1224,outperforms,B
1224,existing,B
1224,neural,I
1224,network,I
1224,-,I
1224,based,I
1224,approaches,I
1224,.,O
1225,Interestingly,O
1225,",",O
1225,we,O
1225,found,O
1225,the,O
1225,model,B
1225,without,B
1225,parent,B
1225,feeding,I
1225,achieves,B
1225,slightly,B
1225,better,I
1225,accuracy,I
1225,on,B
1225,GEO,B
1225,",",O
1225,probably,O
1225,because,O
1225,that,O
1225,its,O
1225,relative,O
1225,simple,O
1225,grammar,O
1225,does,O
1225,not,O
1225,require,O
1225,extra,O
1225,handling,O
1225,of,O
1225,parent,O
1225,information,O
1225,.,O
1226,BERT,O
1226,EM,O
1226,+,O
1226,MTB,O
1226,also,O
1226,significantly,B
1226,outperforms,I
1226,BERT,O
1226,EM,O
1226,in,O
1226,this,O
1226,unsupervised,O
1226,setting,O
1226,",",O
1226,which,O
1226,is,O
1226,to,O
1226,be,O
1226,expected,O
1226,since,O
1226,there,O
1226,is,O
1226,no,O
1226,relation,O
1226,-,O
1226,specific,O
1226,loss,O
1226,during,O
1226,BERT,O
1226,EM,O
1226,'s,O
1226,training,O
1226,.,O
1227,2,O
1227,lists,O
1227,the,O
1227,results,O
1227,on,B
1227,DJANGO,B
1227,.,O
1228,TRANX,B
1228,achieves,B
1228,state,B
1228,-,I
1228,of,I
1228,-,O
1228,the,O
1228,-,O
1228,art,O
1228,results,O
1228,on,O
1228,DJANGO,O
1228,.,O
1229,We,O
1229,also,O
1229,find,B
1229,parent,B
1229,feeding,I
1229,yields,B
1229,+,B
1229,1,I
1229,point,I
1229,gain,I
1229,in,B
1229,accuracy,B
1229,",",O
1229,suggesting,O
1229,the,O
1229,importance,O
1229,of,O
1229,modeling,O
1229,parental,O
1229,connections,O
1229,in,O
1229,ASTs,O
1229,with,O
1229,complex,O
1229,domain,O
1229,grammars,O
1229,(,O
1229,e.g.,O
1230,We,O
1230,find,O
1230,TRANX,B
1230,",",O
1230,although,O
1230,just,O
1230,with,O
1230,simple,O
1230,extensions,O
1230,to,O
1230,adapt,O
1230,to,O
1230,this,O
1230,dataset,O
1230,",",O
1230,achieves,B
1230,impressive,B
1230,results,I
1230,and,O
1230,outperforms,B
1230,many,B
1230,task,I
1230,-,I
1230,specific,I
1230,methods,I
1230,.,O
1231,Dimensions,B
1231,of,B
1231,hidden,B
1231,vectors,I
1231,and,I
1231,word,I
1231,embeddings,I
1231,were,O
1231,selected,B
1231,from,I
1231,{,I
1231,250,I
1231,",",I
1231,300,I
1231,},I
1231,and,O
1231,{,O
1231,150,O
1231,",",O
1231,200,O
1231,",",O
1231,250,O
1231,",",O
1231,300,O
1231,},O
1231,",",O
1231,respectively,O
1231,.,O
1232,The,O
1232,dropout,B
1232,rate,I
1232,was,O
1232,selected,B
1232,from,I
1232,{,B
1232,0.3,I
1232,",",I
1232,0.5,I
1232,},I
1232,.,O
1233,Label,O
1233,smoothing,O
1233,was,O
1233,employed,B
1233,for,I
1233,GEO,B
1233,and,O
1233,ATIS,B
1233,.,O
1234,The,O
1234,smoothing,B
1234,parameter,I
1234,was,O
1234,set,B
1234,to,I
1234,0.1,B
1234,.,O
1235,Word,O
1235,embeddings,O
1235,were,O
1235,initialized,B
1235,by,I
1235,GloVe,B
1235,",",O
1235,and,O
1235,were,O
1235,shared,B
1235,by,O
1235,table,B
1235,encoder,I
1235,and,O
1235,input,B
1235,encoder,O
1235,in,O
1235,Section,O
1235,4.3,O
1235,.,O
1236,When,O
1236,given,B
1236,access,B
1236,to,B
1236,all,B
1236,of,I
1236,the,I
1236,training,I
1236,data,I
1236,",",O
1236,BERT,B
1236,EM,I
1236,approaches,B
1236,BERT,O
1236,EM,O
1236,+,O
1236,MTB,O
1236,'s,O
1236,performance,O
1236,.,O
1237,The,O
1237,part,B
1237,-,I
1237,of,I
1237,-,O
1237,speech,O
1237,tags,O
1237,were,O
1237,obtained,B
1237,by,I
1237,the,O
1237,spaCy,B
1237,toolkit,I
1237,.,O
1238,The,O
1238,learning,B
1238,rate,I
1238,was,O
1238,selected,B
1238,from,I
1238,{,B
1238,0.002,I
1238,",",I
1238,0.005,I
1238,},I
1238,.,O
1239,The,O
1239,batch,B
1239,size,I
1239,was,B
1239,200,B
1239,for,B
1239,WIKISQL,B
1239,",",O
1239,and,O
1239,was,O
1239,64,B
1239,for,O
1239,other,B
1239,datasets,I
1239,.,O
1240,Early,O
1240,stopping,O
1240,was,O
1240,used,O
1240,to,B
1240,determine,I
1240,the,O
1240,number,B
1240,of,I
1240,epochs,I
1240,.,O
1241,We,O
1241,appended,B
1241,10,B
1241,-,I
1241,dimensional,I
1241,part,I
1241,-,O
1241,of,B
1241,-,O
1241,speech,O
1241,tag,O
1241,vectors,O
1241,to,B
1241,embeddings,B
1241,of,O
1241,the,O
1241,question,B
1241,words,I
1241,in,B
1241,WIKISQL,B
1241,.,O
1242,We,O
1242,used,B
1242,the,O
1242,RMSProp,B
1242,optimizer,I
1242,to,B
1242,train,I
1242,the,O
1242,models,B
1242,.,O
1243,In,O
1243,this,O
1243,work,O
1243,",",O
1243,we,O
1243,propose,B
1243,to,I
1243,decompose,I
1243,the,O
1243,decoding,B
1243,process,I
1243,into,B
1243,two,B
1243,stages,I
1243,.,O
1244,The,O
1244,first,B
1244,decoder,I
1244,focuses,B
1244,on,I
1244,predicting,B
1244,a,O
1244,rough,B
1244,sketch,I
1244,of,B
1244,the,O
1244,meaning,B
1244,representation,I
1244,",",O
1244,which,O
1244,omits,O
1244,low,O
1244,-,O
1244,level,O
1244,details,O
1244,",",O
1244,such,O
1244,as,O
1244,arguments,O
1244,and,O
1244,variable,O
1244,names,O
1244,.,O
1245,Then,O
1245,",",O
1245,a,O
1245,second,B
1245,decoder,I
1245,fills,B
1245,in,I
1245,missing,B
1245,details,I
1245,by,B
1245,conditioning,I
1245,on,I
1245,the,O
1245,natural,B
1245,language,I
1245,input,I
1245,and,O
1245,the,O
1245,sketch,B
1245,itself,O
1245,.,O
1246,Specifically,O
1246,",",O
1246,the,O
1246,sketch,B
1246,constrains,B
1246,the,O
1246,generation,B
1246,process,I
1246,and,O
1246,is,O
1246,encoded,B
1246,into,I
1246,vectors,B
1246,to,B
1246,guide,I
1246,decoding,B
1246,.,O
1247,The,O
1247,results,O
1247,in,B
1247,show,B
1247,that,I
1247,MTB,B
1247,training,I
1247,could,B
1247,be,I
1247,used,I
1247,to,I
1247,significantly,B
1247,reduce,I
1247,effort,I
1247,in,O
1247,implementing,O
1247,an,O
1247,exemplar,B
1247,based,I
1247,relation,I
1247,extraction,I
1247,system,I
1247,.,O
1248,Firstly,O
1248,",",O
1248,the,O
1248,decomposition,B
1248,disentangles,B
1248,high,B
1248,-,I
1248,level,I
1248,from,I
1248,low,I
1248,-,O
1248,level,O
1248,semantic,O
1248,information,O
1248,",",O
1248,which,O
1248,enables,B
1248,the,O
1248,decoders,B
1248,to,B
1248,model,I
1248,meaning,B
1248,at,B
1248,different,B
1248,levels,I
1248,of,I
1248,granularity,I
1248,.,O
1249,Secondly,O
1249,",",O
1249,the,O
1249,model,O
1249,can,O
1249,explicitly,B
1249,share,I
1249,knowledge,B
1249,of,B
1249,coarse,B
1249,structures,I
1249,for,B
1249,the,O
1249,examples,O
1249,that,O
1249,have,O
1249,the,O
1249,same,O
1249,sketch,O
1249,(,O
1249,i.e.,O
1250,Thirdly,O
1250,",",O
1250,after,O
1250,generating,B
1250,the,I
1250,sketch,B
1250,",",O
1250,the,O
1250,decoder,B
1250,knows,B
1250,what,O
1250,the,O
1250,basic,B
1250,meaning,I
1250,of,B
1250,the,O
1250,utterance,O
1250,looks,O
1250,like,O
1250,",",O
1250,and,O
1250,the,O
1250,model,B
1250,can,O
1250,use,B
1250,it,I
1250,as,B
1250,global,B
1250,context,I
1250,to,B
1250,improve,I
1250,the,O
1250,prediction,B
1250,of,O
1250,the,O
1250,final,B
1250,details,I
1250,.,O
1251,Coarse,O
1251,-,O
1251,to,O
1251,-,O
1251,Fine,O
1251,Decoding,O
1251,for,O
1251,Neural,B
1251,Semantic,I
1251,Parsing,I
1252,Overall,O
1252,",",O
1252,we,O
1252,observe,B
1252,that,O
1252,COARSE2FINE,B
1252,outperforms,B
1252,ONESTAGE,B
1252,",",O
1252,which,O
1252,suggests,B
1252,that,O
1252,disentangling,B
1252,high,B
1252,-,I
1252,level,I
1252,from,B
1252,low,B
1252,-,O
1252,level,O
1252,information,O
1252,dur,O
1252,-,O
1252,62.3,O
1252,SNM,O
1252,+,O
1252,COPY,O
1252,71,O
1252,and,O
1252,.,O
1253,Again,O
1253,we,O
1253,observe,O
1253,that,O
1253,the,O
1253,sketch,B
1253,encoder,I
1253,is,I
1253,beneficial,B
1253,and,I
1253,that,O
1253,there,B
1253,is,O
1253,an,O
1253,8.9,B
1253,point,I
1253,difference,I
1253,in,B
1253,accuracy,I
1253,between,I
1253,COARSE2FINE,B
1253,and,O
1253,the,O
1253,oracle,O
1253,.,O
1254,Compared,O
1254,with,O
1254,previous,O
1254,neural,O
1254,models,O
1254,that,O
1254,utilize,O
1254,syntax,O
1254,or,O
1254,grammatical,O
1254,information,O
1254,(,O
1254,SEQ2,O
1254,TREE,O
1254,",",O
1254,ASN,O
1254,;,O
1254,the,O
1254,second,O
1254,block,O
1254,in,O
1254,),O
1254,",",O
1254,our,B
1254,method,I
1254,performs,B
1254,competitively,B
1254,despite,B
1254,the,O
1254,use,O
1254,of,O
1254,relatively,B
1254,simple,I
1254,decoders,I
1254,.,O
1255,Our,O
1255,model,O
1255,is,O
1255,superior,B
1255,to,I
1255,ONESTAGE,B
1255,as,O
1255,well,O
1255,as,O
1255,to,O
1255,previous,B
1255,best,I
1255,performing,I
1255,systems,I
1255,.,O
1256,COARSE2FINE,O
1256,'s,O
1256,accuracies,O
1256,on,B
1256,aggregation,B
1256,agg,I
1256,op,I
1256,and,I
1256,agg,O
1256,col,O
1256,are,B
1256,90.2,B
1256,%,I
1256,and,O
1256,92.0,O
1256,%,O
1256,",",O
1256,respectively,O
1256,",",O
1256,which,O
1256,is,O
1256,comparable,B
1256,to,I
1256,SQLNET,B
1256,.,O
1257,For,O
1257,all,O
1257,tasks,O
1257,",",O
1257,we,O
1257,see,B
1257,that,I
1257,MTB,B
1257,based,I
1257,training,I
1257,is,O
1257,even,O
1257,more,O
1257,effective,O
1257,for,O
1257,low,B
1257,-,I
1257,resource,I
1257,cases,I
1257,",",O
1257,where,O
1257,there,O
1257,is,O
1257,a,O
1257,larger,O
1257,gap,O
1257,in,O
1257,performance,O
1257,between,O
1257,our,O
1257,BERT,O
1257,EM,O
1257,and,O
1257,BERT,O
1257,EM,O
1257,+,O
1257,MTB,O
1257,based,O
1257,classifiers,O
1257,.,O
1258,So,O
1258,the,O
1258,most,B
1258,gain,I
1258,is,O
1258,obtained,B
1258,by,I
1258,the,O
1258,improved,B
1258,decoder,I
1258,of,B
1258,the,O
1258,WHERE,B
1258,clause,I
1258,.,O
1259,Sketches,B
1259,produced,B
1259,by,I
1259,COARSE2FINE,B
1259,are,B
1259,more,B
1259,accurate,I
1259,across,O
1259,the,O
1259,board,O
1259,.,O
1260,As,O
1260,can,O
1260,be,O
1260,seen,O
1260,",",O
1260,predicting,B
1260,the,O
1260,sketch,B
1260,correctly,B
1260,boosts,B
1260,performance,B
1260,.,O
1261,We,O
1261,also,O
1261,find,B
1261,that,O
1261,a,O
1261,tableaware,B
1261,input,I
1261,encoder,I
1261,is,B
1261,critical,B
1261,for,B
1261,doing,B
1261,well,I
1261,on,B
1261,this,B
1261,task,I
1261,",",O
1261,since,O
1261,the,O
1261,same,O
1261,question,O
1261,might,O
1261,lead,O
1261,to,O
1261,different,O
1261,SQL,O
1261,queries,O
1261,depending,O
1261,on,O
1261,the,O
1261,table,O
1261,schemas,O
1261,.,O
1262,On,B
1262,WIKISQL,B
1262,",",O
1262,the,O
1262,sketches,B
1262,predicted,B
1262,by,I
1262,COARSE2FINE,B
1262,are,B
1262,marginally,B
1262,better,I
1262,compared,B
1262,with,I
1262,ONESTAGE,B
1262,.,O
1263,We,O
1263,train,B
1263,the,O
1263,model,B
1263,parameters,I
1263,and,I
1263,word,I
1263,/,I
1263,character,I
1263,embeddings,I
1263,by,B
1263,the,O
1263,mini-batch,B
1263,stochastic,I
1263,gradient,I
1263,descent,I
1263,(,I
1263,SGD,I
1263,),I
1263,with,B
1263,batch,B
1263,size,I
1263,10,B
1263,",",O
1263,momentum,B
1263,0.9,B
1263,",",O
1263,initial,B
1263,learning,I
1263,rate,I
1263,0.01,B
1263,and,O
1263,decay,B
1263,rate,O
1263,0.05,B
1263,.,O
1264,We,O
1264,also,O
1264,use,B
1264,a,O
1264,gradient,B
1264,clipping,I
1264,of,B
1264,5.0,B
1264,.,O
1265,The,O
1265,models,O
1265,are,O
1265,trained,B
1265,with,I
1265,early,B
1265,stopping,I
1265,),O
1265,based,B
1265,on,I
1265,the,O
1265,development,B
1265,performance,I
1265,.,O
1266,In,O
1266,this,O
1266,paper,O
1266,",",O
1266,spotlighting,O
1266,a,O
1266,well,O
1266,-,O
1266,studied,O
1266,core,O
1266,problem,O
1266,of,O
1266,NLP,O
1266,",",O
1266,we,O
1266,propose,B
1266,and,I
1266,carefully,I
1266,analyze,I
1266,a,O
1266,neural,B
1266,part,I
1266,-,O
1266,of,O
1266,-,O
1266,speech,O
1266,(,O
1266,POS,O
1266,),O
1266,tagging,O
1266,model,O
1266,that,B
1266,exploits,I
1266,adversarial,B
1266,training,I
1266,.,O
1267,With,B
1267,a,O
1267,BiLSTM,B
1267,-,I
1267,CRF,I
1267,model,I
1267,as,B
1267,our,O
1267,baseline,B
1267,POS,I
1267,tagger,I
1267,",",O
1267,we,O
1267,apply,B
1267,adversarial,B
1267,training,I
1267,by,O
1267,considering,B
1267,perturbations,B
1267,to,B
1267,input,B
1267,word,I
1267,/,I
1267,character,I
1267,embeddings,I
1267,.,O
1268,This,O
1268,further,O
1268,supports,O
1268,our,O
1268,argument,O
1268,that,O
1268,training,B
1268,by,I
1268,matching,B
1268,the,I
1268,blanks,I
1268,can,B
1268,significantly,B
1268,reduce,I
1268,the,O
1268,amount,B
1268,of,I
1268,human,B
1268,input,I
1268,required,O
1268,to,B
1268,create,I
1268,relation,B
1268,extractors,I
1268,",",O
1268,and,O
1268,populate,B
1268,a,O
1268,knowledge,B
1268,base,I
1268,.,O
1269,Robust,O
1269,Multilingual,O
1269,Part,B
1269,-,I
1269,of,I
1269,-,O
1269,Speech,O
1269,Tagging,O
1269,via,O
1269,Adversarial,O
1269,Training,O
1270,In,O
1270,this,O
1270,paper,O
1270,",",O
1270,we,O
1270,propose,O
1270,and,O
1270,analyze,O
1270,a,O
1270,neural,B
1270,POS,I
1270,tagging,I
1270,model,O
1270,that,O
1270,exploits,O
1270,AT,O
1270,.,O
1271,As,O
1271,expected,O
1271,",",O
1271,our,O
1271,baseline,B
1271,(,I
1271,BiLSTM,I
1271,-,I
1271,CRF,I
1271,),I
1271,model,I
1271,(,O
1271,accuracy,B
1271,97.54,B
1271,%,I
1271,),O
1271,performs,B
1271,on,B
1271,par,I
1271,with,B
1271,other,B
1271,state,I
1271,-,O
1271,of,O
1271,-,O
1271,the,O
1271,-,O
1271,art,O
1271,systems,O
1271,.,O
1272,Built,O
1272,upon,O
1272,this,O
1272,baseline,O
1272,",",O
1272,our,O
1272,adversarial,B
1272,training,I
1272,(,I
1272,AT,I
1272,),I
1272,model,I
1272,reaches,B
1272,accuracy,B
1272,97.58,B
1272,%,I
1272,thanks,O
1272,to,O
1272,its,O
1272,regularization,O
1272,power,O
1272,",",O
1272,outperforming,B
1272,recent,B
1272,POS,I
1272,taggers,I
1272,except,O
1272,.,O
1273,Our,O
1273,code,O
1273,is,O
1273,open,O
1273,-,O
1273,source,O
1273,and,O
1273,available,O
1273,together,O
1273,with,O
1273,pre-trained,O
1273,models,O
1273,at,O
1273,:,O
1273,https://github.com/,B
1273,datquocnguyen/jPTDP,I
1273,.,O
1274,Our,O
1274,jPTDP,B
1274,is,O
1274,implemented,B
1274,using,I
1274,DYNET,B
1274,v,I
1274,2.0,I
1274,.,O
1275,We,O
1275,optimize,B
1275,the,O
1275,objective,B
1275,function,I
1275,using,B
1275,Adam,B
1275,(,I
1275,Kingma,I
1275,and,I
1275,Ba,I
1275,",",I
1275,2014,I
1275,),I
1275,with,B
1275,default,B
1275,DYNET,I
1275,parameter,I
1275,settings,I
1275,and,O
1275,no,O
1275,mini-batches,O
1275,.,O
1276,Following,O
1276,Kiperwasser,O
1276,and,O
1276,Goldberg,O
1276,(,O
1276,2016,O
1276,b,O
1276,),O
1276,and,O
1276,",",O
1276,we,O
1276,apply,B
1276,a,O
1276,word,B
1276,dropout,I
1276,rate,I
1276,of,B
1276,0.25,B
1276,and,O
1276,Gaussian,B
1276,noise,I
1276,with,B
1276,?,O
1277,For,O
1277,training,O
1277,",",O
1277,we,O
1277,run,O
1277,for,O
1277,30,B
1277,epochs,I
1277,",",O
1277,and,O
1277,evaluate,O
1277,the,O
1277,mixed,O
1277,accuracy,O
1277,of,O
1277,correctly,O
1277,assigning,O
1277,POS,O
1277,tag,O
1277,together,O
1277,with,O
1277,dependency,O
1277,arc,O
1277,and,O
1277,relation,O
1277,type,O
1277,on,O
1277,the,O
1277,development,O
1277,set,O
1277,after,O
1277,each,O
1277,training,O
1277,epoch,O
1277,.,O
1278,RESIDE,B
1278,outperforms,B
1278,PCNN,B
1278,+,I
1278,ATT,I
1278,and,I
1278,BGWA,I
1278,which,O
1278,indicates,O
1278,that,O
1278,incorporating,O
1278,side,O
1278,information,O
1278,helps,O
1278,in,O
1278,improving,O
1278,the,O
1278,performance,O
1278,of,O
1278,the,O
1278,model,O
1278,.,O
1279,We,O
1279,observe,B
1279,that,O
1279,the,O
1279,three,B
1279,methods,I
1279,all,O
1279,perform,B
1279,worse,B
1279,than,B
1279,R,B
1279,-,I
1279,BERT,I
1279,.,O
1280,We,O
1280,perform,B
1280,a,O
1280,minimal,B
1280,grid,I
1280,search,I
1280,of,B
1280,hyper,B
1280,-,I
1280,parameters,I
1280,on,B
1280,English,B
1280,.,O
1281,compares,B
1281,the,O
1281,POS,B
1281,tagging,I
1281,and,I
1281,dependency,I
1281,parsing,I
1281,results,I
1281,of,B
1281,our,B
1281,model,I
1281,jPTDP,I
1281,with,O
1281,results,O
1281,reported,O
1281,in,O
1281,prior,O
1281,work,O
1281,",",O
1281,using,O
1281,the,O
1281,same,O
1281,experimental,O
1281,setup,O
1281,.,O
1282,In,O
1282,this,O
1282,paper,O
1282,",",O
1282,we,O
1282,propose,B
1282,a,O
1282,novel,B
1282,neural,I
1282,architecture,I
1282,for,B
1282,joint,B
1282,POS,I
1282,tagging,I
1282,and,I
1282,graph,I
1282,-,I
1282,based,I
1282,dependency,I
1282,parsing,I
1282,.,O
1283,Our,O
1283,model,O
1283,learns,B
1283,latent,B
1283,feature,I
1283,representations,I
1283,shared,B
1283,for,I
1283,both,O
1283,POS,B
1283,tagging,I
1283,and,I
1283,dependency,I
1283,parsing,I
1283,tasks,I
1283,by,O
1283,using,B
1283,BiLSTMthe,B
1283,bidirectional,I
1283,LSTM,I
1283,.,O
1284,A,O
1284,Novel,O
1284,Neural,O
1284,Network,O
1284,Model,O
1284,for,O
1284,Joint,B
1284,POS,I
1284,Tagging,I
1284,and,I
1284,Graph,I
1284,-,I
1284,based,I
1284,Dependency,I
1284,Parsing,I
1285,In,O
1285,terms,O
1285,of,O
1285,dependency,B
1285,parsing,I
1285,",",O
1285,in,O
1285,most,O
1285,cases,O
1285,",",O
1285,our,B
1285,model,I
1285,jPTDP,I
1285,outperforms,B
1285,Stack,B
1285,-,I
1285,propagation,I
1285,.,O
1286,It,O
1286,is,O
1286,somewhat,O
1286,unexpected,O
1286,that,O
1286,our,O
1286,model,O
1286,produces,B
1286,about,B
1286,7,I
1286,%,I
1286,absolute,I
1286,lower,I
1286,LAS,I
1286,score,I
1286,than,B
1286,Stack,B
1286,-,I
1286,propagation,I
1286,on,B
1286,Dutch,B
1286,(,I
1286,nl,I
1286,),I
1286,.,O
1287,Without,O
1287,taking,O
1287,"""",O
1287,nl,B
1287,"""",O
1287,into,B
1287,account,B
1287,",",O
1287,our,O
1287,averaged,B
1287,LAS,I
1287,score,I
1287,over,B
1287,all,B
1287,remaining,I
1287,languages,I
1287,is,B
1287,1.1,B
1287,%,I
1287,absolute,I
1287,higher,I
1287,than,B
1287,Stack,B
1287,-,I
1287,propagation,I
1287,'s,I
1287,.,O
1288,The,O
1288,last,O
1288,row,O
1288,in,O
1288,shows,B
1288,an,O
1288,absolute,B
1288,LAS,I
1288,improvement,I
1288,of,B
1288,4.4,B
1288,%,I
1288,on,B
1288,average,B
1288,when,O
1288,comparing,O
1288,our,O
1288,jPTDP,O
1288,with,O
1288,its,O
1288,simplified,O
1288,version,O
1288,of,O
1288,not,O
1288,using,O
1288,characterbased,O
1288,representations,O
1288,:,O
1288,specifically,O
1288,",",O
1288,morphologically,B
1288,rich,I
1288,languages,I
1288,get,B
1288,an,O
1288,averaged,B
1288,improvement,O
1288,of,O
1288,9.3,B
1288,%,O
1288,",",O
1288,vice,O
1288,versa,O
1288,2.6,O
1288,%,O
1288,for,O
1288,others,O
1288,.,O
1289,So,O
1289,",",O
1289,our,O
1289,jPDTP,B
1289,is,O
1289,particularly,O
1289,good,B
1289,for,I
1289,morphologically,B
1289,rich,I
1289,languages,I
1289,",",O
1289,with,B
1289,1.7,B
1289,%,I
1289,higher,I
1289,averaged,I
1289,LAS,I
1289,than,B
1289,Stack,B
1289,-,I
1289,propagation,I
1289,over,O
1289,these,O
1289,languages,O
1289,.,O
1290,Of,O
1290,the,O
1290,methods,O
1290,",",O
1290,BERT,O
1290,-,O
1290,NO,O
1290,-,O
1290,SEP,O
1290,-,O
1290,NO,O
1290,-,O
1290,ENT,O
1290,performs,B
1290,worst,B
1290,",",O
1290,with,B
1290,its,O
1290,F1,B
1290,8.16,I
1290,absolute,I
1290,points,I
1290,worse,B
1290,than,I
1290,R,B
1290,-,O
1290,BERT,O
1290,.,O
1291,shows,O
1291,that,O
1291,separately,B
1291,optimized,I
1291,models,I
1291,are,B
1291,significantly,B
1291,more,I
1291,accurate,I
1291,on,B
1291,average,B
1291,than,B
1291,jointly,B
1291,optimized,O
1291,models,O
1291,.,O
1292,Separate,O
1292,optimization,O
1292,leads,B
1292,to,I
1292,better,B
1292,accuracy,I
1292,for,B
1292,34,B
1292,out,I
1292,of,I
1292,40,I
1292,treebanks,I
1292,for,O
1292,the,O
1292,morphological,B
1292,features,I
1292,task,I
1292,and,O
1292,for,O
1292,30,B
1292,out,O
1292,of,O
1292,39,O
1292,treebanks,O
1292,for,O
1292,xpos,B
1292,tagging,I
1292,.,O
1293,Separate,B
1293,optimization,I
1293,outperformed,B
1293,joint,B
1293,optimization,O
1293,by,B
1293,up,B
1293,to,I
1293,2.1,I
1293,percent,I
1293,absolute,I
1293,",",O
1293,while,O
1293,joint,O
1293,never,B
1293,out,B
1293,-,I
1293,performed,I
1293,separate,O
1293,by,O
1293,more,B
1293,than,I
1293,0.5,I
1293,%,I
1293,absolute,O
1293,.,O
1294,The,O
1294,examples,O
1294,show,O
1294,that,O
1294,the,O
1294,combined,B
1294,model,I
1294,has,O
1294,significantly,B
1294,higher,I
1294,accuracy,I
1294,compared,B
1294,with,I
1294,either,O
1294,the,O
1294,character,B
1294,and,I
1294,word,I
1294,models,I
1294,individually,O
1294,.,O
1295,For,B
1295,all,B
1295,of,I
1295,the,I
1295,network,I
1295,sizes,I
1295,in,B
1295,the,O
1295,grid,B
1295,search,I
1295,",",O
1295,we,O
1295,still,O
1295,observed,B
1295,during,I
1295,training,B
1295,that,B
1295,the,O
1295,accuracy,B
1295,reach,B
1295,a,O
1295,high,B
1295,value,I
1295,and,I
1295,degrades,B
1295,with,I
1295,more,B
1295,iterations,I
1295,for,O
1295,the,O
1295,character,B
1295,and,O
1295,word,O
1295,model,O
1295,.,O
1296,The,O
1296,word,B
1296,embeddings,I
1296,are,B
1296,initialized,B
1296,with,B
1296,zero,B
1296,values,I
1296,and,O
1296,the,O
1296,pre-trained,B
1296,embeddings,O
1296,are,O
1296,not,B
1296,updated,B
1296,during,B
1296,training,B
1296,.,O
1297,The,O
1297,dropout,B
1297,used,B
1297,on,I
1297,the,O
1297,embeddings,B
1297,is,B
1297,achieved,B
1297,by,I
1297,a,O
1297,RRIE,B
1297,is,O
1297,the,O
1297,relative,B
1297,reduction,I
1297,in,I
1297,error,I
1297,.,O
1298,We,O
1298,propose,O
1298,a,O
1298,novel,O
1298,model,O
1298,where,O
1298,we,O
1298,learn,B
1298,context,B
1298,sensitive,I
1298,initial,I
1298,character,I
1298,and,I
1298,word,I
1298,representations,I
1298,through,B
1298,two,B
1298,separate,I
1298,sentence,I
1298,-,I
1298,level,I
1298,recurrent,I
1298,models,I
1298,.,O
1299,These,O
1299,are,O
1299,then,O
1299,combined,B
1299,via,I
1299,a,O
1299,meta-BiLSTM,B
1299,model,I
1299,that,O
1299,builds,B
1299,a,O
1299,unified,B
1299,representation,I
1299,of,B
1299,each,B
1299,word,I
1299,that,O
1299,is,O
1299,then,O
1299,used,B
1299,for,I
1299,syntactic,B
1299,tagging,I
1299,.,O
1300,BERT,B
1300,without,B
1300,special,B
1300,separate,I
1300,tokens,I
1300,can,B
1300,not,I
1300,locate,I
1300,the,O
1300,target,B
1300,entities,I
1300,and,O
1300,lose,O
1300,this,O
1300,key,O
1300,information,O
1300,.,O
1301,Our,O
1301,model,O
1301,outperforms,B
1301,in,B
1301,32,B
1301,of,B
1301,the,O
1301,54,B
1301,treebanks,I
1301,with,B
1301,13,B
1301,ties,I
1301,.,O
1302,Our,O
1302,model,O
1302,tends,O
1302,to,O
1302,produce,B
1302,better,B
1302,results,I
1302,",",O
1302,especially,B
1302,for,I
1302,morphologically,B
1302,rich,I
1302,languages,I
1302,(,O
1302,e.g.,O
1303,Our,O
1303,models,O
1303,tend,O
1303,to,O
1303,produce,B
1303,significantly,B
1303,better,I
1303,results,I
1303,than,B
1303,the,I
1303,winners,B
1303,of,I
1303,the,O
1303,CoNLL,O
1303,2017,O
1303,Shared,O
1303,Task,O
1303,(,O
1303,i.e.,O
1304,The,O
1304,code,O
1304,is,O
1304,released,O
1304,at,O
1304,:,O
1304,https,B
1304,:,O
1304,//github.com/bplank/bilstm-aux,O
1305,epochs,O
1305,",",O
1305,default,B
1305,learning,I
1305,rate,I
1305,(,O
1305,0.1,B
1305,),O
1305,",",O
1305,128,B
1305,dimensions,I
1305,for,B
1305,word,B
1305,embeddings,I
1305,",",O
1305,100,B
1305,for,O
1305,character,B
1305,and,I
1305,byte,I
1305,embeddings,O
1305,",",O
1305,100,O
1305,hidden,B
1305,states,I
1305,and,O
1305,Gaussian,B
1305,noise,I
1305,with,B
1305,?=,O
1305,0.2,B
1305,.,O
1306,As,O
1306,training,B
1306,is,B
1306,stochastic,B
1306,in,O
1306,nature,O
1306,",",O
1306,we,O
1306,use,B
1306,a,O
1306,fixed,B
1306,seed,I
1306,throughout,O
1306,.,O
1307,In,O
1307,that,O
1307,case,O
1307,we,O
1307,use,B
1307,offthe,B
1307,-,I
1307,shelf,I
1307,polyglot,I
1307,embeddings,I
1307,.,O
1308,Finally,O
1308,",",O
1308,we,O
1308,introduce,B
1308,a,O
1308,novel,B
1308,model,I
1308,",",O
1308,a,O
1308,bi,B
1308,-,I
1308,LSTM,I
1308,trained,I
1308,with,I
1308,auxiliary,I
1308,loss,I
1308,.,O
1309,This,O
1309,ablation,O
1309,study,O
1309,demonstrates,B
1309,that,O
1309,both,O
1309,the,O
1309,special,B
1309,separate,I
1309,tokens,I
1309,and,I
1309,the,O
1309,hidden,O
1309,entity,O
1309,vectors,O
1309,make,B
1309,important,B
1309,contributions,I
1309,to,O
1309,our,O
1309,approach,O
1309,.,O
1310,The,O
1310,model,O
1310,jointly,B
1310,predicts,I
1310,the,O
1310,POS,B
1310,and,I
1310,the,O
1310,log,O
1310,frequency,O
1310,of,O
1310,the,O
1310,word,O
1310,.,O
1311,We,O
1311,address,O
1311,these,O
1311,issues,O
1311,and,O
1311,evaluate,O
1311,bi,O
1311,-,O
1311,LSTMs,O
1311,with,O
1311,word,O
1311,",",O
1311,character,O
1311,",",O
1311,and,O
1311,unicode,O
1311,byte,O
1311,embeddings,O
1311,for,O
1311,POS,B
1311,tagging,I
1311,.,O
1312,In,O
1312,an,O
1312,initial,O
1312,investigation,O
1312,",",O
1312,we,O
1312,compared,B
1312,Tnt,B
1312,",",O
1312,HunPos,O
1312,and,O
1312,TreeTagger,B
1312,and,O
1312,found,B
1312,Tnt,O
1312,to,B
1312,be,I
1312,consistently,B
1312,better,I
1312,than,B
1312,Treetagger,O
1312,",",O
1312,Hunpos,O
1312,followed,O
1312,closely,O
1312,but,O
1312,crashed,O
1312,on,O
1312,some,O
1312,languages,O
1312,(,O
1312,e.g.,O
1313,The,O
1313,combined,B
1313,word,I
1313,+,I
1313,character,I
1313,representation,I
1313,model,I
1313,is,B
1313,the,O
1313,best,B
1313,representation,O
1313,",",O
1313,outperforming,B
1313,the,O
1313,baseline,B
1313,on,B
1313,all,B
1313,except,I
1313,one,I
1313,language,I
1313,(,I
1313,Indonesian,I
1313,),I
1313,",",O
1313,providing,O
1313,strong,O
1313,results,O
1313,already,O
1313,without,O
1313,pre-trained,O
1313,embeddings,O
1313,.,O
1314,This,O
1314,model,O
1314,(,O
1314,w,O
1314,+,O
1314,c,O
1314,),O
1314,reaches,B
1314,the,O
1314,biggest,B
1314,improvement,I
1314,(,O
1314,more,B
1314,than,I
1314,+,O
1314,2,O
1314,%,O
1314,accuracy,O
1314,),O
1314,on,B
1314,Hebrew,B
1314,and,I
1314,Slovene,I
1314,.,O
1315,The,O
1315,over,B
1315,all,I
1315,best,I
1315,system,I
1315,is,B
1315,the,O
1315,multi-task,B
1315,bi,I
1315,-,I
1315,LSTM,I
1315,FREQBIN,I
1315,(,O
1315,it,O
1315,uses,O
1315,w,O
1315,+,O
1315,c,O
1315,and,O
1315,POLYGLOT,O
1315,initialization,O
1315,for,O
1315,w,O
1315,),O
1315,.,O
1316,Initializing,B
1316,the,I
1316,word,B
1316,embeddings,I
1316,(,I
1316,+,I
1316,POLYGLOT,I
1316,),I
1316,with,B
1316,off,B
1316,-,I
1316,the,O
1316,-,O
1316,shelf,O
1316,languagespecific,O
1316,embeddings,O
1316,further,O
1316,improves,B
1316,accuracy,B
1316,.,O
1317,Firstly,O
1317,",",O
1317,we,O
1317,use,B
1317,LSTM,B
1317,-,I
1317,CRF,I
1317,with,B
1317,randomly,B
1317,initialized,I
1317,word,I
1317,embeddings,I
1317,as,O
1317,our,O
1317,initial,O
1317,baseline,O
1317,.,O
1318,We,O
1318,adopt,B
1318,two,B
1318,state,I
1318,-,I
1318,of,I
1318,-,O
1318,the,O
1318,-,O
1318,art,O
1318,methods,O
1318,in,B
1318,sequence,B
1318,labeling,I
1318,",",O
1318,denoted,B
1318,as,I
1318,char,B
1318,-,O
1318,LSTM,O
1318,and,O
1318,char,O
1318,-,O
1318,CNN,O
1318,.,O
1319,On,O
1319,the,O
1319,other,O
1319,hand,O
1319,",",O
1319,incorporating,B
1319,the,O
1319,output,B
1319,of,B
1319,the,O
1319,target,B
1319,entity,I
1319,vectors,I
1319,further,B
1319,enriches,I
1319,the,O
1319,information,B
1319,and,O
1319,helps,O
1319,to,B
1319,make,I
1319,more,B
1319,accurate,I
1319,prediction,I
1319,.,O
1320,We,O
1320,add,B
1320,more,B
1320,layers,I
1320,to,I
1320,the,O
1320,char,O
1320,-,O
1320,CNN,O
1320,model,O
1320,and,O
1320,refer,B
1320,to,O
1320,that,O
1320,as,O
1320,char,O
1320,-,O
1320,CNN,O
1320,-,O
1320,5,B
1320,and,O
1320,char,O
1320,-,O
1320,CNN,O
1320,-,O
1320,9,O
1320,",",O
1320,respectively,O
1320,for,B
1320,5,O
1320,and,O
1320,9,O
1320,convolutional,O
1320,layers,O
1320,.,O
1321,Furthermore,O
1321,",",O
1321,we,O
1321,add,O
1321,residual,B
1321,connections,I
1321,to,B
1321,the,O
1321,char,B
1321,-,I
1321,CNN,I
1321,-,O
1321,9,O
1321,and,O
1321,refer,B
1321,it,I
1321,as,I
1321,char,O
1321,-,O
1321,ResNet,O
1321,.,O
1322,Also,O
1322,",",O
1322,we,O
1322,apply,B
1322,3,B
1322,dense,I
1322,blocks,I
1322,based,B
1322,on,I
1322,char,B
1322,-,I
1322,ResNet,I
1322,which,O
1322,we,O
1322,refer,B
1322,to,I
1322,as,I
1322,char,O
1322,-,O
1322,DenseNet,O
1322,",",O
1322,to,O
1322,compare,O
1322,the,O
1322,difference,O
1322,between,O
1322,residual,O
1322,connection,O
1322,and,O
1322,dense,O
1322,connection,O
1322,.,O
1323,The,O
1323,size,B
1323,of,B
1323,the,O
1323,dimensions,B
1323,of,O
1323,character,B
1323,embeddings,I
1323,is,B
1323,32,B
1323,which,O
1323,are,B
1323,randomly,B
1323,initialized,I
1323,using,B
1323,a,O
1323,uniform,B
1323,distribution,I
1323,.,O
1324,The,O
1324,state,B
1324,size,I
1324,of,B
1324,the,O
1324,bi-directional,B
1324,LSTMs,I
1324,is,O
1324,set,B
1324,to,I
1324,256,B
1324,.,O
1325,0.05,B
1325,is,B
1325,the,O
1325,decay,B
1325,ratio,I
1325,",",O
1325,the,O
1325,value,O
1325,of,O
1325,gradient,B
1325,clipping,I
1325,is,O
1325,5,B
1325,.,O
1326,Dropout,B
1326,is,O
1326,applied,B
1326,on,I
1326,the,O
1326,input,B
1326,of,B
1326,IntNet,B
1326,",",I
1326,LSTMs,I
1326,",",O
1326,and,O
1326,CRF,O
1326,",",O
1326,and,O
1326,its,O
1326,ratio,B
1326,0.5,B
1326,is,O
1326,fixed,O
1326,",",O
1326,but,O
1326,with,O
1326,no,O
1326,dropout,O
1326,inside,O
1326,of,O
1326,IntNet,O
1326,.,O
1327,The,O
1327,number,B
1327,of,I
1327,convolutional,I
1327,layers,I
1327,are,B
1327,5,I
1327,and,I
1327,9,I
1327,for,B
1327,IntNet,I
1327,-,I
1327,5,O
1327,and,O
1327,IntNet,O
1327,-,O
1327,9,O
1327,",",O
1327,respectively,O
1327,",",O
1327,and,O
1327,we,O
1327,have,O
1327,adopted,B
1327,the,O
1327,same,B
1327,weight,I
1327,initialization,I
1327,as,B
1327,that,O
1327,of,O
1327,ResNet,B
1327,.,O
1328,We,O
1328,adopt,B
1328,the,O
1328,same,B
1328,initialization,I
1328,method,I
1328,for,B
1328,randomly,B
1328,initialized,I
1328,word,I
1328,embeddings,I
1328,that,O
1328,are,O
1328,updated,B
1328,during,I
1328,training,B
1328,.,O
1329,We,O
1329,adopt,O
1329,standard,B
1329,BIOES,I
1329,tagging,I
1329,scheme,I
1329,for,B
1329,NER,B
1329,and,I
1329,Chunking,I
1329,.,O
1330,We,O
1330,compare,O
1330,our,O
1330,method,O
1330,",",O
1330,R,O
1330,-,O
1330,BERT,O
1330,",",O
1330,against,O
1330,results,O
1330,by,O
1330,multiple,O
1330,methods,O
1330,recently,O
1330,published,O
1330,for,O
1330,the,O
1330,SemEval,O
1330,-,O
1330,2010,O
1330,Task,O
1330,8,O
1330,dataset,O
1330,",",O
1330,including,O
1330,SVM,B
1330,",",O
1330,RNN,B
1330,",",O
1330,MVRNN,B
1330,",",O
1330,CNN,O
1330,+,O
1330,Softmax,O
1330,",",O
1330,FCM,B
1330,",",O
1330,CR,B
1330,-,O
1330,CNN,O
1330,",",O
1330,Attention,O
1330,-,O
1330,CNN,O
1330,",",O
1330,Entity,B
1330,Attention,O
1330,Bi-LSTM,O
1330,.,O
1331,For,B
1331,IntNet,B
1331,",",O
1331,the,O
1331,filter,B
1331,size,I
1331,of,B
1331,the,O
1331,initial,B
1331,convolution,I
1331,is,B
1331,32,B
1331,and,O
1331,that,O
1331,of,O
1331,other,B
1331,convolutions,I
1331,is,O
1331,16,B
1331,.,O
1332,We,O
1332,use,B
1332,pre-trained,B
1332,word,I
1332,embeddings,I
1332,for,B
1332,initialization,B
1332,",",I
1332,GloVe,B
1332,100,I
1332,-,I
1332,dimension,I
1332,word,O
1332,embeddings,O
1332,for,O
1332,English,B
1332,",",O
1332,and,O
1332,fastText,B
1332,300,I
1332,dimension,O
1332,word,O
1332,embeddings,O
1332,for,O
1332,Spanish,B
1332,",",O
1332,Dutch,O
1332,",",O
1332,and,O
1332,German,O
1332,.,O
1333,We,O
1333,employ,B
1333,mini-batch,B
1333,stochastic,I
1333,gradient,I
1333,descent,I
1333,with,B
1333,momentum,B
1333,.,O
1334,Furthermore,O
1334,",",O
1334,we,O
1334,propose,B
1334,IntNet,B
1334,",",O
1334,a,O
1334,funnel,B
1334,-,I
1334,shaped,I
1334,wide,I
1334,convolutional,I
1334,neural,I
1334,network,I
1334,for,B
1334,learning,I
1334,the,O
1334,internal,B
1334,structure,I
1334,of,I
1334,words,I
1334,by,B
1334,composing,I
1334,their,O
1334,characters,B
1334,.,O
1335,Unlike,O
1335,previous,O
1335,CNN,O
1335,-,O
1335,based,O
1335,approaches,O
1335,",",O
1335,our,O
1335,funnel,B
1335,-,O
1335,shaped,O
1335,Int,O
1335,-,O
1335,Net,O
1335,explores,B
1335,deeper,B
1335,and,I
1335,wider,I
1335,architecture,I
1335,with,B
1335,no,I
1335,down,B
1335,-,O
1335,sampling,O
1335,for,B
1335,learning,I
1335,character,B
1335,-,O
1335,to,O
1335,-,O
1335,word,O
1335,representations,O
1335,from,B
1335,limited,B
1335,supervised,I
1335,training,I
1335,corpora,I
1335,.,O
1336,Lastly,O
1336,",",O
1336,we,O
1336,combine,B
1336,our,O
1336,IntNet,B
1336,model,I
1336,with,B
1336,LSTM,B
1336,-,I
1336,CRF,I
1336,",",O
1336,which,O
1336,captures,B
1336,both,O
1336,word,B
1336,shape,I
1336,and,O
1336,context,B
1336,information,I
1336,",",O
1336,and,O
1336,jointly,B
1336,decode,I
1336,tags,B
1336,for,B
1336,sequence,B
1336,labeling,I
1336,.,O
1337,Learning,O
1337,Better,O
1337,Internal,O
1337,Structure,O
1337,of,O
1337,Words,O
1337,for,O
1337,Sequence,B
1337,Labeling,I
1338,5,O
1338,Results,O
1338,and,O
1338,Analysis,O
1338,5.1,O
1338,Character,B
1338,-,I
1338,to,I
1338,-,O
1338,word,O
1338,Models,O
1338,presents,O
1338,the,O
1338,performance,O
1338,of,O
1338,different,O
1338,character,O
1338,-,O
1338,to,O
1338,-,O
1338,word,O
1338,models,O
1338,on,O
1338,six,O
1338,benchmark,O
1338,datasets,O
1338,.,O
1339,The,O
1339,result,O
1339,shows,O
1339,that,O
1339,for,O
1339,most,O
1339,of,O
1339,the,O
1339,datasets,O
1339,",",O
1339,the,O
1339,F1,B
1339,score,I
1339,does,B
1339,not,I
1339,improve,B
1339,much,I
1339,when,B
1339,we,O
1339,directly,B
1339,add,I
1339,more,B
1339,layers,I
1339,.,O
1340,Our,O
1340,proposed,B
1340,character,I
1340,-,I
1340,to,I
1340,-,O
1340,word,O
1340,model,O
1340,",",O
1340,char,O
1340,-,O
1340,IntNet,O
1340,-,O
1340,5,O
1340,and,O
1340,char,O
1340,-,O
1340,IntNet,O
1340,-,O
1340,9,O
1340,generally,O
1340,improves,B
1340,the,O
1340,results,B
1340,across,B
1340,all,B
1340,datasets,I
1340,.,O
1341,We,O
1341,add,O
1341,dropout,B
1341,before,B
1341,each,B
1341,add,O
1341,-,O
1341,on,O
1341,layer,O
1341,.,O
1342,Our,O
1342,IntNet,B
1342,significantly,B
1342,outperforms,I
1342,other,B
1342,character,I
1342,embedding,I
1342,models,I
1342,",",O
1342,for,O
1342,example,O
1342,",",O
1342,the,O
1342,improvement,O
1342,is,O
1342,more,O
1342,than,O
1342,2,O
1342,%,O
1342,in,O
1342,terms,O
1342,of,O
1342,F,O
1342,1,O
1342,score,O
1342,for,O
1342,German,O
1342,and,O
1342,Dutch,O
1342,.,O
1343,We,O
1343,also,O
1343,observe,B
1343,some,B
1343,accuracy,I
1343,drop,I
1343,when,B
1343,we,O
1343,continuously,B
1343,increase,I
1343,the,O
1343,depth,B
1343,.,O
1344,Also,O
1344,",",O
1344,we,O
1344,observe,O
1344,that,O
1344,char,B
1344,-,I
1344,IntNet,I
1344,-,O
1344,5,O
1344,is,B
1344,more,B
1344,effective,I
1344,for,B
1344,learning,I
1344,character,B
1344,-,O
1344,to,O
1344,-,O
1344,word,O
1344,representations,O
1344,than,B
1344,char,O
1344,-,O
1344,IntNet,O
1344,-,O
1344,9,O
1344,in,B
1344,most,B
1344,of,I
1344,the,I
1344,cases,I
1344,.,O
1345,Furthermore,O
1345,",",O
1345,we,O
1345,add,B
1345,residual,B
1345,connections,I
1345,to,B
1345,char,B
1345,-,I
1345,CNN,I
1345,-,O
1345,9,O
1345,as,B
1345,char,O
1345,-,O
1345,ResNet,O
1345,-,O
1345,9,O
1345,",",O
1345,which,O
1345,confirms,B
1345,that,I
1345,residual,O
1345,connections,O
1345,can,O
1345,help,B
1345,train,I
1345,deep,B
1345,layers,I
1345,.,O
1346,We,O
1346,further,O
1346,improve,B
1346,char,B
1346,-,I
1346,ResNet,I
1346,-,O
1346,9,O
1346,by,B
1346,changing,I
1346,residual,B
1346,connections,I
1346,into,B
1346,dense,B
1346,connection,I
1346,blocks,I
1346,as,B
1346,char,O
1346,-,O
1346,DenseNet,O
1346,-,O
1346,9,O
1346,",",O
1346,which,O
1346,shows,B
1346,that,I
1346,the,O
1346,dense,O
1346,connections,O
1346,are,B
1346,better,B
1346,than,B
1346,residual,O
1346,connections,O
1346,for,B
1346,learning,I
1346,word,B
1346,shape,I
1346,information,I
1346,.,O
1347,The,O
1347,improvement,O
1347,is,O
1347,more,O
1347,pronounced,O
1347,for,B
1347,non-English,O
1347,datasets,O
1347,",",O
1347,for,O
1347,example,O
1347,",",O
1347,IntNet,B
1347,improves,B
1347,the,O
1347,F,B
1347,-,I
1347,1,I
1347,score,I
1347,over,B
1347,the,O
1347,stateof,B
1347,-,O
1347,the,O
1347,-,O
1347,art,O
1347,results,O
1347,by,B
1347,more,O
1347,than,O
1347,2,B
1347,%,I
1347,for,O
1347,Dutch,B
1347,and,I
1347,Spanish,I
1347,.,O
1348,Table,O
1348,2,O
1348,presents,O
1348,our,O
1348,proposed,O
1348,model,O
1348,in,B
1348,comparison,I
1348,with,I
1348,state,B
1348,-,I
1348,of,I
1348,-,O
1348,the,O
1348,-,O
1348,art,O
1348,results,O
1348,.,O
1349,These,O
1349,experiments,O
1349,show,B
1349,that,I
1349,our,B
1349,char,I
1349,-,I
1349,IntNet,I
1349,generally,O
1349,improves,B
1349,results,B
1349,across,B
1349,different,B
1349,models,I
1349,and,I
1349,datasets,I
1349,.,O
1350,It,O
1350,also,O
1350,shows,B
1350,that,I
1350,the,O
1350,results,B
1350,of,B
1350,LSTM,B
1350,-,I
1350,CRF,I
1350,are,B
1350,significantly,B
1350,improved,I
1350,after,B
1350,adding,I
1350,character,B
1350,-,O
1350,to,O
1350,-,O
1350,word,O
1350,models,O
1350,",",O
1350,which,O
1350,confirms,O
1350,that,O
1350,word,O
1350,shape,O
1350,information,O
1350,is,O
1350,very,O
1350,important,O
1350,for,O
1350,sequence,O
1350,labeling,O
1350,.,O
1351,We,O
1351,present,B
1351,a,O
1351,transfer,B
1351,learning,I
1351,approach,I
1351,based,B
1351,on,I
1351,a,O
1351,deep,B
1351,hierarchical,I
1351,recurrent,I
1351,neural,I
1351,network,I
1351,",",O
1351,which,O
1351,shares,B
1351,the,I
1351,hidden,B
1351,feature,I
1351,repre-sentation,I
1351,and,I
1351,part,B
1351,of,I
1351,the,O
1351,model,O
1351,parameters,O
1351,between,B
1351,the,O
1351,source,B
1351,task,I
1351,and,O
1351,the,O
1351,target,O
1351,task,O
1351,.,O
1352,For,B
1352,the,O
1352,pre-trained,B
1352,BERT,I
1352,model,I
1352,",",O
1352,we,O
1352,use,B
1352,the,O
1352,uncased,B
1352,basic,I
1352,model,O
1352,.,O
1353,Our,O
1353,approach,O
1353,combines,O
1353,the,O
1353,objectives,O
1353,of,O
1353,the,O
1353,two,O
1353,tasks,O
1353,and,O
1353,uses,B
1353,gradient,B
1353,-,I
1353,based,I
1353,methods,I
1353,for,B
1353,efficient,B
1353,training,I
1353,.,O
1354,1,O
1354,Code,O
1354,is,O
1354,available,O
1354,at,O
1354,https://github.com/kimiyoung/transfer,B
1354,1,O
1354,ar,O
1354,Xiv:1703.06345v1,O
1354,[,O
1354,cs.CL,O
1354,],O
1355,We,O
1355,fix,O
1355,the,O
1355,hyperparameters,O
1355,for,B
1355,all,O
1355,the,O
1355,results,O
1355,reported,O
1355,in,O
1355,this,O
1355,section,O
1355,:,O
1355,we,O
1355,set,B
1355,the,O
1355,character,B
1355,embedding,I
1355,dimension,B
1355,at,B
1355,25,B
1355,",",O
1355,the,O
1355,word,B
1355,embedding,O
1355,dimension,O
1355,at,O
1355,50,B
1355,for,O
1355,English,B
1355,and,O
1355,64,B
1355,for,O
1355,Spanish,B
1355,",",O
1355,the,O
1355,dimension,O
1355,of,B
1355,hidden,B
1355,states,I
1355,of,O
1355,the,O
1355,character,O
1355,-,O
1355,level,O
1355,GRUs,O
1355,at,O
1355,80,B
1355,",",O
1355,the,O
1355,dimension,O
1355,of,O
1355,hidden,O
1355,states,O
1355,of,O
1355,the,O
1355,word,O
1355,-,O
1355,level,O
1355,GRUs,O
1355,at,O
1355,300,B
1355,",",O
1355,and,O
1355,the,O
1355,initial,B
1355,learning,I
1355,rate,I
1355,at,O
1355,0.01,B
1355,.,O
1356,As,O
1356,shown,O
1356,in,O
1356,and,O
1356,2,O
1356,(,O
1356,e,O
1356,),O
1356,",",O
1356,our,B
1356,transfer,I
1356,learning,I
1356,approach,I
1356,can,O
1356,improve,B
1356,the,I
1356,performance,I
1356,on,B
1356,Twitter,B
1356,POS,I
1356,tagging,I
1356,and,O
1356,NER,O
1356,for,B
1356,all,B
1356,labeling,I
1356,rates,I
1356,",",O
1356,and,O
1356,the,O
1356,improvements,B
1356,with,B
1356,0.1,B
1356,labels,I
1356,are,B
1356,more,B
1356,than,I
1356,8,I
1356,%,I
1356,for,O
1356,both,B
1356,datasets,I
1356,.,O
1357,Cross,O
1357,-,O
1357,application,O
1357,transfer,O
1357,also,O
1357,leads,B
1357,to,I
1357,substantial,B
1357,improvement,I
1357,under,B
1357,low,B
1357,-,O
1357,resource,O
1357,conditions,O
1357,.,O
1358,We,O
1358,can,O
1358,see,B
1358,that,I
1358,our,O
1358,transfer,B
1358,learning,I
1358,approach,I
1358,consistently,B
1358,improved,I
1358,over,B
1358,the,O
1358,non-transfer,B
1358,results,I
1358,.,O
1359,We,O
1359,also,O
1359,observe,B
1359,that,I
1359,the,O
1359,improvement,B
1359,by,B
1359,transfer,B
1359,learning,I
1359,is,B
1359,more,B
1359,substantial,I
1359,when,B
1359,the,O
1359,labeling,B
1359,rate,I
1359,is,O
1359,lower,B
1359,.,O
1360,We,O
1360,use,B
1360,publicly,B
1360,available,I
1360,pretrained,I
1360,word,I
1360,embeddings,I
1360,as,B
1360,initialization,B
1360,.,O
1361,In,O
1361,this,O
1361,paper,O
1361,",",O
1361,we,O
1361,apply,B
1361,the,O
1361,pretrained,B
1361,BERT,I
1361,model,I
1361,for,B
1361,relation,B
1361,classification,I
1361,.,O
1362,On,B
1362,the,O
1362,English,B
1362,datasets,I
1362,",",O
1362,following,O
1362,previous,O
1362,works,O
1362,that,O
1362,are,O
1362,based,O
1362,on,O
1362,neural,O
1362,networks,O
1362,",",O
1362,we,O
1362,experiment,B
1362,with,I
1362,both,O
1362,the,O
1362,50,B
1362,-,I
1362,dimensional,I
1362,SENNA,I
1362,embeddings,B
1362,and,I
1362,the,O
1362,100,B
1362,-,O
1362,dimensional,O
1362,GloVe,O
1362,embeddings,O
1362,and,O
1362,use,B
1362,the,O
1362,development,B
1362,set,I
1362,to,B
1362,choose,I
1362,the,O
1362,embeddings,O
1362,for,B
1362,different,B
1362,tasks,I
1362,and,O
1362,settings,O
1362,.,O
1363,For,B
1363,Spanish,B
1363,and,I
1363,Dutch,I
1363,",",O
1363,we,O
1363,use,B
1363,the,O
1363,64,B
1363,-,I
1363,dimensional,I
1363,Polyglot,I
1363,embeddings,I
1363,.,O
1364,We,O
1364,set,B
1364,the,O
1364,hidden,B
1364,state,I
1364,dimensions,I
1364,to,B
1364,be,I
1364,300,B
1364,for,B
1364,the,O
1364,word,B
1364,-,I
1364,level,I
1364,GRU,I
1364,.,O
1365,The,O
1365,initial,B
1365,learning,I
1365,rate,I
1365,for,B
1365,AdaGrad,B
1365,is,O
1365,fixed,B
1365,at,I
1365,0.01,B
1365,.,O
1366,First,O
1366,",",O
1366,our,O
1366,transfer,B
1366,learning,I
1366,approach,I
1366,achieves,B
1366,new,B
1366,state,I
1366,-,I
1366,of,I
1366,-,O
1366,the,O
1366,-,O
1366,art,O
1366,results,O
1366,on,B
1366,all,B
1366,the,O
1366,considered,O
1366,benchmark,O
1366,datasets,O
1366,except,O
1366,PTB,O
1366,POS,O
1366,tagging,O
1366,",",O
1366,which,O
1366,indicates,O
1366,that,O
1366,transfer,O
1366,learning,O
1366,can,O
1366,still,O
1366,improve,O
1366,the,O
1366,performance,O
1366,even,O
1366,on,O
1366,datasets,O
1366,with,O
1366,relatively,O
1366,abundant,O
1366,labels,O
1366,.,O
1367,Second,O
1367,",",O
1367,our,B
1367,base,I
1367,model,I
1367,(,I
1367,w/o,I
1367,transfer,I
1367,),I
1367,performs,B
1367,competitively,B
1367,compared,B
1367,to,I
1367,the,I
1367,state,B
1367,-,I
1367,of,I
1367,-,O
1367,the,O
1367,-,O
1367,art,O
1367,systems,O
1367,",",O
1367,which,O
1367,means,O
1367,that,O
1367,the,O
1367,improvements,O
1367,shown,O
1367,in,O
1367,Section,O
1367,4.2,O
1367,are,O
1367,obtained,O
1367,over,O
1367,a,O
1367,strong,O
1367,baseline,O
1367,.,O
1368,TRANSFER,O
1368,LEARNING,O
1368,FOR,O
1368,SEQUENCE,B
1368,TAGGING,I
1368,WITH,O
1368,HIERARCHICAL,O
1368,RECURRENT,O
1368,NETWORKS,O
1369,We,O
1369,compare,O
1369,the,O
1369,performance,O
1369,with,O
1369,three,B
1369,baseline,I
1369,systems,I
1369,-,I
1369,BRNN,B
1369,",",I
1369,the,O
1369,bi-direction,O
1369,RNN,O
1369,;,O
1369,BLSTM,O
1369,",",O
1369,the,O
1369,bidirection,O
1369,LSTM,O
1369,",",O
1369,and,O
1369,BLSTM,O
1369,-,O
1369,CNNs,O
1369,",",O
1369,the,O
1369,combination,O
1369,of,O
1369,BLSTM,O
1369,with,O
1369,CNN,O
1369,to,B
1369,model,I
1369,characterlevel,B
1369,information,I
1369,.,O
1370,Parameter,O
1370,optimization,O
1370,is,O
1370,performed,B
1370,with,B
1370,minibatch,B
1370,stochastic,I
1370,gradient,I
1370,descent,I
1370,(,I
1370,SGD,I
1370,),I
1370,with,O
1370,batch,B
1370,size,I
1370,10,B
1370,and,O
1370,momentum,B
1370,0.9,B
1370,.,O
1371,The,O
1371,"""",O
1371,best,O
1371,"""",O
1371,parameters,O
1371,appear,B
1371,at,I
1371,around,B
1371,50,I
1371,epochs,I
1371,",",O
1371,according,O
1371,to,O
1371,our,O
1371,experiments,O
1371,.,O
1372,We,O
1372,insert,B
1372,special,B
1372,tokens,I
1372,before,B
1372,and,I
1372,after,I
1372,the,O
1372,target,O
1372,entities,O
1372,before,O
1372,feeding,O
1372,the,O
1372,text,B
1372,to,B
1372,BERT,B
1372,for,B
1372,fine,B
1372,-,I
1372,tuning,I
1372,",",O
1372,in,O
1372,order,O
1372,to,O
1372,identify,O
1372,the,O
1372,locations,B
1372,of,B
1372,the,O
1372,two,B
1372,target,O
1372,entities,O
1372,and,O
1372,transfer,B
1372,the,O
1372,information,B
1372,into,B
1372,the,O
1372,BERT,O
1372,model,O
1372,.,O
1373,We,O
1373,choose,B
1373,an,O
1373,initial,B
1373,learning,I
1373,rate,I
1373,of,B
1373,?,O
1374,0,O
1374,=,O
1374,0.01,B
1374,for,B
1374,POS,B
1374,tagging,I
1374,",",O
1374,and,O
1374,0.015,B
1374,for,O
1374,NER,B
1374,",",O
1374,see,O
1374,Section,O
1374,3.3,O
1374,.,O
1374,),O
1375,",",O
1375,and,O
1375,the,O
1375,learning,O
1375,rate,O
1375,is,O
1375,updated,B
1375,on,I
1375,each,B
1375,epoch,I
1375,of,B
1375,training,B
1375,as,O
1375,?,O
1376,To,O
1376,reduce,B
1376,the,O
1376,effects,B
1376,of,B
1376,"""",O
1376,gradient,B
1376,exploding,I
1376,"""",O
1376,",",O
1376,we,O
1376,use,B
1376,a,O
1376,gradient,O
1376,clipping,O
1376,of,O
1376,5.0,B
1376,.,O
1377,We,O
1377,use,B
1377,early,B
1377,stopping,I
1377,based,B
1377,on,B
1377,performance,B
1377,on,O
1377,validation,B
1377,sets,I
1377,.,O
1378,For,O
1378,each,O
1378,of,B
1378,the,O
1378,embeddings,O
1378,",",O
1378,we,O
1378,fine,B
1378,-,I
1378,tune,I
1378,initial,B
1378,embeddings,O
1378,",",O
1378,modifying,B
1378,them,I
1378,during,I
1378,gradient,B
1378,updates,I
1378,of,O
1378,the,O
1378,neural,B
1378,network,I
1378,model,I
1378,by,B
1378,back,B
1378,-,O
1378,propagating,O
1378,gradients,O
1378,.,O
1379,To,O
1379,mitigate,O
1379,overfitting,B
1379,",",O
1379,we,O
1379,apply,B
1379,the,O
1379,dropout,B
1379,method,I
1379,(,O
1379,Srivastava,O
1379,et,O
1379,al.,O
1380,",",O
1380,2014,O
1380,),O
1380,to,B
1380,regularize,I
1380,our,O
1380,model,B
1380,.,O
1381,As,O
1381,shown,O
1381,in,O
1381,and,O
1381,3,O
1381,",",O
1381,we,O
1381,apply,B
1381,dropout,B
1381,on,B
1381,character,B
1381,embeddings,I
1381,before,B
1381,inputting,I
1381,to,I
1381,CNN,B
1381,",",O
1381,and,O
1381,on,O
1381,both,O
1381,the,O
1381,input,B
1381,and,O
1381,output,O
1381,vectors,O
1381,of,B
1381,BLSTM,B
1381,.,O
1382,We,O
1382,fix,B
1382,dropout,I
1382,rate,I
1382,at,B
1382,0.5,B
1382,for,B
1382,all,B
1382,dropout,O
1382,layers,O
1382,through,O
1382,all,O
1382,the,O
1382,experiments,O
1382,.,O
1383,In,O
1383,this,O
1383,paper,O
1383,",",O
1383,we,O
1383,propose,B
1383,a,O
1383,neural,B
1383,network,I
1383,architecture,I
1383,for,B
1383,sequence,B
1383,labeling,I
1383,.,O
1384,It,O
1384,is,B
1384,a,O
1384,truly,O
1384,endto,B
1384,-,I
1384,end,I
1384,model,I
1384,requiring,B
1384,no,I
1384,task,B
1384,-,O
1384,specific,O
1384,resources,O
1384,",",O
1384,feature,B
1384,engineering,I
1384,",",O
1384,or,O
1384,data,B
1384,pre-processing,I
1384,beyond,B
1384,pre-trained,B
1384,word,I
1384,embeddings,I
1384,on,B
1384,unlabeled,B
1384,corpora,I
1384,.,O
1385,Thus,O
1385,",",O
1385,our,O
1385,model,O
1385,can,O
1385,be,O
1385,easily,B
1385,applied,I
1385,to,I
1385,a,O
1385,wide,B
1385,range,I
1385,of,B
1385,sequence,B
1385,labeling,I
1385,tasks,I
1385,on,B
1385,different,B
1385,languages,I
1385,and,I
1385,domains,I
1385,.,O
1386,The,O
1386,higher,B
1386,performance,I
1386,of,B
1386,BGWA,B
1386,and,I
1386,PCNN,B
1386,+,I
1386,ATT,I
1386,over,B
1386,PCNN,O
1386,shows,B
1386,that,I
1386,attention,B
1386,helps,B
1386,in,I
1386,distant,B
1386,supervised,I
1386,RE,I
1386,.,O
1387,We,O
1387,then,O
1387,locate,B
1387,the,O
1387,positions,B
1387,of,B
1387,the,O
1387,two,B
1387,target,I
1387,entities,I
1387,in,B
1387,the,O
1387,output,B
1387,embedding,I
1387,from,B
1387,BERT,B
1387,model,I
1387,.,O
1388,We,O
1388,first,B
1388,use,I
1388,convolutional,B
1388,neural,I
1388,networks,I
1388,(,I
1388,CNNs,I
1388,),I
1388,to,B
1388,encode,I
1388,character,I
1388,-,I
1388,level,I
1388,information,I
1388,of,B
1388,a,B
1388,word,I
1388,into,B
1388,its,B
1388,character,O
1388,-,O
1388,level,O
1388,representation,O
1388,.,O
1389,Then,O
1389,we,O
1389,combine,B
1389,character,B
1389,-,I
1389,and,I
1389,word,I
1389,-,O
1389,level,O
1389,representations,O
1389,and,O
1389,feed,B
1389,them,I
1389,into,I
1389,bi-directional,B
1389,LSTM,I
1389,(,I
1389,BLSTM,I
1389,),I
1389,to,B
1389,model,I
1389,context,B
1389,information,I
1389,of,B
1389,each,B
1389,word,O
1389,.,O
1390,On,O
1390,top,O
1390,of,O
1390,BLSTM,B
1390,",",O
1390,we,O
1390,use,B
1390,a,O
1390,sequential,B
1390,CRF,I
1390,to,B
1390,jointly,I
1390,decode,I
1390,labels,B
1390,for,B
1390,the,O
1390,whole,B
1390,sentence,I
1390,.,O
1391,State,O
1391,-,O
1391,of,O
1391,-,O
1391,the,O
1391,-,O
1391,art,O
1391,sequence,B
1391,labeling,I
1391,systems,O
1391,traditionally,O
1391,require,O
1391,large,O
1391,amounts,O
1391,of,O
1391,taskspecific,O
1391,knowledge,O
1391,in,O
1391,the,O
1391,form,O
1391,of,O
1391,handcrafted,O
1391,features,O
1391,and,O
1391,data,O
1391,pre-processing,O
1391,.,O
1392,Finally,O
1392,",",O
1392,by,O
1392,adding,B
1392,CRF,B
1392,layer,I
1392,for,B
1392,joint,B
1392,decoding,I
1392,we,O
1392,achieve,B
1392,significant,B
1392,improvements,I
1392,over,B
1392,BLSTM,B
1392,-,I
1392,CNN,I
1392,models,I
1392,for,O
1392,both,O
1392,POS,B
1392,tagging,I
1392,and,I
1392,NER,I
1392,on,O
1392,all,O
1392,metrics,O
1392,.,O
1393,Comparing,O
1393,with,O
1393,traditional,B
1393,statistical,I
1393,models,I
1393,",",O
1393,our,B
1393,system,I
1393,achieves,B
1393,state,B
1393,-,I
1393,of,I
1393,-,O
1393,the,O
1393,-,O
1393,art,O
1393,accuracy,O
1393,",",O
1393,obtaining,B
1393,0.05,B
1393,%,I
1393,improvement,I
1393,over,B
1393,the,O
1393,previously,B
1393,best,I
1393,reported,I
1393,results,I
1393,by,O
1393,.,O
1394,Similar,O
1394,to,O
1394,the,O
1394,observations,O
1394,of,O
1394,POS,O
1394,tagging,O
1394,",",O
1394,our,B
1394,model,I
1394,achieves,B
1394,significant,B
1394,improvements,I
1394,over,B
1394,Senna,B
1394,and,O
1394,the,O
1394,other,B
1394,three,I
1394,neural,I
1394,models,I
1394,",",O
1394,namely,O
1394,the,O
1394,LSTM,O
1394,-,O
1394,CRF,O
1394,proposed,O
1394,by,O
1394,",",O
1394,LSTM,O
1394,-,O
1394,CNNs,O
1394,pro-,O
1394,:,O
1395,To,O
1395,this,O
1395,question,O
1395,",",O
1395,we,O
1395,investigate,B
1395,a,O
1395,neural,B
1395,network,I
1395,model,I
1395,for,B
1395,output,B
1395,label,I
1395,sequences,I
1395,.,O
1396,We,O
1396,use,B
1396,their,O
1396,embeddings,B
1396,as,B
1396,well,O
1396,as,O
1396,the,O
1396,sentence,B
1396,encoding,I
1396,(,O
1396,embedding,B
1396,of,I
1396,the,O
1396,special,B
1396,first,I
1396,token,I
1396,in,B
1396,the,O
1396,setting,O
1396,of,O
1396,BERT,B
1396,),O
1396,as,O
1396,the,O
1396,input,O
1396,to,O
1396,a,O
1396,multi,B
1396,-,I
1396,layer,I
1396,neural,I
1396,network,I
1396,for,B
1396,classification,B
1396,.,O
1397,This,O
1397,makes,O
1397,our,O
1397,task,O
1397,essentially,O
1397,to,O
1397,represent,B
1397,a,O
1397,full,B
1397,-,I
1397,exponential,I
1397,search,I
1397,space,I
1397,without,B
1397,making,I
1397,Markov,B
1397,assumptions,I
1397,.,O
1398,In,O
1398,particular,O
1398,",",O
1398,we,O
1398,represent,O
1398,each,B
1398,possible,I
1398,label,B
1398,using,B
1398,an,O
1398,embedding,B
1398,vector,I
1398,",",O
1398,and,O
1398,aim,B
1398,to,I
1398,encode,I
1398,sequences,B
1398,of,B
1398,label,O
1398,distributions,O
1398,using,O
1398,a,O
1398,recurrent,B
1398,neural,I
1398,network,I
1398,.,O
1399,Hierarchically,O
1399,-,O
1399,Refined,O
1399,Label,O
1399,Attention,O
1399,Network,O
1399,for,O
1399,Sequence,B
1399,Labeling,I
1400,CRF,O
1400,has,O
1400,been,O
1400,used,O
1400,as,O
1400,a,O
1400,powerful,O
1400,model,O
1400,for,O
1400,statistical,B
1400,sequence,I
1400,labeling,I
1400,.,O
1401,WSJ,B
1401,.,O
1402,shows,O
1402,the,O
1402,final,O
1402,POS,O
1402,tagging,O
1402,results,O
1402,on,O
1402,WSJ,B
1402,.,O
1403,BiLSTM,O
1403,-,O
1403,LAN,O
1403,gives,B
1403,significant,B
1403,accuracy,I
1403,improvements,I
1403,over,B
1403,both,O
1403,BiLSTM,O
1403,-,O
1403,CRF,O
1403,and,O
1403,BiLSTM-,B
1403,softmax,I
1403,(,O
1403,p,O
1403,<,O
1403,0.01,O
1403,),O
1403,",",O
1403,which,O
1403,is,O
1403,consistent,O
1403,with,O
1403,observations,O
1403,on,O
1403,development,O
1403,experiments,O
1403,.,O
1404,We,O
1404,design,O
1404,a,O
1404,multilingual,O
1404,experiment,O
1404,to,O
1404,compare,O
1404,BiLSTMsoftmax,O
1404,",",O
1404,BiLSTM,O
1404,-,O
1404,CRF,O
1404,(,O
1404,strictly,O
1404,following,O
1404,1,O
1404,",",O
1404,which,O
1404,is,O
1404,the,O
1404,state,O
1404,-,O
1404,of,O
1404,-,O
1404,theart,O
1404,on,B
1404,multi-lingual,O
1404,POS,O
1404,tagging,O
1404,),O
1404,and,O
1404,BiLSTM,O
1404,-,O
1404,LAN,O
1404,.,O
1405,Our,O
1405,model,O
1405,outperforms,B
1405,all,B
1405,the,I
1405,baselines,I
1405,on,O
1405,all,O
1405,the,O
1405,languages,O
1405,.,O
1406,The,O
1406,improvements,B
1406,are,B
1406,statistically,B
1406,significant,I
1406,for,B
1406,all,B
1406,the,O
1406,languages,B
1406,(,I
1406,p,I
1406,<,I
1406,0.01,I
1406,),I
1406,",",O
1406,suggesting,B
1406,that,I
1406,BiLSTM,B
1406,-,I
1406,LAN,I
1406,is,B
1406,generally,B
1406,effective,I
1406,across,B
1406,languages,O
1406,.,O
1407,In,O
1407,NER,O
1407,",",O
1407,BiLSTM,B
1407,-,I
1407,CRF,I
1407,is,O
1407,widely,O
1407,used,O
1407,",",O
1407,because,O
1407,local,O
1407,dependencies,O
1407,between,O
1407,neighboring,O
1407,labels,O
1407,relatively,O
1407,more,O
1407,important,O
1407,that,O
1407,POS,O
1407,tagging,O
1407,and,O
1407,CCG,O
1407,supertagging,O
1407,.,O
1408,Enriching,O
1408,Pre-trained,O
1408,Language,O
1408,Model,O
1408,with,O
1408,Entity,O
1408,Information,O
1408,for,O
1408,Relation,B
1408,Classification,I
1409,BiLSTM,O
1409,-,O
1409,LAN,O
1409,also,O
1409,significantly,B
1409,outperforms,I
1409,BiLSTM,O
1409,-,O
1409,CRF,O
1409,by,B
1409,1.17,B
1409,F1-score,I
1409,(,O
1409,p,O
1409,<,O
1409,0.01,O
1409,),O
1409,.,O
1410,As,O
1410,shown,O
1410,in,O
1410,",",O
1410,BiLSTM,O
1410,-,O
1410,LAN,B
1410,significantly,O
1410,outperforms,O
1410,both,B
1410,BiLSTMsoftmax,B
1410,and,I
1410,BiLSTM,O
1410,-,O
1410,CRF,O
1410,(,O
1410,p,O
1410,<,O
1410,0.01,O
1410,),O
1410,",",O
1410,showing,B
1410,the,O
1410,advantage,B
1410,of,B
1410,LAN,O
1410,.,O
1411,Compared,O
1411,with,O
1411,these,O
1411,methods,O
1411,",",O
1411,BiLSTM,O
1411,-,O
1411,LAN,O
1411,obtains,B
1411,new,B
1411,state,I
1411,-,O
1411,of,O
1411,-,O
1411,theart,O
1411,results,O
1411,on,B
1411,CCGBank,B
1411,",",O
1411,matching,O
1411,the,O
1411,tri-training,O
1411,performance,O
1411,of,O
1411,",",O
1411,without,O
1411,training,O
1411,on,O
1411,external,O
1411,data,O
1411,.,O
1412,In,O
1412,this,O
1412,paper,O
1412,",",O
1412,we,O
1412,explore,B
1412,an,O
1412,alternative,B
1412,approach,I
1412,based,B
1412,on,I
1412,enriching,B
1412,the,O
1412,document,B
1412,representation,I
1412,(,O
1412,prior,O
1412,to,O
1412,indexing,O
1412,),O
1412,.,O
1413,Focusing,O
1413,on,O
1413,question,B
1413,answering,I
1413,",",O
1413,we,O
1413,train,B
1413,a,O
1413,sequence,O
1413,-,O
1413,to,O
1413,-,O
1413,sequence,O
1413,model,O
1413,",",O
1413,that,B
1413,given,B
1413,a,O
1413,document,B
1413,",",O
1413,generates,B
1413,possible,B
1413,questions,I
1413,that,O
1413,the,O
1413,document,O
1413,might,B
1413,answer,B
1413,.,O
1414,BM25,B
1414,:,O
1414,We,O
1414,use,B
1414,the,O
1414,Anserini,B
1414,open,I
1414,-,I
1414,source,I
1414,IR,I
1414,toolkit,I
1414,3,O
1414,to,B
1414,index,I
1414,the,O
1414,original,B
1414,(,I
1414,non,I
1414,-expanded,I
1414,),I
1414,documents,I
1414,and,O
1414,BM25,O
1414,to,O
1414,rank,O
1414,the,O
1414,passages,B
1414,.,O
1415,We,O
1415,first,O
1415,expand,B
1415,the,O
1415,documents,B
1415,using,B
1415,the,O
1415,proposed,B
1415,Doc2query,I
1415,method,I
1415,.,O
1416,We,O
1416,then,O
1416,index,B
1416,and,I
1416,rank,I
1416,the,O
1416,expanded,B
1416,documents,I
1416,exactly,B
1416,as,I
1416,in,I
1416,the,O
1416,BM25,B
1416,method,I
1416,above,O
1416,.,O
1417,RM3,B
1417,:,O
1418,We,O
1418,can,O
1418,see,B
1418,that,I
1418,R,B
1418,-,I
1418,BERT,I
1418,significantly,B
1418,beats,I
1418,all,O
1418,the,O
1418,baseline,B
1418,methods,I
1418,.,O
1419,To,O
1419,compare,B
1419,document,B
1419,expansion,I
1419,with,B
1419,query,I
1419,expansion,O
1419,",",O
1419,we,O
1419,applied,B
1419,the,O
1419,RM3,B
1419,query,O
1419,expansion,O
1419,technique,O
1419,.,O
1420,BM25,O
1420,+,O
1420,BERT,B
1420,:,O
1420,We,O
1420,index,B
1420,and,I
1420,retrieve,I
1420,documents,B
1420,as,B
1420,in,I
1420,the,O
1420,BM25,O
1420,condition,O
1420,and,O
1420,further,B
1420,re-rank,I
1420,the,O
1420,documents,O
1420,with,B
1420,BERT,O
1420,as,O
1420,described,O
1420,in,O
1420,.,O
1421,BM25,O
1421,+,O
1421,Doc2query,O
1421,+,O
1421,BERT,B
1421,:,O
1421,We,O
1421,expand,B
1421,",",I
1421,index,I
1421,",",O
1421,and,O
1421,retrieve,O
1421,documents,B
1421,as,B
1421,in,I
1421,the,O
1421,BM25,O
1421,+,O
1421,Doc2query,O
1421,condition,O
1421,and,O
1421,further,B
1421,re-rank,I
1421,the,O
1421,documents,O
1421,with,B
1421,BERT,O
1421,.,O
1422,Document,O
1422,expansion,O
1422,with,B
1422,our,B
1422,method,I
1422,(,I
1422,BM25,I
1422,+,I
1422,Doc2query,I
1422,),I
1422,improves,B
1422,retrieval,B
1422,effectiveness,I
1422,by,B
1422,?,O
1423,15,O
1423,%,O
1423,for,B
1423,both,B
1423,datasets,I
1423,.,O
1424,Our,O
1424,full,O
1424,re-ranking,O
1424,condition,O
1424,(,O
1424,BM25,B
1424,+,I
1424,Doc2query,O
1424,+,O
1424,BERT,O
1424,),O
1424,beats,B
1424,BM25,O
1424,+,O
1424,BERT,O
1424,alone,O
1424,",",O
1424,which,O
1424,verifies,O
1424,that,O
1424,the,O
1424,contribution,O
1424,Input,O
1424,Document,O
1424,:,O
1424,July,O
1424,is,O
1424,the,O
1424,hottest,O
1424,month,O
1424,in,O
1424,Washington,O
1424,DC,O
1424,with,O
1424,an,O
1424,average,O
1424,temperature,O
1424,of,O
1424,27C,O
1424,(,O
1424,80F,O
1424,),O
1424,and,O
1424,the,O
1424,coldest,O
1424,is,O
1424,January,O
1424,at,O
1424,4C,O
1424,(,O
1424,38F,O
1424,),O
1424,with,O
1424,the,O
1424,most,O
1424,daily,O
1424,sunshine,O
1424,hours,O
1424,at,O
1424,9,O
1424,in,O
1424,July,O
1424,.,O
1425,Our,O
1425,method,O
1425,without,O
1425,a,O
1425,re-ranker,O
1425,(,O
1425,BM25,O
1425,+,O
1425,Doc2query,O
1425,),O
1425,adds,B
1425,a,O
1425,small,B
1425,latency,I
1425,increase,O
1425,over,B
1425,baseline,B
1425,BM25,O
1425,(,O
1425,50,O
1425,ms,O
1425,vs.,O
1425,90,O
1425,ms,O
1425,),O
1425,but,O
1425,is,B
1425,approximately,O
1425,seven,B
1425,times,I
1425,faster,I
1425,than,B
1425,a,O
1425,neural,B
1425,re-ranker,O
1425,that,B
1425,has,I
1425,a,O
1425,three,B
1425,points,I
1425,higher,I
1425,MRR@10,I
1425,(,O
1425,Single,O
1425,Duet,O
1425,v2,O
1425,",",O
1425,which,O
1425,is,O
1425,presented,O
1425,as,O
1425,a,O
1425,baseline,O
1425,in,O
1425,MS,O
1425,MARCO,O
1425,by,O
1425,the,O
1425,organizers,O
1425,),O
1425,.,O
1426,When,O
1426,we,O
1426,combine,B
1426,document,B
1426,expansion,I
1426,with,B
1426,a,O
1426,state,B
1426,-,I
1426,of,I
1426,-,O
1426,the,O
1426,-,O
1426,art,O
1426,re-ranker,O
1426,(,O
1426,BM25,O
1426,+,O
1426,Doc2query,O
1426,+,O
1426,BERT,O
1426,),O
1426,",",O
1426,we,O
1426,achieve,B
1426,the,O
1426,best,B
1426,-,O
1426,known,O
1426,results,O
1426,to,O
1426,date,O
1426,on,B
1426,TREC,B
1426,CAR,I
1426,;,O
1426,for,B
1426,MS,B
1426,MARCO,I
1426,",",O
1426,we,O
1426,are,O
1426,near,B
1426,the,O
1426,state,O
1426,of,O
1426,the,O
1426,art,O
1426,.,O
1427,We,O
1427,notice,B
1427,that,I
1427,the,O
1427,model,B
1427,tends,O
1427,to,O
1427,copy,B
1427,some,B
1427,words,I
1427,from,B
1427,the,O
1427,input,B
1427,document,I
1427,(,O
1427,e.g.,O
1428,Nevertheless,O
1428,",",O
1428,the,O
1428,model,O
1428,also,O
1428,produces,B
1428,words,B
1428,not,B
1428,present,I
1428,in,I
1428,the,O
1428,input,B
1428,document,I
1428,(,O
1428,e.g.,O
1429,",",O
1429,weather,O
1429,",",O
1429,relationship,O
1429,),O
1429,",",O
1429,which,O
1429,can,O
1429,be,O
1429,characterized,B
1429,as,I
1429,expansion,B
1429,by,B
1429,synonyms,B
1429,and,I
1429,other,I
1429,related,I
1429,terms,I
1429,.,O
1430,The,O
1430,MACRO,B
1430,F1,I
1430,value,I
1430,of,B
1430,R,B
1430,-,I
1430,BERT,I
1430,is,B
1430,89.,O
1431,25,O
1431,",",O
1431,which,O
1431,is,B
1431,much,B
1431,better,I
1431,than,I
1431,the,O
1431,previous,B
1431,best,I
1431,solution,I
1431,on,O
1431,this,O
1431,dataset,O
1431,.,O
1432,If,O
1432,we,O
1432,expand,B
1432,MS,B
1432,MARCO,I
1432,documents,I
1432,using,B
1432,only,B
1432,new,I
1432,words,I
1432,and,O
1432,retrieve,B
1432,the,O
1432,development,B
1432,set,I
1432,queries,I
1432,with,B
1432,BM25,B
1432,",",O
1432,we,O
1432,obtain,B
1432,an,O
1432,MRR@10,B
1432,of,B
1432,18.8,B
1432,(,O
1432,as,O
1432,opposed,O
1432,to,O
1432,18.4,O
1432,when,O
1432,indexing,O
1432,with,O
1432,original,O
1432,documents,O
1432,),O
1432,.,O
1433,Expanding,O
1433,with,O
1433,copied,B
1433,words,I
1433,gives,B
1433,an,O
1433,MRR@10,B
1433,of,B
1433,19.7,B
1433,.,O
1434,We,O
1434,achieve,B
1434,a,O
1434,higher,B
1434,MRR@10,I
1434,of,I
1434,21.5,B
1434,when,B
1434,documents,B
1434,are,O
1434,expanded,B
1434,with,I
1434,both,B
1434,types,I
1434,of,O
1434,words,O
1434,",",O
1434,showing,O
1434,that,O
1434,they,O
1434,are,O
1434,complementary,O
1434,.,O
1435,We,O
1435,find,B
1435,that,I
1435,the,O
1435,Recall@1000,B
1435,of,B
1435,the,O
1435,MS,B
1435,MARCO,I
1435,development,I
1435,set,I
1435,increased,B
1435,from,I
1435,85.3,B
1435,(,I
1435,BM25,I
1435,),I
1435,to,B
1435,89.3,B
1435,(,O
1435,BM25,O
1435,+,O
1435,Doc2query,O
1435,),O
1435,.,O
1436,As,O
1436,a,O
1436,contrastive,O
1436,condition,O
1436,",",O
1436,we,O
1436,find,O
1436,that,O
1436,query,B
1436,expansion,I
1436,with,B
1436,RM3,B
1436,hurts,B
1436,in,B
1436,both,B
1436,datasets,I
1436,",",O
1436,whether,O
1436,applied,O
1436,to,O
1436,the,O
1436,unexpanded,O
1436,corpus,O
1436,(,O
1436,BM25,O
1436,+,O
1436,RM3,O
1436,),O
1436,or,O
1436,the,O
1436,expanded,O
1436,version,O
1436,(,O
1436,BM25,O
1436,+,O
1436,Doc2query,O
1436,+,O
1436,RM3,O
1436,),O
1436,.,O
1437,This,O
1437,result,O
1437,shows,B
1437,that,I
1437,document,B
1437,expansion,I
1437,can,O
1437,be,O
1437,more,B
1437,effective,I
1437,than,I
1437,query,B
1437,expansion,O
1437,",",O
1437,most,O
1437,likely,O
1437,because,O
1437,there,O
1437,are,O
1437,more,O
1437,signals,O
1437,to,O
1437,exploit,O
1437,as,O
1437,documents,O
1437,are,O
1437,much,O
1437,longer,O
1437,.,O
1438,In,O
1438,this,O
1438,paper,O
1438,",",O
1438,we,O
1438,describe,O
1438,in,O
1438,detail,O
1438,how,O
1438,we,O
1438,have,O
1438,re-purposed,B
1438,BERT,B
1438,as,B
1438,a,O
1438,passage,B
1438,re-ranker,I
1438,and,O
1438,achieved,O
1438,state,O
1438,-,O
1438,of,O
1438,-,O
1438,the,O
1438,-,O
1438,art,O
1438,results,O
1438,on,O
1438,the,O
1438,MS,O
1438,MARCO,O
1438,passage,O
1438,re-ranking,O
1438,task,O
1438,.,O
1439,We,O
1439,fine,B
1439,-,I
1439,tune,I
1439,the,O
1439,model,B
1439,using,B
1439,TPUs,B
1439,1,O
1439,with,B
1439,a,O
1439,batch,B
1439,size,I
1439,of,B
1439,32,B
1439,(,O
1439,32,O
1439,sequences,O
1439,*,O
1439,512,O
1439,tokens,O
1439,=,O
1439,"16,384",O
1439,tokens,O
1439,/,O
1439,batch,O
1439,),O
1439,for,B
1439,400,B
1439,k,I
1439,iterations,I
1439,",",O
1439,which,O
1439,takes,B
1439,approximately,B
1439,70,I
1439,hours,I
1439,.,O
1440,We,O
1440,use,B
1440,ADAM,B
1440,(,I
1440,Kingma,I
1440,&,I
1440,Ba,I
1440,",",I
1440,2014,I
1440,),I
1440,with,B
1440,the,O
1440,initial,B
1440,learning,B
1440,rate,I
1440,set,B
1440,to,I
1440,3,O
1440,10,O
1440,?6,O
1440,",",O
1440,?,O
1441,2,O
1441,=,O
1441,0.999,O
1441,",",O
1441,L2,B
1441,weight,I
1441,decay,I
1441,of,B
1441,0.01,B
1441,",",O
1441,learning,B
1441,rate,I
1441,warmup,I
1441,over,B
1441,the,O
1441,first,B
1441,"10,000",I
1441,steps,I
1441,",",O
1441,and,O
1441,linear,B
1441,decay,O
1441,of,O
1441,the,O
1441,learning,O
1441,rate,O
1441,.,O
1442,Mintz,B
1442,represents,B
1442,a,O
1442,traditional,B
1442,distantsupervision,I
1442,-,I
1442,based,I
1442,model,I
1442,that,O
1442,was,O
1442,proposed,O
1442,by,O
1442,.,O
1443,We,O
1443,use,O
1443,a,O
1443,dropout,B
1443,probability,I
1443,of,B
1443,0.1,B
1443,on,B
1443,all,B
1443,layers,I
1443,.,O
1444,For,B
1444,the,O
1444,fine,B
1444,-,I
1444,tuning,I
1444,data,B
1444,",",O
1444,we,O
1444,generate,B
1444,our,B
1444,query,I
1444,-,O
1444,passage,O
1444,pairs,O
1444,by,B
1444,retrieving,I
1444,the,O
1444,top,B
1444,ten,I
1444,passages,I
1444,from,B
1444,the,O
1444,entire,B
1444,TREC,I
1444,-,O
1444,CAR,O
1444,corpus,O
1444,using,B
1444,BM25,B
1444,.,O
1445,We,O
1445,train,B
1445,it,O
1445,for,O
1445,400,B
1445,k,I
1445,iterations,I
1445,",",O
1445,or,O
1445,12.8,B
1445,M,I
1445,examples,I
1445,(,O
1445,400,O
1445,k,O
1445,iterations,O
1445,*,O
1445,32,O
1445,pairs,O
1445,/,O
1445,batch,O
1445,),O
1445,",",O
1445,which,O
1445,corresponds,O
1445,to,O
1445,only,O
1445,40,O
1445,%,O
1445,of,O
1445,the,O
1445,training,O
1445,set,O
1445,.,O
1446,In,O
1446,this,O
1446,paper,O
1446,",",O
1446,we,O
1446,describe,O
1446,a,O
1446,simple,O
1446,re-implementation,O
1446,of,O
1446,BERT,O
1446,for,O
1446,query,B
1446,-,I
1446,based,I
1446,passage,I
1446,re-ranking,I
1446,.,O
1447,Despite,B
1447,training,B
1447,on,B
1447,a,O
1447,fraction,B
1447,of,I
1447,the,I
1447,data,I
1447,available,I
1447,",",O
1447,the,O
1447,proposed,B
1447,BERT,I
1447,-,I
1447,based,I
1447,models,I
1447,surpass,B
1447,the,O
1447,previous,B
1447,state,I
1447,-,O
1447,of,O
1447,-,O
1447,the,O
1447,-,O
1447,art,O
1447,models,O
1447,by,B
1447,a,O
1447,large,B
1447,margin,I
1447,on,O
1447,both,O
1447,of,O
1447,the,O
1447,tasks,O
1447,.,O
1448,In,O
1448,this,O
1448,paper,O
1448,",",O
1448,we,O
1448,describe,O
1448,a,O
1448,semantic,B
1448,parsing,I
1448,approach,O
1448,to,B
1448,the,O
1448,problem,B
1448,of,B
1448,KB,B
1448,QA,I
1448,.,O
1449,Semantic,O
1449,parses,O
1449,can,O
1449,be,O
1449,deterministically,B
1449,converted,I
1449,to,B
1449,a,O
1449,query,B
1449,to,O
1449,extract,O
1449,the,O
1449,answers,B
1449,from,B
1449,the,O
1449,KB,B
1449,.,O
1450,That,O
1450,is,O
1450,",",O
1450,for,B
1450,each,B
1450,input,I
1450,question,I
1450,",",O
1450,we,O
1450,construct,B
1450,an,O
1450,explicit,B
1450,structural,I
1450,semantic,I
1450,parse,I
1450,(,I
1450,semantic,O
1450,graph,O
1450,),O
1450,",",O
1450,as,O
1450,in,O
1450,.,O
1451,MultiR,B
1451,is,B
1451,a,O
1451,multi-instance,B
1451,learning,I
1451,method,I
1451,that,O
1451,was,O
1451,proposed,O
1451,by,O
1451,.,O
1452,In,O
1452,particular,O
1452,",",O
1452,we,O
1452,adapt,B
1452,Gated,B
1452,Graph,I
1452,Neural,I
1452,Networks,I
1452,(,I
1452,GGNNs,I
1452,),I
1452,",",O
1452,described,O
1452,in,O
1452,",",O
1452,to,B
1452,process,I
1452,and,I
1452,score,I
1452,semantic,B
1452,parses,I
1452,.,O
1453,Pooled,O
1453,Edges,O
1453,model,O
1453,-,O
1453,We,O
1453,use,B
1453,the,I
1453,DCNN,B
1453,to,B
1453,encode,I
1453,the,O
1453,question,B
1453,and,I
1453,the,O
1453,label,O
1453,of,O
1453,each,O
1453,edge,O
1453,in,B
1453,the,O
1453,semantic,B
1453,graph,I
1453,.,O
1454,To,O
1454,judge,O
1454,the,O
1454,effect,O
1454,of,B
1454,the,O
1454,gated,O
1454,graph,O
1454,neural,O
1454,architecture,O
1454,",",O
1454,we,O
1454,also,O
1454,include,B
1454,a,O
1454,model,B
1454,variant,I
1454,that,B
1454,does,I
1454,not,I
1454,use,I
1454,the,O
1454,gating,B
1454,mechanism,I
1454,and,I
1454,directly,B
1454,computes,I
1454,the,O
1454,hidden,B
1454,state,I
1454,as,B
1454,a,O
1454,combination,B
1454,of,O
1454,the,O
1454,activations,B
1454,(,I
1454,Eq,I
1454,1,I
1454,),I
1454,and,O
1454,the,O
1454,previous,O
1454,state,O
1454,.,O
1455,Gated,O
1455,Graph,O
1455,Neural,O
1455,Network,O
1455,(,O
1455,GGNN,O
1455,),O
1455,-,O
1455,We,O
1455,use,O
1455,the,O
1455,GGNN,O
1455,to,B
1455,process,I
1455,semantic,B
1455,parses,I
1455,",",O
1455,as,O
1455,described,O
1455,in,O
1455,Section,O
1455,3.2,O
1455,.,O
1456,Modeling,O
1456,Semantics,O
1456,with,O
1456,Gated,O
1456,Graph,O
1456,Neural,O
1456,Networks,O
1456,for,O
1456,Knowledge,B
1456,Base,I
1456,Question,I
1456,Answering,I
1457,QA,B
1457,requires,O
1457,precise,O
1457,modeling,O
1457,of,O
1457,the,O
1457,question,O
1457,semantics,O
1457,through,O
1457,the,O
1457,entities,O
1457,and,O
1457,relations,O
1457,available,O
1457,in,O
1457,the,O
1457,KB,O
1457,in,O
1457,order,O
1457,to,O
1457,retrieve,O
1457,the,O
1457,correct,O
1457,answer,O
1457,.,O
1458,In,O
1458,this,O
1458,paper,O
1458,",",O
1458,we,O
1458,describe,O
1458,a,O
1458,semantic,O
1458,parsing,O
1458,approach,O
1458,to,O
1458,the,O
1458,problem,O
1458,of,O
1458,KB,B
1458,QA,I
1458,.,O
1459,MIML,B
1459,is,B
1459,a,O
1459,multi-instance,B
1459,multilabel,I
1459,model,I
1459,that,O
1459,was,O
1459,proposed,O
1459,by,O
1459,.,O
1460,We,O
1460,compare,O
1460,the,O
1460,results,O
1460,on,B
1460,the,O
1460,WebQSP,B
1460,-,I
1460,WD,I
1460,data,I
1460,set,I
1460,in,O
1460,.,O
1461,As,O
1461,can,O
1461,be,O
1461,seen,O
1461,",",O
1461,the,O
1461,graph,B
1461,models,I
1461,outperform,B
1461,all,I
1461,other,I
1461,models,O
1461,across,B
1461,precision,B
1461,",",O
1461,recall,O
1461,and,O
1461,F-score,O
1461,",",O
1461,with,O
1461,GGNN,B
1461,showing,B
1461,the,O
1461,best,B
1461,over,I
1461,all,O
1461,result,O
1461,.,O
1462,The,O
1462,STAGG,B
1462,architecture,I
1462,delivers,B
1462,the,O
1462,worst,B
1462,results,I
1462,in,O
1462,our,O
1462,experiments,O
1462,",",O
1462,the,O
1462,main,O
1462,reason,O
1462,being,O
1462,supposedly,O
1462,that,O
1462,the,O
1462,model,O
1462,had,O
1462,to,O
1462,rely,O
1462,on,O
1462,manually,O
1462,defined,O
1462,features,O
1462,that,O
1462,are,O
1462,less,O
1462,flexible,O
1462,.,O
1463,The,O
1463,Single,B
1463,Edge,I
1463,model,I
1463,outperforms,B
1463,the,O
1463,more,B
1463,complex,I
1463,Pooled,I
1463,Edges,I
1463,model,O
1463,by,B
1463,a,O
1463,noticeable,B
1463,margin,I
1463,.,O
1464,The,O
1464,Single,B
1464,Edge,I
1464,baseline,I
1464,prefers,B
1464,simple,B
1464,graphs,I
1464,that,B
1464,consist,I
1464,of,I
1464,a,O
1464,single,O
1464,edge,O
1464,which,O
1464,is,B
1464,a,O
1464,good,B
1464,strategy,I
1464,to,B
1464,achieve,I
1464,higher,B
1464,recall,I
1464,values,I
1464,.,O
1465,The,O
1465,Pooled,B
1465,Edges,I
1465,model,I
1465,maintains,B
1465,a,O
1465,better,B
1465,performance,I
1465,across,B
1465,questions,B
1465,of,B
1465,different,I
1465,complexity,I
1465,",",O
1465,which,O
1465,shows,B
1465,the,O
1465,benefits,B
1465,of,O
1465,encoding,O
1465,all,B
1465,graph,I
1465,edges,O
1465,.,O
1466,In,O
1466,",",O
1466,we,O
1466,see,O
1466,that,O
1466,for,B
1466,the,O
1466,STAGG,B
1466,and,I
1466,Single,I
1466,Edge,I
1466,baselines,I
1466,the,O
1466,performance,B
1466,on,B
1466,more,B
1466,complex,I
1466,questions,I
1466,drops,B
1466,compared,B
1466,to,I
1466,the,O
1466,results,B
1466,on,O
1466,simpler,B
1466,questions,O
1466,.,O
1467,We,O
1467,see,B
1467,that,I
1467,the,O
1467,GGNN,B
1467,model,I
1467,offers,B
1467,the,O
1467,best,B
1467,results,I
1467,both,O
1467,on,B
1467,simple,B
1467,and,I
1467,complex,I
1467,questions,I
1467,",",O
1467,as,O
1467,it,O
1467,effectively,O
1467,encodes,O
1467,the,O
1467,structure,O
1467,of,O
1467,semantic,O
1467,graphs,O
1467,.,O
1468,Our,O
1468,baseline,O
1468,models,O
1468,9,O
1468,include,B
1468,the,O
1468,following,O
1468,:,O
1468,GA,B
1468,",",O
1468,a,O
1468,reading,B
1468,comprehension,I
1468,model,I
1468,with,B
1468,gated,B
1468,-,I
1468,attention,I
1468,;,O
1468,BiDAF,B
1468,),O
1468,",",O
1468,a,O
1468,RC,B
1468,model,O
1468,with,O
1468,bidirectional,B
1468,attention,O
1468,flow,O
1468,;,O
1468,AQA,B
1468,),O
1468,",",O
1468,a,O
1468,reinforced,B
1468,system,I
1468,learning,I
1468,to,B
1468,aggregate,I
1468,the,O
1468,answers,B
1468,generated,B
1468,by,I
1468,the,O
1468,re-written,B
1468,questions,I
1468,;,O
1468,R,B
1468,3,I
1468,),O
1468,",",O
1468,a,O
1468,reinforced,O
1468,model,O
1468,making,B
1468,use,I
1468,of,I
1468,a,O
1468,ranker,B
1468,for,B
1468,selecting,I
1468,passages,B
1468,to,O
1468,train,O
1468,the,O
1468,RC,O
1468,model,O
1468,.,O
1469,In,O
1469,this,O
1469,paper,O
1469,",",O
1469,we,O
1469,use,B
1469,the,O
1469,Skip,B
1469,-,I
1469,gram,I
1469,model,I
1469,(,I
1469,word2,I
1469,vec,I
1469,),I
1469,5,O
1469,to,B
1469,train,I
1469,the,O
1469,word,B
1469,embeddings,I
1469,on,B
1469,the,O
1469,NYT,B
1469,corpus,I
1469,.,O
1470,We,O
1470,first,O
1470,use,B
1470,a,O
1470,pre-trained,B
1470,R,I
1470,3,I
1470,model,I
1470,",",I
1470,which,O
1470,gets,O
1470,the,O
1470,state,O
1470,-,O
1470,of,O
1470,-,O
1470,the,O
1470,-,O
1470,art,O
1470,performance,O
1470,on,O
1470,the,O
1470,three,O
1470,public,O
1470,datasets,O
1470,we,O
1470,consider,O
1470,",",O
1470,to,B
1470,generate,I
1470,the,O
1470,top,B
1470,50,I
1470,candidate,I
1470,spans,I
1470,for,I
1470,the,O
1470,training,B
1470,",",O
1470,development,O
1470,and,O
1470,test,O
1470,datasets,O
1470,",",O
1470,and,O
1470,we,O
1470,use,O
1470,them,O
1470,for,O
1470,further,B
1470,ranking,I
1470,.,O
1471,For,B
1471,the,O
1471,coverage,B
1471,-,I
1471,based,I
1471,re-ranker,I
1471,",",O
1471,we,O
1471,use,B
1471,Adam,B
1471,to,B
1471,optimize,I
1471,the,O
1471,model,B
1471,.,O
1472,We,O
1472,set,B
1472,all,B
1472,the,I
1472,words,I
1472,beyond,B
1472,Glove,B
1472,as,B
1472,zero,B
1472,vectors,I
1472,.,O
1473,We,O
1473,set,O
1473,l,B
1473,to,B
1473,300,B
1473,",",O
1473,batch,B
1473,size,I
1473,to,O
1473,30,B
1473,",",O
1473,learning,B
1473,rate,I
1473,to,O
1473,0.002,B
1473,.,O
1474,We,O
1474,tune,B
1474,the,O
1474,dropout,B
1474,probability,I
1474,from,B
1474,0,B
1474,to,I
1474,0.5,I
1474,and,O
1474,the,O
1474,number,B
1474,of,I
1474,candidate,I
1474,answers,I
1474,for,B
1474,re-ranking,B
1474,(,I
1474,K,I
1474,),I
1474,in,B
1474,[,B
1474,3,I
1474,",",I
1474,5,I
1474,",",O
1474,10,O
1474,],O
1474,11,O
1474,.,O
1475,In,O
1475,this,O
1475,paper,O
1475,",",O
1475,we,O
1475,propose,B
1475,a,O
1475,method,B
1475,to,B
1475,improve,I
1475,open,B
1475,-,I
1475,domain,I
1475,QA,I
1475,by,B
1475,explicitly,I
1475,aggregating,I
1475,evidence,B
1475,from,B
1475,across,I
1475,multiple,B
1475,passages,I
1475,.,O
1476,We,O
1476,formulate,B
1476,the,O
1476,above,O
1476,evidence,B
1476,aggregation,I
1476,as,B
1476,an,O
1476,answer,B
1476,re-ranking,I
1476,problem,I
1476,.,O
1477,Here,O
1477,we,O
1477,apply,O
1477,the,O
1477,idea,O
1477,of,B
1477,re-ranking,O
1477,;,O
1477,for,B
1477,each,B
1477,answer,I
1477,candidate,I
1477,",",O
1477,we,O
1477,efficiently,B
1477,incorporate,I
1477,global,B
1477,information,I
1477,from,B
1477,multiple,B
1477,pieces,I
1477,of,O
1477,textual,B
1477,evidence,I
1477,without,B
1477,significantly,B
1477,increasing,I
1477,the,O
1477,complexity,B
1477,of,O
1477,the,O
1477,prediction,B
1477,of,O
1477,the,O
1477,RC,B
1477,model,I
1477,.,O
1478,The,O
1478,re-rankers,B
1478,are,B
1478,:,O
1479,A,O
1479,strength,B
1479,-,I
1479,based,I
1479,re-ranker,I
1479,",",O
1479,which,O
1479,ranks,B
1479,the,O
1479,answer,B
1479,candidates,I
1479,according,B
1479,to,I
1479,how,I
1479,often,I
1479,their,O
1479,evidence,B
1479,occurs,B
1479,in,I
1479,different,B
1479,passages,I
1479,.,O
1480,We,O
1480,use,O
1480,a,O
1480,grid,B
1480,search,I
1480,to,B
1480,determine,I
1480,the,O
1480,optimal,B
1480,parameters,I
1480,and,O
1480,manually,B
1480,specify,I
1480,subsets,B
1480,of,B
1480,the,O
1480,parameter,B
1480,spaces,I
1480,:,O
1480,w,O
1480,?,O
1481,A,O
1481,coverage,B
1481,-,I
1481,based,I
1481,re-ranker,I
1481,",",O
1481,which,O
1481,aims,B
1481,to,I
1481,rank,I
1481,an,O
1481,answer,B
1481,candidate,I
1481,higher,B
1481,if,B
1481,the,O
1481,union,B
1481,of,B
1481,all,B
1481,its,I
1481,contexts,I
1481,in,I
1481,different,B
1481,passages,I
1481,could,B
1481,cover,I
1481,more,B
1481,aspects,I
1481,included,B
1481,in,O
1481,the,O
1481,question,B
1481,.,O
1482,EVIDENCE,O
1482,AGGREGATION,O
1482,FOR,O
1482,ANSWER,O
1482,RE,O
1482,-,O
1482,RANKING,O
1482,IN,O
1482,OPEN,B
1482,-,O
1482,DOMAIN,O
1482,QUESTION,O
1482,ANSWERING,O
1483,Recent,O
1483,work,O
1483,on,O
1483,open,B
1483,-,I
1483,domain,I
1483,QA,I
1483,has,O
1483,focused,O
1483,on,O
1483,using,O
1483,unstructured,O
1483,text,O
1483,retrieved,O
1483,from,O
1483,the,O
1483,web,O
1483,to,O
1483,build,O
1483,machine,O
1483,comprehension,O
1483,models,O
1483,.,O
1484,The,O
1484,results,O
1484,showed,B
1484,that,I
1484,R,B
1484,3,I
1484,achieved,B
1484,F1,B
1484,56.0,I
1484,",",I
1484,EM,I
1484,50.9,I
1484,on,B
1484,Wiki,B
1484,domain,I
1484,and,O
1484,F1,O
1484,68.5,O
1484,",",O
1484,EM,O
1484,63.0,O
1484,on,O
1484,Web,B
1484,domain,O
1484,",",O
1484,which,O
1484,is,O
1484,competitive,B
1484,to,I
1484,the,O
1484,state,B
1484,-,I
1484,of,I
1484,-,O
1484,the,O
1484,-,O
1484,arts,O
1484,.,O
1485,From,O
1485,the,O
1485,results,O
1485,",",O
1485,we,O
1485,can,O
1485,clearly,O
1485,see,B
1485,that,I
1485,the,O
1485,full,B
1485,re-ranker,I
1485,",",O
1485,the,O
1485,combination,B
1485,of,I
1485,different,B
1485,re-rankers,I
1485,",",O
1485,significantly,B
1485,outperforms,I
1485,the,O
1485,previous,B
1485,best,I
1485,performance,I
1485,by,B
1485,a,O
1485,large,B
1485,margin,I
1485,",",O
1485,especially,B
1485,on,I
1485,Quasar,B
1485,-,I
1485,T,I
1485,and,O
1485,Search,B
1485,QA,I
1485,.,O
1486,In,O
1486,addition,O
1486,",",O
1486,we,O
1486,see,O
1486,that,O
1486,our,B
1486,coverage,I
1486,-,I
1486,based,I
1486,re-ranker,I
1486,achieves,B
1486,consistently,B
1486,good,I
1486,performance,I
1486,on,B
1486,the,O
1486,three,B
1486,datasets,I
1486,",",O
1486,even,O
1486,though,O
1486,its,O
1486,performance,O
1486,is,O
1486,marginally,O
1486,lower,O
1486,than,O
1486,the,O
1486,strength,O
1486,-,O
1486,based,O
1486,re-ranker,O
1486,on,O
1486,the,O
1486,Search,O
1486,QA,O
1486,dataset,O
1486,.,O
1487,Moreover,O
1487,",",O
1487,our,B
1487,model,I
1487,is,B
1487,much,B
1487,better,I
1487,than,B
1487,the,O
1487,human,B
1487,performance,I
1487,on,B
1487,the,O
1487,Search,B
1487,QA,I
1487,dataset,I
1487,.,O
1488,Both,O
1488,char,B
1488,-,I
1488,level,I
1488,and,I
1488,word,I
1488,-,O
1488,level,O
1488,embeddings,O
1488,contribute,B
1488,towards,I
1488,the,O
1488,model,B
1488,'s,I
1488,performance,I
1488,.,O
1489,C2Q,O
1489,attention,O
1489,proves,B
1489,to,I
1489,be,I
1489,critical,B
1489,with,B
1489,a,O
1489,drop,B
1489,of,B
1489,more,B
1489,than,I
1489,10,I
1489,points,I
1489,on,O
1489,both,O
1489,metrics,O
1489,.,O
1490,The,O
1490,learned,B
1490,character,I
1490,embeddings,I
1490,are,O
1490,of,B
1490,size,I
1490,8,B
1490,.,O
1491,1,O
1491,-,O
1491,dimensional,O
1491,convolutions,O
1491,of,B
1491,window,I
1491,size,I
1491,3,B
1491,",",O
1491,"4,5",O
1491,are,O
1491,applied,O
1491,per-token,O
1491,with,O
1491,50,O
1491,filters,O
1491,of,O
1491,each,O
1491,window,O
1491,size,O
1491,.,O
1492,We,O
1492,use,O
1492,Adadelta,B
1492,in,B
1492,the,O
1492,update,B
1492,procedure,I
1492,;,O
1492,it,O
1492,relies,O
1492,on,O
1492,two,O
1492,main,O
1492,parameters,O
1492,",",O
1492,?,O
1493,Despite,O
1493,being,O
1493,a,O
1493,simpler,O
1493,attention,O
1493,mechanism,O
1493,",",O
1493,our,O
1493,proposed,B
1493,static,I
1493,attention,O
1493,outperforms,B
1493,the,O
1493,dynamically,B
1493,computed,I
1493,attention,O
1493,by,B
1493,more,B
1493,than,I
1493,3,I
1493,points,I
1493,.,O
1494,At,B
1494,the,O
1494,word,B
1494,embedding,I
1494,layer,I
1494,",",I
1494,query,B
1494,words,I
1494,such,B
1494,as,I
1494,When,B
1494,",",O
1494,Where,O
1494,and,O
1494,Who,O
1494,are,O
1494,not,B
1494,well,I
1494,aligned,I
1494,to,I
1494,possible,B
1494,answers,I
1494,in,B
1494,the,O
1494,context,B
1494,",",O
1494,but,O
1494,this,O
1494,dramatically,O
1494,changes,O
1494,in,O
1494,the,O
1494,contextual,O
1494,embedding,O
1494,layer,O
1494,which,O
1494,has,O
1494,access,O
1494,to,O
1494,context,O
1494,from,O
1494,surrounding,O
1494,words,O
1494,and,O
1494,is,O
1494,just,O
1494,1,O
1494,layer,O
1494,below,O
1494,the,O
1494,attention,O
1494,layer,O
1494,.,O
1495,Each,O
1495,paragraph,O
1495,and,O
1495,question,O
1495,are,O
1495,tokenized,B
1495,by,I
1495,a,O
1495,regular,B
1495,-,I
1495,expression,I
1495,-,O
1495,based,O
1495,word,O
1495,tokenizer,O
1495,(,O
1495,PTB,O
1495,Tokenizer,O
1495,),O
1495,and,O
1495,fed,B
1495,into,I
1495,the,O
1495,model,B
1495,.,O
1496,The,O
1496,hidden,B
1496,state,I
1496,size,I
1496,(,I
1496,d,I
1496,),I
1496,of,B
1496,the,O
1496,model,B
1496,is,B
1496,100,B
1496,.,O
1497,The,O
1497,model,O
1497,has,B
1497,about,I
1497,2.6,B
1497,million,I
1497,parameters,I
1497,.,O
1498,A,O
1498,dropout,B
1498,),I
1498,rate,I
1498,of,B
1498,0.2,B
1498,is,O
1498,used,B
1498,for,B
1498,the,O
1498,CNN,B
1498,",",O
1498,all,B
1498,LSTM,I
1498,layers,I
1498,",",O
1498,and,O
1498,the,O
1498,linear,B
1498,transformation,I
1498,before,B
1498,the,O
1498,softmax,B
1498,for,O
1498,the,O
1498,answers,B
1498,.,O
1499,The,O
1499,training,B
1499,process,I
1499,takes,B
1499,roughly,B
1499,20,I
1499,hours,I
1499,on,B
1499,a,O
1499,single,B
1499,Titan,I
1499,X,I
1499,GPU,I
1499,.,O
1500,We,O
1500,use,B
1500,100,B
1500,1D,I
1500,filters,I
1500,for,B
1500,CNN,B
1500,char,I
1500,embedding,I
1500,",",O
1500,each,O
1500,with,B
1500,a,O
1500,width,B
1500,of,I
1500,5,I
1500,.,O
1501,We,O
1501,use,O
1501,the,O
1501,AdaDelta,B
1501,(,I
1501,Zeiler,I
1501,",",I
1501,2012,I
1501,),I
1501,optimizer,I
1501,",",O
1501,with,B
1501,a,O
1501,minibatch,B
1501,size,I
1501,of,B
1501,60,B
1501,and,O
1501,an,O
1501,initial,B
1501,learning,I
1501,rate,I
1501,of,O
1501,0.5,B
1501,",",O
1501,for,B
1501,12,B
1501,epochs,I
1501,.,O
1502,During,B
1502,training,B
1502,",",O
1502,the,O
1502,moving,B
1502,averages,I
1502,of,B
1502,all,B
1502,weights,I
1502,of,O
1502,the,O
1502,model,B
1502,are,O
1502,maintained,B
1502,with,I
1502,the,O
1502,exponential,B
1502,decay,I
1502,rate,I
1502,of,O
1502,0.999,B
1502,.,O
1503,Following,O
1503,",",O
1503,we,O
1503,tune,B
1503,all,O
1503,of,O
1503,the,O
1503,models,B
1503,using,B
1503,three,B
1503,-,I
1503,fold,I
1503,validation,I
1503,on,B
1503,the,O
1503,training,B
1503,set,I
1503,.,O
1504,At,B
1504,test,B
1504,time,I
1504,",",O
1504,the,O
1504,moving,B
1504,averages,I
1504,instead,B
1504,of,I
1504,the,O
1504,raw,B
1504,weights,I
1504,are,B
1504,used,I
1504,.,O
1505,In,O
1505,this,O
1505,paper,O
1505,",",O
1505,we,O
1505,introduce,B
1505,the,O
1505,Bi-,B
1505,Directional,I
1505,Attention,I
1505,Flow,I
1505,(,I
1505,BIDAF,I
1505,),I
1505,network,I
1505,",",O
1505,a,O
1505,hierarchical,B
1505,multi-stage,I
1505,architecture,I
1505,for,B
1505,modeling,I
1505,the,O
1505,representations,B
1505,of,I
1505,the,O
1505,context,B
1505,paragraph,I
1505,at,B
1505,different,B
1505,levels,I
1505,of,O
1505,granularity,O
1505,),O
1505,.,O
1506,BIDAF,B
1506,includes,B
1506,character,B
1506,-,I
1506,level,I
1506,",",I
1506,word,I
1506,-,O
1506,level,O
1506,",",O
1506,and,O
1506,contextual,O
1506,embeddings,O
1506,",",O
1506,and,O
1506,uses,B
1506,bi-directional,B
1506,attention,I
1506,flow,I
1506,to,B
1506,obtain,I
1506,a,O
1506,query,B
1506,-,O
1506,aware,O
1506,context,O
1506,representation,O
1506,.,O
1507,Instead,O
1507,",",O
1507,the,O
1507,attention,B
1507,is,O
1507,computed,B
1507,for,I
1507,every,B
1507,time,I
1507,step,I
1507,",",O
1507,and,O
1507,the,O
1507,attended,B
1507,vector,I
1507,at,B
1507,each,B
1507,time,O
1507,step,O
1507,",",O
1507,along,O
1507,with,O
1507,the,O
1507,representations,O
1507,from,O
1507,previous,O
1507,layers,O
1507,",",O
1507,is,O
1507,allowed,B
1507,to,B
1507,flow,B
1507,through,I
1507,to,O
1507,the,O
1507,subsequent,B
1507,modeling,I
1507,layer,I
1507,.,O
1508,Second,O
1508,",",O
1508,we,O
1508,use,B
1508,a,O
1508,memory,B
1508,-,I
1508,less,I
1508,attention,I
1508,mechanism,I
1508,.,O
1509,It,O
1509,forces,B
1509,the,I
1509,attention,B
1509,layer,I
1509,to,B
1509,focus,I
1509,on,I
1509,learning,B
1509,the,O
1509,attention,O
1509,between,B
1509,the,O
1509,query,B
1509,and,I
1509,the,O
1509,context,O
1509,",",O
1509,and,O
1509,enables,B
1509,the,O
1509,modeling,B
1509,layer,O
1509,to,O
1509,focus,O
1509,on,O
1509,learning,O
1509,the,O
1509,interaction,B
1509,within,B
1509,the,O
1509,query,O
1509,-,O
1509,aware,O
1509,context,O
1509,representation,O
1509,(,O
1509,the,O
1509,output,O
1509,of,O
1509,the,O
1509,attention,O
1509,layer,O
1509,),O
1509,.,O
1510,It,O
1510,also,O
1510,allows,B
1510,the,O
1510,attention,O
1510,at,B
1510,each,B
1510,time,I
1510,step,I
1510,to,B
1510,be,I
1510,unaffected,B
1510,from,B
1510,incorrect,B
1510,attendances,I
1510,at,O
1510,previous,B
1510,time,O
1510,steps,O
1510,.,O
1511,Third,O
1511,",",O
1511,we,O
1511,use,O
1511,attention,B
1511,mechanisms,I
1511,in,B
1511,both,B
1511,directions,I
1511,",",O
1511,query,O
1511,-,O
1511,to,B
1511,-,O
1511,context,B
1511,and,O
1511,context,O
1511,-,O
1511,to,O
1511,-,O
1511,query,O
1511,",",O
1511,which,B
1511,provide,I
1511,complimentary,B
1511,information,I
1511,to,O
1511,each,B
1511,other,I
1511,.,O
1512,BI,O
1512,-,O
1512,DIRECTIONAL,O
1512,ATTENTION,O
1512,FLOW,O
1512,FOR,O
1512,MACHINE,B
1512,COMPREHENSION,I
1513,Because,O
1513,the,O
1513,position,O
1513,dimension,O
1513,has,O
1513,little,O
1513,effect,O
1513,on,O
1513,the,O
1513,result,O
1513,",",O
1513,we,O
1513,heuristically,B
1513,choose,I
1513,d,B
1513,p,I
1513,=,B
1513,5,B
1513,.,O
1514,Recently,O
1514,",",O
1514,attention,O
1514,mechanisms,O
1514,have,O
1514,been,O
1514,successfully,O
1514,extended,O
1514,to,O
1514,MC,B
1514,.,O
1515,The,O
1515,tasks,O
1515,of,O
1515,machine,O
1515,comprehension,O
1515,(,O
1515,MC,O
1515,),O
1515,and,O
1515,question,B
1515,answering,I
1515,(,O
1515,QA,O
1515,),O
1515,have,O
1515,gained,O
1515,significant,O
1515,popularity,O
1515,over,O
1515,the,O
1515,past,O
1515,few,O
1515,years,O
1515,within,O
1515,the,O
1515,natural,O
1515,language,O
1515,processing,O
1515,and,O
1515,computer,O
1515,vision,O
1515,communities,O
1515,.,O
1516,BIDAF,O
1516,(,O
1516,ensemble,O
1516,),O
1516,achieves,B
1516,an,O
1516,EM,B
1516,score,I
1516,of,B
1516,73.3,B
1516,and,O
1516,an,O
1516,F,B
1516,1,I
1516,score,O
1516,of,O
1516,81.1,B
1516,",",O
1516,outperforming,O
1516,all,O
1516,previous,O
1516,approaches,O
1516,.,O
1517,Memex,O
1517,QA,O
1517,provides,O
1517,4,O
1517,answer,B
1517,choices,O
1517,and,O
1517,only,O
1517,one,O
1517,correct,O
1517,answer,O
1517,for,O
1517,each,O
1517,question,O
1517,.,O
1518,We,O
1518,implement,O
1518,the,O
1518,following,O
1518,methods,O
1518,as,O
1518,baselines,O
1518,:,O
1518,Logistic,B
1518,Regression,I
1518,predicts,B
1518,the,O
1518,answer,O
1518,with,B
1518,concatenated,B
1518,image,I
1518,",",I
1518,question,I
1518,and,I
1518,metadata,I
1518,features,I
1518,as,O
1518,reported,O
1518,in,O
1518,.,O
1519,Embedding,O
1519,+,O
1519,LSTM,O
1519,utilizes,B
1519,word,B
1519,embeddings,I
1519,and,I
1519,character,I
1519,embeddings,O
1519,",",O
1519,along,B
1519,with,I
1519,the,O
1519,same,B
1519,visual,I
1519,embeddings,O
1519,used,B
1519,in,I
1519,FVTA,B
1519,.,O
1520,Embedding,O
1520,+,O
1520,LSTM,O
1520,+,O
1520,Concat,O
1520,concatenates,B
1520,the,O
1520,last,B
1520,LSTM,O
1520,output,O
1520,from,B
1520,different,B
1520,modalities,I
1520,to,B
1520,produce,I
1520,the,O
1520,final,B
1520,output,O
1520,.,O
1521,Classic,O
1521,Soft,O
1521,Attention,O
1521,uses,B
1521,classic,O
1521,one,O
1521,dimensional,O
1521,question,B
1521,-,O
1521,to,B
1521,-,O
1521,context,B
1521,attention,O
1521,to,O
1521,summarize,O
1521,context,O
1521,for,B
1521,question,O
1521,answering,O
1521,.,O
1522,DMN,O
1522,+,O
1522,is,O
1522,the,O
1522,improved,B
1522,dynamic,I
1522,memory,I
1522,networks,I
1522,",",O
1522,which,B
1522,is,O
1522,one,O
1522,of,O
1522,the,O
1522,representative,B
1522,architectures,I
1522,that,B
1522,achieve,I
1522,good,B
1522,performance,I
1522,on,B
1522,the,O
1522,VQA,B
1522,Task,I
1522,.,O
1523,TGIF,O
1523,Temporal,O
1523,Attention,O
1523,is,B
1523,a,O
1523,recently,O
1523,proposed,O
1523,spatial,B
1523,-,I
1523,temporal,O
1523,reasoning,O
1523,network,O
1523,on,B
1523,sequential,B
1523,animated,I
1523,image,I
1523,QA,I
1523,.,O
1524,The,O
1524,batch,B
1524,size,I
1524,is,O
1524,fixed,B
1524,to,I
1524,50,B
1524,.,O
1525,We,O
1525,encode,B
1525,GPS,B
1525,locations,I
1525,using,B
1525,words,B
1525,.,O
1526,All,O
1526,questions,B
1526,",",I
1526,textual,I
1526,context,I
1526,and,I
1526,answers,I
1526,are,B
1526,tokenized,B
1526,using,B
1526,the,O
1526,Stanford,B
1526,word,I
1526,tokenizer,I
1526,.,O
1527,Then,O
1527,a,O
1527,bi-directional,B
1527,LSTM,I
1527,is,O
1527,used,B
1527,for,I
1527,each,B
1527,modality,I
1527,to,B
1527,obtain,I
1527,contextual,B
1527,representations,I
1527,.,O
1528,We,O
1528,use,B
1528,pre-trained,B
1528,Glo,I
1528,Ve,I
1528,word,I
1528,embeddings,I
1528,",",O
1528,which,O
1528,is,O
1528,fixed,B
1528,during,I
1528,training,B
1528,.,O
1529,We,O
1529,then,O
1529,use,O
1529,a,O
1529,linear,B
1529,transformation,I
1529,to,B
1529,compress,I
1529,the,O
1529,image,B
1529,feature,I
1529,into,B
1529,100,B
1529,dimensional,I
1529,.,O
1530,We,O
1530,use,O
1530,the,O
1530,AdaDelta,B
1530,optimizer,I
1530,and,O
1530,an,O
1530,initial,B
1530,learning,I
1530,rate,I
1530,of,B
1530,0.5,B
1530,to,B
1530,train,I
1530,for,I
1530,200,B
1530,epochs,I
1530,with,B
1530,a,O
1530,dropout,B
1530,rate,O
1530,of,O
1530,0.3,B
1530,..,O
1531,For,B
1531,image,B
1531,/,I
1531,video,I
1531,embedding,I
1531,",",O
1531,we,O
1531,extract,B
1531,fixed,B
1531,-,I
1531,size,I
1531,features,I
1531,using,B
1531,the,O
1531,pre-trained,B
1531,CNN,I
1531,model,I
1531,",",O
1531,Inception,B
1531,-,O
1531,ResNet,O
1531,",",O
1531,by,B
1531,concatenating,I
1531,the,O
1531,pool5,B
1531,layer,I
1531,and,I
1531,classification,I
1531,layer,O
1531,'s,O
1531,output,O
1531,before,B
1531,softmax,B
1531,.,O
1532,Given,B
1532,a,O
1532,hidden,B
1532,state,I
1532,size,I
1532,of,B
1532,d,B
1532,",",O
1532,which,O
1532,is,O
1532,set,B
1532,to,I
1532,50,B
1532,",",O
1532,we,O
1532,concatenate,B
1532,the,O
1532,output,B
1532,of,O
1532,both,B
1532,directions,I
1532,of,O
1532,the,O
1532,LSTM,B
1532,and,O
1532,get,B
1532,a,O
1532,question,B
1532,matrix,I
1532,Q,I
1532,?,O
1533,R,O
1533,2,O
1533,d,O
1533,M,O
1533,and,O
1533,context,B
1533,tensor,I
1533,H,I
1533,?,O
1534,R,O
1534,2dV,O
1534,KN,O
1534,6,O
1534,for,B
1534,all,B
1534,media,I
1534,documents,I
1534,.,O
1535,In,B
1535,the,O
1535,dropout,B
1535,operation,I
1535,",",O
1535,we,O
1535,randomly,B
1535,set,I
1535,the,O
1535,hidden,B
1535,unit,I
1535,activities,I
1535,to,B
1535,zero,B
1535,with,B
1535,a,O
1535,probability,B
1535,of,B
1535,0.5,B
1535,during,B
1535,training,B
1535,.,O
1536,We,O
1536,reshape,B
1536,the,O
1536,context,B
1536,tensor,I
1536,into,B
1536,H,O
1536,?,O
1537,To,O
1537,select,O
1537,the,O
1537,best,B
1537,hyperparmeters,I
1537,",",O
1537,we,O
1537,randomly,B
1537,select,O
1537,20,B
1537,%,I
1537,of,B
1537,the,O
1537,official,B
1537,training,I
1537,set,I
1537,as,B
1537,the,O
1537,validation,B
1537,set,O
1537,.,O
1538,FVTA,B
1538,outperforms,B
1538,other,B
1538,attention,I
1538,models,I
1538,on,B
1538,finding,I
1538,the,O
1538,relevant,B
1538,photos,I
1538,for,B
1538,the,O
1538,question,B
1538,.,O
1539,To,O
1539,evaluate,B
1539,the,O
1539,FVTA,B
1539,attention,I
1539,mechanism,I
1539,",",O
1539,we,O
1539,first,B
1539,replace,I
1539,our,B
1539,kernel,I
1539,tensor,I
1539,with,B
1539,simple,B
1539,cosine,I
1539,similarity,I
1539,function,I
1539,.,O
1540,Results,O
1540,show,B
1540,that,I
1540,standard,B
1540,cosine,I
1540,similarity,I
1540,is,O
1540,inferior,B
1540,to,I
1540,our,B
1540,similarity,O
1540,function,O
1540,.,O
1541,For,O
1541,ablating,O
1541,intra-sequence,B
1541,dependency,I
1541,",",O
1541,we,O
1541,use,B
1541,the,O
1541,representations,B
1541,from,B
1541,the,O
1541,last,B
1541,timestep,I
1541,of,B
1541,each,B
1541,context,I
1541,document,I
1541,.,O
1542,For,O
1542,ablating,O
1542,cross,B
1542,sequence,I
1542,interaction,I
1542,",",O
1542,we,O
1542,average,B
1542,all,B
1542,attended,I
1542,context,I
1542,representation,I
1542,from,B
1542,different,B
1542,modalities,I
1542,to,B
1542,get,I
1542,the,O
1542,final,B
1542,context,O
1542,vector,O
1542,.,O
1543,Both,O
1543,aspects,O
1543,of,B
1543,correlation,O
1543,of,O
1543,the,O
1543,FVTA,B
1543,attention,I
1543,tensor,I
1543,contribute,B
1543,towards,I
1543,the,O
1543,model,B
1543,'s,I
1543,performance,I
1543,",",O
1543,while,B
1543,intra-sequence,B
1543,dependency,I
1543,shows,B
1543,more,B
1543,importance,I
1543,in,O
1543,this,O
1543,experiment,O
1543,.,O
1544,We,O
1544,compare,B
1544,the,O
1544,effectiveness,B
1544,of,B
1544,context,B
1544,-,I
1544,aware,I
1544,question,B
1544,attention,I
1544,by,B
1544,removing,I
1544,the,O
1544,question,O
1544,attention,O
1544,and,O
1544,use,B
1544,the,O
1544,last,B
1544,timestep,I
1544,of,O
1544,the,O
1544,LSTM,B
1544,output,I
1544,from,B
1544,the,O
1544,question,O
1544,as,B
1544,the,O
1544,question,O
1544,representation,O
1544,.,O
1545,It,O
1545,shows,B
1545,the,O
1545,question,B
1545,attention,I
1545,provides,B
1545,slight,B
1545,improvement,I
1545,.,O
1546,In,O
1546,this,O
1546,paper,O
1546,",",O
1546,we,O
1546,propose,B
1546,a,O
1546,novel,B
1546,model,I
1546,dubbed,I
1546,Piecewise,I
1546,Convolutional,I
1546,Neural,I
1546,Networks,I
1546,(,I
1546,PC,I
1546,-,I
1546,NNs,I
1546,),I
1546,with,B
1546,multi-instance,B
1546,learning,I
1546,to,O
1546,address,O
1546,the,O
1546,two,O
1546,problems,O
1546,described,O
1546,above,O
1546,.,O
1547,Finally,O
1547,",",O
1547,we,O
1547,train,B
1547,FVTA,B
1547,without,I
1547,photos,I
1547,to,B
1547,see,I
1547,the,O
1547,contribution,B
1547,of,B
1547,visual,B
1547,information,I
1547,.,O
1548,The,O
1548,result,B
1548,is,B
1548,quite,B
1548,good,I
1548,but,O
1548,it,O
1548,is,O
1548,perhaps,O
1548,not,O
1548,surprising,O
1548,due,O
1548,to,O
1548,the,O
1548,language,O
1548,bias,O
1548,in,O
1548,the,O
1548,questions,O
1548,and,O
1548,answers,O
1548,of,O
1548,the,O
1548,dataset,O
1548,",",O
1548,which,O
1548,is,O
1548,not,O
1548,uncommon,O
1548,in,O
1548,VQA,O
1548,dataset,O
1548,and,O
1548,in,O
1548,Visual7W,O
1548,.,O
1549,In,O
1549,the,O
1549,MovieQA,B
1549,dataset,I
1549,",",O
1549,each,O
1549,QA,O
1549,is,O
1549,given,O
1549,a,O
1549,set,O
1549,of,B
1549,N,O
1549,movie,O
1549,clips,O
1549,of,O
1549,the,O
1549,same,O
1549,movie,O
1549,",",O
1549,and,O
1549,each,O
1549,clip,O
1549,comes,O
1549,with,B
1549,subtitles,O
1549,.,O
1550,We,O
1550,implement,B
1550,FVTA,B
1550,network,I
1550,for,B
1550,Movie,B
1550,QA,I
1550,task,I
1550,with,O
1550,modality,B
1550,number,I
1550,of,O
1550,2,B
1550,(,I
1550,video,I
1550,&,I
1550,text,I
1550,),I
1550,.,O
1551,We,O
1551,set,B
1551,the,O
1551,maximum,B
1551,number,I
1551,of,I
1551,movie,I
1551,clips,I
1551,per,I
1551,question,I
1551,to,B
1551,N,B
1551,=,I
1551,20,I
1551,",",O
1551,the,O
1551,maximum,O
1551,number,O
1551,of,O
1551,frames,O
1551,to,O
1551,consider,O
1551,to,O
1551,F,B
1551,=,O
1551,10,O
1551,",",O
1551,the,O
1551,maximum,O
1551,number,O
1551,of,O
1551,subtitle,O
1551,sentences,O
1551,in,O
1551,a,O
1551,clip,O
1551,to,O
1551,K,B
1551,=,O
1551,100,O
1551,and,O
1551,the,O
1551,maximum,O
1551,words,O
1551,to,O
1551,V,B
1551,=,O
1551,10,O
1551,.,O
1552,We,O
1552,use,B
1552,the,O
1552,AdaDelta,B
1552,optimizer,I
1552,with,B
1552,a,O
1552,minibatch,B
1552,of,B
1552,16,B
1552,and,O
1552,an,O
1552,initial,B
1552,learning,I
1552,rate,I
1552,of,O
1552,0.5,B
1552,to,O
1552,trained,B
1552,for,I
1552,300,B
1552,epochs,I
1552,.,O
1553,FVTA,O
1553,model,O
1553,outperforms,B
1553,all,B
1553,baseline,I
1553,methods,I
1553,and,O
1553,achieves,B
1553,comparable,B
1553,performance,I
1553,to,B
1553,the,I
1553,state,B
1553,-,I
1553,of,I
1553,-,O
1553,the,O
1553,-,O
1553,art,O
1553,result,O
1553,2,O
1553,on,B
1553,the,O
1553,MovieQA,B
1553,test,I
1553,server,I
1553,.,O
1554,Our,O
1554,accuracy,B
1554,is,B
1554,0.410,B
1554,(,O
1554,vs,B
1554,0.387,B
1554,by,B
1554,RWMN,B
1554,),O
1554,on,B
1554,the,O
1554,validation,B
1554,set,I
1554,and,O
1554,0.373,B
1554,(,O
1554,vs,O
1554,0.363,B
1554,),O
1554,on,O
1554,the,O
1554,test,B
1554,set,O
1554,.,O
1555,Benefiting,O
1555,from,O
1555,such,O
1555,modeling,O
1555,ability,O
1555,",",O
1555,FVTA,B
1555,consistently,B
1555,outperforms,I
1555,the,O
1555,classical,B
1555,attention,I
1555,models,I
1555,including,B
1555,soft,B
1555,attention,O
1555,",",O
1555,MCB,B
1555,and,O
1555,TGIF,B
1555,.,O
1556,To,O
1556,address,O
1556,these,O
1556,two,O
1556,challenges,O
1556,",",O
1556,we,O
1556,propose,B
1556,a,O
1556,focal,B
1556,visual,I
1556,-,I
1556,text,I
1556,attention,I
1556,(,I
1556,FVTA,I
1556,),I
1556,model,I
1556,for,B
1556,sequential,B
1556,data,I
1557,To,O
1557,address,O
1557,the,O
1557,first,O
1557,problem,O
1557,",",O
1557,distant,B
1557,supervised,I
1557,relation,I
1557,extraction,I
1557,is,O
1557,treated,B
1557,as,I
1557,a,O
1557,multi-instance,B
1557,problem,O
1557,similar,O
1557,to,O
1557,previous,O
1557,studies,O
1557,.,O
1558,We,O
1558,propose,O
1558,a,O
1558,novel,B
1558,attention,I
1558,kernel,I
1558,for,B
1558,VQA,B
1558,on,B
1558,visual,B
1558,-,I
1558,text,I
1558,data,I
1558,.,O
1559,Inspired,O
1559,by,O
1559,this,O
1559,process,O
1559,",",O
1559,FVTA,B
1559,first,O
1559,learns,B
1559,to,I
1559,localize,B
1559,relevant,B
1559,information,I
1559,within,B
1559,a,O
1559,few,B
1559,",",O
1559,small,O
1559,",",O
1559,temporally,O
1559,consecutive,O
1559,regions,O
1559,over,B
1559,the,O
1559,input,B
1559,sequences,I
1559,",",O
1559,and,O
1559,learns,O
1559,to,O
1559,infer,B
1559,an,O
1559,answer,B
1559,based,B
1559,on,I
1559,the,O
1559,cross-modal,B
1559,statistics,I
1559,pooled,B
1559,from,I
1559,these,B
1559,regions,O
1559,.,O
1560,FVTA,O
1560,proposes,B
1560,a,O
1560,novel,B
1560,kernel,I
1560,to,B
1560,compute,I
1560,the,O
1560,attention,B
1560,tensor,I
1560,that,O
1560,jointly,B
1560,models,I
1560,the,O
1560,latent,B
1560,information,I
1560,in,B
1560,three,B
1560,sources,I
1560,:,O
1561,1,O
1561,),O
1561,answer,B
1561,-,I
1561,signaling,I
1561,words,I
1561,in,B
1561,the,O
1561,question,B
1561,",",O
1561,2,O
1561,),O
1561,temporal,B
1561,correlation,I
1561,within,B
1561,a,O
1561,sequence,B
1561,",",O
1561,and,O
1561,3,O
1561,),O
1561,cross-modal,B
1561,interaction,I
1561,between,B
1561,the,O
1561,text,B
1561,and,O
1561,image,O
1561,.,O
1562,FVTA,O
1562,attention,B
1562,allows,B
1562,for,I
1562,collective,B
1562,reasoning,I
1562,by,B
1562,the,O
1562,attention,O
1562,kernel,O
1562,learned,B
1562,over,I
1562,a,O
1562,few,B
1562,",",I
1562,small,I
1562,",",O
1562,consecutive,O
1562,sub-sequences,O
1562,of,B
1562,text,B
1562,and,I
1562,image,I
1562,.,O
1563,Focal,O
1563,Visual,B
1563,-,O
1563,Text,O
1563,Attention,O
1563,for,O
1563,Visual,O
1563,Question,O
1563,Answering,O
1564,Extending,O
1564,from,O
1564,VQA,B
1564,on,O
1564,a,O
1564,single,O
1564,image,O
1564,",",O
1564,this,O
1564,paper,O
1564,considers,O
1564,the,O
1564,following,O
1564,problem,O
1564,:,O
1565,RACE,B
1566,The,O
1566,key,B
1566,competitors,I
1566,are,B
1566,the,O
1566,Stanford,O
1566,Attention,O
1566,Reader,O
1566,(,O
1566,Stanford,O
1566,AR,O
1566,),O
1566,",",O
1566,Gated,B
1566,Attention,O
1566,Reader,O
1566,(,O
1566,GA,O
1566,),O
1566,",",O
1566,and,O
1566,Dynamic,B
1566,Fusion,I
1566,Networks,I
1566,(,O
1566,DFN,O
1566,),O
1566,.,O
1567,The,O
1567,piecewise,B
1567,max,I
1567,pooling,I
1567,procedure,I
1567,returns,B
1567,the,O
1567,maximum,O
1567,value,O
1567,in,B
1567,each,B
1567,segment,I
1567,instead,B
1567,of,I
1567,a,O
1567,single,B
1567,maximum,O
1567,value,O
1567,over,B
1567,the,O
1567,entire,B
1567,sentence,I
1567,.,O
1568,SearchQA,B
1569,The,O
1569,main,B
1569,competitor,I
1569,baseline,I
1569,is,B
1569,the,O
1569,AMANDA,B
1569,model,I
1569,proposed,O
1569,by,O
1569,.,O
1570,NarrativeQA,B
1571,We,O
1571,compete,O
1571,on,O
1571,the,O
1571,summaries,O
1571,setting,O
1571,",",O
1571,in,O
1571,which,O
1571,the,O
1571,baselines,B
1571,are,B
1571,a,O
1571,context,B
1571,-,I
1571,less,I
1571,sequence,I
1571,to,I
1571,sequence,O
1571,(,O
1571,seq2seq,O
1571,),O
1571,model,O
1571,",",O
1571,ASR,B
1571,and,O
1571,BiDAF,B
1571,.,O
1572,We,O
1572,implement,B
1572,all,B
1572,models,I
1572,in,B
1572,TensorFlow,B
1572,.,O
1573,Word,O
1573,embeddings,O
1573,are,O
1573,initialized,B
1573,with,I
1573,300d,B
1573,Glo,I
1573,Ve,I
1573,vectors,I
1573,and,O
1573,are,O
1573,not,B
1573,fine,I
1573,-,I
1573,tuned,I
1573,during,I
1573,training,B
1573,.,O
1574,Dropout,O
1574,rate,O
1574,is,O
1574,tuned,B
1574,amongst,I
1574,{,B
1574,0.1,I
1574,",",I
1574,0.2,I
1574,",",O
1574,0.3,O
1574,},O
1574,on,B
1574,all,B
1574,layers,I
1574,including,B
1574,the,O
1574,embedding,B
1574,layer,I
1574,.,O
1575,The,O
1575,batch,B
1575,size,I
1575,is,O
1575,set,B
1575,to,I
1575,64/256/32,B
1575,accordingly,O
1575,.,O
1576,The,O
1576,maximum,B
1576,sequence,I
1576,lengths,I
1576,are,B
1576,500/200/1100,B
1576,respectively,O
1576,.,O
1577,All,O
1577,models,O
1577,are,O
1577,trained,O
1577,and,O
1577,all,O
1577,runtime,B
1577,benchmarks,I
1577,are,O
1577,based,B
1577,on,I
1577,a,O
1577,TitanXP,B
1577,GPU,I
1577,.,O
1578,We,O
1578,design,B
1578,an,O
1578,objective,B
1578,function,I
1578,at,B
1578,the,O
1578,bag,B
1578,level,I
1578,.,O
1579,We,O
1579,adopt,B
1579,the,O
1579,Adam,B
1579,optimizer,I
1579,(,O
1579,Kingma,O
1579,and,O
1579,Ba,O
1579,",",O
1579,2014,O
1579,),O
1579,with,B
1579,a,O
1579,learning,B
1579,rate,I
1579,of,B
1579,0.0003/,B
1579,0.001/0.001,I
1579,for,B
1579,RACE,B
1579,/,I
1579,SearchQA,I
1579,/,O
1579,Narrative,O
1579,QA,O
1579,respectively,O
1579,.,O
1580,For,B
1580,Narrative,B
1580,QA,I
1580,",",O
1580,we,O
1580,use,B
1580,the,O
1580,Rouge,B
1580,-,I
1580,L,I
1580,score,I
1580,to,I
1580,find,I
1580,the,O
1580,best,B
1580,approximate,I
1580,answer,I
1580,relative,B
1580,to,O
1580,the,O
1580,human,B
1580,written,I
1580,answer,O
1580,for,O
1580,training,O
1580,the,O
1580,span,B
1580,model,I
1580,.,O
1581,To,O
1581,this,O
1581,end,O
1581,",",O
1581,we,O
1581,propose,B
1581,a,O
1581,new,B
1581,compositional,I
1581,encoder,I
1581,that,O
1581,can,O
1581,either,O
1581,be,B
1581,used,I
1581,in,B
1581,place,I
1581,of,B
1581,standard,B
1581,RNN,I
1581,encoders,I
1581,or,O
1581,serve,B
1581,as,I
1581,a,O
1581,new,O
1581,module,O
1581,that,O
1581,is,O
1581,complementary,O
1581,to,O
1581,existing,B
1581,neural,I
1581,architectures,I
1581,.,O
1582,Our,O
1582,proposed,O
1582,encoder,O
1582,leverages,B
1582,dilated,B
1582,compositions,I
1582,to,B
1582,model,I
1582,relationships,B
1582,across,B
1582,multiple,B
1582,granularities,I
1582,.,O
1583,The,O
1583,output,B
1583,of,B
1583,the,O
1583,dilated,B
1583,composition,I
1583,mechanism,I
1583,acts,B
1583,as,I
1583,gating,B
1583,functions,I
1583,",",O
1583,which,O
1583,are,O
1583,then,O
1583,used,B
1583,to,I
1583,learn,I
1583,compositional,B
1583,representations,I
1583,of,O
1583,the,O
1583,input,B
1583,sequence,I
1583,.,O
1584,That,O
1584,is,O
1584,",",O
1584,for,B
1584,a,O
1584,given,B
1584,word,I
1584,in,B
1584,the,O
1584,target,B
1584,sequence,I
1584,",",O
1584,our,B
1584,encoder,I
1584,exploits,B
1584,both,O
1584,long,B
1584,-,I
1584,term,I
1584,(,I
1584,far,I
1584,),I
1584,and,I
1584,short,I
1584,-,O
1584,term,O
1584,(,O
1584,near,O
1584,),O
1584,information,B
1584,to,B
1584,decide,I
1584,how,O
1584,much,O
1584,information,O
1584,to,O
1584,retain,B
1584,for,O
1584,it,O
1584,.,O
1585,Multi,O
1585,-,O
1585,Granular,O
1585,Sequence,O
1585,Encoding,O
1585,via,O
1585,Dilated,O
1585,Compositional,O
1585,Units,O
1585,for,O
1585,Reading,B
1585,Comprehension,I
1586,This,O
1586,paper,O
1586,presents,O
1586,a,O
1586,new,O
1586,compositional,O
1586,encoder,O
1586,for,O
1586,reading,B
1586,comprehension,I
1586,(,I
1586,RC,I
1586,),I
1586,.,O
1587,We,O
1587,conduct,O
1587,experiments,O
1587,on,O
1587,three,O
1587,RC,B
1587,datasets,O
1587,",",O
1587,showing,O
1587,that,O
1587,our,O
1587,proposed,O
1587,encoder,O
1587,demonstrates,O
1587,very,O
1587,promising,O
1587,results,O
1587,both,O
1587,as,O
1587,a,O
1587,standalone,O
1587,encoder,O
1587,as,O
1587,well,O
1587,as,O
1587,a,O
1587,complementary,O
1587,building,O
1587,block,O
1587,.,O
1588,reports,O
1588,our,O
1588,results,O
1588,on,B
1588,the,O
1588,RACE,B
1588,benchmark,I
1588,dataset,I
1588,.,O
1589,In,B
1589,the,O
1589,learning,B
1589,process,I
1589,",",O
1589,the,O
1589,uncertainty,B
1589,of,B
1589,instance,B
1589,labels,I
1589,can,O
1589,be,O
1589,taken,O
1589,into,O
1589,account,O
1589,;,O
1589,this,O
1589,alleviates,B
1589,the,O
1589,wrong,B
1589,label,I
1589,problem,I
1589,.,O
1590,Our,O
1590,proposed,O
1590,DCU,O
1590,model,O
1590,achieves,B
1590,the,O
1590,best,B
1590,result,I
1590,for,B
1590,both,O
1590,single,B
1590,models,I
1590,and,O
1590,ensemble,B
1590,models,O
1590,.,O
1591,The,O
1591,best,B
1591,single,I
1591,model,I
1591,score,I
1591,from,B
1591,RACE,B
1591,-,I
1591,H,I
1591,and,O
1591,RACE,O
1591,-,O
1591,M,O
1591,alternates,B
1591,between,I
1591,Sim,B
1591,-,O
1591,DCU,B
1591,and,O
1591,DCU,O
1591,.,O
1592,We,O
1592,outperform,B
1592,highly,B
1592,complex,I
1592,models,I
1592,such,B
1592,as,I
1592,DFN,B
1592,.,O
1593,We,O
1593,also,O
1593,pull,B
1593,ahead,I
1593,of,I
1593,other,B
1593,recent,I
1593,baselines,I
1593,such,B
1593,as,I
1593,ElimiNet,B
1593,and,O
1593,GA,B
1593,by,B
1593,at,B
1593,least,I
1593,5,I
1593,%,I
1593,.,O
1594,Table,O
1594,2,O
1594,reports,O
1594,our,O
1594,results,O
1594,on,O
1594,the,O
1594,Search,B
1594,QA,I
1594,dataset,I
1594,.,O
1595,We,O
1595,achieve,B
1595,the,O
1595,same,B
1595,accuracy,I
1595,as,B
1595,AMANDA,B
1595,without,B
1595,using,I
1595,any,O
1595,LSTM,B
1595,or,I
1595,GRU,I
1595,encoder,I
1595,.,O
1596,Finally,O
1596,",",O
1596,the,O
1596,hybrid,B
1596,combination,I
1596,",",O
1596,DCU,O
1596,-,O
1596,LSTM,O
1596,significantly,B
1596,outperforms,I
1596,AMANDA,B
1596,by,B
1596,3,B
1596,%,I
1596,.,O
1597,Contrary,O
1597,to,O
1597,MCQ,O
1597,-,O
1597,based,O
1597,datasets,O
1597,",",O
1597,we,O
1597,found,O
1597,that,O
1597,reports,O
1597,our,O
1597,results,O
1597,on,O
1597,the,O
1597,NarrativeQA,B
1597,benchmark,I
1597,.,O
1598,First,O
1598,",",O
1598,we,O
1598,observe,B
1598,that,I
1598,300d,B
1598,DCU,I
1598,can,O
1598,achieve,B
1598,comparable,B
1598,performance,I
1598,with,B
1598,BiDAF,B
1598,.,O
1599,Finally,O
1599,",",O
1599,DCU,B
1599,-,I
1599,LSTM,I
1599,significantly,B
1599,outperforms,I
1599,all,B
1599,models,I
1599,in,B
1599,terms,I
1599,of,I
1599,ROUGE,B
1599,-,O
1599,L,O
1599,",",O
1599,including,B
1599,BiDAF,B
1599,on,O
1599,this,O
1599,dataset,O
1599,.,O
1600,Our,O
1600,stacked,B
1600,bi,I
1600,-,I
1600,LSTMs,I
1600,(,O
1600,Section,O
1600,3.1,O
1600,),O
1600,has,O
1600,3,B
1600,layers,I
1600,with,B
1600,200,B
1600,-,O
1600,dimensional,O
1600,hidden,O
1600,states,O
1600,and,O
1600,highway,B
1600,connections,I
1600,.,O
1601,To,O
1601,address,O
1601,the,O
1601,second,O
1601,problem,O
1601,",",O
1601,we,O
1601,adopt,B
1601,convolutional,B
1601,architecture,I
1601,to,O
1601,automatically,O
1601,learn,O
1601,relevant,B
1601,features,I
1601,without,B
1601,complicated,B
1601,NLP,I
1601,preprocessing,I
1601,inspired,O
1601,by,O
1601,.,O
1602,Performance,O
1602,improvement,O
1602,over,B
1602,the,O
1602,vanilla,B
1602,BiLSTM,I
1602,model,I
1602,ranges,B
1602,from,I
1602,1,O
1602,%,O
1602,?,O
1603,3,O
1603,%,O
1603,across,B
1603,all,B
1603,metrics,I
1603,",",O
1603,suggesting,O
1603,that,O
1603,DCU,O
1603,encoders,O
1603,are,O
1603,also,O
1603,effective,O
1603,as,O
1603,a,O
1603,complementary,O
1603,neural,O
1603,building,O
1603,block,O
1603,.,O
1604,We,O
1604,conduct,O
1604,an,O
1604,ablation,O
1604,study,O
1604,on,B
1604,the,O
1604,New,B
1604,s,I
1604,QA,I
1604,development,I
1604,set,I
1604,.,O
1605,Finally,O
1605,",",O
1605,in,B
1605,(,O
1605,8,O
1605,-,O
1605,9,O
1605,),O
1605,",",O
1605,we,O
1605,varied,O
1605,the,O
1605,FM,O
1605,with,O
1605,linear,O
1605,and,O
1605,nonlinear,O
1605,feed,O
1605,-,O
1605,forward,O
1605,layers,O
1605,.,O
1606,From,O
1606,(,O
1606,1,O
1606,),O
1606,",",O
1606,we,O
1606,observe,B
1606,a,O
1606,significant,B
1606,gap,I
1606,in,B
1606,performance,B
1606,between,B
1606,DECAPROP,B
1606,and,I
1606,R,I
1606,-,I
1606,NET,I
1606,.,O
1607,We,O
1607,observe,O
1607,that,O
1607,the,O
1607,superiority,B
1607,of,B
1607,DECAPROP,B
1607,over,B
1607,R,B
1607,-,I
1607,NET,I
1607,is,B
1607,consistent,B
1607,and,I
1607,relatively,I
1607,stable,I
1607,.,O
1608,Overall,O
1608,",",O
1608,the,O
1608,key,B
1608,insight,I
1608,is,B
1608,that,O
1608,all,B
1608,model,I
1608,components,I
1608,are,B
1608,crucial,I
1608,to,I
1608,DECAPROP,B
1608,.,O
1609,Notably,O
1609,",",O
1609,the,O
1609,DECAENC,B
1609,seems,B
1609,to,B
1609,contribute,I
1609,the,O
1609,most,B
1609,to,O
1609,the,O
1609,over,B
1609,all,I
1609,performance,I
1609,.,O
1610,NewsQA,B
1611,On,O
1611,this,O
1611,dataset,O
1611,",",O
1611,the,O
1611,key,B
1611,competitors,I
1611,are,B
1611,BiDAF,B
1611,",",O
1611,Match,B
1611,-,I
1611,LSTM,I
1611,",",O
1611,FastQA,B
1611,/,I
1611,Fast,I
1611,QA,I
1611,-,O
1611,Ext,O
1611,",",O
1611,R2-BiLSTM,B
1611,",",O
1611,AMANDA,B
1611,.,O
1612,The,O
1612,key,B
1612,competitors,I
1612,on,O
1612,this,O
1612,dataset,O
1612,are,B
1612,BiDAF,B
1612,and,O
1612,the,O
1612,Reinforced,B
1612,Ranker,I
1612,-,I
1612,Reader,I
1612,(,I
1612,R,I
1612,3,I
1612,),I
1612,.,O
1613,To,O
1613,capture,O
1613,structural,B
1613,and,I
1613,other,I
1613,latent,I
1613,information,I
1613,",",O
1613,we,O
1613,divide,B
1613,the,O
1613,convolution,B
1613,results,I
1613,into,B
1613,three,B
1613,segments,I
1613,based,B
1613,on,I
1613,the,O
1613,positions,B
1613,of,I
1613,the,O
1613,two,B
1613,given,I
1613,entities,I
1613,and,O
1613,devise,B
1613,a,O
1613,piecewise,B
1613,max,I
1613,pooling,I
1613,layer,I
1613,instead,B
1613,of,O
1613,the,O
1613,single,B
1613,max,O
1613,pooling,O
1613,layer,O
1613,.,O
1614,SearchQA,B
1615,The,O
1615,competitor,B
1615,baselines,I
1615,on,O
1615,this,O
1615,dataset,O
1615,are,B
1615,Attention,B
1615,Sum,I
1615,Reader,I
1615,(,I
1615,ASR,I
1615,),I
1615,",",O
1615,Focused,B
1615,Hierarchical,I
1615,RNNs,I
1615,(,O
1615,FH,O
1615,-,O
1615,RNN,O
1615,),O
1615,",",O
1615,AMANDA,B
1615,",",O
1615,BiDAF,B
1615,",",O
1615,AQA,B
1615,and,O
1615,the,O
1615,Reinforced,B
1615,Ranker,I
1615,-,O
1615,Reader,O
1615,(,O
1615,R,O
1615,3,O
1615,),O
1615,.,O
1616,We,O
1616,compare,B
1616,with,I
1616,the,O
1616,baselines,B
1616,in,O
1616,the,O
1616,original,O
1616,paper,O
1616,",",O
1616,namely,B
1616,Seq2Seq,B
1616,",",O
1616,Attention,B
1616,Sum,I
1616,Reader,I
1616,and,O
1616,BiDAF,B
1616,.,O
1617,We,O
1617,also,O
1617,compare,O
1617,with,O
1617,the,O
1617,recent,B
1617,BiAttention,I
1617,+,I
1617,MRU,I
1617,model,I
1617,.,O
1618,Our,O
1618,model,B
1618,is,O
1618,implemented,B
1618,in,I
1618,Tensorflow,B
1618,.,O
1619,The,O
1619,sequence,B
1619,lengths,I
1619,are,O
1619,capped,B
1619,at,I
1619,800/700/1500/1100,B
1619,for,B
1619,News,B
1619,QA,I
1619,",",I
1619,Search,I
1619,QA,O
1619,",",O
1619,Quasar,O
1619,-,O
1619,T,O
1619,and,O
1619,Narrative,O
1619,QA,O
1619,respectively,O
1619,.,O
1620,Batch,O
1620,size,O
1620,is,O
1620,tuned,B
1620,amongst,I
1620,{,B
1620,16,I
1620,",",I
1620,32,I
1620,",",O
1620,64,O
1620,},O
1620,.,O
1621,Dropout,O
1621,rate,O
1621,is,O
1621,tuned,B
1621,amongst,I
1621,{,B
1621,0.1,I
1621,",",I
1621,0.2,I
1621,",",O
1621,0.3,O
1621,},O
1621,and,O
1621,applied,B
1621,to,I
1621,all,B
1621,RNN,I
1621,and,O
1621,fully,O
1621,-,O
1621,connected,O
1621,layers,O
1621,.,O
1622,The,O
1622,size,B
1622,of,B
1622,the,O
1622,character,B
1622,embeddings,I
1622,is,O
1622,set,B
1622,to,I
1622,8,B
1622,and,O
1622,the,O
1622,character,O
1622,RNN,O
1622,is,O
1622,set,O
1622,to,O
1622,the,O
1622,same,O
1622,as,O
1622,the,O
1622,word,B
1622,-,I
1622,level,I
1622,RNN,O
1622,encoders,O
1622,.,O
1623,The,O
1623,maximum,B
1623,characters,I
1623,per,I
1623,word,I
1623,is,O
1623,set,B
1623,to,I
1623,16,B
1623,.,O
1624,The,O
1624,number,B
1624,of,I
1624,layers,I
1624,in,B
1624,DECAENC,B
1624,is,O
1624,set,B
1624,to,I
1624,3,B
1624,and,O
1624,the,O
1624,number,O
1624,of,O
1624,factors,O
1624,in,O
1624,the,O
1624,factorization,B
1624,kernel,I
1624,is,O
1624,set,O
1624,to,O
1624,64,B
1624,.,O
1625,We,O
1625,use,B
1625,Adadelta,B
1625,with,B
1625,?,O
1626,=,O
1626,0.5,O
1626,for,B
1626,News,B
1626,QA,I
1626,",",O
1626,Adam,B
1626,with,B
1626,?,O
1627,=,O
1627,0.001,O
1627,for,B
1627,Search,B
1627,QA,I
1627,",",O
1627,Quasar,B
1627,-,I
1627,T,I
1627,and,O
1627,Narrative,B
1627,QA,O
1627,.,O
1628,We,O
1628,use,O
1628,the,O
1628,CUDNN,B
1628,implementation,I
1628,of,B
1628,the,O
1628,RNN,B
1628,encoder,I
1628,.,O
1629,We,O
1629,use,O
1629,a,O
1629,learning,B
1629,rate,I
1629,decay,I
1629,factor,I
1629,of,B
1629,2,B
1629,and,O
1629,patience,B
1629,of,O
1629,3,B
1629,epochs,I
1629,whenever,O
1629,the,O
1629,EM,O
1629,(,O
1629,or,O
1629,ROUGE,O
1629,-,O
1629,L,O
1629,),O
1629,score,O
1629,on,O
1629,the,O
1629,development,O
1629,set,O
1629,does,O
1629,not,O
1629,increase,O
1629,.,O
1630,The,O
1630,choice,B
1630,of,I
1630,the,O
1630,RNN,B
1630,encoder,I
1630,is,O
1630,tuned,B
1630,between,I
1630,GRU,B
1630,and,I
1630,LSTM,I
1630,cells,I
1630,and,O
1630,the,O
1630,hidden,B
1630,size,I
1630,is,O
1630,tuned,O
1630,amongst,O
1630,{,B
1630,32,I
1630,",",I
1630,50,I
1630,",",O
1630,64,O
1630,",",O
1630,75,O
1630,},O
1630,.,O
1631,We,O
1631,apply,B
1631,variational,B
1631,dropout,I
1631,in,B
1631,-,I
1631,between,I
1631,RNN,B
1631,layers,I
1631,.,O
1632,We,O
1632,initialize,B
1632,the,O
1632,word,B
1632,embeddings,I
1632,with,B
1632,300D,B
1632,Glo,I
1632,Ve,I
1632,embeddings,O
1632,and,O
1632,are,O
1632,fixed,B
1632,during,I
1632,training,B
1632,.,O
1633,Firstly,O
1633,",",O
1633,our,O
1633,network,B
1633,is,B
1633,densely,B
1633,connected,I
1633,",",O
1633,connecting,O
1633,every,O
1633,layer,O
1633,of,O
1633,P,O
1633,with,O
1633,every,O
1633,layer,O
1633,of,O
1633,Q,O
1633,.,O
1634,The,O
1634,propagated,B
1634,features,I
1634,are,O
1634,collectively,B
1634,passed,I
1634,into,I
1634,prediction,B
1634,layers,I
1634,",",O
1634,which,O
1634,effectively,B
1634,connect,I
1634,shallow,B
1634,layers,O
1634,to,B
1634,deeper,B
1634,layers,O
1634,.,O
1635,To,O
1635,address,O
1635,the,O
1635,first,O
1635,problem,O
1635,",",O
1635,distant,B
1635,supervised,I
1635,relation,I
1635,extraction,I
1635,is,O
1635,treated,O
1635,as,O
1635,a,O
1635,multi-instance,O
1635,problem,O
1635,similar,O
1635,to,O
1635,previous,O
1635,studies,O
1635,.,O
1636,To,O
1636,this,O
1636,end,O
1636,",",O
1636,we,O
1636,propose,B
1636,efficient,B
1636,Bidirectional,I
1636,Attention,I
1636,Connectors,I
1636,(,I
1636,BAC,I
1636,),I
1636,as,B
1636,a,O
1636,base,B
1636,building,I
1636,block,I
1636,to,O
1636,connect,O
1636,two,B
1636,sequences,I
1636,at,B
1636,arbitrary,B
1636,layers,I
1636,.,O
1637,Overall,O
1637,",",O
1637,we,O
1637,propose,O
1637,DECAPROP,B
1637,(,I
1637,Densely,I
1637,Connected,I
1637,Attention,I
1637,Propagation,I
1637,),I
1637,",",O
1637,a,O
1637,novel,B
1637,architecture,I
1637,for,B
1637,reading,B
1637,comprehension,I
1637,.,O
1638,The,O
1638,key,O
1638,idea,O
1638,is,B
1638,to,B
1638,compress,B
1638,the,O
1638,attention,B
1638,outputs,I
1638,so,O
1638,that,O
1638,they,O
1638,can,O
1638,be,B
1638,small,B
1638,enough,O
1638,to,O
1638,propagate,B
1638,",",O
1638,yet,O
1638,enabling,O
1638,a,O
1638,connection,O
1638,between,O
1638,two,O
1638,sequences,O
1638,.,O
1639,Densely,O
1639,Connected,O
1639,Attention,O
1639,Propagation,O
1639,for,O
1639,Reading,B
1639,Comprehension,I
1640,We,O
1640,propose,O
1640,DECAPROP,O
1640,(,O
1640,Densely,O
1640,Connected,O
1640,Attention,O
1640,Propagation,O
1640,),O
1640,",",O
1640,a,O
1640,new,O
1640,densely,O
1640,connected,O
1640,neural,O
1640,architecture,O
1640,for,O
1640,reading,B
1640,comprehension,I
1640,(,O
1640,RC,O
1640,),O
1640,.,O
1641,We,O
1641,conduct,O
1641,extensive,O
1641,experiments,O
1641,on,O
1641,four,O
1641,challenging,O
1641,RC,B
1641,benchmarks,O
1641,.,O
1642,Overall,O
1642,",",O
1642,our,O
1642,results,O
1642,are,O
1642,optimistic,O
1642,and,O
1642,promising,O
1642,",",O
1642,with,O
1642,results,O
1642,indicating,O
1642,that,O
1642,DECAPROP,B
1642,achieves,B
1642,state,B
1642,-,I
1642,of,I
1642,-,O
1642,the,O
1642,-,O
1642,art,O
1642,performance,O
1642,6,O
1642,on,B
1642,all,B
1642,four,I
1642,datasets,I
1642,.,O
1643,On,O
1643,this,O
1643,dataset,O
1643,",",O
1643,DECAPROP,O
1643,outperforms,B
1643,the,I
1643,existing,B
1643,state,I
1643,-,I
1643,of,I
1643,-,O
1643,the,O
1643,-,O
1643,art,O
1643,",",O
1643,i.e.,B
1644,",",O
1644,the,O
1644,recent,B
1644,AMANDA,I
1644,model,I
1644,by,B
1644,(,O
1644,+,B
1644,4.7,I
1644,%,I
1644,EM,I
1644,/,O
1644,+,O
1644,2.6,O
1644,%,O
1644,F1,O
1644,),O
1644,.,O
1645,Moreover,O
1645,",",O
1645,our,B
1645,proposed,I
1645,model,I
1645,also,O
1645,outperforms,B
1645,well,B
1645,-,I
1645,established,I
1645,baselines,I
1645,such,B
1645,as,I
1645,Match,B
1645,-,O
1645,LSTM,O
1645,(,O
1645,+,O
1645,18,O
1645,%,O
1645,EM,O
1645,/,O
1645,+,O
1645,16.3,O
1645,%,O
1645,F1,O
1645,),O
1645,and,O
1645,BiDAF,B
1645,(,O
1645,+,O
1645,16,O
1645,%,O
1645,EM,O
1645,/,O
1645,+,O
1645,14,O
1645,%,O
1645,F1,O
1645,),O
1645,.,O
1646,reports,O
1646,the,O
1646,results,O
1646,on,B
1646,Quasar,B
1646,-,I
1646,T,I
1646,.,O
1647,In,O
1647,relation,B
1647,extraction,I
1647,",",O
1647,one,O
1647,challenge,O
1647,that,O
1647,is,O
1647,faced,O
1647,when,O
1647,building,O
1647,a,O
1647,machine,O
1647,learning,O
1647,system,O
1647,is,O
1647,the,O
1647,generation,O
1647,of,O
1647,training,O
1647,examples,O
1647,.,O
1648,Our,O
1648,model,O
1648,achieves,B
1648,state,B
1648,-,I
1648,of,B
1648,-,O
1648,the,O
1648,-,O
1648,art,O
1648,performance,O
1648,on,O
1648,this,O
1648,dataset,O
1648,",",O
1648,outperforming,B
1648,the,O
1648,state,O
1648,-,O
1648,of,O
1648,-,O
1648,the,O
1648,-,O
1648,art,O
1648,R,O
1648,3,O
1648,(,O
1648,Reinforced,O
1648,Ranker,O
1648,Reader,O
1648,),O
1648,by,B
1648,a,O
1648,considerable,B
1648,margin,I
1648,of,O
1648,+,O
1648,4.4,O
1648,%,O
1648,EM,O
1648,/,O
1648,+,O
1648,6,O
1648,%,O
1648,F1,O
1648,.,O
1649,On,O
1649,the,O
1649,original,O
1649,setting,O
1649,",",O
1649,our,B
1649,model,I
1649,outperforms,B
1649,AMANDA,B
1649,by,B
1649,+,I
1649,15.4,I
1649,%,I
1649,EM,I
1649,and,I
1649,+,O
1649,14.2,O
1649,%,O
1649,in,O
1649,terms,O
1649,of,O
1649,F1,O
1649,score,O
1649,.,O
1650,On,O
1650,the,O
1650,over,O
1650,all,O
1650,setting,O
1650,",",O
1650,our,O
1650,model,O
1650,outperforms,O
1650,both,O
1650,AQA,B
1650,(,O
1650,+,O
1650,18.1,O
1650,%,O
1650,EM,O
1650,/,O
1650,+,O
1650,18,O
1650,%,O
1650,F1,O
1650,),O
1650,and,O
1650,Reinforced,B
1650,Reader,I
1650,Ranker,I
1650,(,O
1650,+,O
1650,7.8,O
1650,%,O
1650,EM,O
1650,/,O
1650,+,O
1650,8.3,O
1650,%,O
1650,F1,O
1650,),O
1650,.,O
1651,SQuAD,O
1651,reports,O
1651,dev,O
1651,scores,O
1651,8,O
1651,of,O
1651,our,B
1651,model,I
1651,against,O
1651,several,O
1651,representative,O
1651,models,O
1651,on,O
1651,the,O
1651,popular,B
1651,SQuAD,O
1651,benchmark,O
1651,.,O
1652,While,O
1652,our,O
1652,model,O
1652,does,B
1652,not,I
1652,achieve,I
1652,state,B
1652,-,I
1652,of,I
1652,-,O
1652,the,O
1652,-,O
1652,art,O
1652,performance,O
1652,",",O
1652,our,O
1652,model,O
1652,can,B
1652,outperform,I
1652,the,O
1652,base,B
1652,R,I
1652,-,O
1652,NET,O
1652,(,O
1652,both,O
1652,our,O
1652,implementation,O
1652,as,O
1652,well,O
1652,as,O
1652,the,O
1652,published,O
1652,score,O
1652,),O
1652,.,O
1653,All,O
1653,systems,O
1653,except,O
1653,the,O
1653,Minitagger,O
1653,and,O
1653,CRF,O
1653,are,O
1653,our,O
1653,implementations,O
1653,using,O
1653,PyTorch,O
1653,and,O
1653,are,O
1653,made,O
1653,available,O
1653,on,O
1653,GitHub,O
1653,:,O
1653,https://github.com/Helsinki,B
1653,-,I
1653,NLP,I
1653,/,I
1653,prosody,I
1653,.,O
1654,In,O
1654,this,O
1654,paper,O
1654,we,O
1654,introduce,O
1654,a,O
1654,new,O
1654,NLP,O
1654,dataset,O
1654,and,O
1654,benchmark,O
1654,for,B
1654,predicting,I
1654,prosodic,I
1654,prominence,I
1654,from,B
1654,text,B
1654,which,O
1654,is,O
1654,based,B
1654,on,I
1654,the,O
1654,recently,B
1654,published,I
1654,Libri,I
1654,TTS,I
1654,corpus,I
1654,",",O
1654,containing,B
1654,automatically,B
1654,generated,I
1654,prosodic,O
1654,prominence,O
1654,labels,O
1654,for,O
1654,over,B
1654,260,I
1654,hours,I
1654,or,O
1654,2.8,B
1654,million,I
1654,words,I
1654,of,B
1654,English,B
1654,audio,I
1654,books,I
1654,",",O
1654,read,B
1654,by,I
1654,1230,B
1654,different,I
1654,speakers,I
1654,.,O
1655,To,O
1655,our,O
1655,knowledge,O
1655,this,O
1655,will,B
1655,be,I
1655,the,O
1655,largest,B
1655,publicly,I
1655,available,I
1655,dataset,I
1655,with,B
1655,prosodic,B
1655,annotations,I
1655,.,O
1656,We,O
1656,performed,O
1656,experiments,O
1656,with,O
1656,the,O
1656,following,O
1656,models,B
1656,:,O
1657,BERT,O
1657,-,O
1657,base,O
1657,uncased,O
1657,3,B
1657,-,O
1657,layer,O
1657,600D,O
1657,Bidirectional,O
1657,Long,O
1657,Short,O
1657,-,O
1657,Term,O
1657,Memory,O
1657,(,O
1657,BiLSTM,O
1657,),O
1657,(,O
1657,Hochreiter,O
1657,and,O
1657,Schmidhuber,O
1657,",",O
1657,1997,O
1657,),O
1657,Minitagger,B
1657,(,O
1657,SVM,O
1657,),O
1657,),O
1657,+,O
1657,GloVe,O
1657,MarMoT,B
1657,(,O
1657,CRF,O
1657,),O
1657,Majority,B
1657,class,I
1657,per,I
1657,word,I
1658,shows,O
1658,the,O
1658,precision,O
1658,-,O
1658,recall,O
1658,curves,O
1658,for,O
1658,each,O
1658,method,O
1658,",",O
1658,where,O
1658,PCNNs,B
1658,+,I
1658,MIL,I
1658,denotes,O
1658,our,O
1658,method,O
1658,",",O
1658,and,O
1658,demonstrates,B
1658,that,O
1658,PCNNs,O
1658,+,O
1658,MIL,O
1658,achieves,B
1658,higher,B
1658,precision,O
1658,over,B
1658,the,O
1658,entire,B
1658,range,I
1658,of,I
1658,recall,O
1658,.,O
1659,We,O
1659,use,B
1659,the,O
1659,Huggingface,B
1659,PyTorch,B
1659,implementation,I
1659,of,B
1659,BERT,B
1659,available,B
1659,in,I
1659,the,O
1659,pytorch,O
1659,transformers,O
1659,library,O
1659,",",O
1659,3,O
1659,which,O
1659,we,O
1659,further,B
1659,fine,B
1659,-,I
1659,tune,I
1659,during,B
1659,training,B
1659,.,O
1660,For,O
1660,our,O
1660,experiments,O
1660,we,O
1660,use,O
1660,the,O
1660,smaller,B
1660,BERT,I
1660,-,I
1660,base,I
1660,model,I
1660,using,B
1660,the,O
1660,uncased,B
1660,alternative,I
1660,.,O
1661,We,O
1661,use,O
1661,a,O
1661,dropout,B
1661,of,I
1661,0.2,B
1661,between,B
1661,the,I
1661,layers,B
1661,of,O
1661,the,O
1661,BiLSTM,O
1661,.,O
1662,We,O
1662,use,O
1662,a,O
1662,batch,B
1662,size,I
1662,of,B
1662,32,B
1662,and,O
1662,fine,B
1662,-,I
1662,tune,I
1662,the,O
1662,model,B
1662,for,B
1662,2,B
1662,epochs,I
1662,.,O
1663,We,O
1663,take,B
1663,the,O
1663,last,B
1663,hidden,I
1663,layer,I
1663,of,B
1663,BERT,B
1663,and,O
1663,train,B
1663,a,O
1663,single,B
1663,fully,I
1663,-,I
1663,connected,I
1663,classifier,I
1663,layer,O
1663,on,B
1663,top,B
1663,of,O
1663,it,O
1663,",",O
1663,mapping,B
1663,the,O
1663,representation,B
1663,of,O
1663,each,B
1663,word,I
1663,to,B
1663,the,O
1663,labels,B
1663,.,O
1664,For,B
1664,BiLSTM,B
1664,we,O
1664,use,B
1664,pre-trained,B
1664,300D,I
1664,Glo,I
1664,Ve,I
1664,840B,I
1664,word,I
1664,embeddings,I
1664,.,O
1665,For,O
1665,the,O
1665,SVM,B
1665,we,O
1665,use,B
1665,Minitagger,B
1665,4,I
1665,implementation,I
1665,by,O
1665,using,B
1665,each,B
1665,dimension,I
1665,of,B
1665,the,O
1665,pre-trained,B
1665,300D,I
1665,Glo,I
1665,Ve,I
1665,840B,I
1665,word,I
1665,embeddings,I
1665,as,B
1665,features,B
1665,",",O
1665,with,B
1665,context,B
1665,-,I
1665,size,I
1665,1,I
1665,",",O
1665,i.e.,O
1666,For,O
1666,the,O
1666,conditional,B
1666,random,I
1666,field,I
1666,(,I
1666,CRF,I
1666,),I
1666,model,I
1666,we,O
1666,use,B
1666,MarMot,B
1666,5,O
1666,by,O
1666,with,B
1666,the,O
1666,default,B
1666,configuration,I
1666,.,O
1667,As,O
1667,with,O
1667,BERT,O
1667,",",O
1667,we,O
1667,add,B
1667,one,B
1667,fullyconnected,I
1667,classifier,I
1667,layer,I
1667,on,B
1667,top,I
1667,of,B
1667,the,O
1667,BiLSTM,B
1667,",",O
1667,mapping,B
1667,the,O
1667,representation,B
1667,of,O
1667,each,B
1667,word,I
1667,to,B
1667,the,O
1667,labels,B
1667,.,O
1668,PCNNs,O
1668,+,O
1668,MIL,O
1668,enhances,B
1668,the,O
1668,recall,B
1668,to,B
1668,ap,B
1668,-,I
1668,proximately,I
1668,34,I
1668,%,I
1668,without,B
1668,any,I
1668,loss,I
1668,of,I
1668,precision,B
1668,.,O
1669,In,O
1669,this,O
1669,paper,O
1669,we,O
1669,introduce,O
1669,a,O
1669,new,O
1669,natural,O
1669,language,O
1669,processing,O
1669,dataset,O
1669,and,O
1669,benchmark,O
1669,for,O
1669,predicting,B
1669,prosodic,I
1669,prominence,I
1669,from,I
1669,written,I
1669,text,I
1669,.,O
1670,All,O
1670,models,O
1670,reach,B
1670,over,I
1670,80,B
1670,%,I
1670,in,B
1670,the,O
1670,2,B
1670,-,I
1670,way,I
1670,classification,I
1670,task,I
1670,while,O
1670,3,B
1670,-,O
1670,way,O
1670,classification,O
1670,accuracy,O
1670,stays,B
1670,below,I
1670,70,B
1670,%,O
1670,for,O
1670,all,O
1670,of,O
1670,them,O
1670,.,O
1671,All,O
1671,models,O
1671,have,O
1671,reached,B
1671,close,I
1671,to,I
1671,their,O
1671,full,B
1671,predictive,I
1671,capacity,I
1671,with,B
1671,only,B
1671,10,I
1671,%,I
1671,of,I
1671,the,I
1671,training,I
1671,examples,I
1671,.,O
1672,The,O
1672,BERTbased,B
1672,model,I
1672,gets,B
1672,the,O
1672,highest,B
1672,accuracy,I
1672,of,B
1672,83.2,B
1672,%,I
1672,and,I
1672,68.6,I
1672,%,O
1672,in,B
1672,the,O
1672,2,B
1672,-,I
1672,way,I
1672,and,O
1672,3,O
1672,-,O
1672,way,O
1672,classification,O
1672,tasks,O
1672,",",O
1672,respectively,O
1672,",",O
1672,demonstrating,O
1672,the,O
1672,value,O
1672,of,O
1672,a,O
1672,pytorch,O
1672,-,O
1672,transformers,O
1672,4,O
1672,https://github.com/karlstratos/,O
1673,The,O
1673,3layer,B
1673,BiLSTM,I
1673,achieves,B
1673,82.1,B
1673,%,I
1673,in,B
1673,the,O
1673,2,B
1673,-,I
1673,way,I
1673,classification,I
1673,and,O
1673,66.4,B
1673,%,O
1673,in,O
1673,the,O
1673,3,B
1673,-,O
1673,way,O
1673,classification,O
1673,task,O
1673,.,O
1674,The,O
1674,traditional,B
1674,feature,I
1674,-,I
1674,based,I
1674,classifiers,I
1674,perform,B
1674,slightly,B
1674,below,I
1674,the,O
1674,neural,B
1674,network,I
1674,models,I
1674,",",O
1674,with,B
1674,the,O
1674,CRF,B
1674,obtaining,B
1674,81.8,B
1674,%,I
1674,and,I
1674,66.4,I
1674,%,O
1674,for,B
1674,the,O
1674,two,B
1674,classification,I
1674,tasks,I
1674,",",O
1674,respectively,O
1674,.,O
1675,The,O
1675,Minitagger,B
1675,SVM,I
1675,model,I
1675,'s,I
1675,test,I
1675,accuracies,I
1675,are,B
1675,slightly,B
1675,lower,I
1675,than,B
1675,the,O
1675,CRF,B
1675,'s,O
1675,with,B
1675,80.8,B
1675,%,I
1675,and,I
1675,65.4,I
1675,%,O
1675,test,O
1675,accuracies,O
1675,.,O
1676,Finally,O
1676,taking,B
1676,a,O
1676,simple,B
1676,majority,I
1676,class,I
1676,per,I
1676,word,I
1676,gives,B
1676,80.2,B
1676,%,I
1676,for,B
1676,the,O
1676,2,B
1676,-,I
1676,way,I
1676,classification,I
1676,task,I
1676,and,O
1676,62.4,B
1676,%,O
1676,for,O
1676,the,O
1676,3,B
1676,-,O
1676,way,O
1676,classification,O
1676,task,O
1676,.,O
1677,For,B
1677,most,B
1677,of,B
1677,the,I
1677,models,I
1677,the,O
1677,biggest,B
1677,improvement,I
1677,in,B
1677,performance,B
1677,is,O
1677,achieved,B
1677,when,I
1677,moving,B
1677,from,B
1677,1,B
1677,%,I
1677,of,O
1677,the,O
1677,training,B
1677,examples,I
1677,to,B
1677,5,B
1677,%,O
1677,.,O
1678,In,O
1678,terms,O
1678,of,O
1678,both,O
1678,precision,B
1678,and,I
1678,recall,I
1678,",",O
1678,PCNNs,B
1678,+,I
1678,MIL,I
1678,outperforms,B
1678,all,B
1678,other,I
1678,evaluated,I
1678,approaches,I
1678,.,O
1679,As,O
1679,the,O
1679,proposed,O
1679,dataset,O
1679,has,O
1679,been,O
1679,automatically,O
1679,generated,O
1679,as,O
1679,described,O
1679,in,O
1679,Section,O
1679,3,O
1679,",",O
1679,we,O
1679,also,O
1679,tested,O
1679,the,O
1679,best,O
1679,two,O
1679,models,O
1679,",",O
1679,BERT,O
1679,and,O
1679,BiLSTM,O
1679,",",O
1679,with,B
1679,a,O
1679,manually,B
1679,annotated,I
1679,test,I
1679,set,I
1679,from,I
1679,The,O
1679,Boston,O
1679,University,O
1679,radio,O
1679,news,O
1679,corpus,O
1679,.,O
1680,The,O
1680,good,B
1680,results,I
1680,6,O
1680,from,O
1680,this,O
1680,experiment,O
1680,provide,B
1680,further,B
1680,support,I
1680,for,B
1680,the,O
1680,quality,B
1680,of,I
1680,the,O
1680,new,O
1680,dataset,O
1680,.,O
1681,Notice,O
1681,also,O
1681,that,O
1681,the,O
1681,difference,B
1681,between,B
1681,BERT,B
1681,and,I
1681,BiLSTM,I
1681,is,O
1681,much,B
1681,bigger,I
1681,with,O
1681,this,O
1681,test,O
1681,set,O
1681,(,O
1681,+,O
1681,3.9,O
1681,%,O
1681,compared,O
1681,to,O
1681,+,O
1681,1.1,O
1681,%,O
1681,),O
1681,.,O
1682,LSTM,O
1682,:,O
1682,This,O
1682,is,B
1682,the,O
1682,basic,B
1682,LSTM,O
1682,-,O
1682,based,O
1682,deletion,O
1682,method,O
1682,proposed,O
1682,by,O
1682,.,O
1683,LSTM,O
1683,+,O
1683,:,O
1683,This,O
1683,is,O
1683,advanced,O
1683,version,O
1683,of,O
1683,the,O
1683,model,O
1683,proposed,O
1683,by,O
1683,",",O
1683,where,O
1683,the,O
1683,authors,O
1683,incorporated,B
1683,some,O
1683,dependency,B
1683,parse,I
1683,tree,I
1683,information,I
1683,into,B
1683,the,O
1683,LSTM,O
1683,model,O
1683,and,O
1683,used,B
1683,the,O
1683,prediction,B
1683,on,B
1683,the,O
1683,previous,B
1683,word,I
1683,to,B
1683,help,I
1683,the,O
1683,prediction,O
1683,on,O
1683,the,O
1683,current,B
1683,word,O
1683,.,O
1684,This,O
1684,is,B
1684,the,O
1684,ILP,B
1684,-,I
1684,based,I
1684,method,I
1684,proposed,O
1684,by,O
1684,.,O
1685,This,O
1685,is,B
1685,an,O
1685,abstractive,B
1685,sequence,I
1685,-,I
1685,to,I
1685,-,O
1685,sequence,O
1685,model,O
1685,trained,B
1685,on,I
1685,3.8,B
1685,million,I
1685,Gigaword,I
1685,title,I
1685,-,O
1685,article,O
1685,pairs,O
1685,as,O
1685,described,O
1685,in,O
1685,Section,O
1685,1,O
1685,.,O
1686,In,O
1686,the,O
1686,experiments,O
1686,",",O
1686,our,B
1686,model,I
1686,was,O
1686,trained,B
1686,using,I
1686,the,O
1686,Adam,B
1686,algorithm,I
1686,with,B
1686,a,O
1686,learning,B
1686,rate,I
1686,initialized,B
1686,at,I
1686,0.001,B
1686,.,O
1687,Automatically,O
1687,learning,O
1687,features,B
1687,via,B
1687,PCNNs,B
1687,can,O
1687,alleviate,B
1687,the,O
1687,error,B
1687,propagation,I
1687,that,O
1687,occurs,O
1687,in,O
1687,traditional,O
1687,feature,O
1687,extraction,O
1687,.,O
1688,The,O
1688,dimension,B
1688,of,B
1688,the,O
1688,hidden,B
1688,layers,I
1688,of,O
1688,bi,B
1688,-,I
1688,LSTM,I
1688,is,B
1688,100,B
1688,.,O
1689,Word,O
1689,embeddings,O
1689,are,O
1689,initialized,B
1689,from,I
1689,GloVe,B
1689,100,I
1689,dimensional,I
1689,pre-trained,I
1689,embeddings,O
1689,.,O
1690,POS,O
1690,and,O
1690,dependency,O
1690,embeddings,O
1690,are,O
1690,randomly,B
1690,initialized,I
1690,with,I
1690,40,B
1690,-,I
1690,dimensional,I
1690,vectors,I
1690,.,O
1691,The,O
1691,embeddings,B
1691,are,O
1691,all,O
1691,updated,B
1691,during,I
1691,training,B
1691,.,O
1692,Dropping,O
1692,probability,O
1692,for,B
1692,dropout,B
1692,layers,I
1692,between,B
1692,stacked,B
1692,LSTM,I
1692,layers,O
1692,is,B
1692,0.5,B
1692,.,O
1693,The,O
1693,batch,B
1693,size,I
1693,is,O
1693,set,B
1693,as,I
1693,30,B
1693,.,O
1694,We,O
1694,utilize,B
1694,an,O
1694,open,B
1694,source,I
1694,ILP,I
1694,solver,I
1694,4,O
1694,in,O
1694,our,O
1694,method,O
1694,.,O
1695,To,O
1695,this,O
1695,end,O
1695,",",O
1695,we,O
1695,extend,B
1695,the,O
1695,deletionbased,B
1695,LSTM,I
1695,model,I
1695,for,B
1695,sentence,B
1695,compression,I
1695,by,O
1695,.,O
1696,Specifically,O
1696,",",O
1696,we,O
1696,propose,B
1696,two,B
1696,major,I
1696,changes,I
1696,to,O
1696,the,O
1696,model,O
1696,by,O
1696,:,O
1696,We,O
1696,explicitly,B
1696,introduce,I
1696,POS,B
1696,embeddings,I
1696,and,I
1696,dependency,I
1696,relation,I
1696,embeddings,O
1696,into,B
1696,the,O
1696,neural,B
1696,network,I
1696,model,O
1696,.,O
1697,(,O
1697,2,O
1697,),O
1697,Inspired,O
1697,by,O
1697,a,O
1697,previous,O
1697,method,O
1697,",",O
1697,we,O
1697,formulate,B
1697,the,O
1697,final,B
1697,predictions,I
1697,as,B
1697,an,O
1697,Integer,B
1697,Linear,I
1697,Programming,I
1697,problem,I
1697,to,B
1697,incorporate,I
1697,constraints,B
1697,based,B
1697,on,I
1697,syntactic,B
1697,relations,I
1697,between,B
1697,words,B
1697,and,I
1697,expected,I
1697,lengths,I
1697,of,B
1697,the,O
1697,compressed,B
1697,sentences,I
1697,.,O
1698,Incorporating,B
1698,multi-instance,B
1698,learning,I
1698,into,B
1698,a,O
1698,convolutional,B
1698,neural,I
1698,network,I
1698,is,O
1698,an,O
1698,effective,B
1698,means,I
1698,of,I
1698,addressing,I
1698,the,O
1698,wrong,B
1698,label,I
1698,problem,I
1698,.,O
1699,In,O
1699,addition,O
1699,to,B
1699,the,I
1699,two,O
1699,major,O
1699,changes,O
1699,above,O
1699,",",O
1699,we,O
1699,also,O
1699,use,B
1699,bi-directional,B
1699,LSTM,I
1699,to,O
1699,include,O
1699,contextual,B
1699,information,I
1699,from,B
1699,both,B
1699,directions,I
1699,into,I
1699,the,O
1699,model,O
1699,.,O
1700,Improving,O
1700,an,O
1700,LSTM,O
1700,-,O
1700,based,O
1700,Sentence,B
1700,Compression,I
1700,Model,O
1700,for,O
1700,New,O
1700,Domains,O
1701,We,O
1701,can,O
1701,see,B
1701,that,I
1701,indeed,O
1701,this,O
1701,abstractive,B
1701,method,I
1701,performed,B
1701,poorly,B
1701,in,B
1701,cross,B
1701,-,I
1701,domain,I
1701,settings,I
1701,.,O
1702,(,O
1702,2,O
1702,),O
1702,In,B
1702,the,O
1702,in,O
1702,-,O
1702,domain,O
1702,setting,O
1702,",",O
1702,with,B
1702,the,O
1702,same,O
1702,amount,O
1702,of,O
1702,training,O
1702,data,O
1702,(,O
1702,"8,000",O
1702,),O
1702,",",O
1702,our,B
1702,BiLSTM,I
1702,method,I
1702,with,O
1702,syntactic,B
1702,features,I
1702,(,O
1702,BiLSTM,O
1702,+,O
1702,SynFeat,O
1702,and,O
1702,BiL,O
1702,-,O
1702,STM,O
1702,+,O
1702,SynFeat,O
1702,+,O
1702,ILP,O
1702,),O
1702,performs,B
1702,similarly,B
1702,to,I
1702,or,I
1702,better,I
1702,than,B
1702,the,O
1702,LSTM,B
1702,+,O
1702,method,O
1702,proposed,O
1702,by,O
1702,",",O
1702,in,O
1702,terms,O
1702,of,O
1702,both,B
1702,F1,I
1702,and,O
1702,accuracy,O
1702,.,O
1703,(,O
1703,4,O
1703,),O
1703,In,O
1703,the,O
1703,out,B
1703,-,I
1703,of,I
1703,-,O
1703,domain,O
1703,setting,O
1703,",",O
1703,our,B
1703,BiLSTM,I
1703,+,I
1703,SynFeat,I
1703,and,I
1703,BiLSTM+SynFeat+ILP,I
1703,methods,I
1703,clearly,B
1703,outperform,I
1703,the,O
1703,LSTM,O
1703,and,O
1703,LSTM,O
1703,+,O
1703,methods,O
1703,.,O
1704,This,O
1704,shows,O
1704,that,O
1704,our,B
1704,method,I
1704,is,O
1704,comparable,B
1704,to,I
1704,the,O
1704,LSTM,B
1704,+,I
1704,method,O
1704,in,B
1704,the,O
1704,in,O
1704,-,O
1704,domain,O
1704,setting,O
1704,.,O
1705,Therefore,O
1705,",",O
1705,our,O
1705,method,O
1705,works,B
1705,reasonably,B
1705,well,I
1705,for,B
1705,both,I
1705,in,B
1705,-,I
1705,domain,I
1705,and,I
1705,out,I
1705,-,O
1705,ofdomain,O
1705,data,O
1705,.,O
1706,(,O
1706,5,O
1706,),O
1706,The,O
1706,Traditional,B
1706,ILP,I
1706,method,I
1706,also,O
1706,works,B
1706,better,B
1706,than,B
1706,the,O
1706,LSTM,O
1706,and,O
1706,LSTM,O
1706,+,O
1706,methods,O
1706,in,B
1706,the,O
1706,out,B
1706,-,I
1706,of,I
1706,-,O
1706,domain,O
1706,setting,O
1706,.,O
1707,But,O
1707,the,O
1707,Traditional,O
1707,ILP,O
1707,method,O
1707,performs,B
1707,worse,B
1707,in,B
1707,the,O
1707,in,O
1707,-,O
1707,domain,O
1707,setting,O
1707,than,B
1707,both,I
1707,the,O
1707,LSTM,O
1707,and,O
1707,LSTM,O
1707,+,O
1707,methods,O
1707,and,O
1707,our,O
1707,methods,O
1707,.,O
1708,We,O
1708,also,O
1708,notice,O
1708,that,O
1708,on,B
1708,Google,B
1708,News,I
1708,",",O
1708,adding,B
1708,the,O
1708,ILP,B
1708,layer,I
1708,decreased,B
1708,the,O
1708,sentence,B
1708,compression,I
1708,performance,I
1708,.,O
1709,All,O
1709,Multi,O
1709,Layer,O
1709,Perceptrons,O
1709,(,O
1709,MLP,O
1709,),O
1709,has,O
1709,two,B
1709,hidden,I
1709,layers,I
1709,with,B
1709,500,B
1709,dimensions,I
1709,",",O
1709,each,O
1709,followed,B
1709,by,I
1709,ReLU,B
1709,activation,I
1709,.,O
1710,We,O
1710,can,O
1710,see,O
1710,that,O
1710,in,B
1710,the,O
1710,in,O
1710,-,O
1710,domain,O
1710,setting,O
1710,",",O
1710,our,B
1710,method,I
1710,does,B
1710,not,I
1710,have,I
1710,any,B
1710,advantage,I
1710,over,B
1710,the,O
1710,LSTM,B
1710,+,I
1710,method,O
1710,.,O
1711,But,O
1711,in,O
1711,the,O
1711,cross,B
1711,-,I
1711,domain,I
1711,setting,I
1711,",",O
1711,our,B
1711,method,I
1711,that,O
1711,uses,B
1711,ILP,B
1711,to,B
1711,impose,I
1711,syntax,B
1711,-,O
1711,based,O
1711,constraints,O
1711,clearly,O
1711,performs,B
1711,better,B
1711,than,B
1711,LSTM,B
1711,+,I
1711,when,B
1711,the,O
1711,amount,B
1711,of,I
1711,training,I
1711,data,I
1711,is,B
1711,relatively,B
1711,small,I
1711,.,O
1712,In,O
1712,particular,O
1712,",",O
1712,we,O
1712,will,O
1712,present,O
1712,a,O
1712,model,O
1712,which,O
1712,benefits,B
1712,from,I
1712,the,O
1712,very,B
1712,recent,I
1712,advances,I
1712,in,O
1712,deep,O
1712,learning,O
1712,and,O
1712,uses,B
1712,word,B
1712,embeddings,I
1712,and,O
1712,Long,O
1712,Short,O
1712,Term,O
1712,Memory,O
1712,models,O
1712,(,O
1712,LSTMs,O
1712,),O
1712,to,B
1712,output,I
1712,surprisingly,B
1712,readable,I
1712,and,O
1712,informative,O
1712,compressions,O
1712,.,O
1713,Trained,O
1713,on,O
1713,a,O
1713,corpus,B
1713,of,B
1713,less,B
1713,than,I
1713,two,I
1713,million,I
1713,automatically,B
1713,extracted,I
1713,parallel,B
1713,sentences,I
1713,and,O
1713,using,B
1713,a,O
1713,standard,B
1713,tool,I
1713,to,B
1713,obtain,I
1713,word,B
1713,embeddings,I
1713,",",O
1713,in,O
1713,its,O
1713,best,O
1713,and,O
1713,most,O
1713,simple,O
1713,configuration,O
1713,it,O
1713,achieves,O
1713,4.5,O
1713,points,O
1713,out,O
1713,of,O
1713,5,O
1713,in,O
1713,readability,O
1713,and,O
1713,3.8,O
1713,points,O
1713,in,O
1713,informativeness,O
1713,in,O
1713,an,O
1713,extensive,O
1713,evaluation,O
1713,with,O
1713,human,O
1713,judges,O
1713,.,O
1714,We,O
1714,present,O
1714,an,O
1714,LSTM,O
1714,approach,O
1714,to,O
1714,deletion,B
1714,-,I
1714,based,I
1714,sentence,I
1714,compression,I
1714,where,O
1714,the,O
1714,task,O
1714,is,O
1714,to,O
1714,translate,O
1714,a,O
1714,sentence,O
1714,into,O
1714,a,O
1714,sequence,O
1714,of,O
1714,zeros,O
1714,and,O
1714,ones,O
1714,",",O
1714,corresponding,O
1714,to,O
1714,token,O
1714,deletion,O
1714,decisions,O
1714,.,O
1715,There,O
1715,is,O
1715,a,O
1715,significant,B
1715,difference,I
1715,in,I
1715,performance,B
1715,of,I
1715,the,I
1715,MIRA,B
1715,baseline,I
1715,and,I
1715,the,O
1715,LSTM,O
1715,models,O
1715,",",O
1715,both,O
1715,in,O
1715,terms,O
1715,of,O
1715,F1,B
1715,-,I
1715,score,I
1715,and,O
1715,in,O
1715,accuracy,O
1715,.,O
1716,More,O
1716,than,O
1716,30,O
1716,%,O
1716,of,B
1716,golden,B
1716,compressions,I
1716,could,B
1716,be,I
1716,fully,O
1716,regenerated,B
1716,by,B
1716,the,O
1716,LSTM,B
1716,systems,I
1716,which,B
1716,is,I
1716,in,I
1716,sharp,B
1716,contrast,I
1716,with,B
1716,the,O
1716,20,B
1716,%,O
1716,of,O
1716,MIRA,B
1716,.,O
1717,The,O
1717,differences,B
1717,in,B
1717,F-,B
1717,score,I
1717,between,B
1717,the,O
1717,three,B
1717,versions,I
1717,of,I
1717,LSTM,I
1717,are,B
1717,not,B
1717,significant,I
1717,",",O
1717,all,O
1717,scores,B
1717,are,O
1717,close,B
1717,to,I
1717,0.81,B
1717,.,O
1718,Entity,O
1718,-,O
1718,Aware,O
1718,BERT,O
1718,SP,O
1718,:,O
1718,our,B
1718,full,I
1718,model,I
1718,",",O
1718,which,O
1718,includes,O
1718,both,O
1718,improvements,O
1718,in,O
1718,3.1,O
1718,and,O
1718,3.2,O
1718,.,O
1719,Our,O
1719,baseline,B
1719,(,O
1719,BASELINE,O
1719,-,O
1719,LSTM,O
1719,),O
1719,is,B
1719,a,O
1719,multi,B
1719,-,O
1719,task,O
1719,learning,O
1719,1,O
1719,http://groups.inf.ed.ac.uk/ccg/,O
1720,bi,O
1720,-LSTM,O
1720,predicting,B
1720,both,I
1720,CCG,B
1720,supertags,I
1720,and,I
1720,sentence,I
1720,compression,I
1720,(,O
1720,word,O
1720,deletion,O
1720,),O
1720,at,B
1720,the,O
1720,outer,B
1720,layer,I
1720,.,O
1721,Both,O
1721,the,O
1721,baseline,O
1721,and,O
1721,our,O
1721,systems,O
1721,are,B
1721,three,B
1721,-,I
1721,layer,I
1721,bi,I
1721,-,O
1721,LSTM,O
1721,models,O
1721,trained,B
1721,for,I
1721,30,B
1721,iterations,I
1721,with,B
1721,pretrained,B
1721,(,I
1721,SENNA,I
1721,),I
1721,embeddings,I
1721,.,O
1722,The,O
1722,input,B
1722,and,I
1722,hidden,I
1722,layers,I
1722,are,B
1722,50,B
1722,dimensions,I
1722,",",O
1722,and,O
1722,at,O
1722,the,O
1722,output,B
1722,layer,I
1722,we,O
1722,predict,B
1722,sequences,B
1722,of,B
1722,two,B
1722,labels,I
1722,",",O
1722,indicating,O
1722,whether,O
1722,to,O
1722,delete,O
1722,the,O
1722,labeled,O
1722,word,O
1722,or,O
1722,not,O
1722,.,O
1723,We,O
1723,go,O
1723,beyond,O
1723,this,O
1723,by,O
1723,suggesting,B
1723,that,I
1723,eye,B
1723,-,I
1723,tracking,I
1723,recordings,I
1723,can,O
1723,be,O
1723,used,O
1723,to,B
1723,induce,I
1723,better,B
1723,models,I
1723,for,B
1723,sentence,B
1723,compression,I
1723,for,O
1723,text,B
1723,simplification,I
1723,.,O
1724,Specifically,O
1724,",",O
1724,we,O
1724,show,B
1724,how,I
1724,to,B
1724,use,I
1724,existing,B
1724,eye,I
1724,-,I
1724,tracking,I
1724,recordings,I
1724,to,O
1724,improve,O
1724,the,O
1724,induction,B
1724,of,B
1724,Long,B
1724,Short,I
1724,-,O
1724,Term,O
1724,Memory,O
1724,models,O
1724,(,O
1724,LSTMs,O
1724,),O
1724,for,B
1724,sentence,B
1724,compression,I
1724,.,O
1725,Our,O
1725,proposed,O
1725,model,O
1725,does,B
1725,not,I
1725,require,I
1725,that,O
1725,the,O
1725,gaze,B
1725,data,I
1725,and,I
1725,the,O
1725,compression,O
1725,data,O
1725,come,B
1725,from,I
1725,the,O
1725,same,B
1725,source,I
1725,.,O
1726,While,O
1726,not,O
1726,explored,O
1726,here,O
1726,",",O
1726,an,O
1726,intriguing,B
1726,potential,I
1726,of,B
1726,this,B
1726,work,I
1726,is,O
1726,in,B
1726,deriving,I
1726,sentence,B
1726,simplification,I
1726,models,I
1726,that,B
1726,are,I
1726,personalized,B
1726,for,B
1726,individual,B
1726,users,I
1726,",",O
1726,based,B
1726,on,I
1726,their,B
1726,reading,I
1726,behavior,I
1726,.,O
1727,Indeed,O
1727,",",O
1727,in,O
1727,this,O
1727,work,O
1727,we,O
1727,use,B
1727,gaze,B
1727,data,I
1727,from,B
1727,readers,B
1727,of,B
1727,the,O
1727,Dundee,B
1727,Corpus,I
1727,to,B
1727,improve,I
1727,sentence,B
1727,compression,I
1727,results,I
1727,on,B
1727,several,B
1727,datasets,I
1727,.,O
1728,Improving,O
1728,sentence,B
1728,compression,I
1728,by,O
1728,learning,O
1728,to,O
1728,predict,O
1728,gaze,O
1729,We,O
1729,observe,O
1729,that,O
1729,across,B
1729,all,B
1729,three,I
1729,datasets,I
1729,",",O
1729,including,B
1729,all,O
1729,three,O
1729,annotations,O
1729,of,O
1729,BROADCAST,O
1729,",",O
1729,gaze,B
1729,features,I
1729,lead,B
1729,to,I
1729,improvements,B
1729,over,B
1729,our,O
1729,baseline,B
1729,3,I
1729,-,I
1729,layer,I
1729,bi,I
1729,-,O
1729,LSTM,O
1729,.,O
1730,Also,O
1730,",",O
1730,CASCADED,B
1730,-,I
1730,LSTM,I
1730,is,B
1730,consistently,B
1730,better,I
1730,than,B
1730,MULTITASK,B
1730,-,O
1730,LSTM,O
1730,.,O
1731,For,B
1731,all,B
1731,three,I
1731,datasets,I
1731,",",O
1731,the,O
1731,inclusion,B
1731,of,B
1731,gaze,B
1731,measures,I
1731,(,I
1731,first,B
1731,pass,I
1731,duration,I
1731,(,O
1731,FP,O
1731,),O
1731,and,O
1731,regression,B
1731,duration,O
1731,(,O
1731,Regr.,O
1731,),O
1732,),O
1732,leads,B
1732,to,I
1732,improvements,B
1732,over,B
1732,the,O
1732,baseline,B
1732,.,O
1733,With,B
1733,the,O
1733,harder,B
1733,datasets,I
1733,",",O
1733,the,O
1733,impact,B
1733,of,I
1733,the,O
1733,gaze,B
1733,information,I
1733,becomes,B
1733,stronger,B
1733,",",O
1733,consistently,O
1733,favouring,B
1733,the,O
1733,cascaded,B
1733,architecture,I
1733,",",O
1733,and,O
1733,with,O
1733,improvements,B
1733,using,B
1733,both,O
1733,first,B
1733,pass,I
1733,duration,I
1733,and,O
1733,regression,B
1733,duration,O
1733,",",O
1733,the,O
1733,late,O
1733,measure,O
1733,associated,O
1733,with,O
1733,interpretation,O
1733,of,O
1733,content,O
1733,.,O
1734,We,O
1734,choose,O
1734,several,O
1734,strong,O
1734,baselines,O
1734,;,O
1734,the,O
1734,first,O
1734,one,O
1734,is,O
1734,the,O
1734,dependency,B
1734,-,I
1734,tree,I
1734,-,O
1734,based,O
1734,method,O
1734,that,O
1734,considers,B
1734,the,O
1734,sentence,B
1734,compression,I
1734,task,I
1734,as,B
1734,an,O
1734,optimization,B
1734,problem,I
1734,by,B
1734,using,I
1734,integer,B
1734,linear,I
1734,programming,I
1734,5,O
1734,.,O
1735,The,O
1735,second,O
1735,method,O
1735,is,O
1735,the,O
1735,long,B
1735,short,I
1735,-,I
1735,term,I
1735,memory,I
1735,networks,I
1735,(,I
1735,LSTMs,I
1735,),I
1735,which,O
1735,showed,B
1735,strong,B
1735,promise,I
1735,in,B
1735,sentence,B
1735,compression,I
1735,by,O
1735,.,O
1736,6,O
1736,https://github.com/code4conference/code4sc,B
1737,The,O
1737,embedding,B
1737,size,I
1737,for,B
1737,word,B
1737,",",O
1737,part,B
1737,-,I
1737,of,I
1737,-,O
1737,speech,O
1737,tag,O
1737,",",O
1737,and,O
1737,the,O
1737,dependency,B
1737,relation,I
1737,is,B
1737,128,B
1737,.,O
1738,The,O
1738,mini,B
1738,-,I
1738,batch,I
1738,size,I
1738,was,O
1738,chosen,B
1738,from,I
1738,[,B
1738,5,I
1738,",",I
1738,50,I
1738,",",O
1738,100,O
1738,],O
1738,.,O
1739,Vocabulary,O
1739,size,O
1739,was,B
1739,"50,000",B
1739,.,O
1740,This,O
1740,is,B
1740,a,O
1740,more,B
1740,straightforward,I
1740,way,I
1740,to,B
1740,achieve,I
1740,MRE,B
1740,in,B
1740,one,B
1740,-,I
1740,pass,I
1740,derived,O
1740,from,O
1740,previous,O
1740,works,O
1740,using,B
1740,position,B
1740,embeddings,I
1740,.,O
1741,The,O
1741,learning,B
1741,rate,I
1741,for,B
1741,neural,B
1741,language,I
1741,model,I
1741,is,B
1741,2.5,B
1741,e,I
1741,-,I
1741,4,I
1741,",",O
1741,and,O
1741,1e,B
1741,-,O
1741,05,O
1741,for,O
1741,the,O
1741,policy,B
1741,network,I
1741,.,O
1742,We,O
1742,employed,B
1742,the,O
1742,vanilla,B
1742,RNN,I
1742,with,B
1742,a,O
1742,hidden,B
1742,size,I
1742,of,B
1742,512,B
1742,for,B
1742,both,O
1742,the,O
1742,policy,B
1742,network,I
1742,and,O
1742,neural,B
1742,language,I
1742,model,I
1742,.,O
1743,For,B
1743,policy,B
1743,learning,I
1743,",",O
1743,we,O
1743,used,B
1743,the,O
1743,REINFORCE,B
1743,algorithm,I
1743,to,B
1743,update,I
1743,the,O
1743,parameters,B
1743,of,B
1743,the,O
1743,policy,O
1743,network,O
1743,and,O
1743,find,B
1743,an,O
1743,policy,O
1743,that,O
1743,maximizes,B
1743,the,O
1743,reward,B
1743,.,O
1744,To,O
1744,answer,O
1744,the,O
1744,above,O
1744,questions,O
1744,",",O
1744,a,O
1744,syntax,B
1744,-,I
1744,based,I
1744,neural,I
1744,language,I
1744,model,I
1744,is,O
1744,trained,B
1744,on,I
1744,large,B
1744,-,O
1744,scale,O
1744,datasets,O
1744,as,B
1744,a,O
1744,readability,B
1744,evaluator,I
1744,.,O
1745,The,O
1745,neural,B
1745,language,I
1745,model,I
1745,is,O
1745,supposed,O
1745,to,B
1745,learn,I
1745,the,O
1745,correct,B
1745,word,I
1745,collocations,I
1745,in,B
1745,terms,I
1745,of,I
1745,both,O
1745,syntax,B
1745,and,O
1745,semantics,B
1745,.,O
1746,The,O
1746,policy,B
1746,network,B
1746,performs,B
1746,either,I
1746,RETAIN,B
1746,or,O
1746,REMOVE,B
1746,action,O
1746,to,B
1746,form,I
1746,a,O
1746,compression,B
1746,",",O
1746,and,O
1746,receives,B
1746,a,O
1746,reward,O
1746,(,O
1746,e.g.,O
1747,",",O
1747,readability,O
1747,score,O
1747,),O
1747,to,B
1747,update,I
1747,the,O
1747,network,B
1747,.,O
1748,Subsequently,O
1748,",",O
1748,we,O
1748,formulate,B
1748,the,O
1748,deletionbased,B
1748,sentence,I
1748,compression,I
1748,as,O
1748,a,O
1748,series,B
1748,of,I
1748,trialand,B
1748,-,I
1748,error,I
1748,deletion,I
1748,operations,I
1748,through,B
1748,a,O
1748,reinforcement,B
1748,learning,I
1748,framework,I
1748,.,O
1749,A,O
1749,Language,O
1749,Model,O
1749,based,O
1749,Evaluator,O
1749,for,O
1749,Sentence,B
1749,Compression,I
1750,We,O
1750,herein,O
1750,present,O
1750,a,O
1750,language,O
1750,-,O
1750,modelbased,O
1750,evaluator,O
1750,for,O
1750,deletion,B
1750,-,O
1750,based,O
1750,sentence,O
1750,compression,O
1750,",",O
1750,and,O
1750,viewed,O
1750,this,O
1750,task,O
1750,as,O
1750,a,O
1750,series,O
1750,of,O
1750,deletion,O
1750,-,O
1750,and,O
1750,-,O
1750,evaluation,O
1750,operations,O
1750,using,O
1750,the,O
1750,evaluator,O
1750,.,O
1751,(,O
1751,1,O
1751,),O
1751,As,O
1751,shown,O
1751,in,O
1751,",",O
1751,our,O
1751,Evaluator,B
1751,-,I
1751,SLMbased,I
1751,method,I
1751,yields,B
1751,a,O
1751,large,B
1751,improvement,I
1751,over,B
1751,the,O
1751,baselines,B
1751,",",O
1751,demonstrating,O
1751,that,O
1751,the,O
1751,language,O
1751,-,O
1751,modelbased,O
1751,evaluator,O
1751,is,O
1751,effective,O
1751,as,O
1751,a,O
1751,post-hoc,O
1751,grammar,O
1751,checker,O
1751,for,O
1751,the,O
1751,compressed,O
1751,sentences,O
1751,.,O
1752,BERT,O
1752,SP,O
1752,with,O
1752,entity,O
1752,indicators,B
1752,on,O
1752,input,O
1752,layer,O
1752,:,O
1752,it,O
1752,replaces,B
1752,our,B
1752,structured,I
1752,attention,I
1752,layer,O
1752,",",O
1752,and,O
1752,adds,B
1752,indicators,O
1752,of,B
1752,entities,B
1752,(,I
1752,transformed,I
1752,to,I
1752,embeddings,I
1752,),I
1753,(,O
1753,3,O
1753,),O
1753,As,O
1753,for,B
1753,Google,B
1753,news,I
1753,dataset,I
1753,",",O
1753,LSTMs,B
1753,(,O
1753,LSTM,O
1753,+,O
1753,pos+dep,O
1753,),O
1753,(,O
1753,&,O
1753,3,O
1753,),O
1753,is,B
1753,a,O
1753,relatively,B
1753,strong,I
1753,baseline,I
1753,",",O
1753,suggesting,O
1753,that,O
1753,incorporating,B
1753,dependency,B
1753,relations,I
1753,and,O
1753,part,B
1753,-,I
1753,of,I
1753,-,O
1753,speech,O
1753,tags,O
1753,may,O
1753,help,O
1753,model,O
1753,learn,O
1753,the,O
1753,syntactic,O
1753,relations,O
1753,and,O
1753,thus,O
1753,make,O
1753,a,O
1753,better,O
1753,prediction,O
1753,.,O
1754,For,B
1754,Gigaword,B
1754,dataset,I
1754,with,B
1754,1.02,B
1754,million,I
1754,instances,I
1754,",",O
1754,the,O
1754,perplexity,B
1754,of,B
1754,the,O
1754,language,B
1754,model,I
1754,is,B
1754,20.3,B
1754,",",O
1754,while,O
1754,for,O
1754,the,O
1754,Google,O
1754,news,O
1754,dataset,O
1754,with,O
1754,0.2,B
1754,million,O
1754,instances,O
1754,",",O
1754,the,O
1754,perplexity,O
1754,is,O
1754,76.5,B
1754,.,O
1755,When,O
1755,further,O
1755,applying,B
1755,Evaluator,B
1755,-,I
1755,SLM,I
1755,",",O
1755,only,B
1755,a,I
1755,tiny,I
1755,improvement,I
1755,is,O
1755,observed,B
1755,(,O
1755,&3,O
1755,vs,O
1755,&,O
1755,4,O
1755,),O
1755,",",O
1755,not,O
1755,comparable,O
1755,to,O
1755,the,O
1755,improvement,O
1755,between,O
1755,#,O
1755,3,O
1755,and,O
1755,#,O
1755,5,O
1755,.,O
1756,The,O
1756,results,O
1756,shows,B
1756,that,I
1756,small,B
1756,improvements,I
1756,are,O
1756,observed,B
1756,on,I
1756,two,B
1756,datasets,I
1756,(,O
1756,#,O
1756,4,O
1756,vs,O
1756,#,O
1756,5,O
1756,;,O
1756,&,O
1756,4,O
1756,vs,O
1756,&,O
1756,5,O
1756,),O
1756,",",O
1756,suggesting,O
1756,that,O
1756,incorporating,O
1756,syntactic,O
1756,knowledge,O
1756,may,O
1756,help,O
1756,evaluator,O
1756,to,O
1756,encourage,O
1756,more,O
1756,unseen,O
1756,but,O
1756,reasonable,O
1756,word,O
1756,collocations,O
1756,.,O
1757,Each,O
1757,edge,O
1757,is,O
1757,identified,O
1757,by,O
1757,independently,O
1757,predicting,O
1757,which,O
1757,role,O
1757,",",O
1757,if,O
1757,any,O
1757,",",O
1757,holds,O
1757,between,O
1757,every,O
1757,possible,O
1757,pair,O
1757,of,O
1757,text,O
1757,spans,O
1757,",",O
1757,while,O
1757,using,O
1757,aggressive,O
1757,beam,O
1757,1,O
1757,Code,O
1757,and,O
1757,models,O
1757,:,O
1757,https://github.com/luheng/lsgn,B
1757,pruning,O
1757,for,O
1757,efficiency,O
1757,.,O
1758,We,O
1758,propose,B
1758,an,O
1758,end,O
1758,-,O
1758,to,O
1758,-,O
1758,end,O
1758,approach,O
1758,for,B
1758,predicting,I
1758,all,B
1758,the,I
1758,predicates,I
1758,and,O
1758,their,O
1758,argument,B
1758,spans,I
1758,in,B
1758,one,B
1758,forward,I
1758,pass,I
1758,.,O
1759,Our,O
1759,model,O
1759,builds,B
1759,on,I
1759,a,O
1759,recent,B
1759,coreference,I
1759,resolution,I
1759,model,O
1759,",",O
1759,by,B
1759,making,I
1759,central,B
1759,use,B
1759,of,I
1759,learned,B
1759,",",O
1759,contextualized,O
1759,span,O
1759,representations,O
1759,.,O
1760,We,O
1760,use,B
1760,these,O
1760,representations,B
1760,to,B
1760,predict,I
1760,SRL,B
1760,graphs,I
1760,directly,B
1760,over,I
1760,text,B
1760,spans,I
1760,.,O
1761,Each,O
1761,edge,O
1761,is,O
1761,identified,B
1761,by,I
1761,independently,B
1761,predicting,I
1761,which,B
1761,role,B
1761,",",O
1761,if,O
1761,any,O
1761,",",O
1761,holds,B
1761,between,I
1761,every,B
1761,possible,I
1761,pair,I
1761,of,I
1761,text,I
1761,spans,I
1761,",",O
1761,while,O
1761,using,O
1761,aggressive,O
1761,beam,O
1761,1,O
1761,Code,O
1761,and,O
1761,models,O
1761,:,O
1761,https://github.com/luheng/lsgn,O
1761,pruning,O
1761,for,O
1761,efficiency,O
1761,.,O
1762,The,O
1762,final,B
1762,graph,I
1762,is,O
1762,simply,O
1762,the,O
1762,union,B
1762,of,I
1762,predicted,B
1762,SRL,I
1762,roles,I
1762,(,I
1762,edges,I
1762,),I
1762,and,O
1762,their,O
1762,associated,B
1762,text,I
1762,spans,I
1762,(,O
1762,nodes,O
1762,),O
1762,.,O
1763,This,O
1763,work,O
1763,presents,B
1763,a,O
1763,solution,B
1763,that,O
1763,can,O
1763,resolve,B
1763,the,O
1763,inefficient,B
1763,multiple,I
1763,-,I
1763,passes,I
1763,issue,I
1763,of,B
1763,existing,B
1763,solutions,I
1763,for,B
1763,MRE,B
1763,by,B
1763,encoding,I
1763,the,O
1763,input,B
1763,only,I
1763,once,I
1763,",",O
1763,which,O
1763,significantly,O
1763,increases,O
1763,the,O
1763,efficiency,O
1763,and,O
1763,scalability,O
1763,.,O
1764,The,O
1764,span,B
1764,representations,I
1764,also,O
1764,generalize,B
1764,the,O
1764,token,B
1764,-,I
1764,level,I
1764,representations,O
1764,in,B
1764,BIObased,B
1764,models,I
1764,",",O
1764,letting,B
1764,the,O
1764,model,B
1764,dynamically,B
1764,decide,I
1764,which,B
1764,spans,I
1764,and,I
1764,roles,I
1764,to,I
1764,include,I
1764,",",O
1764,without,B
1764,using,I
1764,previously,B
1764,standard,I
1764,syntactic,I
1764,features,I
1764,.,O
1765,To,O
1765,the,O
1765,best,O
1765,of,O
1765,our,O
1765,knowledge,O
1765,",",O
1765,this,O
1765,is,B
1765,the,O
1765,first,B
1765,span,I
1765,-,I
1765,based,I
1765,SRL,I
1765,model,I
1765,that,B
1765,does,I
1765,not,I
1765,assume,I
1765,that,O
1765,predicates,B
1765,are,I
1765,given,I
1765,.,O
1766,Jointly,O
1766,Predicting,O
1766,Predicates,O
1766,and,O
1766,Arguments,O
1766,in,O
1766,Neural,B
1766,Semantic,I
1766,Role,I
1766,Labeling,I
1767,Recent,O
1767,high,O
1767,-,O
1767,performing,O
1767,SRL,B
1767,models,O
1767,are,O
1767,BIO,O
1767,-,O
1767,taggers,O
1767,",",O
1767,labeling,O
1767,argument,O
1767,spans,O
1767,for,O
1767,a,O
1767,single,O
1767,predicate,O
1767,at,O
1767,a,O
1767,time,O
1767,(,O
1767,as,O
1767,shown,O
1767,in,O
1767,.,O
1768,As,O
1768,shown,O
1768,in,O
1768,",",O
1768,2,O
1768,our,O
1768,joint,B
1768,model,I
1768,outperforms,B
1768,the,O
1768,previous,B
1768,best,I
1768,pipeline,I
1768,system,I
1768,by,B
1768,an,O
1768,F1,B
1768,difference,I
1768,of,B
1768,anywhere,B
1768,between,I
1768,1.3,I
1768,and,I
1768,6.0,I
1768,in,O
1768,every,O
1768,setting,O
1768,.,O
1769,On,B
1769,all,B
1769,datasets,I
1769,",",O
1769,our,B
1769,model,I
1769,is,O
1769,able,B
1769,to,I
1769,predict,B
1769,over,B
1769,40,B
1769,%,I
1769,of,B
1769,the,O
1769,sentences,B
1769,completely,B
1769,correctly,I
1769,.,O
1770,We,O
1770,train,B
1770,the,O
1770,model,B
1770,using,B
1770,Nadam,B
1770,(,I
1770,Dozat,I
1770,",",I
1770,2016,I
1770,),I
1770,SGD,I
1770,combined,O
1770,with,O
1770,the,O
1770,learning,O
1770,rate,O
1770,schedule,O
1770,in,O
1770,.,O
1771,In,O
1771,addition,O
1771,to,O
1771,MTL,O
1771,",",O
1771,we,O
1771,regularize,B
1771,our,B
1771,model,I
1771,using,B
1771,dropout,B
1771,.,O
1772,We,O
1772,use,B
1772,gradient,B
1772,clipping,I
1772,to,B
1772,avoid,I
1772,exploding,B
1772,gradients,I
1772,.,O
1773,Specifically,O
1773,",",O
1773,the,O
1773,proposed,B
1773,solution,I
1773,is,O
1773,built,B
1773,on,I
1773,top,I
1773,of,I
1773,the,O
1773,existing,B
1773,transformer,I
1773,-,I
1773,based,I
1773,",",O
1773,pretrained,O
1773,general,O
1773,-,O
1773,purposed,O
1773,language,O
1773,encoders,O
1773,.,O
1774,In,O
1774,response,O
1774,",",O
1774,we,O
1774,propose,B
1774,linguistically,B
1774,-,I
1774,informed,I
1774,self,I
1774,-,O
1774,attention,O
1774,(,O
1774,LISA,O
1774,),O
1774,:,O
1774,a,O
1774,model,O
1774,that,O
1774,combines,O
1774,multi-task,O
1774,learning,O
1774,with,O
1774,stacked,O
1774,layers,O
1774,of,O
1774,multi-head,O
1774,self,O
1774,-,O
1774,attention,O
1774,;,O
1774,the,O
1774,model,O
1774,is,O
1774,trained,B
1774,to,B
1774,:,O
1774,(,O
1774,1,O
1774,),O
1774,jointly,B
1774,predict,I
1774,parts,B
1774,of,O
1774,speech,O
1774,and,O
1774,predicates,O
1774,;,O
1774,(,O
1774,2,O
1774,),O
1774,perform,B
1774,parsing,I
1774,;,O
1774,and,O
1774,(,O
1774,3,O
1774,),O
1774,attend,B
1774,to,O
1774,syntactic,B
1774,parse,I
1774,parents,I
1774,",",O
1774,while,O
1774,(,O
1774,4,O
1774,),O
1774,assigning,B
1774,semantic,B
1774,role,I
1774,labels,I
1774,.,O
1775,Whereas,O
1775,prior,O
1775,work,O
1775,typically,O
1775,requires,O
1775,separate,O
1775,models,O
1775,to,O
1775,provide,O
1775,linguistic,O
1775,analysis,O
1775,",",O
1775,including,O
1775,most,O
1775,syntaxfree,O
1775,neural,O
1775,models,O
1775,which,O
1775,still,O
1775,rely,O
1775,on,O
1775,external,O
1775,predicate,O
1775,detection,O
1775,",",O
1775,our,O
1775,model,O
1775,is,O
1775,truly,O
1775,end,O
1775,-,O
1775,to,O
1775,-,O
1775,end,O
1775,:,O
1775,earlier,B
1775,layers,I
1775,are,O
1775,trained,B
1775,to,O
1775,predict,O
1775,prerequisite,B
1775,parts,I
1775,-,O
1775,of,O
1775,-,O
1775,speech,O
1775,and,O
1775,predicates,O
1775,",",O
1775,the,O
1775,latter,B
1775,of,O
1775,which,O
1775,are,O
1775,supplied,B
1775,to,O
1775,later,B
1775,layers,O
1775,for,B
1775,scoring,B
1775,.,O
1776,Though,O
1776,prior,O
1776,work,O
1776,re-encodes,O
1776,each,B
1776,sentence,I
1776,to,O
1776,predict,O
1776,each,O
1776,desired,O
1776,task,O
1776,and,O
1776,again,O
1776,with,O
1776,respect,O
1776,to,O
1776,each,O
1776,predicate,O
1776,to,O
1776,perform,O
1776,SRL,O
1776,",",O
1776,we,O
1776,more,O
1776,efficiently,O
1776,encode,B
1776,each,O
1776,sentence,O
1776,only,B
1776,once,I
1776,",",O
1776,predict,O
1776,its,O
1776,predicates,B
1776,",",O
1776,part,B
1776,-,I
1776,of,I
1776,-,O
1776,speech,O
1776,tags,O
1776,and,O
1776,labeled,B
1776,syntactic,I
1776,parse,I
1776,",",O
1776,then,B
1776,predict,O
1776,the,O
1776,semantic,B
1776,roles,I
1776,for,O
1776,all,O
1776,predicates,O
1776,in,O
1776,the,O
1776,sentence,O
1776,in,O
1776,parallel,O
1776,.,O
1777,Linguistically,O
1777,-,O
1777,Informed,O
1777,Self,O
1777,-,O
1777,Attention,O
1777,for,O
1777,Semantic,B
1777,Role,I
1777,Labeling,I
1778,Current,O
1778,state,O
1778,-,O
1778,of,O
1778,-,O
1778,the,O
1778,-,O
1778,art,O
1778,semantic,B
1778,role,I
1778,labeling,I
1778,(,I
1778,SRL,I
1778,),I
1778,uses,O
1778,a,O
1778,deep,O
1778,neural,O
1778,network,O
1778,with,O
1778,no,O
1778,explicit,O
1778,linguistic,O
1778,features,O
1778,.,O
1779,However,O
1779,",",O
1779,prior,O
1779,work,O
1779,has,O
1779,shown,O
1779,that,O
1779,gold,O
1779,syntax,O
1779,trees,O
1779,can,O
1779,dramatically,O
1779,improve,O
1779,SRL,B
1779,decoding,O
1779,",",O
1779,suggesting,O
1779,the,O
1779,possibility,O
1779,of,O
1779,increased,O
1779,accuracy,O
1779,from,O
1779,explicit,O
1779,modeling,O
1779,of,O
1779,syntax,O
1779,.,O
1780,We,O
1780,present,O
1780,results,O
1780,on,B
1780,the,I
1780,CoNLL,I
1780,-,I
1780,2005,I
1780,shared,I
1780,task,I
1780,and,I
1780,the,O
1780,CoNLL,O
1780,-,O
1780,2012,O
1780,English,O
1780,subset,O
1780,of,O
1780,OntoNotes,O
1780,5.0,O
1780,",",O
1780,achieving,B
1780,state,B
1780,-,O
1780,of,O
1780,-,O
1780,the,O
1780,-,O
1780,art,O
1780,results,O
1780,for,B
1780,a,O
1780,single,B
1780,model,I
1780,with,B
1780,predicted,B
1780,predicates,I
1780,on,O
1780,both,B
1780,corpora,I
1780,.,O
1781,We,O
1781,demonstrate,B
1781,that,I
1781,our,B
1781,models,I
1781,benefit,B
1781,from,I
1781,injecting,B
1781,state,B
1781,-,I
1781,of,I
1781,-,O
1781,the,O
1781,-,O
1781,art,O
1781,predicted,O
1781,parses,O
1781,at,B
1781,test,B
1781,time,I
1781,(,O
1781,+,O
1781,D&M,O
1781,),O
1781,by,O
1781,fixing,O
1781,the,O
1781,attention,O
1781,to,O
1781,parses,O
1781,predicted,O
1781,by,O
1781,Dozat,O
1781,and,O
1781,Manning,O
1781,(,O
1781,2017,O
1781,),O
1781,",",O
1781,the,O
1781,winner,O
1781,of,O
1781,the,O
1781,2017,O
1781,CoNLL,O
1781,shared,O
1781,task,O
1781,which,O
1781,we,O
1781,re-train,O
1781,using,O
1781,ELMo,O
1781,embeddings,O
1781,.,O
1782,For,B
1782,models,B
1782,using,B
1782,GloVe,B
1782,embeddings,I
1782,",",O
1782,our,B
1782,syntax,I
1782,-,I
1782,free,I
1782,SA,I
1782,model,I
1782,already,O
1782,achieves,B
1782,a,O
1782,new,B
1782,state,I
1782,-,O
1782,of,O
1782,-,O
1782,the,O
1782,-,O
1782,art,O
1782,by,B
1782,jointly,I
1782,predicting,I
1782,predicates,B
1782,",",O
1782,POS,B
1782,and,O
1782,SRL,B
1782,.,O
1783,LISA,B
1783,with,I
1783,it,O
1783,s,O
1783,own,B
1783,parses,I
1783,performs,I
1783,comparably,B
1783,to,B
1783,SA,B
1783,",",O
1783,but,O
1783,when,B
1783,supplied,I
1783,with,O
1783,D&M,B
1783,parses,O
1783,LISA,O
1783,out,B
1783,-,I
1783,performs,O
1783,the,O
1783,previous,B
1783,state,I
1783,-,O
1783,of,O
1783,-,O
1783,the,O
1783,-,O
1783,art,O
1783,by,B
1783,2.5,B
1783,F1,I
1783,points,I
1783,.,O
1784,In,O
1784,this,O
1784,paper,O
1784,we,O
1784,use,B
1784,Bidirectional,B
1784,Encoder,I
1784,Representations,I
1784,from,I
1784,Transformers,I
1784,(,I
1784,BERT,I
1784,),I
1784,as,B
1784,the,O
1784,transformer,B
1784,-,I
1784,based,I
1784,encoder,O
1784,",",O
1784,but,O
1784,this,O
1784,solution,O
1784,is,O
1784,not,O
1784,limited,O
1784,to,O
1784,using,O
1784,BERT,O
1784,alone,O
1784,.,O
1785,On,B
1785,the,O
1785,out,B
1785,-,I
1785,ofdomain,I
1785,Brown,I
1785,test,I
1785,set,I
1785,",",O
1785,LISA,B
1785,also,O
1785,performs,B
1785,comparably,B
1785,to,B
1785,its,B
1785,syntax,B
1785,-,O
1785,free,O
1785,counterpart,O
1785,with,B
1785,its,O
1785,own,O
1785,parses,O
1785,",",O
1785,but,O
1785,with,O
1785,D&M,B
1785,parses,O
1785,LISA,O
1785,performs,O
1785,exceptionally,B
1785,well,I
1785,",",O
1785,more,O
1785,than,O
1785,3.5,O
1785,F1,O
1785,points,O
1785,higher,O
1785,than,O
1785,He,O
1785,et,O
1785,al,O
1785,..,O
1786,Incorporating,B
1786,ELMo,B
1786,em-beddings,I
1786,improves,B
1786,all,B
1786,scores,I
1786,.,O
1787,Without,O
1787,dropout,O
1787,",",O
1787,the,O
1787,model,B
1787,overfits,B
1787,at,B
1787,around,B
1787,300,I
1787,epochs,I
1787,at,O
1787,78,B
1787,F1,I
1787,.,O
1788,Orthonormal,O
1788,parameter,O
1788,initialization,O
1788,is,B
1788,surprisingly,B
1788,important,I
1788,-,O
1788,without,B
1788,this,I
1788,",",O
1788,the,O
1788,model,B
1788,achieves,B
1788,only,B
1788,65,I
1788,F1,I
1788,within,B
1788,the,O
1788,first,B
1788,50,I
1788,epochs,I
1788,.,O
1789,All,O
1789,8,B
1789,layer,I
1789,ablations,I
1789,suffer,B
1789,a,O
1789,loss,B
1789,of,O
1789,more,B
1789,than,I
1789,1.7,B
1789,in,B
1789,absolute,B
1789,F,I
1789,1,I
1789,compared,B
1789,to,I
1789,the,O
1789,full,B
1789,model,I
1789,.,O
1790,Our,O
1790,network,B
1790,consists,B
1790,of,I
1790,8,B
1790,BiLSTM,I
1790,layers,I
1790,(,I
1790,4,I
1790,forward,I
1790,LSTMs,I
1790,and,I
1790,4,O
1790,reversed,O
1790,LSTMs,O
1790,),O
1790,with,B
1790,300,B
1790,dimensional,I
1790,hidden,I
1790,units,I
1790,",",O
1790,and,O
1790,a,O
1790,softmax,B
1790,layer,I
1790,for,B
1790,predicting,I
1790,the,O
1790,output,B
1790,distribution,I
1790,.,O
1791,All,O
1791,the,O
1791,weight,B
1791,matrices,I
1791,in,B
1791,BiL,B
1791,-,I
1791,STMs,I
1791,are,O
1791,initialized,B
1791,with,I
1791,random,B
1791,orthonormal,I
1791,matrices,O
1791,as,O
1791,described,O
1791,in.,O
1792,All,O
1792,tokens,O
1792,are,B
1792,lower,B
1792,-,I
1792,cased,I
1792,and,O
1792,initialized,B
1792,with,I
1792,100,B
1792,-,O
1792,dimensional,O
1792,GloVe,O
1792,embeddings,O
1792,pre-trained,B
1792,on,I
1792,6B,B
1792,tokens,O
1792,and,O
1792,updated,B
1792,during,I
1792,training,B
1792,.,O
1793,Tokens,B
1793,that,O
1793,are,O
1793,not,B
1793,covered,I
1793,by,I
1793,GloVe,B
1793,are,O
1793,replaced,B
1793,with,I
1793,a,O
1793,randomly,B
1793,initialized,I
1793,UNK,I
1793,embedding,I
1793,.,O
1794,All,O
1794,the,O
1794,models,B
1794,are,O
1794,trained,B
1794,for,I
1794,500,B
1794,epochs,I
1794,with,B
1794,early,B
1794,stopping,I
1794,based,B
1794,on,I
1794,development,B
1794,results,I
1794,.,O
1795,The,O
1795,two,O
1795,novel,O
1795,modifications,O
1795,to,O
1795,the,O
1795,original,O
1795,BERT,O
1795,architecture,O
1795,are,O
1795,:,O
1795,(,O
1795,1,O
1795,),O
1795,we,O
1795,introduce,B
1795,a,O
1795,structured,B
1795,prediction,I
1795,layer,I
1795,for,B
1795,predicting,I
1795,multiple,B
1795,relations,I
1795,for,O
1795,different,B
1795,entity,I
1795,pairs,I
1795,;,O
1795,and,O
1795,(,O
1795,2,O
1795,),O
1795,we,O
1795,make,B
1795,the,O
1795,selfattention,B
1795,layers,I
1795,aware,B
1795,of,B
1795,the,O
1795,positions,B
1795,of,O
1795,all,B
1795,en-tities,I
1795,in,B
1795,the,O
1795,input,B
1795,paragraph,I
1795,.,O
1796,Training,O
1796,We,O
1796,use,B
1796,Adadelta,B
1796,(,O
1796,Zeiler,O
1796,",",O
1796,2012,O
1796,),O
1796,with,B
1796,=,O
1796,1e,O
1796,?6,O
1796,and,O
1796,?,O
1797,=,O
1797,0.95,O
1797,and,O
1797,mini-batches,B
1797,of,O
1797,size,B
1797,80,B
1797,.,O
1798,We,O
1798,set,B
1798,RNN,B
1798,-,I
1798,dropout,I
1798,probability,I
1798,to,B
1798,0.1,B
1798,and,O
1798,clip,B
1798,gradients,B
1798,with,B
1798,norm,B
1798,larger,B
1798,than,I
1798,1,B
1798,.,O
1799,In,O
1799,this,O
1799,paper,O
1799,",",O
1799,we,O
1799,show,O
1799,that,O
1799,this,O
1799,result,O
1799,can,O
1799,be,O
1799,pushed,O
1799,further,O
1799,using,B
1799,deep,B
1799,highway,I
1799,bidirectional,I
1799,LSTMs,I
1799,with,B
1799,constrained,B
1799,decoding,I
1799,",",O
1799,again,O
1799,significantly,O
1799,moving,O
1799,the,O
1799,state,O
1799,of,O
1799,the,O
1799,art,O
1799,(,O
1799,another,O
1799,2,O
1799,points,O
1799,on,O
1799,CoNLL,O
1799,2005,O
1799,),O
1799,.,O
1800,Fol,O
1800,-,O
1800,lowing,O
1800,",",O
1800,we,O
1800,treat,B
1800,SRL,B
1800,as,B
1800,a,O
1800,BIO,B
1800,tagging,I
1800,problem,I
1800,and,O
1800,use,B
1800,deep,B
1800,bidirectional,I
1800,LSTMs,I
1800,.,O
1801,However,O
1801,",",O
1801,we,O
1801,differ,B
1801,by,I
1801,(,O
1801,1,O
1801,),O
1801,simplifying,B
1801,the,O
1801,input,B
1801,and,I
1801,output,I
1801,layers,I
1801,",",O
1801,(,O
1801,2,O
1801,),O
1801,introducing,B
1801,highway,B
1801,connections,I
1801,",",O
1801,(,O
1801,3,O
1801,),O
1801,using,B
1801,recurrent,B
1801,dropout,I
1801,",",O
1801,(,O
1801,4,O
1801,),O
1801,decoding,B
1801,with,B
1801,BIOconstraints,B
1801,",",O
1801,and,O
1801,(,O
1801,5,O
1801,),O
1801,ensembling,B
1801,with,O
1801,a,O
1801,product,B
1801,of,I
1801,experts,I
1801,.,O
1802,We,O
1802,introduce,O
1802,a,O
1802,new,O
1802,deep,O
1802,learning,O
1802,model,O
1802,for,O
1802,semantic,B
1802,role,I
1802,labeling,I
1802,(,I
1802,SRL,I
1802,),I
1802,that,O
1802,significantly,O
1802,improves,O
1802,the,O
1802,state,O
1802,of,O
1802,the,O
1802,art,O
1802,",",O
1802,along,O
1802,with,O
1802,detailed,O
1802,analyses,O
1802,to,O
1802,reveal,O
1802,its,O
1802,strengths,O
1802,and,O
1802,limitations,O
1802,.,O
1803,Recently,O
1803,breakthroughs,O
1803,involving,O
1803,end,O
1803,-,O
1803,to,O
1803,-,O
1803,end,O
1803,deep,O
1803,models,O
1803,for,O
1803,SRL,B
1803,without,O
1803,syntactic,O
1803,input,O
1803,seem,O
1803,to,O
1803,overturn,O
1803,the,O
1803,long,O
1803,-,O
1803,held,O
1803,belief,O
1803,that,O
1803,syntactic,O
1803,parsing,O
1803,is,O
1803,a,O
1803,prerequisite,O
1803,for,O
1803,this,O
1803,task,O
1803,.,O
1804,Our,O
1804,ensemble,O
1804,(,O
1804,PoE,O
1804,),O
1804,has,O
1804,an,B
1804,absolute,I
1804,improvement,I
1804,of,B
1804,2.1,B
1804,F1,I
1804,on,B
1804,both,O
1804,CoNLL,B
1804,2005,I
1804,and,O
1804,CoNLL,O
1804,2012,O
1804,over,B
1804,the,I
1804,previous,B
1804,state,I
1804,of,O
1804,the,O
1804,art,O
1804,.,O
1805,Our,O
1805,single,O
1805,model,O
1805,also,O
1805,achieves,B
1805,more,B
1805,than,I
1805,a,I
1805,0.4,I
1805,improvement,I
1805,on,B
1805,both,B
1805,datasets,I
1805,.,O
1806,In,O
1806,comparison,O
1806,with,O
1806,the,O
1806,best,B
1806,reported,I
1806,results,I
1806,",",O
1806,our,B
1806,percentage,I
1806,of,I
1806,completely,I
1806,correct,I
1806,predicates,I
1806,improves,B
1806,by,I
1806,5.9,B
1806,points,I
1806,.,O
1807,While,O
1807,the,O
1807,continuing,O
1807,trend,O
1807,of,O
1807,improving,O
1807,SRL,O
1807,without,O
1807,syntax,O
1807,seems,O
1807,to,O
1807,suggest,O
1807,that,O
1807,neural,O
1807,end,O
1807,-,O
1807,to,O
1807,-,O
1807,end,O
1807,systems,O
1807,no,O
1807,longer,O
1807,needs,O
1807,parsers,O
1807,",",O
1807,our,O
1807,analysis,O
1807,in,O
1807,Section,O
1807,4.4,O
1807,will,O
1807,show,B
1807,that,O
1807,accurate,B
1807,syntactic,I
1807,information,I
1807,can,O
1807,improve,B
1807,these,O
1807,deep,B
1807,models,I
1807,.,O
1808,We,O
1808,initialize,B
1808,the,O
1808,weights,B
1808,of,B
1808,all,B
1808,sub-layers,I
1808,as,B
1808,random,B
1808,orthogonal,I
1808,matrices,I
1808,.,O
1809,For,O
1809,other,B
1809,parameters,I
1809,",",O
1809,we,O
1809,initialize,O
1809,them,O
1809,by,B
1809,sampling,I
1809,each,B
1809,element,I
1809,from,B
1809,a,O
1809,Gaussian,B
1809,distribution,I
1809,with,B
1809,mean,O
1809,0,O
1809,and,O
1809,variance,O
1809,1,O
1809,?,O
1810,The,O
1810,embedding,B
1810,layer,I
1810,can,B
1810,be,I
1810,initialized,B
1810,randomly,I
1810,or,O
1810,using,O
1810,pre-trained,B
1810,word,I
1810,embeddings,I
1810,.,O
1811,The,O
1811,dimension,B
1811,of,I
1811,word,B
1811,embeddings,I
1811,and,I
1811,predicate,I
1811,mask,I
1811,embeddings,O
1811,is,O
1811,set,B
1811,to,I
1811,100,B
1811,and,O
1811,the,O
1811,number,B
1811,of,O
1811,hidden,O
1811,layers,O
1811,is,O
1811,set,O
1811,to,O
1811,10,B
1811,.,O
1812,The,O
1812,number,B
1812,of,I
1812,heads,I
1812,h,I
1812,is,O
1812,set,B
1812,to,I
1812,8,B
1812,.,O
1813,Dropout,O
1813,layers,O
1813,are,O
1813,added,B
1813,before,I
1813,residual,B
1813,connections,I
1813,with,B
1813,a,O
1813,keep,B
1813,probability,I
1813,of,B
1813,0.8,B
1813,.,O
1814,Dropout,B
1814,is,O
1814,also,O
1814,applied,B
1814,before,I
1814,the,O
1814,attention,B
1814,softmax,I
1814,layer,I
1814,and,O
1814,the,O
1814,feed,B
1814,-,I
1814,froward,I
1814,ReLU,I
1814,hidden,I
1814,layer,O
1814,",",O
1814,and,O
1814,the,O
1814,keep,B
1814,probabilities,I
1814,are,O
1814,set,B
1814,to,I
1814,0.9,B
1814,.,O
1815,Learning,O
1815,Parameter,O
1815,optimization,O
1815,is,O
1815,performed,B
1815,using,I
1815,stochastic,B
1815,gradient,I
1815,descent,I
1815,.,O
1816,Regularization,O
1816,Dropout,B
1816,is,O
1816,applied,B
1816,with,I
1816,dropout,O
1816,rate,O
1816,0.2,O
1816,to,B
1816,all,B
1816,hidden,I
1816,layers,I
1816,of,B
1816,all,O
1816,MLPs,O
1816,and,O
1816,feature,O
1816,encodings,O
1816,",",O
1816,with,O
1816,dropout,O
1816,rate,O
1816,0.5,O
1816,to,O
1816,all,O
1816,word,O
1816,and,O
1816,character,O
1816,embeddings,O
1816,and,O
1816,with,O
1816,dropout,O
1816,rate,O
1816,0.4,O
1816,to,O
1816,all,O
1816,LSTM,O
1816,layer,O
1816,outputs,O
1816,.,O
1817,The,O
1817,state,O
1817,-,O
1817,of,O
1817,-,O
1817,the,O
1817,-,O
1817,art,O
1817,solutions,O
1817,for,O
1817,extracting,B
1817,multiple,I
1817,entity,I
1817,-,O
1817,relations,O
1817,from,O
1817,an,O
1817,input,O
1817,paragraph,O
1817,always,O
1817,require,O
1817,a,O
1817,multiple,O
1817,-,O
1817,pass,O
1817,encoding,O
1817,on,O
1817,the,O
1817,input,O
1817,.,O
1818,Each,O
1818,SGD,B
1818,contains,B
1818,a,O
1818,mini-batch,B
1818,of,B
1818,approximately,I
1818,4096,B
1818,tokens,I
1818,for,B
1818,the,O
1818,CoNLL,B
1818,-,I
1818,2005,I
1818,dataset,I
1818,and,O
1818,8192,B
1818,tokens,O
1818,for,O
1818,the,O
1818,CoNLL,O
1818,-,O
1818,2012,O
1818,dataset,O
1818,.,O
1819,The,O
1819,learning,B
1819,rate,I
1819,is,O
1819,initialized,B
1819,to,I
1819,1.0,B
1819,.,O
1820,We,O
1820,set,B
1820,the,O
1820,number,B
1820,of,I
1820,hidden,I
1820,units,I
1820,d,I
1820,to,B
1820,200,B
1820,.,O
1821,We,O
1821,also,O
1821,employ,B
1821,label,B
1821,smoothing,B
1821,technique,I
1821,with,B
1821,a,O
1821,smoothing,O
1821,value,O
1821,of,B
1821,0.1,B
1821,during,B
1821,training,B
1821,.,O
1822,We,O
1822,adopt,B
1822,Adadelta,B
1822,),O
1822,(,O
1822,=,O
1822,10,O
1822,6,O
1822,and,O
1822,?,O
1823,=,O
1823,0.95,O
1823,),O
1823,as,B
1823,the,O
1823,optimizer,B
1823,.,O
1824,To,O
1824,avoid,O
1824,exploding,B
1824,gradients,I
1824,problem,I
1824,",",O
1824,we,O
1824,clip,B
1824,the,O
1824,norm,B
1824,of,B
1824,gradients,O
1824,with,B
1824,a,O
1824,predefined,B
1824,threshold,I
1824,1.0,I
1824,.,O
1825,After,O
1825,training,O
1825,400,B
1825,k,I
1825,steps,I
1825,",",O
1825,we,O
1825,halve,B
1825,the,O
1825,learning,B
1825,rate,I
1825,every,B
1825,100,B
1825,K,O
1825,steps,O
1825,.,O
1826,We,O
1826,train,B
1826,all,B
1826,models,I
1826,for,B
1826,600,B
1826,K,I
1826,steps,I
1826,.,O
1827,For,B
1827,DEEP,B
1827,-,I
1827,ATT,I
1827,with,B
1827,FFN,B
1827,sub,I
1827,-,O
1827,layers,O
1827,",",O
1827,the,O
1827,whole,B
1827,training,I
1827,stage,I
1827,takes,B
1827,about,O
1827,two,B
1827,days,I
1827,to,B
1827,finish,B
1827,on,B
1827,a,O
1827,single,B
1827,Titan,I
1827,X,I
1827,GPU,I
1827,",",O
1827,which,B
1827,is,I
1827,2.5,B
1827,times,I
1827,faster,I
1827,than,O
1827,the,O
1827,previous,O
1827,approach,O
1827,),O
1827,.,O
1828,To,O
1828,address,O
1828,these,O
1828,problems,O
1828,above,O
1828,",",O
1828,we,O
1828,present,B
1828,a,O
1828,deep,B
1828,attentional,I
1828,neural,I
1828,network,I
1828,(,I
1828,DEEPATT,I
1828,),I
1828,for,B
1828,the,O
1828,task,O
1828,of,O
1828,SRL,B
1828,1,O
1828,.,O
1829,This,O
1829,paper,O
1829,proposes,O
1829,a,O
1829,new,O
1829,solution,O
1829,that,O
1829,can,O
1829,complete,O
1829,the,O
1829,multiple,B
1829,entityrelations,I
1829,extraction,I
1829,task,O
1829,with,O
1829,only,O
1829,one,O
1829,-,O
1829,pass,O
1829,encoding,O
1829,on,O
1829,the,O
1829,input,O
1829,corpus,O
1829,",",O
1829,and,O
1829,achieve,O
1829,a,O
1829,new,O
1829,state,O
1829,-,O
1829,of,O
1829,-,O
1829,the,O
1829,-,O
1829,art,O
1829,accuracy,O
1829,performance,O
1829,",",O
1829,as,O
1829,demonstrated,O
1829,in,O
1829,the,O
1829,ACE,O
1829,2005,O
1829,benchmark,O
1829,.,O
1830,Our,O
1830,models,O
1830,rely,B
1830,on,I
1830,the,O
1830,self,B
1830,-,I
1830,attention,I
1830,mechanism,I
1830,which,O
1830,directly,B
1830,draws,I
1830,the,O
1830,global,B
1830,dependencies,I
1830,of,B
1830,the,O
1830,inputs,B
1830,.,O
1831,In,B
1831,contrast,O
1831,to,O
1831,RNNs,O
1831,",",O
1831,a,O
1831,major,B
1831,advantage,I
1831,of,I
1831,self,B
1831,-,I
1831,attention,I
1831,is,O
1831,that,O
1831,it,O
1831,conducts,B
1831,direct,B
1831,connections,I
1831,between,B
1831,two,B
1831,arbitrary,I
1831,tokens,I
1831,in,O
1831,a,O
1831,sentence,B
1831,.,O
1832,Therefore,O
1832,",",O
1832,distant,B
1832,elements,I
1832,can,B
1832,interact,I
1832,with,I
1832,each,B
1832,other,I
1832,by,B
1832,shorter,B
1832,paths,I
1832,(,O
1832,O,O
1832,(,O
1832,1,O
1832,),O
1832,v.s.,O
1833,O,O
1833,(,O
1833,n,O
1833,),O
1833,),O
1833,",",O
1833,which,O
1833,allows,B
1833,unimpeded,B
1833,information,I
1833,flow,I
1833,through,B
1833,the,O
1833,network,B
1833,.,O
1834,Self,O
1834,-,O
1834,attention,O
1834,also,O
1834,provides,B
1834,a,O
1834,more,B
1834,flexible,I
1834,way,I
1834,to,I
1834,select,I
1834,",",I
1834,represent,I
1834,and,I
1834,synthesize,I
1834,the,O
1834,information,B
1834,of,B
1834,the,O
1834,inputs,B
1834,and,O
1834,is,O
1834,complementary,B
1834,to,O
1834,RNN,B
1834,based,I
1834,models,I
1834,.,O
1835,Along,O
1835,with,O
1835,self,B
1835,-,I
1835,attention,I
1835,",",O
1835,DEEP,B
1835,-,O
1835,ATT,O
1835,comes,B
1835,with,O
1835,three,B
1835,variants,I
1835,which,O
1835,uses,B
1835,recurrent,B
1835,(,I
1835,RNN,I
1835,),I
1835,",",O
1835,convolutional,B
1835,(,O
1835,CNN,O
1835,),O
1835,and,O
1835,feed,B
1835,-,O
1835,forward,O
1835,(,O
1835,FFN,O
1835,),O
1835,neural,O
1835,network,O
1835,to,B
1835,further,I
1835,enhance,I
1835,the,O
1835,representations,B
1835,.,O
1836,In,O
1836,this,O
1836,paper,O
1836,",",O
1836,we,O
1836,present,O
1836,a,O
1836,simple,O
1836,and,O
1836,effective,O
1836,architecture,O
1836,for,O
1836,SRL,B
1836,which,O
1836,aims,O
1836,to,O
1836,address,O
1836,these,O
1836,problems,O
1836,.,O
1837,In,O
1837,Remarkably,O
1837,",",O
1837,we,O
1837,get,B
1837,74.1,B
1837,F,I
1837,1,I
1837,score,I
1837,on,B
1837,the,O
1837,out,B
1837,-,I
1837,of,I
1837,-,O
1837,domain,O
1837,dataset,O
1837,",",O
1837,which,O
1837,outperforms,O
1837,the,O
1837,previous,O
1837,state,O
1837,-,O
1837,of,O
1837,-,O
1837,the,O
1837,-,O
1837,art,O
1837,system,O
1837,by,O
1837,2.0,O
1837,F,O
1837,1,O
1837,score,O
1837,.,O
1838,When,O
1838,ensembling,O
1838,5,B
1838,models,I
1838,with,B
1838,FFN,B
1838,nonlinear,I
1838,sub,I
1838,-,I
1838,layers,I
1838,",",O
1838,our,B
1838,approach,I
1838,achieves,B
1838,an,O
1838,F,B
1838,1,I
1838,score,I
1838,of,I
1838,84.6,B
1838,and,I
1838,83.9,I
1838,on,O
1838,the,O
1838,two,O
1838,datasets,O
1838,respectively,O
1838,",",O
1838,which,O
1838,has,O
1838,an,O
1838,absolute,B
1838,improvement,I
1838,of,O
1838,1.4,B
1838,and,O
1838,0.5,O
1838,over,B
1838,the,O
1838,previous,B
1838,state,I
1838,-,O
1838,of,O
1838,-,O
1838,the,O
1838,-,O
1838,art,O
1838,.,O
1839,These,O
1839,results,B
1839,are,O
1839,consistent,O
1839,with,O
1839,our,O
1839,intuition,O
1839,that,B
1839,the,O
1839,self,B
1839,-,I
1839,attention,I
1839,layers,I
1839,is,O
1839,helpful,B
1839,to,I
1839,capture,I
1839,structural,B
1839,information,I
1839,and,O
1839,long,B
1839,distance,I
1839,dependencies,I
1839,.,O
1840,For,O
1840,comparison,O
1840,",",O
1840,as,O
1840,a,O
1840,model,O
1840,based,O
1840,on,O
1840,BIO,O
1840,tagging,O
1840,approaches,O
1840,",",O
1840,we,O
1840,use,B
1840,the,O
1840,BiLSTM,B
1840,-,I
1840,CRF,I
1840,model,O
1840,proposed,O
1840,by,O
1840,.,O
1841,As,B
1841,the,O
1841,base,O
1841,function,O
1841,f,O
1841,base,O
1841,",",O
1841,we,O
1841,use,B
1841,4,B
1841,BiLSTM,I
1841,layers,I
1841,with,B
1841,300,B
1841,dimensional,I
1841,hidden,I
1841,units,I
1841,.,O
1842,As,O
1842,the,O
1842,objective,B
1842,function,I
1842,",",O
1842,we,O
1842,use,B
1842,the,O
1842,crossentropy,B
1842,L,I
1842,?,O
1843,3,O
1843,with,B
1843,L2,B
1843,weight,I
1843,decay,I
1843,",",O
1844,To,O
1844,optimize,B
1844,the,O
1844,model,B
1844,parameters,I
1844,",",O
1844,we,O
1844,use,B
1844,Adam,B
1844,.,O
1845,To,O
1845,validate,O
1845,the,O
1845,model,B
1845,performance,I
1845,",",O
1845,we,O
1845,use,B
1845,two,B
1845,types,I
1845,of,I
1845,word,I
1845,embeddings,I
1845,.,O
1846,Typical,O
1846,word,O
1846,embeddings,O
1846,",",O
1846,SENNA,B
1846,6,O
1846,(,O
1846,Collobert,O
1846,et,O
1846,al.,O
1847,",",O
1847,2011,O
1847,),O
1847,Contextualized,O
1847,word,O
1847,embeddings,O
1847,",",O
1847,ELMo,B
1847,7,O
1847,SENNA,B
1847,and,O
1847,ELMo,O
1847,can,O
1847,be,O
1847,regarded,O
1847,as,O
1847,different,O
1847,types,O
1847,of,O
1847,embeddings,O
1847,in,O
1847,terms,O
1847,of,O
1847,the,O
1847,context,O
1847,sensitivity,O
1847,.,O
1848,These,O
1848,embeddings,B
1848,are,O
1848,fixed,B
1848,during,I
1848,training,B
1848,.,O
1849,To,O
1849,fill,O
1849,this,O
1849,gap,O
1849,",",O
1849,this,O
1849,paper,O
1849,presents,B
1849,a,O
1849,simple,B
1849,and,I
1849,accurate,I
1849,span,I
1849,-,I
1849,based,I
1849,model,I
1849,.,O
1850,One,O
1850,particular,O
1850,type,O
1850,of,O
1850,the,O
1850,RE,B
1850,task,O
1850,is,O
1850,multiplerelations,B
1850,extraction,I
1850,(,I
1850,MRE,I
1850,),I
1850,that,O
1850,aims,O
1850,to,O
1850,recognize,O
1850,relations,O
1850,of,O
1850,multiple,O
1850,pairs,O
1850,of,O
1850,entity,O
1850,mentions,O
1850,from,O
1850,an,O
1850,input,O
1850,paragraph,O
1850,.,O
1851,Inspired,O
1851,by,O
1851,recent,O
1851,span,B
1851,-,O
1851,based,B
1851,models,O
1851,in,O
1851,syntactic,O
1851,parsing,O
1851,and,O
1851,coreference,O
1851,resolution,O
1851,",",O
1851,our,O
1851,model,O
1851,directly,B
1851,scores,I
1851,all,B
1851,possible,I
1851,labeled,I
1851,spans,I
1851,based,O
1851,on,O
1851,span,O
1851,representations,O
1851,induced,B
1851,from,I
1851,neural,B
1851,networks,I
1851,.,O
1852,At,B
1852,decoding,B
1852,time,I
1852,",",O
1852,we,O
1852,greedily,B
1852,select,I
1852,higher,B
1852,scoring,I
1852,labeled,I
1852,spans,I
1852,.,O
1853,The,O
1853,model,B
1853,parameters,I
1853,are,O
1853,learned,B
1853,by,I
1853,optimizing,B
1853,loglikelihood,I
1853,of,B
1853,correct,B
1853,labeled,I
1853,spans,I
1853,.,O
1854,A,O
1854,Span,O
1854,Selection,O
1854,Model,O
1854,for,O
1854,Semantic,B
1854,Role,I
1854,Labeling,I
1855,We,O
1855,present,O
1855,a,O
1855,simple,O
1855,and,O
1855,accurate,O
1855,span,O
1855,-,O
1855,based,O
1855,model,O
1855,for,O
1855,semantic,B
1855,role,I
1855,labeling,I
1855,(,I
1855,SRL,I
1855,),I
1855,.,O
1856,Given,O
1856,a,O
1856,sentence,O
1856,and,O
1856,a,O
1856,target,O
1856,predicate,O
1856,",",O
1856,SRL,B
1856,systems,O
1856,have,O
1856,to,O
1856,predict,O
1856,semantic,O
1856,arguments,O
1856,of,O
1856,the,O
1856,predicate,O
1856,.,O
1857,We,O
1857,report,B
1857,averaged,B
1857,scores,I
1857,across,B
1857,five,B
1857,different,I
1857,runs,I
1857,of,B
1857,the,O
1857,model,B
1857,training,O
1857,.,O
1858,Overall,O
1858,",",O
1858,our,O
1858,span,B
1858,-,I
1858,based,I
1858,ensemble,I
1858,model,I
1858,using,B
1858,ELMo,B
1858,achieved,B
1858,the,O
1858,best,B
1858,F1,I
1858,scores,I
1858,",",O
1858,87.4,B
1858,F1,O
1858,and,O
1858,87.0,O
1858,F1,O
1858,on,B
1858,the,O
1858,CoNLL,O
1858,-,O
1858,2005,O
1858,and,O
1858,CoNLL,O
1858,-,O
1858,2012,O
1858,datasets,O
1858,",",O
1858,respectively,O
1858,.,O
1859,Our,O
1859,single,O
1859,and,O
1859,ensemble,O
1859,models,O
1859,using,O
1859,ELMO,O
1859,achieved,B
1859,the,I
1859,best,B
1859,F,I
1859,1,I
1859,scores,I
1859,on,B
1859,all,B
1859,the,O
1859,test,O
1859,sets,O
1859,except,B
1859,the,O
1859,Brown,B
1859,test,O
1859,set,O
1859,.,O
1860,In,O
1860,comparison,O
1860,with,O
1860,the,O
1860,CRF,B
1860,-,I
1860,based,I
1860,single,I
1860,model,I
1860,",",I
1860,our,B
1860,span,I
1860,-,O
1860,based,O
1860,single,O
1860,model,O
1860,consistently,B
1860,yielded,I
1860,better,B
1860,F,I
1860,1,I
1860,scores,I
1860,regardless,B
1860,of,I
1860,the,O
1860,word,B
1860,embeddings,I
1860,",",O
1860,SENNA,O
1860,and,O
1860,ELMO,O
1860,.,O
1861,Because,O
1861,in,O
1861,real,O
1861,-,O
1861,world,O
1861,applications,O
1861,",",O
1861,whose,O
1861,input,O
1861,paragraphs,O
1861,dominantly,O
1861,contain,O
1861,multiple,O
1861,pairs,O
1861,of,O
1861,entities,O
1861,",",O
1861,an,O
1861,efficient,O
1861,and,O
1861,effective,O
1861,solution,O
1861,for,O
1861,MRE,B
1861,has,O
1861,more,O
1861,important,O
1861,and,O
1861,more,O
1861,practical,O
1861,implications,O
1861,.,O
1862,The,O
1862,method,O
1862,was,O
1862,implemented,B
1862,in,I
1862,TensorFlow,B
1862,.,O
1863,We,O
1863,use,B
1863,300,B
1863,dimensional,I
1863,GloVe,I
1863,embeddings,I
1863,to,B
1863,represent,I
1863,words,B
1863,.,O
1864,Each,O
1864,embedding,O
1864,vector,O
1864,was,O
1864,normalized,B
1864,to,B
1864,have,I
1864,2,B
1864,norm,I
1864,of,I
1864,1,I
1864,and,O
1864,projected,B
1864,down,I
1864,to,O
1864,200,B
1864,dimensions,I
1864,",",O
1864,a,O
1864,number,O
1864,determined,O
1864,via,O
1864,hyperparameter,O
1864,tuning,O
1864,.,O
1865,Out,O
1865,-,O
1865,of,O
1865,-,O
1865,vocabulary,O
1865,(,O
1865,OOV,O
1865,),O
1865,words,O
1865,are,O
1865,hashed,B
1865,to,I
1865,one,B
1865,of,O
1865,100,O
1865,random,O
1865,embeddings,O
1865,each,O
1865,initialized,B
1865,to,O
1865,mean,B
1865,0,I
1865,and,O
1865,standard,B
1865,deviation,I
1865,1,I
1865,.,O
1866,All,O
1866,other,B
1866,parameter,I
1866,weights,I
1866,(,I
1866,hidden,I
1866,layers,I
1866,etc.,I
1866,),I
1867,were,O
1867,initialized,B
1867,from,I
1867,random,B
1867,Gaussians,I
1867,with,B
1867,mean,B
1867,0,I
1867,and,O
1867,standard,B
1867,deviation,I
1867,0.01,I
1867,.,O
1868,Each,O
1868,hyperparameter,O
1868,setting,O
1868,was,O
1868,run,B
1868,on,I
1868,a,O
1868,single,B
1868,machine,I
1868,with,B
1868,10,B
1868,asynchronous,I
1868,gradient,I
1868,-,I
1868,update,I
1868,threads,I
1868,",",O
1868,using,B
1868,Adagrad,B
1868,for,B
1868,optimization,B
1868,with,O
1868,the,O
1868,default,B
1868,initial,I
1868,accumulator,I
1868,value,I
1868,of,B
1868,0.1,B
1868,.,O
1869,Dropout,O
1869,regularization,O
1869,was,O
1869,used,B
1869,for,I
1869,all,B
1869,ReLU,I
1869,layers,I
1869,",",O
1869,but,O
1869,not,B
1869,for,O
1869,the,O
1869,final,B
1869,linear,I
1869,layer,I
1869,.,O
1870,We,O
1870,additionally,O
1870,tuned,O
1870,the,O
1870,following,O
1870,hyperparameters,O
1870,and,O
1870,present,O
1870,their,O
1870,chosen,O
1870,values,O
1870,in,O
1870,",",O
1870,1,O
1870,dropout,B
1870,ratio,I
1870,(,O
1870,0.2,B
1870,),O
1870,and,O
1870,learning,B
1870,rate,I
1870,(,O
1870,0.05,B
1870,-,O
1870,vanilla,B
1870,",",O
1870,0.025,B
1870,-,O
1870,intra-attention,B
1870,),O
1870,.,O
1871,In,O
1871,contrast,O
1871,to,O
1871,existing,O
1871,approaches,O
1871,",",O
1871,our,O
1871,approach,O
1871,only,O
1871,relies,B
1871,on,I
1871,alignment,B
1871,and,O
1871,is,O
1871,fully,B
1871,computationally,I
1871,decomposable,I
1871,with,B
1871,respect,I
1871,to,O
1871,the,O
1871,input,B
1871,text,I
1871,.,O
1872,Finally,O
1872,",",O
1872,the,O
1872,results,B
1872,of,B
1872,these,O
1872,subproblems,B
1872,are,O
1872,merged,B
1872,to,B
1872,produce,I
1872,the,O
1872,final,B
1872,classification,I
1872,.,O
1873,The,O
1873,first,B
1873,observation,I
1873,is,B
1873,that,I
1873,our,B
1873,model,I
1873,architecture,I
1873,achieves,B
1873,much,B
1873,better,I
1873,results,I
1873,compared,B
1873,to,I
1873,the,O
1873,previous,B
1873,state,I
1873,-,I
1873,of,I
1873,-,O
1873,the,O
1873,-,O
1873,art,O
1873,methods,O
1873,.,O
1874,Given,B
1874,two,B
1874,sentences,I
1874,",",O
1874,where,O
1874,each,B
1874,word,I
1874,is,O
1874,repre-sented,B
1874,by,I
1874,an,O
1874,embedding,B
1874,vector,I
1874,",",O
1874,we,O
1874,first,O
1874,create,B
1874,a,O
1874,soft,B
1874,alignment,I
1874,matrix,I
1874,using,B
1874,neural,B
1874,attention,I
1874,.,O
1875,We,O
1875,then,O
1875,use,B
1875,the,O
1875,(,B
1875,soft,I
1875,),I
1875,alignment,I
1875,to,B
1875,decompose,I
1875,the,O
1875,task,B
1875,into,B
1875,subproblems,B
1875,that,O
1875,are,O
1875,solved,O
1875,separately,O
1875,.,O
1876,In,O
1876,addition,O
1876,",",O
1876,we,O
1876,optionally,O
1876,apply,B
1876,intra-sentence,B
1876,attention,I
1876,to,I
1876,endow,I
1876,the,O
1876,model,B
1876,with,B
1876,a,O
1876,richer,B
1876,encoding,I
1876,of,B
1876,substructures,B
1876,prior,B
1876,to,O
1876,the,O
1876,alignment,B
1876,step,I
1876,.,O
1877,A,O
1877,Decomposable,O
1877,Attention,O
1877,Model,O
1877,for,O
1877,Natural,B
1877,Language,I
1877,Inference,I
1878,NLI,B
1878,is,O
1878,a,O
1878,central,O
1878,problem,O
1878,in,O
1878,language,O
1878,understanding,O
1878,),O
1878,and,O
1878,recently,O
1878,the,O
1878,large,O
1878,SNLI,O
1878,corpus,O
1878,of,O
1878,570K,O
1878,sentence,O
1878,pairs,O
1878,was,O
1878,created,O
1878,for,O
1878,this,O
1878,task,O
1878,.,O
1879,Our,O
1879,vanilla,O
1879,approach,O
1879,achieves,B
1879,state,B
1879,-,I
1879,of,I
1879,-,O
1879,theart,O
1879,results,O
1879,with,B
1879,almost,B
1879,an,I
1879,order,I
1879,of,O
1879,magnitude,O
1879,fewer,O
1879,parameters,O
1879,than,B
1879,the,O
1879,LSTMN,B
1879,of,O
1879,.,O
1880,Adding,B
1880,intra-sentence,B
1880,attention,I
1880,gives,B
1880,a,O
1880,considerable,B
1880,improvement,I
1880,of,I
1880,0.5,B
1880,percentage,I
1880,points,I
1880,over,B
1880,the,I
1880,existing,B
1880,state,I
1880,of,O
1880,the,O
1880,art,O
1880,.,O
1881,Within,O
1881,this,O
1881,domain,O
1881,",",O
1881,we,O
1881,propose,O
1881,an,O
1881,approach,O
1881,that,B
1881,learns,B
1881,to,I
1881,both,O
1881,select,B
1881,and,I
1881,explain,I
1881,answers,I
1881,",",O
1881,when,B
1881,the,O
1881,only,B
1881,supervision,I
1881,available,I
1881,is,I
1881,for,O
1881,which,B
1881,answer,I
1881,is,O
1881,correct,O
1881,(,O
1881,but,O
1881,not,B
1881,how,B
1881,to,O
1881,explain,O
1881,it,O
1881,),O
1881,.,O
1882,Intuitively,O
1882,",",O
1882,our,O
1882,approach,O
1882,chooses,B
1882,the,O
1882,justifications,B
1882,that,B
1882,provide,I
1882,the,O
1882,most,B
1882,help,I
1882,towards,B
1882,ranking,B
1882,the,O
1882,correct,B
1882,answers,I
1882,higher,B
1882,than,B
1882,incorrect,B
1882,ones,I
1882,.,O
1883,The,O
1883,simpler,O
1883,version,O
1883,of,O
1883,our,O
1883,approach,O
1883,",",O
1883,BERT,O
1883,SP,O
1883,",",O
1883,can,O
1883,successfully,B
1883,adapt,I
1883,the,O
1883,pre-trained,B
1883,BERT,O
1883,to,B
1883,the,O
1883,MRE,B
1883,task,I
1883,",",O
1883,and,O
1883,achieves,B
1883,comparable,B
1883,performance,I
1883,at,O
1883,the,O
1883,3,O
1883,Note,O
1883,the,O
1883,usage,O
1883,of,O
1883,relative,O
1883,position,O
1883,embeddings,O
1883,does,O
1883,notwork,O
1883,for,O
1883,one,O
1883,-,O
1883,pass,O
1883,MRE,O
1883,",",O
1883,since,O
1883,each,O
1883,word,O
1883,corresponds,O
1883,to,O
1883,a,O
1883,varying,O
1883,number,O
1883,of,O
1883,position,O
1883,embedding,O
1883,vectors,O
1883,.,O
1884,More,O
1884,formally,B
1884,",",O
1884,our,B
1884,neural,I
1884,network,I
1884,approach,I
1884,alternates,B
1884,between,O
1884,using,B
1884,the,O
1884,current,B
1884,model,I
1884,with,B
1884,max,B
1884,-,I
1884,pooling,I
1884,to,B
1884,choose,I
1884,the,O
1884,highest,B
1884,scoring,I
1884,justifications,B
1884,for,B
1884,correct,B
1884,answers,I
1884,",",O
1884,and,O
1884,optimizing,B
1884,the,O
1884,answer,B
1884,ranking,I
1884,model,O
1884,given,B
1884,these,O
1884,justifications,O
1884,.,O
1885,For,O
1885,this,O
1885,baseline,O
1885,",",O
1885,we,O
1885,rank,B
1885,answer,I
1885,candidates,I
1885,by,B
1885,the,O
1885,maximum,B
1885,tf,I
1885,.idf,I
1885,document,I
1885,retrieval,I
1885,score,I
1885,using,B
1885,an,O
1885,unboosted,B
1885,query,I
1885,of,B
1885,question,B
1885,and,I
1885,answer,O
1885,terms,O
1885,(,O
1885,see,O
1885,Section,O
1885,4.1,O
1885,for,O
1885,retrieval,O
1885,details,O
1885,),O
1885,.,O
1886,This,O
1886,baseline,O
1886,uses,B
1886,the,I
1886,same,B
1886,architecture,I
1886,as,B
1886,the,O
1886,full,B
1886,model,I
1886,",",O
1886,as,O
1886,described,O
1886,in,O
1886,Section,O
1886,4.3,O
1886,",",O
1886,but,O
1886,with,B
1886,only,B
1886,the,O
1886,IR,O
1886,++,O
1886,feature,O
1886,group,O
1886,.,O
1887,Tell,O
1887,Me,O
1887,Why,O
1887,:,O
1887,Using,O
1887,Question,O
1887,Answering,O
1887,as,O
1887,Distant,O
1887,Supervision,O
1887,for,O
1887,Answer,B
1887,Justification,I
1888,Our,O
1888,full,O
1888,model,O
1888,that,O
1888,combines,B
1888,IR,I
1888,++,I
1888,",",I
1888,lexical,I
1888,overlap,I
1888,",",O
1888,discourse,O
1888,",",O
1888,and,O
1888,embeddings,O
1888,-,O
1888,based,O
1888,features,O
1888,",",O
1888,has,O
1888,a,O
1888,P@1,B
1888,of,B
1888,53.3,B
1888,%,I
1888,(,O
1888,line,O
1888,7,O
1888,),O
1888,",",O
1888,an,O
1888,absolute,B
1888,gain,I
1888,of,O
1888,6.3,B
1888,%,O
1888,over,B
1888,the,O
1888,strong,B
1888,IR,O
1888,baseline,O
1888,despite,O
1888,using,O
1888,the,O
1888,same,O
1888,background,O
1888,knowledge,O
1888,.,O
1889,also,O
1889,tackle,B
1889,the,O
1889,AI2,B
1889,Kaggle,I
1889,question,I
1889,set,I
1889,with,O
1889,an,O
1889,approach,O
1889,that,O
1889,learns,O
1889,alignments,O
1889,between,O
1889,questions,O
1889,and,O
1889,structured,O
1889,and,O
1889,semistructured,O
1889,KB,O
1889,data,O
1889,.,O
1890,Our,O
1890,full,O
1890,model,O
1890,",",O
1890,with,O
1890,the,O
1890,structured,B
1890,fine,I
1890,-,I
1890,tuning,I
1890,of,I
1890,attention,B
1890,layers,I
1890,",",O
1890,brings,B
1890,further,B
1890,improvement,I
1890,of,O
1890,about,B
1890,5.5,I
1890,%,I
1890,",",O
1890,in,B
1890,the,O
1890,MRE,B
1890,one,I
1890,-,O
1890,pass,O
1890,setting,O
1890,",",O
1890,and,O
1890,achieves,B
1890,a,O
1890,new,B
1890,state,I
1890,-,O
1890,of,O
1890,-,O
1890,the,O
1890,-,O
1890,art,O
1890,performance,O
1890,when,O
1890,compared,B
1890,to,I
1890,the,O
1890,methods,B
1890,with,O
1890,domain,O
1890,adaptation,O
1890,.,O
1891,By,O
1891,way,O
1891,of,O
1891,a,O
1891,loose,B
1891,comparison,I
1891,(,O
1891,since,O
1891,we,O
1891,are,O
1891,evaluating,O
1891,on,O
1891,different,O
1891,data,O
1891,partitions,O
1891,),O
1891,",",O
1891,our,B
1891,model,I
1891,has,O
1891,approximately,B
1891,5,I
1891,%,I
1891,higher,I
1891,performance,I
1891,despite,O
1891,our,O
1891,simpler,O
1891,set,O
1891,of,O
1891,features,O
1891,and,O
1891,unstructured,O
1891,KB,O
1891,.,O
1892,In,B
1892,comparison,O
1892,to,O
1892,other,B
1892,systems,I
1892,that,B
1892,competed,B
1892,in,O
1892,the,O
1892,Kaggle,B
1892,challenge,I
1892,",",O
1892,our,B
1892,system,I
1892,comes,O
1892,in,O
1892,in,O
1892,7th,B
1892,place,I
1892,out,B
1892,of,I
1892,170,B
1892,competitors,I
1892,(,O
1892,top,O
1892,4,O
1892,%,O
1892,),O
1892,.,O
1893,Note,O
1893,that,O
1893,61,B
1893,%,I
1893,of,B
1893,the,O
1893,top,B
1893,-,I
1893,ranked,I
1893,justifications,I
1893,from,B
1893,our,B
1893,system,I
1893,were,O
1893,rated,B
1893,as,I
1893,Good,B
1893,as,O
1893,compared,B
1893,to,I
1893,52,B
1893,%,O
1893,from,O
1893,the,O
1893,IR,B
1893,baseline,I
1893,(,O
1893,a,O
1893,gain,O
1893,of,O
1893,9,O
1893,%,O
1893,),O
1893,",",O
1893,despite,O
1893,the,O
1893,systems,O
1893,using,O
1893,identical,O
1893,corpora,O
1893,.,O
1894,The,O
1894,spaCy,B
1894,tool,I
1894,2,O
1894,is,O
1894,used,B
1894,to,I
1894,tokenize,B
1894,the,O
1894,both,B
1894,passages,B
1894,and,I
1894,questions,I
1894,",",O
1894,and,O
1894,generate,B
1894,lemma,B
1894,",",O
1894,part,B
1894,-,I
1894,of,I
1894,-,O
1894,speech,O
1894,and,O
1894,named,B
1894,entity,I
1894,tags,I
1894,.,O
1895,The,O
1895,mini-batch,B
1895,size,I
1895,is,O
1895,set,B
1895,to,I
1895,32,B
1895,and,O
1895,Adamax,B
1895,is,O
1895,used,B
1895,as,I
1895,our,B
1895,optimizer,I
1895,.,O
1896,The,O
1896,learning,B
1896,rate,I
1896,is,O
1896,set,B
1896,to,I
1896,0.002,B
1896,at,B
1896,first,B
1896,and,O
1896,decreased,B
1896,by,B
1896,half,B
1896,after,B
1896,every,B
1896,10,I
1896,epochs,I
1896,.,O
1897,We,O
1897,use,B
1897,2,B
1897,-,I
1897,layer,I
1897,BiLSTM,I
1897,with,B
1897,d,B
1897,=,I
1897,128,I
1897,hidden,I
1897,units,I
1897,for,B
1897,both,B
1897,passage,I
1897,and,I
1897,question,I
1897,encoding,I
1897,.,O
1898,We,O
1898,set,B
1898,the,I
1898,dropout,B
1898,rate,I
1898,for,B
1898,all,B
1898,the,O
1898,hidden,O
1898,units,O
1898,of,B
1898,LSTM,B
1898,",",O
1898,and,O
1898,the,O
1898,answer,B
1898,module,I
1898,output,I
1898,layer,I
1898,to,B
1898,0.4,B
1898,.,O
1899,To,O
1899,prevent,O
1899,degenerate,B
1899,output,I
1899,",",O
1899,we,O
1899,ensure,B
1899,that,I
1899,at,B
1899,least,I
1899,one,I
1899,step,I
1899,in,B
1899,the,O
1899,answer,B
1899,module,I
1899,is,B
1899,active,B
1899,during,B
1899,training,B
1899,.,O
1900,Our,O
1900,Entity,O
1900,-,O
1900,Aware,O
1900,BERT,O
1900,SP,O
1900,gives,B
1900,comparable,B
1900,results,I
1900,to,B
1900,the,O
1900,top,B
1900,-,O
1900,ranked,O
1900,system,O
1900,in,B
1900,the,O
1900,shared,B
1900,task,I
1900,",",O
1900,with,B
1900,slightly,B
1900,lower,I
1900,Macro,I
1900,-,O
1900,F1,O
1900,",",O
1900,which,O
1900,is,O
1900,the,O
1900,official,O
1900,metric,O
1900,of,O
1900,the,O
1900,task,O
1900,",",O
1900,and,O
1900,slightly,O
1900,higher,O
1900,Micro,O
1900,-,O
1900,F1,O
1900,.,O
1901,In,O
1901,this,O
1901,work,O
1901,",",O
1901,we,O
1901,derive,B
1901,an,O
1901,alternative,B
1901,multi-step,I
1901,reasoning,I
1901,neural,I
1901,network,I
1901,for,B
1901,MRC,B
1901,.,O
1902,During,B
1902,training,B
1902,",",O
1902,we,O
1902,fix,B
1902,the,O
1902,number,B
1902,of,I
1902,reasoning,I
1902,steps,I
1902,",",O
1902,but,O
1902,perform,B
1902,stochastic,B
1902,dropout,I
1902,on,B
1902,the,O
1902,answer,B
1902,module,I
1902,(,I
1902,final,I
1902,layer,I
1902,predictions,I
1902,),I
1902,.,O
1903,During,O
1903,decoding,B
1903,",",O
1903,we,O
1903,generate,B
1903,answers,B
1903,based,B
1903,on,I
1903,the,O
1903,average,B
1903,of,B
1903,predictions,B
1903,in,B
1903,all,B
1903,steps,I
1903,",",O
1903,rather,B
1903,than,I
1903,the,O
1903,final,B
1903,step,I
1903,.,O
1904,We,O
1904,call,B
1904,this,O
1904,a,O
1904,stochastic,B
1904,answer,I
1904,network,I
1904,(,I
1904,SAN,I
1904,),I
1904,because,O
1904,the,O
1904,stochastic,O
1904,dropout,O
1904,is,O
1904,applied,O
1904,to,O
1904,the,O
1904,answer,O
1904,module,O
1904,;,O
1904,albeit,O
1904,simple,O
1904,",",O
1904,this,O
1904,technique,O
1904,significantly,O
1904,improves,O
1904,the,O
1904,robustness,O
1904,and,O
1904,over,O
1904,all,O
1904,accuracy,O
1904,of,O
1904,the,O
1904,model,O
1904,.,O
1905,Stochastic,O
1905,Answer,O
1905,Networks,O
1905,for,O
1905,Machine,B
1905,Reading,I
1905,Comprehension,I
1906,It,O
1906,has,O
1906,been,O
1906,hypothesized,O
1906,that,O
1906,difficult,O
1906,MRC,B
1906,problems,O
1906,require,O
1906,some,O
1906,form,O
1906,of,O
1906,multi-step,O
1906,synthesis,O
1906,and,O
1906,reasoning,O
1906,.,O
1907,We,O
1907,observe,B
1907,that,O
1907,SAN,B
1907,achieves,B
1907,76.235,B
1907,EM,I
1907,and,O
1907,84.056,B
1907,F1,I
1907,",",O
1907,outperforming,B
1907,all,B
1907,other,I
1907,models,I
1907,.,O
1908,Standard,O
1908,1,O
1908,-,O
1908,step,O
1908,model,O
1908,only,B
1908,achieves,B
1908,75.139,B
1908,EM,I
1908,and,O
1908,dynamic,B
1908,steps,I
1908,(,I
1908,via,I
1908,ReasoNet,I
1908,),I
1908,achieves,O
1908,only,O
1908,75.355,O
1908,EM,O
1908,.,O
1909,SAN,B
1909,also,O
1909,outperforms,B
1909,a,O
1909,5,B
1909,-,I
1909,step,I
1909,memory,I
1909,net,I
1909,with,B
1909,averaging,B
1909,",",O
1909,which,O
1909,implies,O
1909,averaging,O
1909,predictions,O
1909,is,O
1909,not,O
1909,the,O
1909,only,O
1909,thing,O
1909,that,O
1909,led,O
1909,to,O
1909,SAN,O
1909,'s,O
1909,superior,O
1909,results,O
1909,;,O
1909,indeed,O
1909,",",O
1909,stochastic,O
1909,prediction,O
1909,dropout,O
1909,is,O
1909,an,O
1909,effective,O
1909,technique,O
1909,.,O
1910,Note,B
1910,that,O
1910,our,B
1910,method,I
1910,was,O
1910,not,B
1910,designed,I
1910,for,I
1910,domain,B
1910,adaptation,I
1910,",",O
1910,it,O
1910,still,B
1910,outperforms,I
1910,those,O
1910,methods,B
1910,with,B
1910,domain,O
1910,adaptation,O
1910,.,O
1911,SAN,O
1911,also,O
1911,outperforms,O
1911,the,O
1911,other,B
1911,models,B
1911,in,B
1911,terms,I
1911,of,I
1911,K-,B
1911,best,I
1911,oracle,I
1911,scores,I
1911,.,O
1912,We,O
1912,see,B
1912,that,I
1912,SAN,B
1912,is,B
1912,very,B
1912,competitive,I
1912,in,B
1912,both,B
1912,single,I
1912,and,I
1912,ensemble,I
1912,settings,I
1912,(,O
1912,ranked,B
1912,in,O
1912,second,B
1912,),O
1912,despite,O
1912,its,O
1912,simplicity,O
1912,.,O
1913,To,O
1913,alleviate,O
1913,this,O
1913,challenge,O
1913,",",O
1913,we,O
1913,identify,B
1913,an,O
1913,attention,B
1913,scoring,I
1913,function,I
1913,utilizing,B
1913,all,B
1913,layers,I
1913,of,B
1913,representation,B
1913,with,B
1913,less,B
1913,training,I
1913,burden,I
1913,.,O
1914,This,O
1914,leads,B
1914,to,I
1914,an,O
1914,attention,B
1914,that,O
1914,thoroughly,B
1914,captures,I
1914,the,I
1914,complete,B
1914,information,I
1914,between,B
1914,the,O
1914,question,B
1914,and,I
1914,the,O
1914,context,O
1914,.,O
1915,With,B
1915,this,O
1915,fully,B
1915,-,I
1915,aware,I
1915,attention,I
1915,",",O
1915,we,O
1915,put,B
1915,forward,I
1915,a,O
1915,multi,B
1915,-level,I
1915,attention,O
1915,mechanism,O
1915,to,B
1915,understand,I
1915,the,O
1915,information,B
1915,in,B
1915,the,O
1915,question,B
1915,",",O
1915,and,O
1915,exploit,B
1915,it,I
1915,layer,I
1915,by,I
1915,layer,O
1915,on,B
1915,the,O
1915,context,B
1915,side,I
1915,.,O
1916,All,O
1916,of,O
1916,these,O
1916,innovations,B
1916,are,O
1916,integrated,B
1916,into,I
1916,a,O
1916,new,B
1916,end,I
1916,-,I
1916,to,I
1916,-,O
1916,end,O
1916,structure,O
1916,called,B
1916,FusionNet,B
1916,in,O
1916,",",O
1916,with,O
1916,details,O
1916,described,O
1916,in,O
1916,Section,O
1916,3,O
1916,.,O
1917,FUSIONNET,O
1917,:,O
1917,FUSING,O
1917,VIA,O
1917,FULLY,O
1917,-,O
1917,AWARE,O
1917,ATTENTION,O
1917,WITH,O
1917,APPLICATION,O
1917,TO,O
1917,MACHINE,B
1917,COMPREHENSION,I
1918,Many,O
1918,neural,O
1918,network,O
1918,models,O
1918,have,O
1918,been,O
1918,proposed,O
1918,for,O
1918,this,O
1918,challenge,O
1918,and,O
1918,they,O
1918,generally,O
1918,frame,O
1918,this,O
1918,problem,O
1918,as,O
1918,a,O
1918,machine,B
1918,reading,I
1918,comprehension,I
1918,(,I
1918,MRC,I
1918,),I
1918,task,O
1918,.,O
1919,We,O
1919,argue,O
1919,that,O
1919,this,O
1919,hypothesis,O
1919,also,O
1919,holds,O
1919,in,O
1919,language,B
1919,understanding,I
1919,and,O
1919,MRC,B
1919,.,O
1920,Learning,B
1920,Learning,O
1920,is,O
1920,done,B
1920,with,B
1920,Adam,B
1920,(,I
1920,Kingma,I
1920,and,I
1920,Ba,I
1920,",",I
1920,2015,I
1920,),I
1920,with,O
1920,default,B
1920,parameters,I
1920,.,O
1921,Among,B
1921,all,B
1921,the,I
1921,BERT,I
1921,-,I
1921,based,I
1921,approaches,I
1921,",",O
1921,finetuning,B
1921,the,O
1921,off,B
1921,-,O
1921,the,O
1921,-,O
1921,shelf,O
1921,BERT,O
1921,does,B
1921,not,I
1921,give,I
1921,a,O
1921,satisfying,B
1921,result,I
1921,",",O
1921,because,O
1921,the,O
1921,sentence,O
1921,embeddings,O
1921,can,O
1921,not,O
1921,distinguish,O
1921,different,O
1921,entity,O
1921,pairs,O
1921,.,O
1922,From,O
1922,the,O
1922,results,O
1922,",",O
1922,we,O
1922,can,O
1922,see,B
1922,that,I
1922,our,B
1922,models,I
1922,not,B
1922,only,I
1922,perform,I
1922,well,B
1922,on,B
1922,the,O
1922,original,B
1922,SQuAD,I
1922,dataset,I
1922,",",O
1922,but,O
1922,also,B
1922,outperform,B
1922,all,B
1922,previous,I
1922,models,O
1922,by,B
1922,more,B
1922,than,I
1922,5,I
1922,%,I
1922,in,B
1922,EM,B
1922,score,I
1922,on,O
1922,the,O
1922,adversarial,B
1922,datasets,I
1922,.,O
1923,This,O
1923,shows,B
1923,that,O
1923,FusionNet,B
1923,is,B
1923,better,B
1923,at,B
1923,language,B
1923,understanding,I
1923,of,B
1923,both,I
1923,the,O
1923,context,B
1923,and,I
1923,question,I
1923,.,O
1924,attention,O
1924,-,O
1924,based,O
1924,recurrent,O
1924,network,O
1924,(,O
1924,GARNN,O
1924,),O
1924,and,O
1924,self,B
1924,-,O
1924,matching,O
1924,attention,O
1924,mechanism,O
1924,positively,B
1924,contribute,I
1924,to,B
1924,the,O
1924,final,B
1924,results,I
1924,of,B
1924,gated,B
1924,self,O
1924,-,O
1924,matching,O
1924,networks,O
1924,.,O
1925,Characterlevel,O
1925,embeddings,O
1925,contribute,B
1925,towards,I
1925,the,O
1925,model,B
1925,'s,I
1925,performance,I
1925,since,O
1925,it,O
1925,can,B
1925,better,B
1925,handle,I
1925,out,B
1925,-,I
1925,ofvocab,I
1925,or,I
1925,rare,I
1925,words,I
1925,.,O
1926,Character,O
1926,-,O
1926,level,O
1926,embeddings,O
1926,are,O
1926,not,B
1926,utilized,B
1926,.,O
1927,As,O
1927,shown,O
1927,in,O
1927,",",O
1927,the,O
1927,gate,B
1927,introduced,B
1927,in,O
1927,question,B
1927,and,I
1927,passage,I
1927,matching,I
1927,layer,I
1927,is,O
1927,helpful,B
1927,for,B
1927,both,O
1927,GRU,B
1927,and,O
1927,LSTM,O
1927,on,O
1927,the,O
1927,SQuAD,O
1927,dataset,O
1927,.,O
1928,Removing,B
1928,self,B
1928,-,I
1928,matching,I
1928,results,B
1928,in,I
1928,3.5,B
1928,point,I
1928,EM,I
1928,drop,I
1928,",",O
1928,which,O
1928,reveals,O
1928,that,O
1928,information,O
1928,in,O
1928,the,O
1928,passage,O
1928,plays,O
1928,an,O
1928,important,O
1928,role,O
1928,.,O
1929,We,O
1929,use,B
1929,the,O
1929,tokenizer,B
1929,from,B
1929,Stanford,B
1929,CoreNLP,I
1929,to,B
1929,preprocess,I
1929,each,B
1929,passage,I
1929,and,I
1929,question,I
1929,.,O
1930,The,O
1930,hidden,B
1930,vector,I
1930,length,I
1930,is,O
1930,set,B
1930,to,I
1930,75,B
1930,for,B
1930,all,B
1930,layers,I
1930,.,O
1931,The,O
1931,hidden,B
1931,size,I
1931,used,O
1931,to,B
1931,compute,I
1931,attention,B
1931,scores,I
1931,is,B
1931,also,O
1931,75,B
1931,.,O
1932,It,O
1932,works,B
1932,for,I
1932,the,O
1932,singlerelation,B
1932,per,I
1932,pass,I
1932,setting,I
1932,",",O
1932,but,O
1932,the,O
1932,performance,B
1932,lags,B
1932,behind,I
1932,using,I
1932,only,B
1932,indicators,I
1932,of,B
1932,the,O
1932,two,B
1932,target,I
1932,entities,I
1932,.,O
1933,The,O
1933,Gated,B
1933,Recurrent,I
1933,Unit,I
1933,variant,I
1933,of,B
1933,LSTM,B
1933,is,O
1933,used,B
1933,throughout,I
1933,our,B
1933,model,I
1933,.,O
1934,The,O
1934,model,B
1934,is,O
1934,optimized,B
1934,with,B
1934,AdaDelta,B
1934,(,I
1934,Zeiler,I
1934,",",I
1934,2012,I
1934,),I
1934,with,O
1934,an,O
1934,initial,B
1934,learning,I
1934,rate,I
1934,of,B
1934,1,B
1934,.,O
1935,For,B
1935,word,B
1935,embedding,I
1935,",",O
1935,we,O
1935,use,B
1935,pretrained,B
1935,case,I
1935,-,I
1935,sensitive,I
1935,GloVe,I
1935,embeddings,I
1935,2,O
1935,(,O
1935,Pennington,O
1935,et,O
1935,al.,O
1936,",",O
1936,2014,O
1936,),O
1936,for,B
1936,both,O
1936,questions,B
1936,and,I
1936,passages,I
1936,",",O
1936,and,O
1936,it,O
1936,is,O
1936,fixed,B
1936,during,B
1936,training,B
1936,;,O
1936,We,O
1936,use,B
1936,zero,B
1936,vectors,I
1936,to,B
1936,represent,I
1936,all,B
1936,out,I
1936,-,I
1936,of,I
1936,-,O
1936,vocab,O
1936,words,O
1936,.,O
1937,We,O
1937,utilize,B
1937,1,B
1937,layer,I
1937,of,I
1937,bi-directional,I
1937,GRU,I
1937,to,B
1937,compute,I
1937,character,B
1937,-,I
1937,level,I
1937,embeddings,I
1937,and,I
1937,3,B
1937,layers,I
1937,of,O
1937,bi-directional,O
1937,GRU,O
1937,to,O
1937,encode,O
1937,questions,B
1937,and,O
1937,passages,O
1937,",",O
1937,the,O
1937,gated,B
1937,attention,I
1937,-,O
1937,based,O
1937,recurrent,O
1937,network,O
1937,for,B
1937,question,B
1937,and,O
1937,passage,O
1937,matching,O
1937,is,O
1937,also,O
1937,encoded,B
1937,bidirectionally,B
1937,in,O
1937,our,O
1937,experiment,O
1937,.,O
1938,We,O
1938,also,O
1938,apply,B
1938,dropout,B
1938,between,B
1938,layers,B
1938,with,B
1938,a,O
1938,dropout,O
1938,rate,O
1938,of,B
1938,0.2,B
1938,.,O
1939,and,O
1939,used,B
1939,in,I
1939,AdaDelta,B
1939,are,B
1939,0.95,O
1939,and,O
1939,1e,O
1939,?,O
1940,Inspired,O
1940,by,O
1940,",",O
1940,we,O
1940,introduce,B
1940,a,O
1940,gated,B
1940,self,I
1940,-,I
1940,matching,I
1940,network,I
1940,",",O
1940,illustrated,O
1940,in,O
1940,",",O
1940,an,O
1940,end,O
1940,-,O
1940,to,O
1940,-,O
1940,end,O
1940,neural,O
1940,network,O
1940,model,O
1940,for,B
1940,reading,B
1940,comprehension,I
1940,and,I
1940,question,I
1940,answering,I
1940,.,O
1941,Our,O
1941,model,O
1941,consists,B
1941,of,I
1941,four,B
1941,parts,I
1941,:,O
1942,1,O
1942,),O
1942,the,O
1942,recurrent,B
1942,network,I
1942,encoder,I
1942,to,B
1942,build,I
1942,representation,B
1942,for,B
1942,questions,B
1942,and,I
1942,passages,I
1942,separately,O
1942,",",O
1942,2,O
1942,),O
1942,the,O
1942,gated,B
1942,matching,I
1942,layer,I
1942,to,O
1942,match,O
1942,the,O
1942,question,B
1942,and,O
1942,passage,O
1942,",",O
1942,3,O
1942,),O
1942,the,O
1942,self,B
1942,-,I
1942,matching,O
1942,layer,O
1942,to,O
1942,aggregate,O
1942,information,B
1942,from,B
1942,the,O
1942,whole,B
1942,passage,O
1942,",",O
1942,and,O
1942,4,O
1942,),O
1942,the,O
1942,pointernetwork,B
1942,based,I
1942,answer,I
1942,boundary,I
1942,prediction,I
1942,layer,O
1942,.,O
1943,Gated,O
1943,Self,O
1943,-,O
1943,Matching,O
1943,Networks,O
1943,for,O
1943,Reading,B
1943,Comprehension,I
1943,and,I
1943,Question,I
1943,Answering,I
1944,For,B
1944,BERT,B
1944,SP,I
1944,with,B
1944,entity,B
1944,indicators,I
1944,on,B
1944,inputs,B
1944,",",O
1944,it,O
1944,is,O
1944,expected,O
1944,to,O
1944,perform,O
1944,slightly,O
1944,better,O
1944,in,O
1944,the,O
1944,single,O
1944,-,O
1944,relation,O
1944,setting,O
1944,",",O
1944,because,O
1944,of,O
1944,the,O
1944,mixture,O
1944,of,O
1944,information,O
1944,from,O
1944,multiple,O
1944,pairs,O
1944,.,O
1945,In,O
1945,this,O
1945,paper,O
1945,",",O
1945,we,O
1945,present,O
1945,the,O
1945,gated,O
1945,selfmatching,O
1945,networks,O
1945,for,O
1945,reading,B
1945,comprehension,I
1945,style,I
1945,question,I
1945,answering,I
1945,",",O
1945,which,O
1945,aims,O
1945,to,O
1945,answer,O
1945,questions,O
1945,from,O
1945,a,O
1945,given,O
1945,passage,O
1945,.,O
1946,GORU,O
1946,is,O
1946,implemented,O
1946,in,O
1946,Tensorflow,O
1946,",",O
1946,available,O
1946,from,O
1946,https://github.com/jingli9111/GORU-tensorflow,B
1947,We,O
1947,propose,B
1947,a,O
1947,new,B
1947,architecture,I
1947,",",O
1947,the,O
1947,Gated,B
1947,Orthogonal,B
1947,Recurrent,I
1947,Unit,I
1947,(,I
1947,GORU,I
1947,),I
1947,",",O
1947,which,O
1947,combines,B
1947,the,O
1947,advantages,O
1947,of,O
1947,the,O
1947,above,O
1947,two,O
1947,frameworks,O
1947,",",O
1947,namely,O
1947,(,O
1947,i,O
1947,),O
1947,the,O
1947,ability,B
1947,to,B
1947,capture,I
1947,long,B
1947,term,I
1947,dependencies,I
1947,by,B
1947,using,I
1947,orthogonal,O
1947,matrices,O
1947,and,O
1947,(,O
1947,ii,O
1947,),O
1947,the,O
1947,ability,O
1947,to,O
1947,"""",O
1947,forget,B
1947,"""",O
1947,by,O
1947,using,O
1947,a,O
1947,GRU,B
1947,structure,I
1947,.,O
1948,We,O
1948,demonstrate,B
1948,that,O
1948,GORU,B
1948,is,O
1948,able,B
1948,to,I
1948,learn,I
1948,long,B
1948,term,I
1948,dependencies,I
1948,effectively,B
1948,",",O
1948,even,O
1948,in,O
1948,complicated,O
1948,datasets,O
1948,which,O
1948,require,O
1948,a,O
1948,forgetting,O
1948,ability,O
1948,.,O
1949,In,O
1949,this,O
1949,work,O
1949,",",O
1949,we,O
1949,focus,B
1949,on,I
1949,implementation,B
1949,of,B
1949,orthogonal,B
1949,transition,I
1949,matrices,I
1949,which,B
1949,is,I
1949,just,O
1949,a,O
1949,subset,B
1949,of,O
1949,the,O
1949,unitary,B
1949,matrices,O
1949,.,O
1950,We,O
1950,present,O
1950,a,O
1950,novel,O
1950,recurrent,B
1950,neural,I
1950,network,I
1950,(,I
1950,RNN,I
1950,),I
1950,based,O
1950,model,O
1950,that,O
1950,combines,O
1950,the,O
1950,remembering,O
1950,ability,O
1950,of,O
1950,unitary,O
1950,RNNs,O
1950,with,O
1950,the,O
1950,ability,O
1950,of,O
1950,gated,O
1950,RNNs,O
1950,to,O
1950,effectively,O
1950,forget,O
1950,redundant,O
1950,/,O
1950,irrelevant,O
1950,information,O
1950,in,O
1950,its,O
1950,memory,O
1950,.,O
1951,These,O
1951,works,O
1951,have,O
1951,proven,O
1951,the,O
1951,importance,O
1951,of,O
1951,gating,B
1951,units,I
1951,for,I
1951,Recurrent,I
1951,Neural,I
1951,Networks,I
1951,.,O
1952,The,O
1952,main,O
1952,advantage,O
1952,of,O
1952,using,O
1952,these,O
1952,gated,O
1952,units,O
1952,in,O
1952,RNNs,B
1952,is,O
1952,primarily,O
1952,due,O
1952,to,O
1952,the,O
1952,ease,O
1952,of,O
1952,optimization,O
1952,of,O
1952,the,O
1952,models,O
1952,using,O
1952,them,O
1952,and,O
1952,to,O
1952,reduce,O
1952,the,O
1952,learning,O
1952,degeneracies,O
1952,such,O
1952,as,O
1952,vanishing,O
1952,gradients,O
1952,that,O
1952,can,O
1952,cripple,O
1952,conventional,O
1952,RNNs,O
1952,.,O
1953,The,O
1953,first,O
1953,task,O
1953,we,O
1953,consider,O
1953,is,O
1953,the,O
1953,well,O
1953,known,O
1953,Copying,B
1953,Memory,I
1953,Task,O
1953,.,O
1954,A,O
1954,2,B
1954,%,I
1954,gap,I
1954,is,O
1954,observed,B
1954,as,O
1954,expected,O
1954,.,O
1955,In,O
1955,this,O
1955,experiment,O
1955,",",O
1955,we,O
1955,use,B
1955,RMSProp,B
1955,optimization,I
1955,with,B
1955,a,O
1955,learning,B
1955,rate,I
1955,of,B
1955,0.001,B
1955,and,O
1955,a,O
1955,decay,B
1955,rate,O
1955,of,O
1955,0.9,B
1955,for,O
1955,all,O
1955,models,O
1955,.,O
1956,The,O
1956,batch,B
1956,size,I
1956,is,O
1956,set,B
1956,to,I
1956,128,B
1956,.,O
1957,Hidden,O
1957,state,O
1957,sizes,O
1957,are,O
1957,set,B
1957,to,B
1957,128,B
1957,",",I
1957,100,I
1957,",",O
1957,90,O
1957,",",O
1957,512,O
1957,",",O
1957,respectively,O
1957,to,O
1957,match,O
1957,total,B
1957,number,I
1957,of,B
1957,hidden,O
1957,to,O
1957,hidden,O
1957,parameters,O
1957,.,O
1958,The,O
1958,GORU,B
1958,is,B
1958,the,O
1958,only,B
1958,gated,I
1958,-,I
1958,system,I
1958,to,B
1958,successfully,B
1958,solve,I
1958,this,O
1958,task,B
1958,while,O
1958,the,O
1958,GRU,O
1958,and,O
1958,LSTM,O
1958,get,O
1958,stuck,O
1958,at,O
1958,the,O
1958,baseline,O
1958,as,O
1958,shown,O
1958,in,O
1958,.,O
1959,Just,O
1959,as,O
1959,in,O
1959,the,O
1959,previous,O
1959,experiment,O
1959,",",O
1959,we,O
1959,use,B
1959,RM,B
1959,-,I
1959,SProp,I
1959,optimization,I
1959,algorithm,I
1959,with,B
1959,a,O
1959,learning,B
1959,rate,I
1959,of,B
1959,0.01,B
1959,and,O
1959,a,O
1959,decay,B
1959,rate,O
1959,of,O
1959,0.9,B
1959,for,O
1959,all,O
1959,models,O
1959,.,O
1960,The,O
1960,batch,B
1960,size,I
1960,is,O
1960,set,B
1960,to,I
1960,128,B
1960,.,O
1961,Hidden,O
1961,state,O
1961,sizes,O
1961,are,O
1961,set,B
1961,to,I
1961,128,B
1961,",",I
1961,100,I
1961,",",O
1961,90,O
1961,",",O
1961,512,O
1961,",",O
1961,respectively,O
1961,to,O
1961,match,O
1961,total,B
1961,number,I
1961,of,I
1961,hidden,O
1961,to,O
1961,hidden,O
1961,parameters,O
1961,.,O
1962,EURNN,O
1962,get,O
1962,stuck,O
1962,at,O
1962,the,O
1962,baseline,O
1962,because,O
1962,of,O
1962,lacking,O
1962,forgetting,O
1962,mechanism,O
1962,",",O
1962,while,O
1962,GORU,B
1962,and,I
1962,GRU,I
1962,successfully,B
1962,solve,I
1962,the,O
1962,task,B
1962,.,O
1963,For,O
1963,BERT,B
1963,SP,I
1963,with,I
1963,position,I
1963,embeddings,I
1963,on,B
1963,the,O
1963,final,B
1963,attention,I
1963,layer,I
1963,",",O
1963,we,O
1963,train,B
1963,the,O
1963,model,B
1963,in,B
1963,the,O
1963,single,B
1963,-,I
1963,relation,I
1963,setting,I
1963,and,O
1963,test,B
1963,with,O
1963,two,B
1963,different,I
1963,settings,I
1963,",",O
1963,so,B
1963,the,O
1963,results,B
1963,are,B
1963,the,O
1963,same,B
1963,.,O
1964,In,O
1964,our,O
1964,experiment,O
1964,",",O
1964,the,O
1964,total,B
1964,input,I
1964,length,I
1964,is,O
1964,set,B
1964,to,I
1964,200,B
1964,.,O
1965,We,O
1965,used,B
1965,batch,B
1965,size,I
1965,128,B
1965,and,O
1965,RMSProp,B
1965,Optimizer,I
1965,with,B
1965,a,O
1965,learning,B
1965,rate,I
1965,0.001,B
1965,",",O
1965,decay,B
1965,rate,O
1965,0.9,B
1965,on,O
1965,all,O
1965,models,O
1965,.,O
1966,The,O
1966,GORU,B
1966,is,O
1966,able,B
1966,to,I
1966,successfully,B
1966,outperform,I
1966,GRU,B
1966,",",O
1966,LSTM,B
1966,and,O
1966,EURNN,B
1966,in,B
1966,terms,I
1966,of,I
1966,both,O
1966,learning,B
1966,speed,I
1966,and,O
1966,final,B
1966,performances,I
1966,as,O
1966,shown,O
1966,in,O
1966,.,O
1967,We,O
1967,also,O
1967,analyzed,B
1967,the,O
1967,activations,O
1967,of,O
1967,the,O
1967,update,B
1967,gates,I
1967,for,B
1967,GORU,B
1967,and,I
1967,GRU,I
1967,.,O
1968,We,O
1968,used,B
1968,batch,B
1968,size,I
1968,50,B
1968,and,O
1968,hidden,B
1968,size,O
1968,128,B
1968,for,O
1968,all,O
1968,models,O
1968,.,O
1969,The,O
1969,RNNs,B
1969,are,O
1969,trained,B
1969,with,B
1969,RMSProp,B
1969,optimizer,I
1969,with,O
1969,a,O
1969,learning,B
1969,rate,I
1969,of,B
1969,0.001,B
1969,and,O
1969,decay,B
1969,rate,O
1969,of,O
1969,0.9,B
1969,.,O
1970,We,O
1970,found,B
1970,that,I
1970,the,O
1970,GORU,B
1970,performs,B
1970,averagely,B
1970,better,I
1970,than,B
1970,GRU,B
1970,/,I
1970,LSTM,I
1970,and,I
1970,EURNN,I
1970,.,O
1971,Results,O
1971,in,O
1971,show,B
1971,that,O
1971,SRL,B
1971,embedding,I
1971,can,O
1971,boost,B
1971,the,O
1971,ESIM,B
1971,+,B
1971,ELMo,I
1971,model,I
1971,by,B
1971,+,O
1971,0.7,O
1971,%,O
1971,improvement,O
1971,.,O
1972,When,O
1972,predicting,O
1972,multiple,B
1972,relations,I
1972,in,B
1972,one,B
1972,-,I
1972,pass,I
1972,",",O
1972,we,O
1972,have,B
1972,0.9,B
1972,%,I
1972,drop,I
1972,on,B
1972,Macro,B
1972,-,O
1972,F1,O
1972,",",O
1972,but,O
1972,a,O
1972,further,B
1972,0.8,I
1972,%,O
1972,improvement,O
1972,on,O
1972,Micro,B
1972,-,O
1972,F1,O
1972,.,O
1973,With,B
1973,the,I
1973,semantic,B
1973,cues,I
1973,",",O
1973,the,O
1973,simple,B
1973,sequential,I
1973,encoding,I
1973,model,I
1973,yields,B
1973,substantial,B
1973,gains,I
1973,",",O
1973,and,O
1973,our,B
1973,single,I
1973,BERT,I
1973,LARGE,I
1973,model,O
1973,also,O
1973,achieves,B
1973,a,O
1973,new,B
1973,stateof,I
1973,-,I
1973,the,O
1973,-,O
1973,art,O
1973,",",O
1973,even,O
1973,outperforms,B
1973,all,B
1973,the,O
1973,ensemble,O
1973,models,O
1973,in,B
1973,the,O
1973,leaderboard,B
1973,8,O
1973,.,O
1974,Our,O
1974,baseline,O
1974,includes,B
1974,MQAN,B
1974,for,B
1974,single,B
1974,task,I
1974,and,I
1974,multi-task,I
1974,with,B
1974,SRL,B
1974,",",O
1974,BiDAF,B
1974,+,I
1974,ELMo,I
1974,",",O
1974,R.M.,O
1975,Reader,O
1975,and,O
1975,BERT,B
1975,.,O
1976,The,O
1976,SRL,B
1976,embeddings,I
1976,give,B
1976,substantial,B
1976,performance,I
1976,gains,I
1976,over,B
1976,all,B
1976,the,O
1976,strong,O
1976,baselines,O
1976,",",O
1976,showing,B
1976,it,O
1976,is,O
1976,also,O
1976,quite,B
1976,effective,I
1976,for,B
1976,more,B
1976,complex,I
1976,document,I
1976,and,I
1976,question,I
1976,encoding,I
1976,.,O
1977,In,O
1977,this,O
1977,work,O
1977,",",O
1977,to,O
1977,alleviate,O
1977,such,O
1977,an,O
1977,obvious,O
1977,shortcoming,O
1977,about,O
1977,semantics,O
1977,",",O
1977,we,O
1977,make,O
1977,attempt,O
1977,to,O
1977,explore,B
1977,integrative,B
1977,models,I
1977,for,B
1977,finer,B
1977,-,I
1977,grained,I
1977,text,I
1977,comprehension,I
1977,and,I
1977,inference,I
1977,.,O
1978,In,O
1978,this,O
1978,work,O
1978,",",O
1978,we,O
1978,propose,B
1978,a,O
1978,semantics,B
1978,enhancement,I
1978,framework,I
1978,for,B
1978,TC,B
1978,tasks,I
1978,",",O
1978,which,O
1978,boosts,O
1978,the,O
1978,strong,O
1978,baselines,O
1978,effectively,O
1978,.,O
1979,We,O
1979,implement,B
1979,an,O
1979,easy,B
1979,and,I
1979,feasible,I
1979,scheme,I
1979,to,B
1979,integrate,I
1979,semantic,B
1979,signals,I
1979,in,B
1979,downstream,B
1979,neural,I
1979,models,I
1979,in,O
1979,end,O
1979,-,O
1979,to,O
1979,-,O
1979,end,O
1979,manner,O
1979,to,O
1979,boost,O
1979,strong,B
1979,baselines,I
1979,effectively,B
1979,.,O
1980,Explicit,O
1980,Contextual,O
1980,Semantics,O
1980,for,O
1980,Text,B
1980,Comprehension,I
1981,This,O
1981,paper,O
1981,focuses,O
1981,on,O
1981,two,O
1981,core,O
1981,text,B
1981,comprehension,I
1981,(,I
1981,TC,I
1981,),I
1981,tasks,O
1981,",",O
1981,machine,B
1981,reading,I
1981,comprehension,O
1981,(,O
1981,MRC,O
1981,),O
1981,and,O
1981,textual,B
1981,entailment,I
1981,(,O
1981,TE,O
1981,),O
1981,.,O
1982,The,O
1982,1,B
1982,-,I
1982,layer,I
1982,linear,I
1982,setting,I
1982,performs,B
1982,the,O
1982,best,B
1982,and,O
1982,is,O
1982,therefore,O
1982,reported,O
1982,in,O
1982,.,O
1983,On,O
1983,the,O
1983,other,O
1983,hand,O
1983,",",O
1983,compared,B
1983,to,I
1983,the,O
1983,top,B
1983,singlemodel,I
1983,result,I
1983,",",O
1983,which,B
1983,makes,I
1983,use,I
1983,of,I
1983,additional,B
1983,word,I
1983,and,I
1983,entity,I
1983,embeddings,I
1983,pretrained,O
1983,on,O
1983,in,B
1983,-,I
1983,domain,I
1983,data,I
1983,",",O
1983,our,B
1983,methods,I
1983,demonstrate,B
1983,clear,B
1983,advantage,I
1983,as,B
1983,a,O
1983,single,B
1983,model,I
1983,.,O
1984,Using,B
1984,ReLU,B
1984,seems,B
1984,to,I
1984,be,I
1984,worse,B
1984,than,B
1984,nonlinear,B
1984,FC,I
1984,layers,I
1984,.,O
1985,In,O
1985,",",O
1985,we,O
1985,explore,B
1985,the,O
1985,utility,B
1985,of,B
1985,using,I
1985,character,B
1985,and,I
1985,syntactic,I
1985,embeddings,I
1985,",",O
1985,which,O
1985,we,O
1985,found,B
1985,to,I
1985,have,O
1985,helped,B
1985,CAFE,B
1985,marginally,O
1985,.,O
1986,In,O
1986,(,O
1986,4,O
1986,),O
1986,",",O
1986,we,O
1986,remove,B
1986,the,O
1986,inter-attention,B
1986,alignment,I
1986,features,I
1986,",",O
1986,which,O
1986,naturally,B
1986,impact,I
1986,the,O
1986,model,B
1986,performance,I
1986,significantly,B
1986,.,O
1987,We,O
1987,observe,B
1987,that,O
1987,both,B
1987,highway,I
1987,layers,I
1987,have,B
1987,marginally,B
1987,helped,I
1987,the,O
1987,over,B
1987,all,I
1987,performance,I
1987,.,O
1988,We,O
1988,observe,O
1988,that,O
1988,the,O
1988,Sub,B
1988,and,I
1988,Concat,I
1988,compositions,I
1988,were,B
1988,more,B
1988,important,I
1988,than,B
1988,the,O
1988,Mul,B
1988,composition,I
1988,.,O
1989,Finally,O
1989,",",O
1989,in,O
1989,(,O
1989,10,O
1989,),O
1989,",",O
1989,we,O
1989,replace,B
1989,the,O
1989,LSTM,B
1989,encoder,I
1989,with,B
1989,a,O
1989,BiLSTM,B
1989,",",O
1989,observing,B
1989,that,O
1989,adding,B
1989,bi-directionality,I
1989,did,B
1989,not,I
1989,improve,I
1989,performance,B
1989,for,B
1989,our,B
1989,model,I
1989,.,O
1990,We,O
1990,implement,B
1990,our,B
1990,model,I
1990,in,B
1990,TensorFlow,B
1990,and,O
1990,train,B
1990,them,I
1990,on,I
1990,Nvidia,B
1990,P100,I
1990,GPUs,I
1990,.,O
1991,We,O
1991,use,B
1991,the,O
1991,Adam,B
1991,optimizer,I
1991,(,O
1991,Kingma,O
1991,and,O
1991,Ba,O
1991,",",O
1991,2014,O
1991,),O
1991,with,B
1991,an,O
1991,initial,B
1991,learning,I
1991,rate,I
1991,of,B
1991,0.0003,B
1991,.,O
1992,L2,O
1992,regularization,O
1992,is,O
1992,set,B
1992,to,I
1992,10,B
1992,?6,I
1992,.,O
1993,Dropout,B
1993,with,B
1993,a,O
1993,keep,B
1993,probability,I
1993,of,B
1993,0.8,B
1993,is,O
1993,applied,B
1993,after,I
1993,each,B
1993,fullyconnected,I
1993,",",I
1993,recurrent,I
1993,or,I
1993,highway,I
1993,layer,I
1993,.,O
1994,presents,B
1994,the,O
1994,results,B
1994,of,I
1994,an,I
1994,ablation,I
1994,test,I
1994,of,O
1994,our,B
1994,position,I
1994,-,I
1994,aware,I
1994,attention,I
1994,model,I
1994,on,B
1994,the,O
1994,development,B
1994,set,I
1994,of,O
1994,TACRED,O
1994,.,O
1995,The,O
1995,batch,B
1995,size,I
1995,is,O
1995,tuned,B
1995,amongst,I
1995,{,B
1995,128,I
1995,",",I
1995,256,I
1995,",",O
1995,512,O
1995,},O
1995,.,O
1996,The,O
1996,number,B
1996,of,I
1996,latent,I
1996,factors,I
1996,k,I
1996,for,B
1996,the,O
1996,factorization,B
1996,layer,I
1996,is,O
1996,tuned,B
1996,amongst,I
1996,{,B
1996,5,I
1996,",",I
1996,10,I
1996,",",O
1996,50,O
1996,",",O
1996,100,O
1996,",",O
1996,150,O
1996,},O
1996,.,O
1997,The,O
1997,size,B
1997,of,B
1997,the,O
1997,hidden,B
1997,layers,I
1997,of,O
1997,the,O
1997,highway,B
1997,network,I
1997,layers,O
1997,are,O
1997,set,B
1997,to,I
1997,300,B
1997,.,O
1998,All,O
1998,parameters,B
1998,are,O
1998,initialized,B
1998,with,I
1998,xavier,B
1998,initialization,I
1998,.,O
1999,Word,O
1999,embeddings,O
1999,are,O
1999,preloaded,B
1999,with,I
1999,300d,B
1999,Glo,I
1999,Ve,I
1999,embeddings,O
1999,and,O
1999,fixed,B
1999,during,I
1999,training,B
1999,.,O
2000,Sequence,O
2000,lengths,O
2000,are,O
2000,padded,B
2000,to,I
2000,batch,B
2000,-,I
2000,wise,I
2000,maximum,I
2000,.,O
2001,The,O
2001,batch,B
2001,order,I
2001,is,O
2001,(,B
2001,randomly,I
2001,),I
2001,sorted,I
2001,within,I
2001,buckets,B
2001,following,O
2001,.,O
2002,Each,O
2002,scalar,B
2002,valued,I
2002,feature,I
2002,is,O
2002,used,B
2002,to,I
2002,augment,B
2002,the,O
2002,base,B
2002,word,I
2002,representation,I
2002,",",O
2002,allowing,O
2002,the,O
2002,subsequent,O
2002,RNN,O
2002,encoder,O
2002,layers,O
2002,to,O
2002,benefit,O
2002,from,O
2002,not,O
2002,only,O
2002,global,O
2002,but,O
2002,also,O
2002,cross,O
2002,sentence,O
2002,information,O
2002,.,O
2003,Firstly,O
2003,",",O
2003,we,O
2003,propose,B
2003,a,O
2003,compare,B
2003,",",O
2003,compress,O
2003,and,O
2003,propagate,O
2003,(,O
2003,Com,O
2003,Prop,O
2003,),O
2003,architecture,O
2003,where,O
2003,compressed,B
2003,alignment,I
2003,features,I
2003,are,O
2003,propagated,B
2003,to,I
2003,upper,B
2003,layers,I
2003,(,O
2003,such,B
2003,as,I
2003,a,O
2003,RNN,B
2003,-,I
2003,based,I
2003,encoder,I
2003,),O
2003,for,B
2003,enhancing,I
2003,representation,B
2003,learning,I
2003,.,O
2004,Secondly,O
2004,",",O
2004,in,O
2004,order,O
2004,to,B
2004,achieve,B
2004,an,O
2004,efficient,B
2004,propagation,I
2004,of,B
2004,alignment,I
2004,features,I
2004,",",O
2004,we,O
2004,propose,B
2004,alignment,O
2004,factorization,O
2004,layers,O
2004,to,O
2004,reduce,O
2004,each,B
2004,alignment,O
2004,vector,O
2004,to,O
2004,a,O
2004,single,B
2004,scalar,I
2004,valued,I
2004,feature,I
2004,.,O
2005,The,O
2005,entire,O
2005,attention,O
2005,mechanism,O
2005,contributes,B
2005,about,B
2005,1.5,I
2005,%,I
2005,F,I
2005,1,I
2005,",",O
2005,where,B
2005,the,O
2005,position,B
2005,-,I
2005,aware,I
2005,term,I
2005,in,O
2005,Eq.,O
2006,Compare,O
2006,",",O
2006,Compress,O
2006,and,O
2006,Propagate,O
2006,:,O
2006,Enhancing,O
2006,Neural,O
2006,Architectures,O
2006,with,O
2006,Alignment,O
2006,Factorization,O
2006,for,O
2006,Natural,B
2006,Language,I
2006,Inference,I
2007,This,O
2007,paper,O
2007,presents,O
2007,a,O
2007,new,O
2007,deep,O
2007,learning,O
2007,architecture,O
2007,for,O
2007,Natural,B
2007,Language,I
2007,Inference,I
2007,(,I
2007,NLI,I
2007,),I
2007,.,O
2008,More,O
2008,concretely,O
2008,",",O
2008,given,O
2008,a,O
2008,premise,O
2008,and,O
2008,hypothesis,O
2008,",",O
2008,NLI,B
2008,aims,O
2008,to,O
2008,detect,O
2008,whether,O
2008,the,O
2008,latter,O
2008,entails,O
2008,or,O
2008,contradicts,O
2008,the,O
2008,former,O
2008,.,O
2009,Table,O
2009,1,O
2009,reports,O
2009,our,O
2009,results,O
2009,on,B
2009,the,O
2009,SNLI,B
2009,benchmark,I
2009,.,O
2010,On,B
2010,the,O
2010,cross,B
2010,sentence,I
2010,(,I
2010,single,I
2010,model,I
2010,setting,I
2010,),I
2010,",",O
2010,the,O
2010,performance,B
2010,of,B
2010,our,O
2010,proposed,B
2010,CAFE,I
2010,model,O
2010,is,B
2010,extremely,B
2010,competitive,I
2010,.,O
2011,CAFE,B
2011,obtains,B
2012,88.5,O
2012,%,O
2012,accuracy,O
2012,on,B
2012,the,O
2012,SNLI,B
2012,test,I
2012,set,I
2012,",",O
2012,an,O
2012,extremely,B
2012,competitive,I
2012,score,I
2012,on,O
2012,the,O
2012,extremely,O
2012,popular,O
2012,benchmark,O
2012,.,O
2013,For,O
2013,example,O
2013,",",O
2013,CAFE,O
2013,also,O
2013,achieves,B
2013,88.3,B
2013,%,I
2013,and,I
2013,88.1,I
2013,%,O
2013,test,O
2013,accuracy,O
2013,with,B
2013,only,B
2013,3.5,I
2013,M,I
2013,and,O
2013,1.5,O
2013,M,O
2013,parameters,O
2014,Due,O
2014,to,O
2014,resource,O
2014,constraints,O
2014,",",O
2014,we,O
2014,did,O
2014,not,O
2014,train,O
2014,CAFE,B
2014,+,I
2014,ELMo,I
2014,ensembles,O
2014,but,O
2014,a,O
2014,single,O
2014,run,O
2014,(,O
2014,and,O
2014,single,O
2014,model,O
2014,),O
2014,of,O
2014,CAFE,O
2014,+,O
2014,ELMo,O
2014,already,O
2014,achieves,B
2014,89.0,B
2014,score,I
2014,on,B
2014,SNLI,B
2014,.,O
2015,This,O
2015,outperforms,B
2015,the,O
2015,state,B
2015,-,I
2015,of,B
2015,-,O
2015,theart,O
2015,ESIM,O
2015,and,O
2015,DIIN,O
2015,models,O
2015,with,B
2015,only,O
2015,a,O
2015,fraction,B
2015,of,O
2015,the,O
2015,parameter,B
2015,cost,I
2015,.,O
2016,(,O
2016,3,O
2016,),O
2016,alone,O
2016,contributes,B
2016,about,B
2016,1,I
2016,%,I
2016,F,I
2016,1,O
2016,score,O
2016,.,O
2017,Moreover,O
2017,",",O
2017,our,O
2017,lightweight,B
2017,adaptation,I
2017,achieves,B
2017,87.7,B
2017,%,I
2017,with,O
2017,only,O
2017,750K,O
2017,parameters,O
2017,",",O
2017,which,O
2017,makes,O
2017,it,O
2017,extremely,O
2017,performant,O
2017,amongst,O
2017,models,O
2017,having,O
2017,the,O
2017,same,O
2017,amount,O
2017,of,O
2017,parameters,O
2017,such,O
2017,as,O
2017,the,O
2017,decomposable,O
2017,attention,O
2017,model,O
2017,(,O
2017,86.8,O
2017,%,O
2017,),O
2017,.,O
2018,Finally,O
2018,",",O
2018,an,O
2018,ensemble,B
2018,of,B
2018,5,B
2018,CAFE,I
2018,models,I
2018,achieves,B
2018,89.3,B
2018,%,I
2018,test,I
2018,accuracy,I
2018,",",O
2018,the,O
2018,best,B
2018,test,O
2018,scores,O
2018,on,O
2018,the,O
2018,SNLI,O
2018,benchmark,O
2018,to,O
2018,date,O
2018,3,O
2018,.,O
2019,On,O
2019,MultiNLI,B
2019,",",O
2019,CAFE,B
2019,significantly,B
2019,outperforms,I
2019,ESIM,B
2019,",",O
2019,a,O
2019,strong,O
2019,state,O
2019,-,O
2019,of,O
2019,-,O
2019,the,O
2019,-,O
2019,art,O
2019,model,O
2019,on,O
2019,both,O
2019,settings,O
2019,.,O
2020,We,O
2020,also,O
2020,outperform,B
2020,the,O
2020,ESIM,B
2020,+,I
2020,Read,I
2020,model,I
2020,.,O
2021,An,O
2021,ensemble,B
2021,of,I
2021,CAFE,I
2021,models,I
2021,achieve,B
2021,competitive,B
2021,re-sult,I
2021,on,O
2021,the,O
2021,MultiNLI,O
2021,dataset,O
2021,.,O
2022,On,B
2022,SciTail,B
2022,",",O
2022,our,O
2022,proposed,B
2022,CAFE,I
2022,model,I
2022,achieves,B
2022,state,B
2022,-,I
2022,of,I
2022,-,O
2022,the,O
2022,-,O
2022,art,O
2022,performance,O
2022,.,O
2023,The,O
2023,performance,B
2023,gain,I
2023,over,B
2023,strong,B
2023,baselines,I
2023,such,B
2023,as,I
2023,DecompAtt,B
2023,and,O
2023,ESIM,B
2023,are,B
2023,?,O
2024,13,O
2024,%,O
2024,in,B
2024,terms,I
2024,of,I
2024,accuracy,B
2024,.,O
2025,CAFE,B
2025,also,O
2025,outperforms,B
2025,DGEM,B
2025,",",O
2025,which,O
2025,uses,O
2025,a,O
2025,graph,O
2025,-,O
2025,based,O
2025,attention,O
2025,for,O
2025,improved,O
2025,performance,O
2025,",",O
2025,by,B
2025,a,O
2025,significant,B
2025,margin,I
2025,of,B
2025,5,B
2025,%,I
2025,.,O
2026,The,O
2026,learning,B
2026,rate,I
2026,is,O
2026,annealed,B
2026,by,I
2026,1,B
2026,%,I
2026,every,B
2026,100,B
2026,iterations,I
2026,.,O
2027,shows,O
2027,how,O
2027,the,O
2027,slot,B
2027,filling,I
2027,evaluation,I
2027,scores,I
2027,change,B
2027,as,B
2027,we,O
2027,change,O
2027,the,O
2027,amount,O
2027,of,O
2027,negative,O
2027,(,O
2027,i.e.,O
2028,",",O
2028,no,O
2028,relation,O
2028,),O
2028,training,O
2028,data,O
2028,provided,B
2028,to,I
2028,our,B
2028,proposed,I
2028,model,I
2028,.,O
2029,To,O
2029,train,O
2029,the,O
2029,model,O
2029,",",O
2029,we,O
2029,use,B
2029,the,O
2029,standard,B
2029,pairwise,I
2029,ranking,I
2029,objective,I
2029,from,O
2029,Eq.,O
2030,We,O
2030,sample,B
2030,minibatches,B
2030,of,B
2030,128,B
2030,random,I
2030,image,I
2030,-,I
2030,caption,I
2030,pairs,I
2030,",",O
2030,and,O
2030,draw,B
2030,all,O
2030,contrastive,O
2030,terms,O
2030,from,B
2030,the,O
2030,minibatch,B
2030,",",O
2030,giving,B
2030,us,O
2030,127,B
2030,contrastive,O
2030,images,O
2030,for,B
2030,each,B
2030,caption,O
2030,and,O
2030,captions,B
2030,for,O
2030,each,O
2030,image,O
2030,.,O
2031,We,O
2031,train,B
2031,for,I
2031,15,B
2031,-,I
2031,30,I
2031,epochs,I
2031,using,B
2031,the,O
2031,Adam,B
2031,optimizer,I
2031,with,B
2031,learning,B
2031,rate,I
2031,0.001,I
2031,",",O
2031,and,O
2031,early,B
2031,stopping,I
2031,on,B
2031,the,O
2031,validation,B
2031,set,I
2031,.,O
2032,We,O
2032,set,B
2032,the,I
2032,dimension,B
2032,of,B
2032,the,O
2032,embedding,B
2032,space,I
2032,and,I
2032,the,O
2032,GRU,O
2032,hidden,O
2032,state,O
2032,N,O
2032,to,B
2032,1024,B
2032,",",O
2032,the,O
2032,dimension,O
2032,of,O
2032,the,O
2032,learned,B
2032,word,I
2032,embeddings,I
2032,to,O
2032,300,B
2032,",",O
2032,and,O
2032,the,O
2032,margin,B
2032,?,O
2033,to,B
2033,0.05,B
2033,.,O
2034,For,O
2034,consistency,O
2034,with,O
2034,and,O
2034,to,B
2034,mitigate,O
2034,overfitting,O
2034,",",O
2034,we,O
2034,constrain,B
2034,the,O
2034,caption,B
2034,and,O
2034,image,O
2034,embeddings,O
2034,to,O
2034,have,O
2034,unit,B
2034,L2,I
2034,norm,I
2034,.,O
2035,We,O
2035,see,B
2035,that,I
2035,order-,B
2035,embeddings,I
2035,outperform,B
2035,the,O
2035,skipthought,B
2035,baseline,I
2035,despite,O
2035,not,B
2035,using,I
2035,external,B
2035,text,I
2035,corpora,I
2035,.,O
2036,Just,O
2036,as,O
2036,for,O
2036,caption,O
2036,-,O
2036,image,O
2036,ranking,O
2036,",",O
2036,we,O
2036,set,B
2036,the,O
2036,dimensions,B
2036,of,B
2036,the,O
2036,embedding,B
2036,space,I
2036,and,I
2036,GRU,I
2036,hidden,I
2036,state,I
2036,to,B
2036,be,I
2036,1024,B
2036,",",O
2036,the,O
2036,dimension,B
2036,of,O
2036,the,O
2036,word,B
2036,embeddings,B
2036,to,O
2036,be,O
2036,300,B
2036,",",O
2036,and,O
2036,constrain,B
2036,the,O
2036,embeddings,O
2036,to,O
2036,have,O
2036,unit,B
2036,L2,I
2036,norm,I
2036,.,O
2037,We,O
2037,train,B
2037,for,I
2037,10,B
2037,epochs,I
2037,with,B
2037,batches,B
2037,of,B
2037,128,B
2037,sentence,I
2037,pairs,I
2037,.,O
2038,We,O
2038,use,B
2038,the,O
2038,Adam,B
2038,optimizer,I
2038,with,B
2038,learning,B
2038,rate,I
2038,0.001,I
2038,and,O
2038,early,B
2038,stopping,I
2038,on,B
2038,the,O
2038,validation,B
2038,set,I
2038,.,O
2039,We,O
2039,find,O
2039,that,O
2039,:,O
2039,(,O
2039,1,O
2039,),O
2039,At,B
2039,hop,B
2039,-,I
2039,0,I
2039,level,I
2039,",",O
2039,precision,B
2039,increases,B
2039,as,O
2039,we,O
2039,provide,B
2039,more,I
2039,negative,B
2039,examples,I
2039,",",O
2039,while,B
2039,recall,B
2039,stays,B
2039,almost,B
2039,unchanged,I
2039,.,O
2040,We,O
2040,call,B
2040,embeddings,I
2040,learned,B
2040,in,O
2040,this,O
2040,way,O
2040,order-,B
2040,embeddings,O
2040,.,O
2041,In,O
2041,contrast,O
2041,",",O
2041,we,O
2041,propose,O
2041,to,O
2041,exploit,B
2041,the,O
2041,partial,B
2041,order,I
2041,structure,I
2041,of,B
2041,the,O
2041,visual,B
2041,-,I
2041,semantic,I
2041,hierarchy,I
2041,by,B
2041,learning,I
2041,a,O
2041,mapping,B
2041,which,O
2041,is,O
2041,not,B
2041,distance,B
2041,-,O
2041,preserving,O
2041,but,B
2041,order,O
2041,-,O
2041,preserving,O
2041,between,B
2041,the,O
2041,visualsemantic,B
2041,hierarchy,O
2041,and,O
2041,a,O
2041,partial,O
2041,order,O
2041,over,B
2041,the,O
2041,embedding,B
2041,space,I
2041,.,O
2042,Hypernymy,O
2042,",",O
2042,textual,O
2042,entailment,O
2042,",",O
2042,and,O
2042,image,O
2042,captioning,O
2042,can,O
2042,be,O
2042,seen,O
2042,as,O
2042,special,O
2042,cases,O
2042,of,O
2042,a,O
2042,single,B
2042,visual,I
2042,-,I
2042,semantic,I
2042,hierarchy,I
2042,over,I
2042,words,I
2042,",",O
2042,sentences,O
2042,",",O
2042,and,O
2042,images,O
2042,.,O
2043,In,O
2043,fact,O
2043,",",O
2043,all,O
2043,three,O
2043,relations,O
2043,can,O
2043,be,O
2043,seen,O
2043,as,O
2043,special,O
2043,cases,O
2043,of,O
2043,a,O
2043,partial,O
2043,order,O
2043,over,O
2043,images,O
2043,and,O
2043,language,O
2043,",",O
2043,illustrated,O
2043,in,O
2043,",",O
2043,which,O
2043,we,O
2043,refer,O
2043,to,O
2043,as,O
2043,the,O
2043,visualsemantic,B
2043,hierarchy,I
2043,.,O
2044,All,O
2044,models,O
2044,are,O
2044,trained,B
2044,end,I
2044,-,I
2044,to,I
2044,-,O
2044,end,O
2044,jointly,B
2044,with,B
2044,the,O
2044,refinement,B
2044,module,I
2044,using,B
2044,a,I
2044,dimensionality,I
2044,of,B
2044,n,B
2044,=,I
2044,300,I
2044,for,B
2044,all,O
2044,but,O
2044,the,O
2044,TriviaQA,O
2044,experiments,O
2044,for,O
2044,which,O
2044,we,O
2044,had,B
2044,to,O
2044,reduce,O
2044,n,O
2044,to,O
2044,150,O
2044,due,B
2044,to,O
2044,memory,B
2044,constraints,I
2044,.,O
2045,All,O
2045,baselines,O
2045,operate,B
2045,on,I
2045,the,O
2045,unrefined,B
2045,word,I
2045,embeddings,I
2045,E,O
2045,0,O
2045,described,O
2045,in,O
2045,3.1,O
2045,.,O
2046,For,B
2046,the,O
2046,DQA,B
2046,baseline,I
2046,system,I
2046,we,O
2046,add,B
2046,the,O
2046,lemma,B
2046,in,B
2046,-,O
2046,question,B
2046,feature,I
2046,(,I
2046,liq,I
2046,),I
2046,suggested,O
2046,in,O
2046,.,O
2047,In,B
2047,this,O
2047,paper,O
2047,",",O
2047,we,O
2047,develop,B
2047,a,O
2047,new,B
2047,architecture,I
2047,for,B
2047,dynamically,I
2047,incorporating,I
2047,external,B
2047,background,I
2047,knowledge,I
2047,in,O
2047,NLU,B
2047,models,I
2047,.,O
2048,Rather,O
2048,than,O
2048,relying,O
2048,only,O
2048,on,O
2048,static,O
2048,knowledge,O
2048,implicitly,O
2048,present,O
2048,in,O
2048,the,O
2048,training,O
2048,data,O
2048,",",O
2048,supplementary,B
2048,knowledge,O
2048,is,O
2048,retrieved,B
2048,from,I
2048,external,B
2048,knowledge,O
2048,sources,O
2048,(,O
2048,in,O
2048,this,O
2048,paper,O
2048,",",O
2048,ConceptNet,B
2048,and,O
2048,Wikipedia,B
2048,),O
2048,to,O
2048,assist,B
2048,with,I
2048,understanding,I
2048,text,B
2048,inputs,I
2048,.,O
2049,F,O
2049,1,O
2049,score,O
2049,keeps,B
2049,increasing,B
2049,.,O
2050,These,O
2050,refined,O
2050,embeddings,O
2050,are,B
2050,then,O
2050,used,B
2050,as,I
2050,input,B
2050,to,B
2050,a,O
2050,task,B
2050,-,I
2050,specific,I
2050,NLU,I
2050,architecture,I
2050,(,O
2050,any,O
2050,architecture,O
2050,that,O
2050,reads,O
2050,text,O
2050,as,O
2050,a,O
2050,sequence,O
2050,of,O
2050,word,O
2050,embeddings,O
2050,can,O
2050,be,O
2050,used,O
2050,here,O
2050,),O
2050,.,O
2051,The,O
2051,retrieved,B
2051,supplementary,I
2051,texts,I
2051,are,O
2051,read,B
2051,together,I
2051,with,I
2051,the,O
2051,task,B
2051,inputs,I
2051,by,B
2051,an,O
2051,initial,B
2051,reading,I
2051,module,I
2051,whose,B
2051,outputs,B
2051,are,O
2051,contextually,B
2051,refined,I
2051,word,I
2051,embeddings,I
2051,(,O
2051,3,O
2051,),O
2051,.,O
2052,The,O
2052,initial,B
2052,reading,I
2052,module,I
2052,and,I
2052,the,O
2052,task,O
2052,module,O
2052,are,B
2052,learnt,I
2052,jointly,B
2052,",",I
2052,end,I
2052,-,I
2052,to,I
2052,-,O
2052,end,O
2052,.,O
2053,Dynamic,O
2053,Integration,O
2053,of,O
2053,Background,O
2053,Knowledge,O
2053,in,O
2053,Neural,B
2053,NLU,I
2053,Systems,O
2054,Common-,O
2054,sense,O
2054,and,O
2054,background,O
2054,knowledge,O
2054,is,O
2054,required,O
2054,to,O
2054,understand,O
2054,natural,O
2054,language,O
2054,",",O
2054,but,O
2054,in,O
2054,most,O
2054,neural,B
2054,natural,O
2054,language,O
2054,understanding,O
2054,(,O
2054,NLU,O
2054,),O
2054,systems,O
2054,",",O
2054,this,O
2054,knowledge,O
2054,must,O
2054,be,O
2054,acquired,O
2054,from,O
2054,training,O
2054,corpora,O
2054,during,O
2054,learning,O
2054,",",O
2054,and,O
2054,then,O
2054,it,O
2054,is,O
2054,static,O
2054,at,O
2054,test,O
2054,time,O
2054,.,O
2055,Wikipedia,O
2055,(,O
2055,W,O
2055,),O
2055,yields,B
2055,further,B
2055,",",I
2055,significant,I
2055,improvements,I
2055,on,B
2055,TriviaQA,B
2055,",",O
2055,slightly,B
2055,outperforming,I
2055,the,I
2055,current,B
2055,state,I
2055,of,I
2055,the,O
2055,art,O
2055,model,O
2055,.,O
2056,shows,O
2056,the,O
2056,results,O
2056,of,O
2056,our,O
2056,RTE,B
2056,experiments,I
2056,.,O
2057,In,O
2057,general,O
2057,",",O
2057,the,O
2057,introduction,B
2057,of,I
2057,our,B
2057,refinement,I
2057,strategy,I
2057,almost,B
2057,always,I
2057,helps,I
2057,",",O
2057,both,O
2057,with,B
2057,and,I
2057,without,I
2057,external,B
2057,knowledge,I
2057,.,O
2058,When,O
2058,providing,O
2058,additional,B
2058,background,I
2058,knowledge,I
2058,from,B
2058,ConceptNet,B
2058,",",O
2058,our,B
2058,BiLSTM,I
2058,based,I
2058,models,I
2058,improve,B
2058,substantially,I
2058,",",O
2058,while,O
2058,the,O
2058,ESIM,B
2058,-,I
2058,based,O
2058,models,O
2058,improve,O
2058,only,B
2058,on,I
2058,the,O
2058,more,B
2058,difficult,I
2058,MultiNLI,I
2058,dataset,I
2058,.,O
2059,Compared,O
2059,to,O
2059,previously,O
2059,published,O
2059,state,O
2059,of,O
2059,the,O
2059,art,O
2059,systems,O
2059,",",O
2059,our,B
2059,models,I
2059,acquit,B
2059,themselves,O
2059,quite,B
2059,well,I
2059,on,B
2059,the,O
2059,MultiNLI,B
2059,benchmark,I
2059,",",O
2059,and,O
2059,competitively,B
2059,on,O
2059,the,O
2059,SNLI,B
2059,benchmark,O
2059,.,O
2060,(,O
2060,2,O
2060,),O
2060,At,O
2060,hop,B
2060,-,I
2060,all,I
2060,level,I
2060,",",O
2060,F,B
2060,1,I
2060,score,I
2060,increases,B
2060,by,B
2060,Performance,B
2060,by,O
2060,sentence,B
2060,length,I
2060,.,O
2061,Nevertheless,O
2061,",",O
2061,both,B
2061,ESIM,I
2061,and,I
2061,our,I
2061,BiL,I
2061,-,I
2061,STM,I
2061,models,I
2061,when,O
2061,trained,B
2061,with,I
2061,knowledge,B
2061,from,B
2061,ConceptNet,B
2061,are,O
2061,sensitive,B
2061,to,I
2061,the,O
2061,semantics,B
2061,of,B
2061,the,O
2061,provided,B
2061,assertions,I
2061,as,O
2061,demonstrated,O
2061,in,O
2061,our,O
2061,analysis,O
2061,in,O
2061,5.3,O
2061,.,O
2062,We,O
2062,do,O
2062,find,B
2062,that,I
2062,there,O
2062,is,O
2062,little,B
2062,impact,I
2062,of,B
2062,using,I
2062,external,B
2062,knowledge,I
2062,on,B
2062,the,O
2062,RTE,B
2062,task,I
2062,with,B
2062,ESIM,B
2062,",",O
2062,although,O
2062,the,O
2062,refinement,O
2062,strategy,O
2062,helps,O
2062,using,O
2062,just,O
2062,p,O
2062,+,O
2062,q.,O
2063,Furthermore,O
2063,",",O
2063,increasing,B
2063,the,O
2063,coverage,B
2063,of,B
2063,assertions,B
2063,in,B
2063,ConceptNet,B
2063,would,O
2063,most,B
2063,likely,I
2063,yield,I
2063,improved,B
2063,performance,I
2063,even,O
2063,without,B
2063,retraining,I
2063,our,B
2063,models,I
2063,.,O
2064,We,O
2064,run,B
2064,our,B
2064,experiments,I
2064,on,B
2064,a,O
2064,machine,B
2064,that,O
2064,contains,B
2064,a,O
2064,single,B
2064,GTX,I
2064,1080,I
2064,GPU,I
2064,with,B
2064,8,B
2064,GB,I
2064,VRAM,I
2064,.,O
2065,As,O
2065,introduced,O
2065,in,O
2065,Section,O
2065,2,O
2065,",",O
2065,we,O
2065,use,B
2065,a,O
2065,variable,B
2065,character,I
2065,embedding,I
2065,with,B
2065,a,O
2065,fixed,B
2065,pre-trained,I
2065,word,I
2065,embedding,O
2065,to,B
2065,serve,I
2065,as,O
2065,part,B
2065,of,B
2065,the,O
2065,input,B
2065,into,B
2065,the,O
2065,model,B
2065,.,O
2066,The,O
2066,character,B
2066,embedding,I
2066,is,O
2066,implemented,B
2066,using,I
2066,CNN,B
2066,with,B
2066,a,O
2066,one,B
2066,-dimensional,I
2066,layer,I
2066,consists,B
2066,of,B
2066,100,B
2066,units,I
2066,with,O
2066,a,O
2066,channel,B
2066,size,I
2066,of,O
2066,5,B
2066,.,O
2067,It,O
2067,has,O
2067,an,O
2067,input,B
2067,depth,I
2067,of,B
2067,8,B
2067,.,O
2068,The,O
2068,max,B
2068,length,I
2068,of,B
2068,SQuAD,B
2068,is,B
2068,16,B
2068,which,O
2068,means,O
2068,there,O
2068,are,O
2068,a,O
2068,maximum,O
2068,16,O
2068,words,O
2068,in,O
2068,a,O
2068,sentence,O
2068,.,O
2069,The,O
2069,fixed,B
2069,word,I
2069,embedding,I
2069,has,O
2069,a,O
2069,dimension,B
2069,of,B
2069,100,B
2069,",",O
2069,which,O
2069,is,O
2069,provided,B
2069,by,I
2069,the,O
2069,GloVe,B
2069,data,I
2069,set,I
2069,.,O
2070,The,O
2070,POS,O
2070,model,O
2070,contains,B
2070,syntactic,B
2070,information,I
2070,with,B
2070,39,B
2070,different,I
2070,POS,O
2070,tags,O
2070,that,O
2070,serve,B
2070,as,O
2070,both,B
2070,input,I
2070,and,I
2070,output,I
2070,.,O
2071,We,O
2071,find,B
2071,that,I
2071,:,O
2071,(,O
2071,1,O
2071,),O
2071,Performance,B
2071,of,B
2071,all,B
2071,models,I
2071,degrades,B
2071,substantially,B
2071,as,B
2071,the,O
2071,sentences,B
2071,get,B
2071,longer,B
2071,.,O
2072,For,B
2072,SECT,B
2072,and,I
2072,SEDT,I
2072,the,O
2072,input,B
2072,of,B
2072,the,O
2072,model,B
2072,has,O
2072,a,O
2072,size,B
2072,of,O
2072,8,B
2072,with,B
2072,30,B
2072,units,I
2072,to,B
2072,be,I
2072,output,B
2072,.,O
2073,Both,O
2073,of,O
2073,them,O
2073,has,O
2073,a,O
2073,maximum,B
2073,length,I
2073,size,I
2073,that,O
2073,is,O
2073,set,B
2073,to,I
2073,be,I
2073,10,B
2073,and,I
2073,20,I
2073,respectively,O
2073,",",O
2073,which,O
2073,values,O
2073,will,O
2073,be,O
2073,further,O
2073,discussed,O
2073,in,O
2073,Section,O
2073,4.5,O
2073,.,O
2074,We,O
2074,first,O
2074,compared,B
2074,the,O
2074,performance,B
2074,of,B
2074,single,O
2074,models,O
2074,between,O
2074,the,O
2074,baseline,B
2074,approach,I
2074,BiDAF,I
2074,and,O
2074,the,O
2074,proposed,B
2074,SEST,I
2074,approaches,I
2074,",",O
2074,including,B
2074,SE,B
2074,-,I
2074,POS,I
2074,",",O
2074,SECT,B
2074,-,O
2074,LSTM,O
2074,",",O
2074,SECT,O
2074,-,O
2074,CNN,O
2074,",",O
2074,SEDT,B
2074,-,O
2074,LSTM,O
2074,",",O
2074,and,O
2074,SEDT,O
2074,-,O
2074,CNN,O
2074,",",O
2074,on,B
2074,the,O
2074,development,B
2074,dataset,I
2074,of,O
2074,SQuAD,B
2074,.,O
2075,Another,O
2075,observation,O
2075,is,O
2075,that,O
2075,our,B
2075,propose,I
2075,models,I
2075,achieve,B
2075,higher,B
2075,relative,I
2075,improvements,I
2075,in,B
2075,EM,B
2075,scores,I
2075,than,B
2075,F,B
2075,1,I
2075,scores,O
2075,over,B
2075,the,O
2075,baseline,B
2075,methods,I
2075,",",O
2075,providing,O
2075,the,O
2075,evidence,O
2075,that,O
2075,syntactic,O
2075,information,O
2075,can,O
2075,accurately,O
2075,locate,O
2075,the,O
2075,boundaries,O
2075,of,O
2075,the,O
2075,answer,O
2075,.,O
2076,Moreover,O
2076,",",O
2076,we,O
2076,found,B
2076,that,I
2076,both,O
2076,SECT,B
2076,-,I
2076,LSTM,I
2076,and,I
2076,SEDT,I
2076,-,O
2076,LSTM,O
2076,have,B
2076,better,B
2076,performance,I
2076,than,B
2076,their,O
2076,CNN,B
2076,counterparts,I
2076,",",O
2076,which,O
2076,suggests,O
2076,that,O
2076,LSTM,O
2076,can,O
2076,more,O
2076,effectively,O
2076,preserve,O
2076,the,O
2076,syntactic,O
2076,information,O
2076,.,O
2077,From,O
2077,the,O
2077,table,O
2077,we,O
2077,see,O
2077,that,O
2077,both,B
2077,the,O
2077,ordering,O
2077,and,O
2077,the,O
2077,contents,B
2077,of,B
2077,the,O
2077,syntactic,B
2077,tree,I
2077,are,B
2077,important,B
2077,for,B
2077,the,O
2077,models,B
2077,to,I
2077,work,I
2077,properly,B
2077,:,O
2077,constituency,B
2077,and,O
2077,dependency,O
2077,trees,O
2077,achieved,B
2077,over,B
2077,20,I
2077,%,I
2077,boost,I
2077,on,B
2077,performance,B
2077,compared,B
2077,to,O
2077,the,O
2077,randomly,B
2077,generated,I
2077,ones,I
2077,and,O
2077,our,B
2077,proposed,I
2077,ordering,O
2077,also,O
2077,out,B
2077,-,I
2077,performed,I
2077,the,O
2077,random,B
2077,ordering,O
2077,.,O
2078,It,O
2078,also,O
2078,worth,O
2078,mentioning,O
2078,that,O
2078,the,O
2078,ordering,B
2078,of,B
2078,dependency,B
2078,trees,I
2078,seems,B
2078,to,I
2078,have,I
2078,less,B
2078,impact,I
2078,on,B
2078,the,O
2078,performance,B
2078,compared,B
2078,to,O
2078,that,O
2078,of,O
2078,the,O
2078,constituency,B
2078,trees,O
2078,.,O
2079,When,O
2079,compared,B
2079,with,B
2079,the,I
2079,CNN,B
2079,-,I
2079,PE,I
2079,model,I
2079,",",O
2079,our,O
2079,position,B
2079,-,O
2079,aware,O
2079,attention,O
2079,model,O
2079,achieves,B
2079,improved,B
2079,F,I
2079,1,I
2079,scores,I
2079,on,B
2079,30,B
2079,out,I
2079,of,I
2079,the,O
2079,41,O
2079,slot,O
2079,types,O
2079,",",O
2079,with,O
2079,the,O
2079,top,B
2079,5,I
2079,slot,O
2079,types,O
2079,being,B
2079,org,B
2079,:,I
2079,members,I
2079,",",O
2079,per:,B
2079,country,I
2079,of,O
2079,death,O
2079,",",O
2079,org,O
2079,:,O
2079,shareholders,O
2079,",",O
2079,per:children,B
2079,and,O
2079,per:religion,B
2079,.,O
2080,In,O
2080,practice,O
2080,",",O
2080,we,O
2080,found,O
2080,that,O
2080,limiting,B
2080,the,O
2080,window,B
2080,size,I
2080,also,O
2080,benefits,B
2080,the,O
2080,performance,B
2080,of,B
2080,our,B
2080,models,I
2080,.,O
2081,In,O
2081,general,O
2081,the,O
2081,results,O
2081,illustrate,B
2081,that,O
2081,performances,B
2081,of,B
2081,the,O
2081,models,B
2081,increase,B
2081,with,B
2081,the,O
2081,length,B
2081,of,O
2081,the,O
2081,window,B
2081,.,O
2082,We,O
2082,also,O
2082,observed,B
2082,that,O
2082,larger,B
2082,window,I
2082,size,I
2082,does,B
2082,not,I
2082,generate,I
2082,predictive,B
2082,results,I
2082,that,O
2082,is,O
2082,as,O
2082,good,O
2082,as,O
2082,the,O
2082,one,B
2082,with,I
2082,window,O
2082,size,O
2082,set,B
2082,to,I
2082,10,B
2082,.,O
2083,In,O
2083,this,O
2083,paper,O
2083,",",O
2083,we,O
2083,propose,B
2083,Structural,B
2083,Embedding,I
2083,of,I
2083,Syntactic,B
2083,Trees,I
2083,(,I
2083,SEST,I
2083,),I
2083,that,O
2083,encode,B
2083,syntactic,O
2083,information,O
2083,structured,B
2083,by,I
2083,constituency,B
2083,tree,I
2083,and,I
2083,dependency,I
2083,tree,O
2083,into,B
2083,neural,B
2083,attention,I
2083,models,I
2083,for,B
2083,the,O
2083,question,B
2083,answering,I
2083,task,I
2083,.,O
2084,Structural,O
2084,Embedding,O
2084,of,O
2084,Syntactic,O
2084,Trees,O
2084,for,O
2084,Machine,B
2084,Comprehension,I
2085,Looking,O
2085,at,O
2085,the,O
2085,results,B
2085,one,O
2085,can,O
2085,see,O
2085,that,O
2085,adding,B
2085,any,B
2085,external,I
2085,information,I
2085,results,O
2085,in,O
2085,a,O
2085,significant,B
2085,improvement,I
2085,over,B
2085,the,O
2085,baseline,B
2085,model,I
2085,(,O
2085,B,O
2085,),O
2085,(,O
2085,3.7,B
2085,-,I
2085,10.5,I
2085,points,I
2085,),O
2085,.,O
2086,We,O
2086,found,O
2086,that,O
2086,adding,B
2086,the,O
2086,spelling,B
2086,(,O
2086,S,O
2086,),O
2086,helps,B
2086,more,I
2086,than,B
2086,adding,O
2086,a,O
2086,dictionary,B
2086,(,O
2086,D,O
2086,),O
2086,(,O
2086,3,B
2086,points,I
2086,difference,I
2086,),O
2086,",",O
2086,possibly,O
2086,due,O
2086,to,O
2086,relatively,O
2086,lower,O
2086,coverage,O
2086,of,O
2086,our,O
2086,dictionary,O
2086,.,O
2087,When,O
2087,the,O
2087,dictionary,B
2087,alone,I
2087,is,O
2087,used,O
2087,",",O
2087,mean,B
2087,pooling,I
2087,(,O
2087,D3,O
2087,),O
2087,performs,B
2087,similarly,B
2087,to,B
2087,LSTM,B
2087,(,O
2087,D4,O
2087,),O
2087,.,O
2088,When,O
2088,compared,O
2088,with,B
2088,SDP,B
2088,-,I
2088,LSTM,I
2088,model,I
2088,",",O
2088,our,B
2088,model,O
2088,achieves,B
2088,improved,B
2088,F,I
2088,1,I
2088,scores,I
2088,on,B
2088,26,B
2088,out,I
2088,of,I
2088,the,I
2088,41,I
2088,slot,I
2088,types,I
2088,",",O
2088,with,O
2088,the,O
2088,top,B
2088,5,I
2088,slot,O
2088,types,O
2088,being,B
2088,org,B
2088,:,I
2088,political,I
2088,/,I
2088,religious,I
2088,affiliation,I
2088,",",O
2088,per:,B
2088,country,I
2088,of,O
2088,death,O
2088,",",O
2088,org,O
2088,:,O
2088,alternate,O
2088,names,O
2088,",",O
2088,per:religion,B
2088,and,O
2088,per:,O
2088,alternate,O
2088,names,O
2088,.,O
2089,The,O
2089,model,B
2089,with,B
2089,GLoVe,I
2089,embeddings,I
2089,(,I
2089,G,I
2089,),I
2089,is,B
2089,still,B
2089,ahead,I
2089,with,O
2089,a,O
2089,1.1,B
2089,point,I
2089,margin,I
2089,",",O
2089,but,O
2089,the,O
2089,gap,O
2089,has,O
2089,been,O
2089,shrunk,O
2089,.,O
2090,However,O
2090,",",O
2090,the,O
2090,model,B
2090,that,O
2090,uses,B
2090,both,O
2090,(,O
2090,SD,B
2090,),O
2090,has,O
2090,a,O
2090,1.1,B
2090,point,I
2090,advantage,I
2090,over,B
2090,the,O
2090,model,O
2090,that,O
2090,uses,O
2090,just,B
2090,the,O
2090,spelling,O
2090,(,O
2090,S,O
2090,),O
2090,",",O
2090,demonstrating,O
2090,that,O
2090,combining,O
2090,several,O
2090,forms,O
2090,of,O
2090,auxiliary,O
2090,data,O
2090,allows,O
2090,the,O
2090,model,O
2090,to,O
2090,exploit,O
2090,the,O
2090,complementary,O
2090,information,O
2090,they,O
2090,provide,O
2090,.,O
2091,Compared,O
2091,to,O
2091,the,O
2091,SQuAD,O
2091,results,O
2091,",",O
2091,an,O
2091,important,O
2091,difference,O
2091,is,O
2091,that,O
2091,spelling,B
2091,was,B
2091,not,B
2091,as,I
2091,useful,I
2091,on,B
2091,SNLI,B
2091,and,I
2091,MultiNLI,I
2091,.,O
2092,shows,O
2092,that,O
2092,",",O
2092,as,O
2092,expected,O
2092,",",O
2092,dictionary,B
2092,-,I
2092,enabled,I
2092,models,I
2092,significantly,B
2092,outperform,I
2092,baseline,B
2092,models,O
2092,for,B
2092,sentences,B
2092,containing,B
2092,rare,B
2092,words,I
2092,.,O
2093,We,O
2093,also,O
2093,note,O
2093,that,O
2093,we,O
2093,tried,O
2093,using,B
2093,fixed,B
2093,random,I
2093,embeddings,I
2093,for,B
2093,OOV,B
2093,words,I
2093,as,O
2093,proposed,O
2093,by,O
2093,",",O
2093,and,O
2093,that,O
2093,this,O
2093,method,O
2093,did,B
2093,not,I
2093,bring,I
2093,a,I
2093,significant,I
2093,advantage,I
2093,over,B
2093,the,O
2093,baseline,B
2093,.,O
2094,Similarly,O
2094,to,B
2094,our,O
2094,other,O
2094,experiments,O
2094,",",O
2094,using,B
2094,external,B
2094,information,I
2094,to,O
2094,compute,O
2094,embeddings,B
2094,of,B
2094,unknown,B
2094,words,I
2094,helps,B
2094,in,B
2094,all,B
2094,cases,I
2094,.,O
2095,We,O
2095,note,B
2095,that,I
2095,lemma,B
2095,+,I
2095,lowercase,I
2095,performs,B
2095,worse,B
2095,than,B
2095,any,B
2095,model,I
2095,with,B
2095,the,O
2095,dictionary,B
2095,",",O
2095,which,O
2095,suggests,O
2095,that,O
2095,dictionary,O
2095,definitions,O
2095,are,O
2095,used,O
2095,in,O
2095,a,O
2095,non-trivial,O
2095,way,O
2095,.,O
2096,Adding,B
2096,spelling,B
2096,consistently,B
2096,helps,I
2096,more,I
2096,than,B
2096,adding,O
2096,dictionary,B
2096,definitions,I
2096,.,O
2097,We,O
2097,observe,B
2097,that,I
2097,slot,B
2097,types,I
2097,with,B
2097,relatively,B
2097,sparse,I
2097,training,I
2097,examples,I
2097,tend,O
2097,to,O
2097,be,O
2097,improved,B
2097,by,I
2097,using,O
2097,the,O
2097,position,B
2097,-,I
2097,aware,I
2097,attention,I
2097,model,I
2097,.,O
2098,Using,B
2098,both,O
2098,dictionary,B
2098,and,I
2098,spelling,I
2098,is,O
2098,consistently,B
2098,slightly,I
2098,better,I
2098,than,B
2098,using,O
2098,just,B
2098,spelling,O
2098,",",O
2098,and,O
2098,the,O
2098,improvement,O
2098,is,O
2098,more,O
2098,pronounced,O
2098,in,O
2098,the,O
2098,restricted,O
2098,setting,O
2098,.,O
2099,Using,O
2099,Glo,B
2099,Ve,I
2099,embeddings,I
2099,results,B
2099,in,I
2099,the,O
2099,best,B
2099,perplexity,I
2099,.,O
2100,In,B
2100,this,O
2100,paper,O
2100,we,O
2100,propose,B
2100,a,O
2100,new,B
2100,method,I
2100,for,B
2100,computing,I
2100,embeddings,B
2100,"""",I
2100,on,I
2100,the,I
2100,fly,I
2100,"""",O
2100,",",O
2100,which,O
2100,jointly,B
2100,addresses,I
2100,the,O
2100,large,B
2100,vocabulary,I
2100,problem,I
2100,and,O
2100,the,O
2100,paucity,B
2100,of,I
2100,data,I
2100,for,O
2100,learning,O
2100,representations,B
2100,in,O
2100,the,O
2100,long,B
2100,tail,I
2100,of,O
2100,the,O
2100,Zipfian,O
2100,distribution,O
2100,.,O
2101,This,O
2101,method,O
2101,",",O
2101,which,O
2101,we,O
2101,illustrate,O
2101,in,O
2101,",",O
2101,can,O
2101,be,O
2101,summarized,O
2101,as,O
2101,follows,O
2101,:,O
2101,instead,O
2101,of,B
2101,directly,O
2101,learning,O
2101,separate,O
2101,representations,B
2101,for,O
2101,all,O
2101,words,B
2101,in,O
2101,a,O
2101,potentially,O
2101,unbounded,O
2101,vocabulary,O
2101,",",O
2101,we,O
2101,train,B
2101,a,O
2101,network,B
2101,to,B
2101,predict,I
2101,the,O
2101,representations,O
2101,of,O
2101,words,O
2101,based,B
2101,on,I
2101,auxiliary,B
2101,data,I
2101,.,O
2102,Several,O
2102,sources,O
2102,of,O
2102,auxiliary,O
2102,data,O
2102,can,O
2102,be,O
2102,used,B
2102,simultaneously,B
2102,as,B
2102,input,B
2102,to,B
2102,a,O
2102,neural,B
2102,network,I
2102,that,O
2102,will,O
2102,compute,B
2102,a,O
2102,combined,B
2102,representation,I
2102,.,O
2103,These,O
2103,representations,O
2103,can,O
2103,then,O
2103,be,O
2103,used,B
2103,for,I
2103,out,B
2103,-,I
2103,of,I
2103,-,O
2103,vocabulary,O
2103,words,O
2103,",",O
2103,or,O
2103,combined,B
2103,with,I
2103,withinvocabulary,B
2103,word,I
2103,embeddings,I
2103,directly,B
2103,trained,I
2103,on,I
2103,the,O
2103,task,B
2103,of,O
2103,interest,O
2103,or,O
2103,pretrained,B
2103,from,I
2103,an,O
2103,external,B
2103,data,I
2103,source,I
2103,.,O
2104,Importantly,O
2104,",",O
2104,the,O
2104,auxiliary,B
2104,data,I
2104,encoders,I
2104,are,O
2104,trained,B
2104,jointly,I
2104,with,B
2104,the,O
2104,objective,B
2104,",",O
2104,ensuring,B
2104,the,O
2104,preservation,B
2104,of,B
2104,semantic,B
2104,alignment,I
2104,with,O
2104,representations,B
2104,of,O
2104,within,B
2104,-,I
2104,vocabulary,I
2104,words,I
2104,.,O
2105,LEARNING,O
2105,TO,O
2105,COMPUTE,B
2105,WORD,I
2105,EMBEDDINGS,I
2105,ON,I
2105,THE,I
2105,FLY,I
2106,We,O
2106,find,B
2106,that,O
2106,the,O
2106,model,B
2106,learns,O
2106,to,B
2106,pay,I
2106,more,B
2106,attention,I
2106,to,O
2106,words,B
2106,that,O
2106,are,O
2106,informative,B
2106,for,I
2106,the,O
2106,relation,B
2106,(,O
2106,e.g.,O
2107,",",O
2107,"""",O
2107,refused,O
2107,to,B
2107,name,O
2107,the,O
2107,three,O
2107,"""",O
2107,),O
2107,.,O
2108,Similar,O
2108,to,O
2108,100D,O
2108,experiments,O
2108,",",O
2108,we,O
2108,initialize,B
2108,the,O
2108,word,B
2108,embedding,I
2108,matrix,I
2108,with,B
2108,GloVe,B
2108,300D,I
2108,pretrained,I
2108,vectors,I
2108,4,O
2108,",",O
2108,however,O
2108,we,O
2108,do,O
2108,not,O
2108,update,O
2108,the,O
2108,word,O
2108,representations,O
2108,during,O
2108,training,O
2108,.,O
2109,The,O
2109,dropout,B
2109,probability,I
2109,is,O
2109,set,B
2109,to,I
2109,0.2,B
2109,and,O
2109,word,O
2109,embeddings,O
2109,are,O
2109,not,O
2109,updated,O
2109,during,O
2109,training,O
2109,.,O
2110,The,O
2110,size,B
2110,of,B
2110,mini-batches,B
2110,is,O
2110,set,B
2110,to,I
2110,128,B
2110,in,O
2110,all,O
2110,experiments,O
2110,",",O
2110,and,O
2110,hyperparameters,O
2110,are,O
2110,tuned,O
2110,using,O
2110,the,O
2110,validation,O
2110,split,O
2110,.,O
2111,The,O
2111,temperature,B
2111,parameter,I
2111,?,O
2112,of,B
2112,Gumbel,B
2112,-,I
2112,Softmax,I
2112,is,O
2112,set,B
2112,to,I
2112,1.0,B
2112,",",O
2112,and,O
2112,we,O
2112,did,O
2112,not,O
2112,find,O
2112,that,O
2112,temperature,O
2112,annealing,O
2112,improves,O
2112,performance,O
2112,.,O
2113,For,O
2113,training,O
2113,models,B
2113,",",O
2113,Adam,B
2113,optimizer,I
2113,is,O
2113,used,B
2113,.,O
2114,All,O
2114,of,O
2114,our,O
2114,models,O
2114,converged,O
2114,within,O
2114,a,O
2114,few,O
2114,hours,O
2114,on,B
2114,a,O
2114,machine,B
2114,with,B
2114,NVIDIA,B
2114,Titan,I
2114,Xp,I
2114,GPU,I
2114,.,O
2115,First,O
2115,",",O
2115,we,O
2115,can,O
2115,see,B
2115,that,I
2115,LSTM,B
2115,-,I
2115,based,I
2115,leaf,I
2115,transformation,I
2115,has,O
2115,a,O
2115,clear,B
2115,advantage,I
2115,over,B
2115,the,O
2115,affine,B
2115,-,O
2115,transformation,O
2115,-,O
2115,based,O
2115,one,O
2115,.,O
2116,Secondly,O
2116,",",O
2116,comparing,O
2116,ours,O
2116,with,O
2116,other,O
2116,models,O
2116,",",O
2116,we,O
2116,find,B
2116,that,I
2116,our,B
2116,100D,I
2116,and,I
2116,300D,I
2116,model,I
2116,outperform,B
2116,all,B
2116,other,O
2116,models,O
2116,of,O
2116,similar,B
2116,numbers,I
2116,of,O
2116,parameters,O
2116,.,O
2117,Our,O
2117,600D,O
2117,model,O
2117,achieves,B
2117,the,I
2117,accuracy,B
2117,of,I
2117,86.0,B
2117,%,I
2117,",",O
2117,which,O
2117,is,O
2117,comparable,B
2117,to,I
2117,that,O
2117,of,O
2117,the,O
2117,state,B
2117,-,I
2117,of,O
2117,-,O
2117,the,O
2117,-,O
2117,art,O
2117,model,O
2117,",",O
2117,while,O
2117,using,O
2117,far,O
2117,less,O
2117,parameters,O
2117,.,O
2118,We,O
2118,also,O
2118,observe,B
2118,that,O
2118,the,O
2118,model,B
2118,tends,B
2118,to,I
2118,put,I
2118,a,O
2118,lot,B
2118,of,I
2118,weight,I
2118,onto,B
2118,object,B
2118,entities,I
2118,",",O
2118,as,O
2118,the,O
2118,object,O
2118,NER,O
2118,signatures,O
2118,are,O
2118,very,O
2118,informative,O
2118,to,O
2118,the,O
2118,classification,O
2118,of,O
2118,relations,O
2118,.,O
2119,is,B
2119,a,O
2119,single,B
2119,-,I
2119,hidden,I
2119,layer,I
2119,MLP,I
2119,with,B
2119,the,O
2119,ReLU,B
2119,activation,I
2119,function,I
2119,.,O
2120,We,O
2120,trained,B
2120,our,O
2120,SST,B
2120,-,I
2120,2,I
2120,model,I
2120,with,B
2120,hyperparameters,I
2120,D,I
2120,x,I
2120,=,I
2120,300,I
2120,",",I
2120,D,O
2120,h,O
2120,=,O
2120,300,O
2120,",",O
2120,D,O
2120,c,O
2120,=,O
2120,300,O
2120,.,O
2121,The,O
2121,word,B
2121,vectors,I
2121,are,O
2121,initialized,B
2121,with,B
2121,GloVe,B
2121,300D,I
2121,pretrained,I
2121,vectors,O
2121,and,O
2121,fine,B
2121,-,I
2121,tuned,I
2121,during,B
2121,training,B
2121,.,O
2122,The,O
2122,size,B
2122,of,B
2122,mini-batches,B
2122,is,O
2122,set,B
2122,to,I
2122,32,B
2122,and,O
2122,Adadelta,B
2122,optimizer,I
2122,is,O
2122,used,B
2122,for,I
2122,optimization,B
2122,.,O
2123,We,O
2123,apply,B
2123,dropout,B
2123,(,I
2123,p,I
2123,=,I
2123,0.5,I
2123,),I
2123,on,B
2123,the,I
2123,output,I
2123,of,B
2123,the,O
2123,word,B
2123,embedding,I
2123,layer,I
2123,and,I
2123,the,O
2123,input,B
2123,and,O
2123,the,O
2123,output,O
2123,of,O
2123,the,O
2123,MLP,B
2123,layer,O
2123,.,O
2124,For,B
2124,our,O
2124,SST,B
2124,-,I
2124,5,I
2124,model,B
2124,",",I
2124,hyperparameters,B
2124,are,O
2124,set,B
2124,to,I
2124,D,I
2124,x,I
2124,=,I
2124,300,I
2124,",",O
2124,D,O
2124,h,O
2124,=,O
2124,300,O
2124,",",O
2124,D,O
2124,c,O
2124,=,O
2124,1024,O
2124,.,O
2125,Similar,O
2125,to,O
2125,the,O
2125,SST,O
2125,-,O
2125,2,O
2125,model,B
2125,",",O
2125,we,O
2125,optimize,B
2125,the,O
2125,model,O
2125,using,B
2125,Adadelta,B
2125,optimizer,I
2125,with,B
2125,batch,B
2125,size,I
2125,64,I
2125,and,O
2125,apply,B
2125,dropout,B
2125,with,O
2125,p,B
2125,=,I
2125,0.5,I
2125,.,O
2126,Our,O
2126,SST,B
2126,-,I
2126,2,I
2126,model,I
2126,outperforms,B
2126,all,B
2126,other,I
2126,models,I
2126,substantially,B
2126,except,B
2126,byte,B
2126,-,O
2126,m,O
2126,LSTM,O
2126,",",O
2126,where,O
2126,a,O
2126,byte,O
2126,-,O
2126,level,O
2126,language,O
2126,model,O
2126,trained,O
2126,on,O
2126,the,O
2126,large,O
2126,product,O
2126,review,O
2126,dataset,O
2126,is,O
2126,used,O
2126,to,O
2126,obtain,O
2126,sentence,O
2126,representations,O
2126,.,O
2127,We,O
2127,also,O
2127,see,B
2127,that,I
2127,the,I
2127,performance,B
2127,of,I
2127,our,B
2127,SST,I
2127,-,I
2127,5,I
2127,model,I
2127,is,O
2127,on,B
2127,par,I
2127,with,I
2127,that,O
2127,of,O
2127,the,O
2127,current,B
2127,state,I
2127,-,O
2127,of,O
2127,-,O
2127,the,O
2127,-,O
2127,art,O
2127,model,O
2127,",",O
2127,which,O
2127,is,O
2127,pretrained,O
2127,on,O
2127,large,O
2127,parallel,O
2127,datasets,O
2127,and,O
2127,uses,O
2127,character,O
2127,n-gram,O
2127,embeddings,O
2127,alongside,O
2127,word,O
2127,embeddings,O
2127,",",O
2127,even,O
2127,though,O
2127,our,O
2127,model,O
2127,does,O
2127,not,O
2127,utilize,O
2127,external,O
2127,resources,O
2127,other,O
2127,than,O
2127,GloVe,O
2127,vectors,O
2127,and,O
2127,only,O
2127,uses,O
2127,wordlevel,O
2127,representations,O
2127,.,O
2128,The,O
2128,authors,O
2128,of,O
2128,stated,O
2128,that,O
2128,utilizing,B
2128,pretraining,B
2128,and,I
2128,character,I
2128,n-gram,I
2128,embeddings,I
2128,improves,B
2128,validation,B
2128,accuracy,I
2128,by,B
2128,2.8,B
2128,%,I
2128,(,I
2128,SST,I
2128,-,I
2128,2,I
2128,),I
2128,or,O
2128,1.7,B
2128,%,O
2128,(,O
2128,SST,O
2128,-,O
2128,5,O
2128,),O
2128,.,O
2129,In,O
2129,this,O
2129,paper,O
2129,",",O
2129,we,O
2129,propose,B
2129,Gumbel,B
2129,Tree,I
2129,-,I
2129,LSTM,I
2129,",",O
2129,which,O
2129,is,B
2129,a,O
2129,novel,B
2129,RvNN,I
2129,architecture,I
2129,that,O
2129,does,O
2129,not,B
2129,require,I
2129,structured,B
2129,data,I
2129,and,O
2129,learns,B
2129,to,I
2129,compose,I
2129,task,B
2129,-,O
2129,specific,O
2129,tree,O
2129,structures,O
2129,without,B
2129,explicit,B
2129,guidance,I
2129,.,O
2130,We,O
2130,find,O
2130,that,O
2130,the,O
2130,model,B
2130,performs,B
2130,best,B
2130,when,B
2130,aliases,B
2130,are,O
2130,provided,B
2130,by,I
2130,the,O
2130,KB,B
2130,itself,O
2130,.,O
2131,Minibatch,O
2131,Size,O
2131,is,B
2131,1,B
2131,.,O
2132,Secondly,O
2132,",",O
2132,we,O
2132,markedly,B
2132,improve,I
2132,the,O
2132,availability,B
2132,of,I
2132,supervised,I
2132,training,I
2132,data,I
2132,by,B
2132,using,I
2132,Mechanical,B
2132,Turk,I
2132,crowd,I
2132,annotation,I
2132,to,B
2132,produce,I
2132,a,O
2132,large,B
2132,supervised,O
2132,training,O
2132,dataset,O
2132,",",O
2132,suitable,B
2132,for,I
2132,the,O
2132,common,B
2132,relations,I
2132,between,B
2132,people,B
2132,",",O
2132,organizations,O
2132,and,O
2132,locations,O
2132,which,O
2132,are,O
2132,used,B
2132,in,I
2132,the,O
2132,TAC,B
2132,KBP,I
2132,evaluations,I
2132,.,O
2133,Our,O
2133,Gumbel,O
2133,Tree,O
2133,-,O
2133,LSTM,O
2133,model,O
2133,is,O
2133,based,B
2133,on,I
2133,tree,O
2133,-,O
2133,structured,O
2133,long,O
2133,short,O
2133,-,O
2133,term,O
2133,memory,O
2133,(,O
2133,Tree,O
2133,-,O
2133,LSTM,O
2133,),O
2133,architecture,O
2133,",",O
2133,which,O
2133,is,O
2133,one,O
2133,of,O
2133,the,O
2133,most,O
2133,renowned,O
2133,variants,O
2133,of,O
2133,RvNN,O
2133,.,O
2134,To,O
2134,learn,O
2134,how,O
2134,to,O
2134,compose,O
2134,task,O
2134,-,O
2134,specific,O
2134,tree,O
2134,structures,O
2134,without,O
2134,depending,O
2134,on,O
2134,structured,O
2134,input,O
2134,",",O
2134,our,B
2134,model,I
2134,introduces,B
2134,composition,B
2134,query,I
2134,vector,I
2134,that,O
2134,measures,B
2134,validity,B
2134,of,B
2134,a,O
2134,composition,O
2134,.,O
2135,Using,B
2135,validity,B
2135,scores,I
2135,computed,B
2135,by,I
2135,the,O
2135,composition,B
2135,query,I
2135,vector,I
2135,",",O
2135,our,B
2135,model,I
2135,recursively,B
2135,selects,I
2135,compositions,B
2135,until,B
2135,only,B
2135,a,I
2135,single,I
2135,representation,I
2135,remains,I
2135,.,O
2136,We,O
2136,use,B
2136,Straight,B
2136,-,I
2136,Through,I
2136,(,I
2136,ST,I
2136,),I
2136,Gumbel,I
2136,-,O
2136,Softmax,O
2136,estimator,O
2136,to,B
2136,sample,I
2136,compositions,B
2136,in,B
2136,the,O
2136,training,B
2136,phase,I
2136,.,O
2137,ST,O
2137,Gumbel,O
2137,-,O
2137,Softmax,O
2137,estimator,O
2137,relaxes,B
2137,the,O
2137,discrete,B
2137,sampling,I
2137,operation,I
2137,to,B
2137,be,I
2137,continuous,B
2137,in,B
2137,the,O
2137,backward,B
2137,pass,I
2137,",",O
2137,thus,O
2137,our,O
2137,model,O
2137,can,O
2137,be,O
2137,trained,O
2137,via,O
2137,the,O
2137,standard,O
2137,backpropagation,O
2137,.,O
2138,Learning,O
2138,to,O
2138,Compose,O
2138,Task,B
2138,-,I
2138,Specific,I
2138,Tree,I
2138,Structures,I
2139,In,O
2139,this,O
2139,paper,O
2139,",",O
2139,we,O
2139,propose,O
2139,Gumbel,O
2139,Tree,O
2139,-,O
2139,LSTM,O
2139,",",O
2139,a,O
2139,novel,O
2139,tree,O
2139,-,O
2139,structured,O
2139,long,O
2139,short,O
2139,-,O
2139,term,O
2139,memory,O
2139,architecture,O
2139,that,O
2139,learns,O
2139,how,O
2139,to,O
2139,compose,O
2139,task,B
2139,-,O
2139,specific,O
2139,tree,O
2139,structures,O
2139,only,O
2139,from,O
2139,plain,O
2139,text,O
2139,data,O
2139,efficiently,O
2139,.,O
2140,To,O
2140,train,O
2140,our,B
2140,model,I
2140,",",O
2140,we,O
2140,used,B
2140,stochastic,B
2140,gradient,I
2140,descent,I
2140,with,B
2140,the,O
2140,ADAM,B
2140,optimizer,I
2140,(,O
2140,Kingma,O
2140,and,O
2140,Ba,O
2140,",",O
2140,2014,O
2140,),O
2140,",",O
2140,with,O
2140,an,O
2140,initial,B
2140,learning,I
2140,rate,I
2140,of,B
2140,0.001,B
2140,.,O
2141,We,O
2141,set,O
2141,the,O
2141,batch,B
2141,size,I
2141,to,B
2141,32,B
2141,and,O
2141,we,O
2141,decay,B
2141,the,O
2141,learning,B
2141,rate,I
2141,by,B
2141,0.8,B
2141,if,B
2141,the,O
2141,accuracy,B
2141,on,B
2141,the,O
2141,validation,B
2141,set,O
2141,does,O
2141,not,B
2141,increase,I
2141,after,B
2141,a,O
2141,half,B
2141,-,I
2141,epoch,I
2141,",",O
2141,i.e.,B
2142,2000,O
2142,batches,O
2142,(,O
2142,for,B
2142,CBT,B
2142,),O
2142,and,O
2142,5000,B
2142,batches,O
2142,for,O
2142,(,O
2142,CNN,B
2142,),O
2142,.,O
2143,We,O
2143,initialize,B
2143,all,B
2143,weights,I
2143,of,B
2143,our,B
2143,model,I
2143,by,B
2143,sampling,B
2143,from,B
2143,the,O
2143,normal,B
2143,distribution,I
2143,N,I
2143,(,I
2143,0,I
2143,",",I
2143,0.05,I
2143,),I
2143,.,O
2144,We,O
2144,name,O
2144,this,O
2144,dataset,O
2144,the,O
2144,TAC,B
2144,Relation,I
2144,Extraction,I
2144,Dataset,O
2144,(,O
2144,TACRED,O
2144,),O
2144,",",O
2144,and,O
2144,will,O
2144,make,B
2144,it,I
2144,available,I
2144,through,I
2144,the,O
2144,Linguistic,B
2144,Data,I
2144,Consortium,I
2144,(,O
2144,LDC,O
2144,),O
2144,in,O
2144,order,O
2144,to,B
2144,respect,I
2144,copyrights,B
2144,on,B
2144,the,O
2144,underlying,B
2144,text,I
2144,.,O
2145,Following,O
2145,",",O
2145,the,O
2145,GRU,B
2145,recurrent,I
2145,weights,I
2145,are,B
2145,initialized,B
2145,to,B
2145,be,I
2145,orthogonal,B
2145,and,O
2145,biases,B
2145,are,O
2145,initialized,O
2145,to,O
2145,zero,B
2145,.,O
2146,Our,O
2146,model,O
2146,is,O
2146,implemented,B
2146,in,I
2146,Theano,B
2146,",",O
2146,using,B
2146,the,O
2146,Keras,B
2146,library,I
2146,.,O
2147,In,O
2147,order,O
2147,to,B
2147,stabilize,I
2147,the,O
2147,learning,B
2147,",",O
2147,we,O
2147,clip,B
2147,the,O
2147,gradients,B
2147,if,B
2147,their,O
2147,norm,B
2147,is,O
2147,greater,B
2147,than,I
2147,5,B
2147,and,O
2147,those,O
2147,marked,O
2147,with,O
2147,2,O
2147,are,O
2147,from,O
2147,.,O
2148,We,O
2148,found,O
2148,that,O
2148,setting,B
2148,embedding,B
2148,regularization,I
2148,to,B
2148,0.0001,B
2148,",",O
2148,T,O
2148,=,O
2148,8,O
2148,",",O
2148,d,O
2148,=,O
2148,384,O
2148,",",O
2148,h,O
2148,=,O
2148,128,O
2148,",",O
2148,s,O
2148,=,O
2148,512,O
2148,worked,B
2148,robustly,B
2148,across,B
2148,the,O
2148,datasets,B
2148,.,O
2149,Encouraged,O
2149,by,O
2149,the,O
2149,recent,O
2149,success,O
2149,of,O
2149,deep,O
2149,learning,O
2149,attention,O
2149,architectures,O
2149,",",O
2149,we,O
2149,propose,B
2149,a,O
2149,novel,B
2149,neural,I
2149,attention,O
2149,-,O
2149,based,O
2149,inference,O
2149,model,O
2149,designed,O
2149,to,B
2149,perform,I
2149,machine,B
2149,reading,I
2149,comprehension,I
2149,tasks,I
2149,.,O
2150,The,O
2150,model,O
2150,first,B
2150,reads,I
2150,the,O
2150,document,B
2150,and,I
2150,the,O
2150,query,O
2150,using,B
2150,a,O
2150,recurrent,B
2150,neural,I
2150,network,I
2150,.,O
2151,Then,O
2151,",",O
2151,it,O
2151,deploys,B
2151,an,O
2151,iterative,B
2151,inference,I
2151,process,I
2151,to,B
2151,uncover,I
2151,the,O
2151,inferential,B
2151,links,I
2151,that,O
2151,exist,O
2151,between,B
2151,the,O
2151,missing,B
2151,query,B
2151,word,I
2151,",",O
2151,the,O
2151,query,O
2151,",",O
2151,and,O
2151,the,O
2151,document,B
2151,.,O
2152,This,O
2152,phase,O
2152,involves,B
2152,a,O
2152,novel,B
2152,alternating,I
2152,attention,I
2152,mechanism,I
2152,;,O
2152,it,O
2152,first,B
2152,attends,I
2152,to,O
2152,some,B
2152,parts,I
2152,of,B
2152,the,O
2152,query,B
2152,",",O
2152,then,B
2152,finds,I
2152,their,O
2152,corresponding,B
2152,matches,I
2152,by,B
2152,attending,I
2152,to,O
2152,the,O
2152,document,B
2152,.,O
2153,The,O
2153,result,B
2153,of,O
2153,this,O
2153,alternating,O
2153,search,O
2153,is,O
2153,fed,B
2153,back,I
2153,into,I
2153,the,O
2153,iterative,B
2153,inference,I
2153,process,I
2153,to,B
2153,seed,I
2153,the,O
2153,next,B
2153,search,O
2153,step,O
2153,.,O
2154,After,B
2154,a,O
2154,fixed,B
2154,number,I
2154,of,B
2154,iterations,I
2154,",",O
2154,the,O
2154,model,B
2154,uses,B
2154,a,O
2154,summary,B
2154,of,O
2154,its,O
2154,inference,B
2154,process,I
2154,to,B
2154,predict,I
2154,the,O
2154,answer,B
2154,.,O
2155,We,O
2155,map,B
2155,words,B
2155,that,O
2155,occur,B
2155,less,I
2155,than,I
2155,2,B
2155,times,I
2155,in,B
2155,the,O
2155,training,B
2155,set,I
2155,to,B
2155,a,O
2155,special,B
2155,<,I
2155,UNK,I
2155,>,I
2155,token,I
2155,.,O
2156,Iterative,O
2156,Alternating,O
2156,Neural,O
2156,Attention,O
2156,for,O
2156,Machine,B
2156,Reading,I
2157,We,O
2157,propose,O
2157,a,O
2157,novel,O
2157,neural,O
2157,attention,O
2157,architecture,O
2157,to,O
2157,tackle,O
2157,machine,B
2157,comprehension,I
2157,tasks,O
2157,",",O
2157,such,O
2157,as,O
2157,answering,O
2157,Cloze,O
2157,-,O
2157,style,O
2157,queries,O
2157,with,O
2157,respect,O
2157,to,O
2157,a,O
2157,document,O
2157,.,O
2158,We,O
2158,also,O
2158,include,B
2158,a,O
2158,distance,B
2158,-,I
2158,based,I
2158,method,I
2158,that,B
2158,uses,I
2158,word,B
2158,embeddings,I
2158,(,O
2158,sim-entity,O
2158,),O
2158,.,O
2159,We,O
2159,trained,B
2159,a,O
2159,4,B
2159,-,I
2159,gram,I
2159,Kneser,I
2159,-,O
2159,Ney,O
2159,model,O
2159,on,B
2159,CliCR,B
2159,training,I
2159,data,I
2159,(,O
2159,with,B
2159,multi-word,B
2159,entities,I
2159,represented,B
2159,as,I
2159,a,O
2159,single,B
2159,token,I
2159,),O
2159,using,B
2159,SRILM,B
2159,.,O
2160,For,O
2160,our,O
2160,dataset,O
2160,",",O
2160,we,O
2160,construct,B
2160,queries,B
2160,",",O
2160,answers,O
2160,and,O
2160,supporting,O
2160,passages,O
2160,from,B
2160,BMJ,B
2160,Case,I
2160,Reports,I
2160,",",O
2160,the,O
2160,largest,O
2160,online,O
2160,repository,O
2160,of,O
2160,such,O
2160,documents,O
2160,.,O
2161,A,O
2161,case,O
2161,report,O
2161,is,B
2161,a,O
2161,detailed,B
2161,description,I
2161,of,I
2161,a,O
2161,clinical,B
2161,case,O
2161,that,O
2161,focuses,B
2161,on,I
2161,rare,B
2161,diseases,I
2161,",",O
2161,unusual,B
2161,presentation,I
2161,of,O
2161,common,O
2161,conditions,O
2161,and,O
2161,novel,B
2161,treatment,I
2161,methods,I
2161,.,O
2162,Each,O
2162,report,O
2162,contains,B
2162,a,O
2162,Learning,B
2162,points,I
2162,section,I
2162,",",O
2162,summarizing,B
2162,the,O
2162,key,B
2162,pieces,I
2162,of,B
2162,information,B
2162,from,O
2162,that,O
2162,report,O
2162,.,O
2163,We,O
2163,use,B
2163,these,O
2163,learning,B
2163,points,I
2163,to,B
2163,create,I
2163,queries,B
2163,by,B
2163,blanking,I
2163,out,I
2163,a,O
2163,medical,B
2163,entity,I
2163,.,O
2164,Our,O
2164,dataset,O
2164,contains,B
2164,around,B
2164,"100,000",I
2164,queries,I
2164,on,B
2164,"12,000",B
2164,case,I
2164,reports,I
2164,",",O
2164,has,O
2164,long,B
2164,support,I
2164,passages,I
2164,(,O
2164,around,O
2164,"1,500",O
2164,tokens,O
2164,on,O
2164,average,O
2164,),O
2164,and,O
2164,includes,B
2164,answers,B
2164,which,B
2164,are,I
2164,single,B
2164,-,I
2164,or,I
2164,multiword,I
2164,medical,I
2164,entities,I
2164,.,O
2165,CliCR,O
2165,:,O
2165,A,O
2165,Dataset,O
2165,of,O
2165,Clinical,O
2165,Case,O
2165,Reports,O
2165,for,O
2165,Machine,B
2165,Reading,I
2165,Comprehension,I
2165,*,O
2166,We,O
2166,use,B
2166,the,O
2166,pre-trained,B
2166,GloVe,I
2166,vectors,I
2166,to,B
2166,initialize,I
2166,word,B
2166,embeddings,I
2166,.,O
2167,We,O
2167,present,O
2167,a,O
2167,new,O
2167,dataset,O
2167,for,O
2167,machine,B
2167,comprehension,I
2167,in,O
2167,the,O
2167,medical,O
2167,domain,O
2167,.,O
2168,We,O
2168,see,B
2168,that,B
2168,answer,B
2168,prediction,I
2168,based,B
2168,on,I
2168,contextual,B
2168,representation,I
2168,of,B
2168,queries,B
2168,and,I
2168,passages,I
2168,(,I
2168,sim,I
2168,-entity,I
2168,),I
2168,achieves,B
2168,a,O
2168,strong,B
2168,base,I
2168,performance,I
2168,that,O
2168,is,O
2168,only,O
2168,outperformed,B
2168,by,B
2168,GA,B
2168,7,O
2168,In,O
2168,precision,O
2168,",",O
2168,the,O
2168,number,O
2168,of,O
2168,correct,O
2168,words,O
2168,is,O
2168,divided,O
2168,by,O
2168,the,O
2168,number,O
2168,of,O
2168,all,O
2168,predicted,O
2168,words,O
2168,.,O
2169,The,O
2169,language,B
2169,model,I
2169,performs,B
2169,poorly,B
2169,on,B
2169,EM,B
2169,and,I
2169,F1,I
2169,",",O
2169,but,O
2169,the,O
2169,embedding,B
2169,-,I
2169,metric,I
2169,score,I
2169,is,B
2169,higher,B
2169,",",O
2169,likely,O
2169,reflecting,O
2169,the,O
2169,fact,O
2169,that,O
2169,the,O
2169,predicted,O
2169,answers,O
2169,-,O
2169,though,O
2169,mostly,O
2169,incorrect,O
2169,-,O
2169,are,O
2169,related,O
2169,to,O
2169,the,O
2169,ground,O
2169,-,O
2169,truth,O
2169,answers,O
2169,.,O
2170,The,O
2170,GA,B
2170,reader,I
2170,performs,B
2170,well,B
2170,across,B
2170,all,B
2170,entity,I
2170,set,I
2170,-,I
2170,ups,I
2170,",",O
2170,even,O
2170,when,O
2170,the,O
2170,entities,O
2170,are,O
2170,not,O
2170,marked,O
2170,in,O
2170,the,O
2170,passage,O
2170,.,O
2171,The,O
2171,results,O
2171,for,O
2171,SA,B
2171,reader,I
2171,are,B
2171,far,B
2171,below,I
2171,the,O
2171,per-formance,B
2171,of,B
2171,GA,B
2171,reader,O
2171,.,O
2172,We,O
2172,also,O
2172,see,O
2172,that,O
2172,it,O
2172,performs,B
2172,much,B
2172,better,I
2172,on,I
2172,anonymized,B
2172,entities,I
2172,than,B
2172,on,O
2172,non-anonymized,B
2172,ones,I
2172,.,O
2173,Upon,O
2173,inspecting,O
2173,the,O
2173,predicted,O
2173,answers,O
2173,more,O
2173,closely,O
2173,",",O
2173,we,O
2173,have,O
2173,observed,B
2173,that,I
2173,GA,B
2173,-,I
2173,NoEnt,I
2173,tends,B
2173,to,I
2173,predict,I
2173,longer,B
2173,answers,O
2173,than,B
2173,GA,O
2173,-,O
2173,Ent,O
2173,/,O
2173,Anonym,O
2173,.,O
2174,According,O
2174,to,O
2174,the,O
2174,ablation,O
2174,results,O
2174,",",O
2174,we,O
2174,infer,O
2174,that,O
2174,:,O
2174,(,O
2174,a,O
2174,),O
2174,When,B
2174,the,O
2174,number,B
2174,of,I
2174,layers,I
2174,is,B
2174,only,B
2174,one,I
2174,",",O
2174,the,O
2174,model,B
2174,lacks,B
2174,reasoning,B
2174,capability,I
2174,.,O
2175,In,O
2175,the,O
2175,case,O
2175,of,O
2175,1,B
2175,k,I
2175,dataset,I
2175,",",O
2175,when,B
2175,there,O
2175,are,O
2175,too,B
2175,many,I
2175,layers,I
2175,(,O
2175,6,O
2175,),O
2175,",",O
2175,it,O
2175,seems,O
2175,correctly,B
2175,training,I
2175,the,O
2175,model,B
2175,becomes,B
2175,increasingly,B
2175,difficult,I
2175,.,O
2176,In,O
2176,the,O
2176,case,O
2176,of,O
2176,10,B
2176,k,I
2176,dataset,I
2176,",",O
2176,many,B
2176,layers,I
2176,(,I
2176,6,I
2176,),I
2176,and,I
2176,hidden,I
2176,dimensions,I
2176,(,O
2176,200,O
2176,),O
2176,helps,B
2176,reasoning,B
2176,",",O
2176,most,O
2176,notably,O
2176,in,O
2176,difficult,O
2176,task,O
2176,such,O
2176,as,O
2176,task,O
2176,16,O
2176,.,O
2177,For,B
2177,all,B
2177,the,I
2177,LSTM,I
2177,layers,I
2177,",",O
2177,we,O
2177,find,B
2177,that,I
2177,2,B
2177,-,I
2177,layer,I
2177,stacked,I
2177,LSTMs,I
2177,generally,O
2177,work,B
2177,better,I
2177,than,I
2177,one,B
2177,-,O
2177,layer,O
2177,LSTMs,O
2177,.,O
2178,(,O
2178,b,O
2178,),O
2178,Adding,B
2178,the,O
2178,reset,B
2178,gate,I
2178,helps,B
2178,.,O
2179,(,O
2179,c,O
2179,),O
2179,Including,B
2179,vector,B
2179,gates,I
2179,hurts,B
2179,in,B
2179,1,B
2179,k,I
2179,datasets,I
2179,",",O
2179,as,O
2179,the,O
2179,model,O
2179,either,O
2179,overfits,O
2179,to,O
2179,the,O
2179,training,O
2179,data,O
2179,or,O
2179,converges,O
2179,to,O
2179,local,O
2179,minima,O
2179,.,O
2180,On,O
2180,the,O
2180,other,O
2180,hand,O
2180,",",O
2180,vector,B
2180,gates,I
2180,in,B
2180,bAbI,B
2180,story,I
2180,-,I
2180,based,I
2180,QA,I
2180,10,I
2180,k,I
2180,dataset,I
2180,sometimes,B
2180,help,B
2180,.,O
2181,It,O
2181,can,O
2181,be,O
2181,hypothesized,B
2181,that,I
2181,a,O
2181,larger,B
2181,hidden,I
2181,state,I
2181,is,O
2181,required,B
2181,for,I
2181,real,B
2181,data,I
2181,.,O
2182,(,O
2182,d,O
2182,),O
2182,Increasing,B
2182,the,O
2182,dimension,B
2182,of,B
2182,the,O
2182,hidden,B
2182,state,I
2182,to,B
2182,100,B
2182,in,B
2182,the,O
2182,dialog,B
2182,'s,I
2182,Task,I
2182,6,I
2182,(,O
2182,DSTC2,O
2182,),O
2182,helps,B
2182,",",O
2182,while,O
2182,there,O
2182,is,O
2182,not,O
2182,much,O
2182,improvement,O
2182,in,O
2182,the,O
2182,dialog,O
2182,'s,O
2182,Task,O
2182,1,O
2182,-,O
2182,5,O
2182,.,O
2183,These,O
2183,include,B
2183,LSTM,B
2183,",",O
2183,End,O
2183,-,O
2183,to,O
2183,-,O
2183,end,O
2183,Memory,O
2183,Networks,O
2183,(,O
2183,N2N,O
2183,),O
2183,",",O
2183,Dynamic,B
2183,Memory,O
2183,Networks,O
2183,(,O
2183,DMN,O
2183,+,O
2183,),O
2183,",",O
2183,Gated,B
2183,End,O
2183,-,O
2183,to,O
2183,-,O
2183,end,O
2183,Memory,O
2183,Networks,O
2183,(,O
2183,GMe,O
2183,m,O
2183,N2N,O
2183,),O
2183,",",O
2183,and,O
2183,Differentiable,B
2183,Neural,I
2183,Computer,I
2183,(,O
2183,DNC,O
2183,),O
2183,.,O
2184,We,O
2184,withhold,B
2184,10,B
2184,%,I
2184,of,B
2184,the,O
2184,training,B
2184,for,B
2184,development,B
2184,.,O
2185,We,O
2185,use,B
2185,the,O
2185,hidden,B
2185,state,I
2185,size,I
2185,of,B
2185,50,B
2185,by,B
2185,deafult,B
2185,.,O
2186,Batch,O
2186,sizes,O
2186,of,B
2186,32,B
2186,for,B
2186,bAbI,B
2186,story,I
2186,-,I
2186,based,I
2186,QA,I
2186,1k,I
2186,",",O
2186,bAb,B
2186,I,I
2186,dialog,I
2186,and,O
2186,DSTC2,B
2186,dialog,O
2186,",",O
2186,and,O
2186,128,B
2186,for,O
2186,bAbI,O
2186,QA,O
2186,10,O
2186,k,O
2186,are,O
2186,used,O
2186,.,O
2187,The,O
2187,weights,B
2187,in,B
2187,the,O
2187,input,B
2187,and,I
2187,output,I
2187,modules,I
2187,are,O
2187,initialized,B
2187,with,I
2187,zero,B
2187,mean,I
2187,and,O
2187,the,O
2187,standard,O
2187,deviation,O
2187,of,O
2187,1,O
2187,/,O
2187,?,O
2188,We,O
2188,minimize,B
2188,cross,B
2188,-,I
2188,entropy,I
2188,loss,I
2188,over,B
2188,all,B
2188,42,I
2188,relations,I
2188,using,B
2188,AdaGrad,B
2188,.,O
2189,Forget,O
2189,bias,O
2189,of,B
2189,2.5,B
2189,is,O
2189,used,B
2189,for,I
2189,update,B
2189,gates,I
2189,(,O
2189,no,O
2189,bias,O
2189,for,O
2189,reset,O
2189,gates,O
2189,),O
2189,.,O
2190,L2,O
2190,weight,O
2190,decay,O
2190,of,B
2190,0.001,B
2190,(,I
2190,0.0005,I
2190,for,I
2190,QA,I
2190,10,I
2190,k,I
2190,),I
2190,is,O
2190,used,B
2190,for,O
2190,all,B
2190,weights,I
2190,.,O
2191,The,O
2191,loss,B
2191,function,I
2191,is,B
2191,the,O
2191,cross,B
2191,entropy,I
2191,between,B
2191,v,B
2191,and,I
2191,the,O
2191,one,O
2191,-,O
2191,hot,O
2191,vector,O
2191,of,B
2191,the,O
2191,true,B
2191,answer,I
2191,.,O
2192,The,O
2192,loss,B
2192,is,B
2192,minimized,B
2192,by,I
2192,stochastic,B
2192,gradient,I
2192,descent,I
2192,for,B
2192,maximally,B
2192,500,I
2192,epochs,I
2192,",",O
2192,but,O
2192,training,B
2192,is,O
2192,early,B
2192,stopped,I
2192,if,B
2192,the,O
2192,loss,O
2192,on,B
2192,the,O
2192,development,B
2192,data,I
2192,does,O
2192,not,B
2192,decrease,I
2192,for,O
2192,50,B
2192,epochs,O
2192,.,O
2193,The,O
2193,learning,O
2193,rate,O
2193,is,O
2193,controlled,B
2193,by,I
2193,AdaGrad,B
2193,with,B
2193,the,O
2193,initial,B
2193,learning,O
2193,rate,O
2193,of,B
2193,0.5,B
2193,(,I
2193,0.1,I
2193,for,I
2193,QA,I
2193,10,I
2193,k,I
2193,),I
2193,.,O
2194,Since,O
2194,the,O
2194,model,O
2194,is,O
2194,sensitive,O
2194,to,O
2194,the,O
2194,weight,O
2194,initialization,O
2194,",",O
2194,we,O
2194,repeat,B
2194,each,B
2194,training,I
2194,procedure,I
2194,10,I
2194,times,I
2194,(,I
2194,50,I
2194,times,O
2194,for,O
2194,10,O
2194,k,O
2194,),O
2194,with,B
2194,the,O
2194,new,B
2194,random,I
2194,initialization,O
2194,of,B
2194,the,O
2194,weights,B
2194,and,O
2194,report,O
2194,the,O
2194,result,O
2194,on,O
2194,the,O
2194,test,O
2194,data,O
2194,with,O
2194,the,O
2194,lowest,O
2194,loss,O
2194,on,O
2194,the,O
2194,development,O
2194,data,O
2194,.,O
2195,Our,O
2195,proposed,O
2195,model,O
2195,",",O
2195,Query,B
2195,-,I
2195,Reduction,I
2195,Network,I
2195,1,I
2195,(,I
2195,QRN,I
2195,),I
2195,",",O
2195,is,B
2195,a,O
2195,single,B
2195,recurrent,B
2195,unit,I
2195,that,B
2195,addresses,I
2195,the,O
2195,long,B
2195,-,O
2195,term,O
2195,dependency,O
2195,problem,O
2195,of,B
2195,most,B
2195,RNN,B
2195,-,O
2195,based,O
2195,models,O
2195,by,B
2195,simplifying,I
2195,the,O
2195,recurrent,O
2195,update,O
2195,",",O
2195,while,O
2195,taking,B
2195,the,O
2195,advantage,B
2195,of,O
2195,RNN,O
2195,'s,O
2195,capability,O
2195,to,B
2195,model,O
2195,sequential,B
2195,data,I
2195,),O
2195,.,O
2196,QRN,O
2196,considers,B
2196,the,O
2196,context,B
2196,sentences,I
2196,as,B
2196,a,O
2196,sequence,B
2196,of,B
2196,state,B
2196,-,I
2196,changing,I
2196,triggers,I
2196,",",O
2196,and,O
2196,transforms,B
2196,(,O
2196,reduces,O
2196,),O
2196,the,O
2196,original,B
2196,query,I
2196,to,B
2196,a,O
2196,more,B
2196,informed,I
2196,query,O
2196,as,O
2196,it,O
2196,observes,B
2196,each,O
2196,trigger,O
2196,through,B
2196,time,I
2196,.,O
2197,Compared,O
2197,to,O
2197,memory,O
2197,-,O
2197,based,O
2197,approaches,O
2197,",",O
2197,QRN,O
2197,can,O
2197,better,B
2197,encodes,I
2197,locality,B
2197,information,I
2197,because,O
2197,it,O
2197,does,O
2197,not,O
2197,use,O
2197,a,O
2197,global,O
2197,memory,O
2197,access,O
2197,controller,O
2197,(,O
2197,circle,O
2197,nodes,O
2197,in,O
2197,),O
2197,",",O
2197,and,O
2197,the,O
2197,query,B
2197,updates,I
2197,are,O
2197,performed,B
2197,locally,B
2197,.,O
2198,Published,O
2198,as,O
2198,a,O
2198,conference,O
2198,paper,O
2198,at,O
2198,ICLR,O
2198,2017,O
2198,QUERY,O
2198,-,O
2198,REDUCTION,O
2198,NETWORKS,O
2198,FOR,O
2198,QUESTION,B
2198,ANSWERING,I
2199,We,O
2199,apply,B
2199,Dropout,B
2199,with,B
2199,p,B
2199,=,I
2199,0.5,I
2199,to,B
2199,CNNs,B
2199,and,I
2199,LSTMs,I
2199,.,O
2200,In,O
2200,this,O
2200,paper,O
2200,",",O
2200,we,O
2200,study,O
2200,the,O
2200,problem,O
2200,of,O
2200,question,B
2200,answering,I
2200,when,I
2200,reasoning,I
2200,over,I
2200,multiple,I
2200,facts,I
2200,is,O
2200,required,O
2200,.,O
2201,In,B
2201,1,B
2201,k,I
2201,data,I
2201,",",O
2201,QRN,B
2201,'s,I
2201,',I
2201,2,I
2201,r',I
2201,(,I
2201,2,O
2201,layers,O
2201,+,O
2201,reset,O
2201,gate,O
2201,+,O
2201,d,O
2201,=,O
2201,50,O
2201,),O
2201,outperforms,B
2201,all,B
2201,other,I
2201,models,I
2201,by,B
2201,a,O
2201,large,B
2201,margin,I
2201,(,O
2201,2.8,O
2201,+,O
2201,%,O
2201,),O
2201,.,O
2202,In,O
2202,10,B
2202,k,I
2202,dataset,I
2202,",",O
2202,the,O
2202,average,B
2202,accuracy,I
2202,of,B
2202,QRN,B
2202,'s,I
2202,',I
2202,6r200,I
2202,',O
2202,(,O
2202,6,O
2202,layers,O
2202,+,O
2202,reset,O
2202,gate,O
2202,+,O
2202,d,O
2202,=,O
2202,200,O
2202,),O
2202,model,O
2202,outperforms,B
2202,all,B
2202,previous,I
2202,models,I
2202,by,B
2202,a,O
2202,large,B
2202,margin,I
2202,(,O
2202,2.5,O
2202,+,O
2202,%,O
2202,),O
2202,",",O
2202,achieving,B
2202,a,O
2202,nearly,B
2202,perfect,I
2202,score,I
2202,of,O
2202,99.7,B
2202,%,O
2202,.,O
2203,QRN,B
2203,outperforms,B
2203,previous,B
2203,work,I
2203,by,B
2203,a,O
2203,large,B
2203,margin,I
2203,(,I
2203,2.0,I
2203,+,I
2203,%,I
2203,),I
2203,in,O
2203,every,O
2203,comparison,O
2203,.,O
2204,If,O
2204,we,O
2204,remove,B
2204,the,O
2204,gated,B
2204,-,I
2204,attention,I
2204,",",O
2204,the,O
2204,accuracies,B
2204,drop,B
2204,to,B
2204,72.8,B
2204,%,I
2204,and,I
2204,73.6,I
2204,%,O
2204,.,O
2205,If,O
2205,we,O
2205,remove,O
2205,charactercomposition,B
2205,vector,I
2205,",",O
2205,the,O
2205,accuracies,B
2205,drop,B
2205,to,B
2205,72.9,B
2205,%,I
2205,and,I
2205,73.5,I
2205,%,O
2205,.,O
2206,If,O
2206,we,O
2206,remove,O
2206,word,B
2206,-,I
2206,level,I
2206,embedding,I
2206,",",O
2206,the,O
2206,accuracies,B
2206,drop,B
2206,to,B
2206,65.6,B
2206,%,I
2206,and,I
2206,66.0,I
2206,%,O
2206,.,O
2207,To,O
2207,help,O
2207,replicate,O
2207,our,O
2207,results,O
2207,",",O
2207,we,O
2207,publish,O
2207,our,O
2207,code,O
2207,at,O
2207,https,B
2207,:,I
2207,//github.com/lukecq1231/enc_nli,I
2208,We,O
2208,use,B
2208,the,O
2208,Adam,B
2208,(,I
2208,Kingma,I
2208,and,I
2208,Ba,I
2208,",",I
2208,2014,I
2208,),I
2208,for,B
2208,optimization,B
2208,.,O
2209,We,O
2209,use,O
2209,pretrained,B
2209,GloVe,I
2209,-,I
2209,840B,I
2209,-,O
2209,300D,O
2209,vectors,O
2209,as,B
2209,our,B
2209,word,I
2209,-,O
2209,level,O
2209,embeddings,O
2209,and,O
2209,fix,B
2209,these,O
2209,embeddings,O
2209,during,B
2209,the,O
2209,training,B
2209,process,I
2209,.,O
2210,During,B
2210,training,B
2210,we,O
2210,also,O
2210,find,B
2210,a,O
2210,word,B
2210,dropout,I
2210,strategy,I
2210,to,B
2210,be,I
2210,very,B
2210,effective,I
2210,:,O
2210,we,O
2210,randomly,B
2210,set,I
2210,a,O
2210,token,B
2210,to,O
2210,be,O
2210,<,B
2210,UNK,I
2210,>,I
2210,with,B
2210,a,O
2210,probability,O
2210,p.,O
2211,Stacked,O
2211,BiLSTM,O
2211,has,O
2211,3,B
2211,layers,I
2211,",",O
2211,and,O
2211,all,B
2211,hidden,I
2211,states,I
2211,of,B
2211,BiLSTMs,B
2211,and,O
2211,MLP,O
2211,have,B
2211,600,B
2211,dimensions,I
2211,.,O
2212,The,O
2212,character,B
2212,embedding,I
2212,has,O
2212,15,B
2212,dimensions,I
2212,",",I
2212,and,O
2212,CNN,B
2212,filters,I
2212,length,I
2212,is,B
2212,[,B
2212,1,I
2212,",",O
2212,3,O
2212,",",O
2212,5,O
2212,],O
2212,",",O
2212,each,O
2212,of,O
2212,those,O
2212,is,O
2212,100,B
2212,dimensions,O
2212,.,O
2213,Out,O
2213,-,O
2213,of,O
2213,-,O
2213,vocabulary,O
2213,(,O
2213,OOV,O
2213,),O
2213,words,O
2213,are,O
2213,initialized,B
2213,randomly,I
2213,with,B
2213,Gaussian,B
2213,samples,I
2213,.,O
2214,We,O
2214,present,O
2214,here,O
2214,the,O
2214,proposed,B
2214,natural,B
2214,language,I
2214,inference,I
2214,networks,I
2214,which,O
2214,are,O
2214,composed,B
2214,of,I
2214,the,O
2214,following,O
2214,major,O
2214,components,O
2214,:,O
2214,word,B
2214,embedding,I
2214,",",O
2214,sequence,B
2214,encoder,I
2214,",",O
2214,composition,B
2214,layer,I
2214,",",O
2214,and,O
2214,the,O
2214,toplayer,B
2214,classifier,I
2214,.,O
2215,We,O
2215,concatenate,B
2215,embeddings,B
2215,learned,B
2215,at,I
2215,two,B
2215,different,I
2215,levels,I
2215,to,B
2215,represent,I
2215,each,B
2215,word,I
2215,in,B
2215,the,O
2215,sentence,B
2215,:,O
2215,the,O
2215,character,B
2215,composition,I
2215,and,O
2215,holistic,B
2215,word,O
2215,-,O
2215,level,O
2215,embedding,O
2215,.,O
2216,To,O
2216,represent,O
2216,words,O
2216,and,O
2216,their,O
2216,context,O
2216,in,O
2216,a,O
2216,premise,O
2216,and,O
2216,hypothesis,O
2216,",",O
2216,sentence,B
2216,pairs,I
2216,are,O
2216,fed,B
2216,into,I
2216,sentence,O
2216,encoders,O
2216,to,O
2216,obtain,O
2216,hidden,B
2216,vectors,I
2216,(,I
2216,h,I
2216,p,I
2216,and,O
2216,h,O
2216,h,O
2216,),O
2216,.,O
2217,We,O
2217,use,B
2217,stacked,B
2217,bidirectional,I
2217,LSTMs,I
2217,(,I
2217,BiL,I
2217,-,I
2217,STM,I
2217,),I
2217,as,B
2217,the,O
2217,encoders,B
2217,.,O
2218,We,O
2218,set,B
2218,p,B
2218,to,B
2218,be,I
2218,0.06,B
2218,for,B
2218,the,O
2218,SDP,B
2218,-,I
2218,LSTM,I
2218,model,I
2218,and,O
2218,0.04,B
2218,for,O
2218,all,B
2218,other,I
2218,models,I
2218,.,O
2219,To,O
2219,transform,O
2219,sentences,B
2219,into,B
2219,fixed,B
2219,-,I
2219,length,I
2219,vector,I
2219,representations,I
2219,and,I
2219,reason,O
2219,using,O
2219,those,O
2219,representations,O
2219,",",O
2219,we,O
2219,need,O
2219,to,O
2219,compose,B
2219,the,O
2219,hidden,B
2219,vectors,I
2219,obtained,B
2219,by,I
2219,the,O
2219,sequence,B
2219,encoder,I
2219,layer,I
2219,(,I
2219,h,I
2219,p,I
2219,and,O
2219,h,O
2219,h,O
2219,),O
2219,.,O
2220,We,O
2220,propose,B
2220,intra-sentence,B
2220,gated,I
2220,-,I
2220,attention,I
2220,to,B
2220,obtain,I
2220,a,O
2220,fixed,B
2220,-,O
2220,length,O
2220,vector,O
2220,.,O
2221,Our,O
2221,inference,O
2221,model,O
2221,feeds,B
2221,the,O
2221,resulting,B
2221,vectors,I
2221,obtained,O
2221,above,O
2221,to,B
2221,the,O
2221,final,B
2221,classifier,I
2221,to,O
2221,determine,O
2221,the,O
2221,over,B
2221,all,I
2221,inference,O
2221,relationship,O
2221,.,O
2222,Recurrent,O
2222,Neural,O
2222,Network,O
2222,-,O
2222,Based,O
2222,Sentence,O
2222,Encoder,O
2222,with,O
2222,Gated,O
2222,Attention,O
2222,for,O
2222,Natural,B
2222,Language,I
2222,Inference,I
2223,Task,O
2223,aims,O
2223,to,O
2223,evaluate,O
2223,language,O
2223,understanding,O
2223,models,O
2223,for,O
2223,sentence,O
2223,representation,O
2223,with,O
2223,natural,B
2223,language,O
2223,inference,O
2223,(,O
2223,NLI,O
2223,),O
2223,tasks,O
2223,",",O
2223,where,O
2223,a,O
2223,sentence,O
2223,is,O
2223,represented,O
2223,as,O
2223,a,O
2223,fixedlength,O
2223,vector,O
2223,.,O
2224,Specifically,O
2224,",",O
2224,NLI,B
2224,is,O
2224,concerned,O
2224,with,O
2224,determining,O
2224,whether,O
2224,a,O
2224,hypothesis,O
2224,sentence,O
2224,h,O
2224,can,O
2224,be,O
2224,inferred,O
2224,from,O
2224,a,O
2224,premise,O
2224,sentence,O
2224,p.,O
2225,In,B
2225,addition,O
2225,",",O
2225,we,O
2225,also,O
2225,use,O
2225,our,B
2225,implementation,I
2225,of,I
2225,ESIM,I
2225,",",O
2225,which,O
2225,achieves,B
2225,an,O
2225,accuracy,B
2225,of,O
2225,76.8,B
2225,%,I
2225,in,O
2225,the,O
2225,in,O
2225,-,O
2225,domain,O
2225,test,O
2225,set,O
2225,",",O
2225,and,O
2225,75.8,B
2225,%,O
2225,in,O
2225,the,O
2225,cross,B
2225,-,O
2225,domain,O
2225,test,O
2225,set,O
2225,",",O
2225,which,O
2225,presents,B
2225,the,O
2225,state,B
2225,-,O
2225,of,O
2225,-,O
2225,the,O
2225,-,O
2225,art,O
2225,results,O
2225,.,O
2226,After,O
2226,removing,O
2226,the,O
2226,cross,B
2226,-,I
2226,sentence,I
2226,attention,I
2226,and,I
2226,adding,B
2226,our,B
2226,gated,I
2226,-,O
2226,attention,O
2226,model,O
2226,",",O
2226,we,O
2226,achieve,B
2226,accuracies,B
2226,of,B
2226,73.5,B
2226,%,I
2226,and,O
2226,73.6,O
2226,%,O
2226,",",O
2226,which,O
2226,ranks,B
2226,first,B
2226,in,B
2226,the,O
2226,cross,O
2226,-,O
2226,domain,O
2226,test,O
2226,set,O
2226,and,O
2226,ranks,O
2226,second,B
2226,in,O
2226,the,O
2226,in,O
2226,-,O
2226,domain,O
2226,test,O
2226,set,O
2226,among,B
2226,the,O
2226,single,B
2226,models,I
2226,.,O
2227,When,B
2227,ensembling,B
2227,our,B
2227,models,I
2227,",",O
2227,we,O
2227,obtain,B
2227,accuracies,B
2227,74.9,I
2227,%,I
2227,and,I
2227,74.9,O
2227,%,O
2227,",",O
2227,which,O
2227,ranks,B
2227,first,B
2227,in,I
2227,both,B
2227,test,I
2227,sets,I
2227,.,O
2228,We,O
2228,propose,B
2228,a,O
2228,new,B
2228,",",I
2228,effective,I
2228,neural,I
2228,network,I
2228,sequence,I
2228,model,I
2228,for,B
2228,relation,B
2228,classification,I
2228,.,O
2229,Our,O
2229,code,O
2229,for,O
2229,the,O
2229,model,O
2229,is,O
2229,available,O
2229,at,O
2229,https://github.com/soskek/der-network,B
2230,For,B
2230,preprocessing,B
2230,",",O
2230,we,O
2230,segment,B
2230,sentences,B
2230,at,O
2230,punctuation,B
2230,marks,I
2230,"""",O
2230,.,B
2230,"""",O
2231,",",O
2231,"""",O
2231,!,B
2231,"""",O
2232,",",O
2232,and,O
2232,"""",O
2232,?,B
2232,"""",O
2233,.,B
2234,We,O
2234,train,B
2234,our,O
2234,model,B
2234,8,O
2234,with,B
2234,hyper,B
2234,-,I
2234,parameters,I
2234,lightly,B
2234,tuned,I
2234,on,B
2234,the,O
2234,validation,B
2234,set,I
2234,9,O
2234,",",O
2234,and,O
2234,we,O
2234,conduct,O
2234,ablation,O
2234,test,O
2234,on,O
2234,several,O
2234,techniques,O
2234,that,O
2234,improve,O
2234,our,O
2234,basic,O
2234,model,O
2234,.,O
2235,We,O
2235,",",O
2235,however,O
2235,",",O
2235,take,O
2235,it,O
2235,as,B
2235,a,O
2235,strong,O
2235,motivation,O
2235,to,O
2235,implement,B
2235,a,O
2235,reader,B
2235,that,O
2235,dynamically,B
2235,builds,I
2235,meaning,B
2235,representations,I
2235,for,B
2235,each,B
2235,entity,B
2235,",",O
2235,by,B
2235,gathering,I
2235,and,I
2235,accumulating,I
2235,information,B
2235,on,B
2235,that,O
2235,entity,O
2235,as,O
2235,it,O
2235,reads,O
2235,a,O
2235,document,B
2235,(,O
2235,Section,O
2235,2,O
2235,),O
2235,.,O
2236,Dynamic,O
2236,Entity,O
2236,Representation,O
2236,with,O
2236,Max,O
2236,-,O
2236,pooling,O
2236,Improves,O
2236,Machine,B
2236,Reading,I
2237,As,O
2237,shown,O
2237,in,O
2237,",",O
2237,Max,B
2237,-,I
2237,pooling,I
2237,described,O
2237,in,O
2237,Section,O
2237,2.2,O
2237,drastically,B
2237,improves,I
2237,performance,B
2237,",",O
2237,showing,O
2237,the,O
2237,effect,O
2237,of,O
2237,accumulating,O
2237,information,O
2237,on,O
2237,entities,O
2237,.,O
2238,The,O
2238,99,B
2238,%,I
2238,confidence,I
2238,intervals,I
2238,of,B
2238,the,O
2238,results,B
2238,of,O
2238,full,B
2238,DER,I
2238,Network,I
2238,and,I
2238,the,O
2238,one,O
2238,initialized,O
2238,by,O
2238,word2vec,O
2238,on,B
2238,the,O
2238,test,B
2238,set,I
2238,were,B
2238,[,B
2238,0.700,I
2238,",",I
2238,0.740,I
2238,],I
2238,and,O
2238,[,O
2238,0.708,O
2238,",",O
2238,0.749,O
2238,],O
2238,",",O
2238,respectively,O
2238,(,O
2238,measured,O
2238,by,O
2238,bootstrap,O
2238,tests,O
2238,),O
2238,.,O
2239,Further,O
2239,",",O
2239,we,O
2239,note,B
2239,that,I
2239,initializing,B
2239,our,B
2239,model,I
2239,with,B
2239,pre-trained,B
2239,word,I
2239,vectors,I
2239,10,O
2239,is,B
2239,helpful,B
2239,",",O
2239,though,O
2239,world,O
2239,knowledge,O
2239,of,O
2239,entities,O
2239,has,O
2239,been,O
2239,prevented,O
2239,by,O
2239,the,O
2239,anonymization,O
2239,process,O
2239,.,O
2240,Finally,O
2240,",",O
2240,we,O
2240,note,O
2240,that,O
2240,our,B
2240,model,I
2240,",",O
2240,full,B
2240,DER,I
2240,Network,I
2240,",",O
2240,shows,B
2240,the,O
2240,best,B
2240,results,I
2240,compared,B
2240,to,I
2240,several,B
2240,previous,I
2240,reader,I
2240,models,I
2240,",",O
2240,endorsing,O
2240,our,O
2240,approach,O
2240,as,O
2240,promising,O
2240,.,O
2241,We,O
2241,use,B
2241,a,O
2241,context,B
2241,window,I
2241,of,B
2241,size,B
2241,3,B
2241,for,B
2241,Insurance,B
2241,QA,I
2241,",",O
2241,while,O
2241,we,O
2241,set,O
2241,this,O
2241,parameter,O
2241,to,O
2241,4,B
2241,for,O
2241,TREC,B
2241,-,I
2241,QA,O
2241,and,O
2241,Wiki,B
2241,QA,O
2241,.,O
2242,Early,O
2242,Stopping,O
2242,of,B
2242,20,B
2242,evaluations,I
2242,on,B
2242,the,O
2242,dev,B
2242,set,I
2242,is,O
2242,used,O
2242,.,O
2243,Its,O
2243,architecture,B
2243,is,O
2243,better,B
2243,customized,I
2243,for,I
2243,the,O
2243,slot,B
2243,filling,I
2243,task,I
2243,:,O
2243,the,O
2243,word,O
2243,representations,O
2243,are,O
2243,augmented,B
2243,by,I
2243,extra,B
2243,distributed,I
2243,representations,O
2243,of,B
2243,word,O
2243,position,O
2243,relative,B
2243,to,I
2243,the,O
2243,subject,B
2243,and,I
2243,object,I
2243,of,O
2243,the,O
2243,putative,B
2243,relation,I
2243,.,O
2244,For,B
2244,AP,B
2244,-,I
2244,CNN,I
2244,",",O
2244,AP,O
2244,-,O
2244,biLSTM,O
2244,and,O
2244,QA,B
2244,-,O
2244,LSTM,O
2244,",",O
2244,we,O
2244,also,O
2244,use,O
2244,a,O
2244,learning,B
2244,rate,I
2244,schedule,I
2244,that,B
2244,decreases,B
2244,the,O
2244,learning,O
2244,rate,O
2244,?,O
2245,Using,O
2245,the,O
2245,selected,O
2245,hyperparameters,O
2245,",",O
2245,the,O
2245,best,B
2245,results,I
2245,are,O
2245,normally,O
2245,achieved,O
2245,using,O
2245,between,B
2245,15,I
2245,and,I
2245,25,I
2245,training,I
2245,epochs,I
2245,.,O
2246,In,O
2246,our,O
2246,experiments,O
2246,",",O
2246,the,O
2246,four,B
2246,NN,I
2246,architectures,I
2246,QA,B
2246,-,I
2246,CNN,I
2246,",",O
2246,AP,B
2246,-,O
2246,CNN,O
2246,",",O
2246,QA,O
2246,-,O
2246,biLSTM,O
2246,and,O
2246,AP,O
2246,-,O
2246,biLSTM,O
2246,are,O
2246,implemented,B
2246,using,I
2246,Theano,B
2246,.,O
2247,The,O
2247,key,O
2247,contribution,O
2247,of,B
2247,this,O
2247,work,O
2247,is,O
2247,that,B
2247,we,O
2247,propose,B
2247,Attentive,B
2247,Pooling,I
2247,(,I
2247,AP,I
2247,),I
2247,",",O
2247,a,O
2247,two,B
2247,-,I
2247,way,I
2247,attention,I
2247,mechanism,I
2247,",",O
2247,that,O
2247,significantly,B
2247,improves,I
2247,such,O
2247,discriminative,B
2247,models,I
2247,',I
2247,performance,I
2247,on,B
2247,pair,B
2247,-,O
2247,wise,O
2247,ranking,O
2247,or,O
2247,classification,O
2247,",",O
2247,by,B
2247,enabling,I
2247,a,O
2247,joint,B
2247,learning,I
2247,of,O
2247,the,O
2247,representations,B
2247,of,O
2247,both,O
2247,inputs,B
2247,as,I
2247,well,I
2247,as,O
2247,their,B
2247,similarity,I
2247,measurement,I
2247,.,O
2248,Specifically,O
2248,",",O
2248,AP,B
2248,enables,B
2248,the,O
2248,pooling,B
2248,layer,I
2248,to,B
2248,be,I
2248,aware,I
2248,of,B
2248,the,O
2248,current,B
2248,input,I
2248,pair,I
2248,",",O
2248,in,B
2248,a,I
2248,way,I
2248,that,I
2248,information,B
2248,from,B
2248,the,O
2248,two,B
2248,input,O
2248,items,O
2248,can,O
2248,directly,B
2248,influence,I
2248,the,O
2248,computation,B
2248,of,O
2248,each,B
2248,other,I
2248,'s,I
2248,representations,I
2248,.,O
2249,The,O
2249,main,O
2249,idea,O
2249,in,B
2249,AP,O
2249,consists,B
2249,of,B
2249,learning,B
2249,a,O
2249,similarity,B
2249,measure,I
2249,over,B
2249,projected,O
2249,segments,B
2249,(,O
2249,e.g.,O
2250,trigrams,O
2250,),O
2250,of,B
2250,the,O
2250,two,B
2250,items,I
2250,in,B
2250,the,O
2250,input,B
2250,pair,I
2250,",",O
2250,and,O
2250,using,B
2250,the,O
2250,similarity,B
2250,scores,I
2250,between,B
2250,the,O
2250,segments,B
2250,to,B
2250,compute,I
2250,attention,B
2250,vectors,I
2250,in,O
2250,both,B
2250,directions,I
2250,.,O
2251,Next,O
2251,",",O
2251,the,O
2251,attention,B
2251,vectors,I
2251,are,O
2251,used,O
2251,to,B
2251,perform,I
2251,pooling,B
2251,.,O
2252,However,O
2252,",",O
2252,most,O
2252,recent,O
2252,work,O
2252,on,O
2252,neural,O
2252,attention,B
2252,models,O
2252,have,O
2252,focused,O
2252,on,O
2252,one,O
2252,-,O
2252,way,O
2252,attention,O
2252,mechanisms,O
2252,based,O
2252,on,O
2252,recurrent,O
2252,neural,O
2252,networks,O
2252,designed,O
2252,.,O
2253,In,O
2253,",",O
2253,we,O
2253,present,O
2253,the,O
2253,experimental,O
2253,results,O
2253,of,O
2253,the,O
2253,four,O
2253,NNs,O
2253,for,B
2253,the,O
2253,Insurance,B
2253,QA,I
2253,dataset,I
2253,.,O
2254,This,O
2254,means,B
2254,that,I
2254,the,O
2254,neural,B
2254,attention,I
2254,model,I
2254,can,O
2254,effectively,B
2254,exploit,I
2254,the,O
2254,combination,B
2254,of,I
2254,semantic,I
2254,similarity,I
2254,-,I
2254,based,I
2254,attention,O
2254,and,O
2254,positionbased,O
2254,attention,O
2254,.,O
2255,On,O
2255,the,O
2255,bottom,O
2255,part,O
2255,of,O
2255,this,O
2255,table,O
2255,",",O
2255,we,O
2255,can,O
2255,see,B
2255,that,I
2255,AP,B
2255,-,I
2255,CNN,I
2255,outperforms,B
2255,QA,B
2255,-,O
2255,CNN,O
2255,by,B
2255,a,O
2255,large,B
2255,margin,I
2255,in,B
2255,both,B
2255,test,I
2255,sets,I
2255,",",O
2255,as,O
2255,well,O
2255,as,O
2255,in,O
2255,the,O
2255,dev,B
2255,set,I
2255,.,O
2256,AP,O
2256,-,O
2256,CNN,O
2256,and,O
2256,AP,O
2256,-,O
2256,biLSTM,O
2256,have,B
2256,similar,B
2256,performance,I
2256,.,O
2257,Both,O
2257,AP,O
2257,-,O
2257,CNN,O
2257,and,O
2257,AP,O
2257,-,O
2257,biLSTM,O
2257,outperform,B
2257,the,I
2257,state,B
2257,-,O
2257,of,O
2257,-,O
2257,the,O
2257,-,O
2257,art,O
2257,systems,O
2257,.,O
2258,In,O
2258,",",O
2258,we,O
2258,present,O
2258,the,O
2258,experimental,O
2258,results,O
2258,of,O
2258,the,O
2258,four,O
2258,NNs,O
2258,for,O
2258,the,O
2258,TREC,B
2258,-,I
2258,QA,I
2258,dataset,I
2258,.,O
2259,We,O
2259,use,O
2259,the,O
2259,official,O
2259,trec,O
2259,eval,O
2259,that,O
2259,AP,B
2259,-,I
2259,CNN,I
2259,outperforms,B
2259,QA,B
2259,-,O
2259,CNN,O
2259,by,B
2259,a,O
2259,large,B
2259,margin,I
2259,in,B
2259,both,B
2259,metrics,I
2259,.,O
2260,AP,O
2260,-,O
2260,CNN,O
2260,outperforms,O
2260,the,O
2260,state,B
2260,-,O
2260,of,O
2260,-,O
2260,the,O
2260,-,O
2260,art,O
2260,systems,O
2260,in,B
2260,both,B
2260,metrics,I
2260,",",O
2260,MAP,B
2260,and,I
2260,MRR,I
2260,.,O
2261,AP,O
2261,-,O
2261,biLSTM,O
2261,outperforms,B
2261,the,O
2261,QA,B
2261,-,O
2261,biLSTM,O
2261,",",O
2261,but,O
2261,its,O
2261,performance,B
2261,is,O
2261,not,B
2261,as,B
2261,good,I
2261,as,O
2261,the,O
2261,of,O
2261,AP,O
2261,-,O
2261,CNN,O
2261,.,O
2262,shows,O
2262,the,O
2262,experimental,O
2262,results,O
2262,of,O
2262,the,O
2262,four,O
2262,NNs,O
2262,for,O
2262,the,O
2262,WikiQA,B
2262,dataset,I
2262,.,O
2263,Like,O
2263,in,O
2263,the,O
2263,other,O
2263,two,O
2263,datasets,O
2263,",",O
2263,AP,B
2263,-,I
2263,CNN,I
2263,outperforms,B
2263,QA,B
2263,-,O
2263,CNN,O
2263,",",O
2263,and,O
2263,AP,O
2263,-,O
2263,biLSTM,O
2263,outperforms,O
2263,the,O
2263,QA,O
2263,-,O
2263,biLSTM,O
2263,.,O
2264,The,O
2264,difference,B
2264,of,I
2264,performance,I
2264,between,B
2264,AP,B
2264,-,I
2264,CNN,I
2264,and,I
2264,QA,I
2264,-,O
2264,CNN,O
2264,is,B
2264,smaller,B
2264,than,B
2264,the,O
2264,one,O
2264,for,O
2264,the,O
2264,Insurance,B
2264,QA,O
2264,dataset,O
2264,.,O
2265,However,O
2265,",",O
2265,the,O
2265,ability,O
2265,to,O
2265,populate,B
2265,knowledge,I
2265,bases,I
2265,with,I
2265,facts,I
2265,automatically,O
2265,extracted,O
2265,from,O
2265,documents,O
2265,has,O
2265,improved,O
2265,frustratingly,O
2265,slowly,O
2265,.,O
2266,We,O
2266,used,B
2266,the,O
2266,Glove,B
2266,840B,I
2266,300D,I
2266,1,I
2266,(,I
2266,d,I
2266,e,I
2266,=,I
2266,300,I
2266,),I
2266,for,B
2266,the,O
2266,pre-trained,B
2266,word,I
2266,embedding,I
2266,without,B
2266,any,O
2266,finetuning,B
2266,.,O
2267,This,O
2267,is,O
2267,to,O
2267,train,B
2267,the,O
2267,more,B
2267,universally,I
2267,usable,I
2267,sentence,I
2267,encoder,I
2267,.,O
2268,Layer,O
2268,normalization,O
2268,was,O
2268,applied,B
2268,to,I
2268,all,B
2268,linear,I
2268,projections,I
2268,of,B
2268,masked,B
2268,multihead,I
2268,attention,I
2268,",",O
2268,fusion,B
2268,gate,I
2268,",",O
2268,and,O
2268,multi-dimensional,B
2268,attention,O
2268,.,O
2269,Batch,O
2269,size,O
2269,was,B
2269,64,B
2269,",",O
2269,and,O
2269,the,O
2269,model,B
2269,was,O
2269,trained,B
2269,with,B
2269,Adam,B
2269,optimizer,I
2269,",",O
2269,with,O
2269,a,O
2269,learning,B
2269,rate,I
2269,of,B
2269,0.001,B
2269,.,O
2270,We,O
2270,applied,B
2270,residual,B
2270,dropout,B
2270,as,O
2270,used,O
2270,in,O
2270,",",O
2270,with,B
2270,dropout,O
2270,to,B
2270,the,O
2270,output,B
2270,of,I
2270,masked,B
2270,multi-head,I
2270,attention,I
2270,and,O
2270,SF,B
2270,+H,I
2270,F,I
2270,+b,I
2270,F,O
2270,of,O
2270,fusion,O
2270,gate,O
2270,.,O
2271,We,O
2271,set,B
2271,h,O
2271,=,O
2271,5,O
2271,",",O
2271,?,O
2272,=,O
2272,1.5,O
2272,in,B
2272,the,O
2272,masked,B
2272,multi-head,I
2272,attention,I
2272,",",O
2272,and,O
2272,the,O
2272,dropout,B
2272,probability,I
2272,was,O
2272,set,B
2272,to,I
2272,0.1,B
2272,.,O
2273,All,O
2273,models,O
2273,were,O
2273,implemented,B
2273,via,I
2273,Tensorflow,B
2273,on,B
2273,single,B
2273,Nvidia,I
2273,Geforce,I
2273,GTX,I
2273,1080,I
2273,Ti,I
2273,GPU,I
2273,.,O
2274,To,O
2274,tackle,O
2274,this,O
2274,limitation,O
2274,",",O
2274,we,O
2274,propose,B
2274,Distancebased,B
2274,Self,I
2274,-,I
2274,Attention,I
2274,Network,I
2274,which,O
2274,introduces,B
2274,a,O
2274,distance,O
2274,mask,O
2274,which,O
2274,models,B
2274,the,O
2274,relative,B
2274,distance,O
2274,between,B
2274,words,B
2274,.,O
2275,In,B
2275,conjunction,O
2275,with,O
2275,a,O
2275,directional,B
2275,mask,I
2275,",",O
2275,the,O
2275,distance,B
2275,mask,O
2275,allows,B
2275,us,I
2275,to,I
2275,incorporate,I
2275,complete,B
2275,positional,I
2275,information,I
2275,of,I
2275,words,I
2275,in,O
2275,our,B
2275,model,I
2275,.,O
2276,Distance,O
2276,-,O
2276,based,O
2276,Self,O
2276,-,O
2276,Attention,O
2276,Network,O
2276,for,O
2276,Natural,B
2276,Language,I
2276,Inference,I
2277,A,O
2277,basic,O
2277,but,O
2277,highly,O
2277,important,O
2277,challenge,O
2277,in,O
2277,natural,O
2277,language,O
2277,understanding,O
2277,is,O
2277,being,O
2277,able,O
2277,to,O
2277,populate,B
2277,a,O
2277,knowledge,O
2277,base,O
2277,with,O
2277,relational,O
2277,facts,O
2277,contained,O
2277,in,O
2277,a,O
2277,piece,O
2277,of,O
2277,text,O
2277,.,O
2278,Our,O
2278,model,O
2278,shows,O
2278,good,O
2278,performance,O
2278,with,O
2278,NLI,B
2278,data,O
2278,",",O
2278,and,O
2278,it,O
2278,records,O
2278,the,O
2278,new,O
2278,state,O
2278,-,O
2278,of,O
2278,-,O
2278,the,O
2278,-,O
2278,art,O
2278,result,O
2278,with,O
2278,SNLI,O
2278,data,O
2278,.,O
2279,More,O
2279,recently,O
2279,",",O
2279,models,O
2279,incorporating,O
2279,attention,O
2279,mechanisms,O
2279,have,O
2279,shown,O
2279,good,O
2279,performance,O
2279,in,O
2279,machine,O
2279,translation,O
2279,",",O
2279,Natural,B
2279,Language,I
2279,Inference,I
2279,(,I
2279,NLI,I
2279,),I
2279,",",O
2279,and,O
2279,Question,O
2279,Answering,O
2279,(,O
2279,QA,O
2279,),O
2279,etc,O
2279,.,O
2280,Experimental,O
2280,results,O
2280,of,B
2280,SNLI,B
2280,data,I
2280,compared,O
2280,with,O
2280,the,O
2280,existing,O
2280,models,O
2280,on,O
2280,the,O
2280,SNLI,O
2280,leader,O
2280,-,O
2280,board,O
2280,2,O
2280,are,O
2280,shown,O
2280,in,O
2280,.,O
2281,Compared,O
2281,with,O
2281,the,O
2281,existing,B
2281,state,I
2281,-,I
2281,of,I
2281,-,O
2281,the,O
2281,-,O
2281,art,O
2281,model,O
2281,",",O
2281,the,O
2281,number,O
2281,of,O
2281,parameters,O
2281,and,O
2281,the,O
2281,training,O
2281,time,O
2281,increased,O
2281,",",O
2281,but,O
2281,our,B
2281,results,I
2281,show,B
2281,the,O
2281,new,B
2281,state,O
2281,-,O
2281,of,O
2281,-,O
2281,theart,O
2281,record,O
2281,.,O
2282,Results,O
2282,show,B
2282,that,O
2282,the,O
2282,addition,B
2282,of,B
2282,the,O
2282,distance,B
2282,mask,I
2282,improved,B
2282,the,O
2282,performance,B
2282,without,B
2282,significantly,B
2282,affecting,I
2282,the,O
2282,training,B
2282,time,I
2282,or,O
2282,increasing,B
2282,the,O
2282,number,O
2282,of,O
2282,parameters,B
2282,.,O
2283,2,O
2283,The,O
2283,improvement,B
2283,of,B
2283,the,O
2283,test,B
2283,accuracy,I
2283,by,B
2283,introducing,I
2283,the,O
2283,distance,B
2283,mask,I
2283,is,B
2283,only,I
2283,by,O
2283,0.3,B
2283,%,I
2283,point,I
2283,",",O
2283,potentially,O
2283,because,O
2283,SNLI,O
2283,data,O
2283,mostly,O
2283,consist,O
2283,of,O
2283,short,O
2283,sentences,O
2283,.,O
2284,The,O
2284,results,O
2284,of,O
2284,applying,B
2284,SNLI,B
2284,best,I
2284,model,I
2284,to,B
2284,MultiNLI,B
2284,dataset,I
2284,without,O
2284,additional,O
2284,parameter,O
2284,tuning,O
2284,are,O
2284,presented,O
2284,in,O
2284,.,O
2285,Compared,O
2285,with,O
2285,the,O
2285,result,B
2285,of,I
2285,RepEVAL,I
2285,2017,I
2285,",",O
2285,we,O
2285,can,O
2285,see,B
2285,that,I
2285,the,O
2285,Distance,B
2285,-,I
2285,based,I
2285,Self,I
2285,-,O
2285,Attention,O
2285,Network,O
2285,performs,B
2285,well,B
2285,.,O
2286,When,O
2286,compared,O
2286,with,B
2286,the,O
2286,model,O
2286,of,O
2286,",",O
2286,our,B
2286,model,O
2286,showed,B
2286,similar,B
2286,average,I
2286,test,I
2286,accuracy,I
2286,with,O
2286,much,B
2286,lower,I
2286,number,I
2286,of,O
2286,parameters,O
2286,.,O
2287,Existing,O
2287,work,O
2287,on,O
2287,relation,B
2287,extraction,I
2287,(,O
2287,e.g.,O
2288,Vocab,O
2288,Size,O
2288,:,O
2288,For,O
2288,training,O
2288,our,O
2288,ReasoNet,O
2288,",",O
2288,we,O
2288,keep,B
2288,the,O
2288,most,B
2288,frequent,I
2288,|,I
2288,V,I
2288,|,O
2288,=,O
2288,101,O
2288,k,O
2288,words,O
2288,(,O
2288,not,O
2288,including,O
2288,584,O
2288,entities,O
2288,and,O
2288,1,O
2288,placeholder,O
2288,marker,O
2288,),O
2288,in,B
2288,the,O
2288,CNN,B
2288,dataset,I
2288,",",O
2288,and,O
2288,|,O
2288,V,O
2288,|,O
2288,=,O
2288,151,O
2288,k,O
2288,words,O
2288,(,O
2288,not,O
2288,including,O
2288,530,O
2288,entities,O
2288,and,O
2288,1,O
2288,placeholder,O
2288,marker,O
2288,),O
2288,in,O
2288,the,O
2288,Daily,B
2288,Mail,I
2288,dataset,O
2288,.,O
2289,We,O
2289,choose,B
2289,300,B
2289,-,I
2289,dimensional,I
2289,word,I
2289,embeddings,I
2289,",",O
2289,and,O
2289,use,B
2289,the,O
2289,300,O
2289,-,O
2289,dimensional,O
2289,pretrained,O
2289,Glove,O
2289,word,O
2289,embeddings,O
2289,for,B
2289,initialization,B
2289,.,O
2290,We,O
2290,also,O
2290,apply,B
2290,dropout,B
2290,with,B
2290,probability,B
2290,0.2,I
2290,to,B
2290,the,O
2290,embedding,B
2290,layer,I
2290,.,O
2291,The,O
2291,absolute,B
2291,value,I
2291,of,B
2291,gradient,B
2291,on,B
2291,each,B
2291,parameter,I
2291,is,B
2291,clipped,B
2291,within,B
2291,0.001,B
2291,.,O
2292,The,O
2292,batch,B
2292,size,I
2292,is,B
2292,64,B
2292,for,B
2292,both,B
2292,CNN,I
2292,and,I
2292,Daily,I
2292,Mail,I
2292,datasets,I
2292,.,O
2293,We,O
2293,use,B
2293,ADAM,B
2293,optimizer,I
2293,for,B
2293,parameter,B
2293,optimization,I
2293,with,B
2293,an,O
2293,initial,B
2293,learning,I
2293,rate,I
2293,of,B
2293,0.0005,O
2293,",",O
2293,?,O
2294,Models,O
2294,are,O
2294,trained,B
2294,on,I
2294,GTX,B
2294,TitanX,I
2294,12,I
2294,GB,I
2294,.,O
2295,Comparing,O
2295,with,O
2295,the,O
2295,AS,B
2295,Reader,I
2295,",",O
2295,ReasoNet,B
2295,shows,B
2295,the,O
2295,signi,B
2295,cant,I
2295,improvement,I
2295,by,B
2295,capturing,I
2295,multi-turn,O
2295,reasoning,B
2295,in,B
2295,the,O
2295,paragraph,B
2295,.,O
2296,Iterative,O
2296,Attention,O
2296,Reader,O
2296,",",O
2296,EpiReader,O
2296,and,O
2296,GA,O
2296,Reader,O
2296,are,B
2296,the,O
2296,three,B
2296,multi-turn,I
2296,reasoning,I
2296,models,I
2296,with,B
2296,xed,B
2296,reasoning,O
2296,steps,O
2296,.,O
2297,We,O
2297,observe,B
2297,that,O
2297,all,B
2297,neural,B
2297,models,I
2297,achieve,B
2297,higher,B
2297,F,I
2297,1,I
2297,scores,I
2297,than,B
2297,the,O
2297,logistic,B
2297,regression,I
2297,and,I
2297,patterns,I
2297,systems,I
2297,",",O
2297,which,O
2297,demonstrates,B
2297,the,O
2297,effectiveness,B
2297,of,B
2297,neural,O
2297,models,O
2297,for,B
2297,relation,B
2297,extraction,I
2297,.,O
2298,ReasoNet,B
2298,also,O
2298,outperforms,B
2298,all,O
2298,of,O
2298,them,O
2298,by,B
2298,integrating,I
2298,termination,B
2298,gate,I
2298,in,B
2298,the,O
2298,model,B
2298,which,O
2298,allows,B
2298,di,B
2298,erent,I
2298,reasoning,I
2298,steps,I
2298,for,B
2298,di,O
2298,erent,O
2298,test,O
2298,cases,O
2298,.,O
2299,ReasoNet,B
2299,obtains,B
2299,comparable,B
2299,results,I
2299,with,B
2299,AoA,B
2299,Reader,I
2299,on,B
2299,CNN,B
2299,test,I
2299,set,I
2299,.,O
2300,We,O
2300,use,B
2300,the,O
2300,python,B
2300,NLTK,I
2300,tokenizer,I
2300,6,O
2300,to,B
2300,preprocess,I
2300,passages,B
2300,and,I
2300,questions,I
2300,",",O
2300,and,O
2300,obtain,B
2300,about,I
2300,100K,B
2300,words,I
2300,in,B
2300,the,O
2300,vocabulary,B
2300,.,O
2301,Embedding,O
2301,Layer,O
2301,:,O
2301,We,O
2301,use,B
2301,the,O
2301,100,B
2301,-,I
2301,dimensional,I
2301,pretrained,I
2301,Glove,I
2301,vectors,I
2301,as,B
2301,word,B
2301,embeddings,I
2301,.,O
2302,The,O
2302,maximum,B
2302,reasoning,I
2302,step,I
2302,T,I
2302,max,I
2302,is,O
2302,set,B
2302,to,I
2302,10,B
2302,in,O
2302,SQuAD,O
2302,experiments,O
2302,.,O
2303,We,O
2303,use,B
2303,AdaDelta,B
2303,optimizer,I
2303,for,B
2303,parameter,B
2303,optimization,I
2303,with,B
2303,an,O
2303,initial,B
2303,learning,I
2303,rate,I
2303,of,B
2303,0.5,B
2303,and,O
2303,a,O
2303,batch,O
2303,size,O
2303,Results,O
2303,:,O
2304,In,O
2304,",",O
2304,we,O
2304,demonstrate,B
2304,that,O
2304,ReasoNet,B
2304,outperforms,B
2304,all,B
2304,existing,I
2304,published,I
2304,approaches,I
2304,.,O
2305,While,O
2305,we,O
2305,compare,B
2305,ReasoNet,B
2305,with,O
2305,BiDAF,B
2305,",",O
2305,ReasoNet,O
2305,exceeds,B
2305,BiDAF,O
2305,both,B
2305,in,I
2305,single,B
2305,model,I
2305,and,I
2305,ensemble,I
2305,model,O
2305,cases,O
2305,.,O
2306,Although,O
2306,positional,B
2306,embeddings,I
2306,help,B
2306,increase,I
2306,the,O
2306,F,B
2306,1,I
2306,by,B
2306,around,I
2306,2,B
2306,%,I
2306,over,B
2306,the,O
2306,plain,B
2306,CNN,I
2306,model,I
2306,",",O
2306,a,O
2306,simple,O
2306,(,O
2306,2,O
2306,-,O
2306,layer,O
2306,),O
2306,LSTM,O
2306,model,O
2306,performs,O
2306,surprisingly,O
2306,better,O
2306,than,O
2306,CNN,O
2306,and,O
2306,dependency,O
2306,-,O
2306,based,O
2306,models,O
2306,.,O
2307,In,B
2307,the,I
2307,bottom,O
2307,part,O
2307,of,O
2307,",",O
2307,we,O
2307,compare,O
2307,ReasoNet,B
2307,with,O
2307,all,B
2307,unpublished,O
2307,methods,O
2307,at,O
2307,the,O
2307,time,O
2307,of,O
2307,this,O
2307,submission,O
2307,",",O
2307,ReasoNet,O
2307,holds,B
2307,the,O
2307,second,B
2307,position,I
2307,in,O
2307,all,O
2307,the,O
2307,competing,O
2307,approaches,O
2307,in,O
2307,the,O
2307,SQuAD,B
2307,leaderboard,I
2307,.,O
2308,We,O
2308,use,B
2308,a,O
2308,100,B
2308,-,I
2308,dimensional,I
2308,embedding,I
2308,vector,I
2308,for,B
2308,each,B
2308,symbol,I
2308,in,B
2308,the,O
2308,query,B
2308,and,I
2308,graph,I
2308,description,I
2308,.,O
2309,The,O
2309,maximum,B
2309,reasoning,I
2309,step,I
2309,T,I
2309,max,I
2309,is,O
2309,set,B
2309,to,I
2309,15,B
2309,and,I
2309,25,I
2309,for,B
2309,the,O
2309,small,B
2309,graph,I
2309,and,O
2309,large,O
2309,graph,O
2309,dataset,O
2309,",",O
2309,respectively,O
2309,.,O
2310,We,O
2310,use,B
2310,AdaDelta,B
2310,optimizer,I
2310,for,B
2310,parameter,B
2310,optimization,I
2310,with,B
2310,an,O
2310,initial,B
2310,learning,I
2310,rate,I
2310,of,B
2310,0.5,B
2310,and,O
2310,a,O
2310,batch,B
2310,size,I
2310,of,O
2310,32,B
2310,.,O
2311,Deep,O
2311,LSTM,O
2311,Reader,O
2311,achieves,B
2311,90.92,B
2311,%,I
2311,and,I
2311,71.55,I
2311,%,O
2311,accuracy,O
2311,in,B
2311,the,O
2311,small,B
2311,and,O
2311,large,O
2311,graph,O
2311,dataset,O
2311,",",O
2311,respectively,O
2311,",",O
2311,which,O
2311,indicates,O
2311,the,O
2311,graph,O
2311,reachibility,O
2311,task,O
2311,is,O
2311,not,O
2311,trivial,O
2311,.,O
2312,With,O
2312,this,O
2312,motivation,O
2312,",",O
2312,we,O
2312,propose,B
2312,a,O
2312,novel,B
2312,neural,I
2312,network,I
2312,architecture,I
2312,called,B
2312,Reasoning,B
2312,Network,O
2312,(,O
2312,ReasoNet,O
2312,),O
2312,.,O
2313,With,B
2313,a,O
2313,question,B
2313,in,B
2313,mind,B
2313,",",O
2313,ReasoNets,B
2313,read,B
2313,a,O
2313,document,B
2313,repeatedly,B
2313,",",O
2313,each,O
2313,time,O
2313,focusing,B
2313,on,I
2313,di,B
2313,erent,I
2313,parts,I
2313,of,B
2313,the,O
2313,document,O
2313,until,B
2313,a,O
2313,satisfying,B
2313,answer,I
2313,is,B
2313,found,B
2313,or,I
2313,formed,I
2313,.,O
2314,Moreover,O
2314,",",O
2314,unlike,O
2314,previous,O
2314,approaches,O
2314,using,O
2314,xed,O
2314,number,O
2314,of,O
2314,hops,O
2314,or,O
2314,iterations,O
2314,",",O
2314,ReasoNets,O
2314,introduce,B
2314,a,O
2314,termination,B
2314,state,I
2314,in,B
2314,the,O
2314,inference,B
2314,.,O
2315,Lastly,O
2315,",",O
2315,our,O
2315,proposed,B
2315,position,I
2315,-,I
2315,aware,I
2315,mechanism,I
2315,is,B
2315,very,B
2315,effective,I
2315,and,O
2315,achieves,B
2315,an,O
2315,F,B
2315,1,I
2315,score,I
2315,of,B
2315,65.4,B
2315,%,I
2315,",",O
2315,with,B
2315,an,O
2315,absolute,B
2315,increase,I
2315,of,O
2315,3.9,B
2315,%,O
2315,over,B
2315,the,O
2315,best,B
2315,baseline,B
2315,neural,I
2315,model,I
2315,(,I
2315,LSTM,I
2315,),I
2315,and,O
2315,7.9,B
2315,%,O
2315,over,O
2315,the,O
2315,baseline,O
2315,logistic,O
2315,regression,O
2315,system,O
2315,.,O
2316,Motivated,O
2316,by,O
2316,",",O
2316,we,O
2316,tackle,O
2316,this,O
2316,challenge,O
2316,by,O
2316,proposing,B
2316,a,O
2316,reinforcement,B
2316,learning,I
2316,approach,I
2316,",",O
2316,which,O
2316,utilizes,B
2316,an,O
2316,instance,B
2316,-,I
2316,dependent,I
2316,reward,I
2316,baseline,I
2316,",",O
2316,to,B
2316,successfully,I
2316,train,I
2316,ReasoNets,B
2316,.,O
2317,ReasoNet,O
2317,:,O
2317,Learning,O
2317,to,O
2317,Stop,O
2317,Reading,O
2317,in,O
2317,Machine,B
2317,Comprehension,I
2318,We,O
2318,first,O
2318,tokenize,B
2318,all,B
2318,the,I
2318,passages,I
2318,",",I
2318,questions,I
2318,and,I
2318,answers,I
2318,.,O
2319,We,O
2319,use,B
2319,word,B
2319,embeddings,I
2319,from,B
2319,GloVe,B
2319,to,B
2319,initialize,I
2319,the,O
2319,model,B
2319,.,O
2320,We,O
2320,use,O
2320,ADAMAX,B
2320,with,B
2320,the,O
2320,coefficients,B
2320,?,O
2321,2,O
2321,=,O
2321,0.999,O
2321,to,B
2321,optimize,I
2321,the,O
2321,model,B
2321,.,O
2322,Words,B
2322,not,B
2322,found,I
2322,in,I
2322,Glo,B
2322,Ve,I
2322,are,O
2322,initialized,B
2322,as,I
2322,zero,B
2322,vectors,I
2322,.,O
2323,The,O
2323,dimensionality,B
2323,l,I
2323,of,B
2323,the,O
2323,hidden,B
2323,layers,I
2323,is,O
2323,set,B
2323,to,I
2323,be,I
2323,150,B
2323,or,I
2323,300,I
2323,.,O
2324,We,O
2324,propose,B
2324,two,B
2324,ways,I
2324,to,B
2324,apply,I
2324,the,O
2324,Ptr,B
2324,-,I
2324,Net,I
2324,model,I
2324,for,B
2324,our,B
2324,task,I
2324,:,O
2324,a,O
2324,sequence,B
2324,model,O
2324,and,O
2324,a,O
2324,boundary,B
2324,model,O
2324,.,O
2325,We,O
2325,also,O
2325,further,O
2325,extend,B
2325,the,O
2325,boundary,B
2325,model,I
2325,with,B
2325,a,O
2325,search,B
2325,mechanism,I
2325,.,O
2326,CNN,O
2326,-,O
2326,based,O
2326,models,O
2326,tend,B
2326,to,I
2326,have,B
2326,higher,B
2326,precision,I
2326,;,O
2326,RNN,B
2326,-,O
2326,based,O
2326,models,O
2326,have,O
2326,better,B
2326,recall,I
2326,.,O
2327,Furthermore,O
2327,",",O
2327,our,B
2327,boundary,I
2327,model,I
2327,has,O
2327,outperformed,B
2327,the,O
2327,sequence,B
2327,model,O
2327,",",O
2327,achieving,B
2327,an,O
2327,exact,B
2327,match,I
2327,score,I
2327,of,B
2327,61.1,B
2327,%,I
2327,and,O
2327,an,O
2327,F1,B
2327,score,O
2327,of,O
2327,71.2,B
2327,%,O
2327,.,O
2328,In,O
2328,particular,O
2328,",",O
2328,in,O
2328,terms,O
2328,of,O
2328,the,O
2328,exact,B
2328,match,I
2328,score,I
2328,",",O
2328,the,O
2328,boundary,B
2328,model,I
2328,has,O
2328,a,O
2328,clear,B
2328,advantage,I
2328,over,B
2328,the,O
2328,sequence,B
2328,model,O
2328,.,O
2329,While,O
2329,by,O
2329,adding,B
2329,Bi,B
2329,-,I
2329,Ans,I
2329,-,O
2329,Ptr,O
2329,with,B
2329,bi-directional,B
2329,pre-processing,I
2329,LSTM,I
2329,",",O
2329,we,O
2329,can,O
2329,get,B
2329,1.2,B
2329,%,I
2329,improvement,I
2329,in,B
2329,F1,B
2329,.,O
2330,Next,O
2330,",",O
2330,we,O
2330,observe,B
2330,a,O
2330,substantial,B
2330,drop,I
2330,when,B
2330,removing,I
2330,tokenspecific,B
2330,attentions,I
2330,over,B
2330,the,I
2330,query,I
2330,in,B
2330,the,O
2330,GA,O
2330,module,O
2330,",",O
2330,which,O
2330,allow,B
2330,gating,I
2330,individual,B
2330,tokens,I
2330,in,O
2330,the,O
2330,document,B
2330,only,O
2330,by,B
2330,parts,B
2330,of,I
2330,the,O
2330,query,O
2330,relevant,B
2330,to,I
2330,that,O
2330,token,B
2330,rather,B
2330,than,I
2330,the,O
2330,over,O
2330,all,O
2330,query,O
2330,representation,O
2330,.,O
2331,Finally,O
2331,",",O
2331,removing,B
2331,the,I
2331,character,B
2331,embeddings,I
2331,",",O
2331,which,O
2331,were,O
2331,only,O
2331,used,B
2331,for,I
2331,WDW,B
2331,and,I
2331,CBT,I
2331,",",O
2331,leads,B
2331,to,I
2331,a,O
2331,reduction,B
2331,of,B
2331,about,B
2331,1,I
2331,%,I
2331,in,I
2331,the,O
2331,performance,O
2331,.,O
2332,Source,O
2332,code,O
2332,is,O
2332,available,O
2332,on,O
2332,github,O
2332,:,O
2332,https://,B
2332,github.com/bdhingra/ga-reader,I
2333,More,O
2333,specifically,O
2333,",",O
2333,unlike,O
2333,existing,O
2333,models,O
2333,where,O
2333,the,O
2333,query,B
2333,attention,I
2333,is,O
2333,applied,B
2333,either,O
2333,token,B
2333,-,I
2333,wise,I
2333,or,O
2333,sentence,O
2333,-,O
2333,wise,O
2333,to,B
2333,allow,O
2333,weighted,O
2333,aggregation,O
2333,",",O
2333,the,O
2333,Gated,B
2333,-,O
2333,Attention,O
2333,(,O
2333,GA,O
2333,),O
2333,module,O
2333,proposed,O
2333,in,O
2333,this,O
2333,work,O
2333,allows,B
2333,the,O
2333,query,O
2333,to,O
2333,directly,O
2333,interact,O
2333,with,O
2333,each,B
2333,dimension,I
2333,of,B
2333,the,O
2333,token,O
2333,embeddings,O
2333,at,B
2333,the,O
2333,semantic,B
2333,-,O
2333,level,O
2333,",",O
2333,and,O
2333,is,O
2333,applied,O
2333,layer,B
2333,-,O
2333,wise,O
2333,as,B
2333,information,B
2333,filters,I
2333,during,B
2333,the,O
2333,multi-hop,B
2333,representation,I
2333,learning,I
2333,process,I
2333,.,O
2334,Such,O
2334,a,O
2334,fine,B
2334,-,I
2334,grained,I
2334,attention,I
2334,enables,B
2334,our,O
2334,model,B
2334,to,B
2334,learn,I
2334,conditional,B
2334,token,I
2334,representations,I
2334,w.r.t.,B
2335,the,O
2335,given,B
2335,question,I
2335,",",O
2335,leading,O
2335,to,O
2335,accurate,O
2335,answer,O
2335,selections,O
2335,.,O
2336,Gated,O
2336,-,O
2336,Attention,O
2336,Readers,O
2336,for,O
2336,Text,B
2336,Comprehension,I
2337,Evaluating,O
2337,relation,O
2337,extraction,O
2337,systems,O
2337,on,O
2337,slot,B
2337,filling,I
2337,is,O
2337,particularly,O
2337,challenging,O
2337,in,O
2337,that,O
2337,:,O
2337,(,O
2337,1,O
2337,),O
2337,Endto,B
2337,-,I
2337,end,I
2337,cold,I
2337,start,I
2337,slot,O
2337,filling,O
2337,scores,O
2337,conflate,B
2337,the,O
2337,performance,B
2337,of,B
2337,all,O
2337,modules,O
2337,in,O
2337,the,O
2337,system,O
2337,(,O
2337,i.e.,O
2338,A,O
2338,recent,O
2338,trend,O
2338,to,O
2338,measure,O
2338,progress,O
2338,towards,O
2338,machine,B
2338,reading,I
2338,is,O
2338,to,O
2338,test,O
2338,a,O
2338,system,O
2338,'s,O
2338,ability,O
2338,to,O
2338,answer,O
2338,questions,O
2338,about,O
2338,a,O
2338,document,O
2338,it,O
2338,has,O
2338,to,O
2338,comprehend,O
2338,.,O
2339,Interestingly,O
2339,",",O
2339,we,O
2339,observe,B
2339,that,I
2339,feature,B
2339,engineering,I
2339,leads,B
2339,to,I
2339,significant,B
2339,improvements,I
2339,for,I
2339,WDW,B
2339,and,I
2339,CBT,I
2339,datasets,I
2339,",",O
2339,but,O
2339,not,B
2339,for,O
2339,CNN,B
2339,and,O
2339,Daily,O
2339,Mail,O
2339,datasets,O
2339,.,O
2340,Similarly,O
2340,",",O
2340,fixing,B
2340,the,O
2340,word,B
2340,embeddings,I
2340,provides,B
2340,an,O
2340,improvement,B
2340,for,I
2340,the,O
2340,WDW,B
2340,and,I
2340,CBT,I
2340,",",O
2340,but,O
2340,not,B
2340,for,O
2340,CNN,B
2340,and,O
2340,Daily,O
2340,Mail,O
2340,.,O
2341,Comparing,O
2341,with,O
2341,prior,O
2341,work,O
2341,",",O
2341,on,O
2341,the,O
2341,WDW,B
2341,dataset,I
2341,the,O
2341,basic,B
2341,version,I
2341,of,I
2341,the,O
2341,GA,O
2341,Reader,O
2341,outperforms,B
2341,all,B
2341,previously,I
2341,published,I
2341,models,I
2341,when,B
2341,trained,I
2341,on,O
2341,the,O
2341,Strict,B
2341,setting,I
2341,.,O
2342,Lastly,O
2342,",",O
2342,on,O
2342,CBT,B
2342,-,I
2342,CN,I
2342,the,O
2342,GA,B
2342,Reader,I
2342,with,B
2342,the,O
2342,qe-comm,B
2342,feature,I
2342,outperforms,B
2342,all,B
2342,previously,I
2342,published,I
2342,single,I
2342,models,I
2342,except,B
2342,the,O
2342,NSE,B
2342,",",O
2342,and,O
2342,AS,B
2342,Reader,O
2342,trained,B
2342,on,O
2342,a,O
2342,larger,B
2342,corpus,I
2342,.,O
2343,By,B
2343,adding,B
2343,the,O
2343,qecomm,B
2343,feature,I
2343,the,O
2343,performance,B
2343,increases,B
2343,by,O
2343,3.2,B
2343,%,I
2343,and,I
2343,3.5,I
2343,%,O
2343,on,B
2343,the,O
2343,Strict,B
2343,and,O
2343,Relaxed,O
2343,settings,O
2343,respectively,O
2343,to,O
2343,set,O
2343,a,O
2343,new,O
2343,state,O
2343,of,O
2343,the,O
2343,art,O
2343,on,O
2343,this,O
2343,dataset,O
2343,.,O
2344,On,B
2344,the,O
2344,CNN,B
2344,and,I
2344,Daily,I
2344,Mail,I
2344,datasets,I
2344,the,O
2344,GA,B
2344,Reader,I
2344,leads,B
2344,to,I
2344,an,O
2344,improvement,B
2344,of,B
2344,3.2,B
2344,%,I
2344,and,O
2344,4.3,O
2344,%,O
2344,respectively,O
2344,over,B
2344,the,O
2344,best,B
2344,previous,I
2344,single,I
2344,models,I
2344,.,O
2345,For,B
2345,CBT,B
2345,-,I
2345,NE,I
2345,",",O
2345,GA,B
2345,Reader,I
2345,with,B
2345,the,O
2345,qecomm,B
2345,feature,I
2345,outperforms,B
2345,all,B
2345,previous,I
2345,single,I
2345,and,I
2345,ensemble,I
2345,models,I
2345,except,B
2345,the,O
2345,AS,B
2345,Reader,O
2345,trained,B
2345,on,I
2345,the,O
2345,much,B
2345,larger,I
2345,BookTest,I
2345,Corpus,I
2345,.,O
2346,Then,O
2346,we,O
2346,conduct,O
2346,an,O
2346,ablation,O
2346,study,O
2346,by,O
2346,replacing,B
2346,the,O
2346,knowledge,B
2346,aided,I
2346,attention,I
2346,mechanisms,I
2346,with,B
2346,the,O
2346,mutual,B
2346,attention,O
2346,proposed,O
2346,by,O
2346,and,O
2346,the,O
2346,self,B
2346,attention,O
2346,proposed,O
2346,by,O
2346,separately,O
2346,",",O
2346,and,O
2346,find,B
2346,that,I
2346,the,O
2346,F,B
2346,1,I
2346,score,I
2346,of,B
2346,KAR,B
2346,drops,B
2346,by,O
2346,4.2,B
2346,on,B
2346,the,O
2346,development,B
2346,set,I
2346,",",O
2346,7.8,B
2346,on,O
2346,AddSent,B
2346,",",O
2346,and,O
2346,9.1,B
2346,on,O
2346,AddOneSent,B
2346,.,O
2347,On,O
2347,the,O
2347,one,O
2347,hand,O
2347,",",O
2347,we,O
2347,propose,B
2347,a,O
2347,data,B
2347,enrichment,I
2347,method,I
2347,",",O
2347,which,B
2347,uses,I
2347,WordNet,B
2347,to,B
2347,extract,I
2347,inter-word,B
2347,semantic,I
2347,connections,I
2347,as,B
2347,general,B
2347,knowledge,I
2347,from,B
2347,each,B
2347,given,I
2347,passage,I
2347,-,I
2347,question,I
2347,pair,I
2347,.,O
2348,We,O
2348,only,O
2348,consider,B
2348,spans,B
2348,that,O
2348,are,O
2348,entirely,B
2348,within,I
2348,a,O
2348,sentence,B
2348,and,O
2348,limit,B
2348,spans,O
2348,to,B
2348,a,O
2348,max,B
2348,length,I
2348,of,B
2348,L,B
2348,=,I
2348,10,I
2348,.,O
2349,(,O
2349,2,O
2349,),O
2349,Errors,B
2349,in,B
2349,hop,B
2349,-,I
2349,0,I
2349,predictions,I
2349,can,O
2349,easily,B
2349,propagate,I
2349,to,I
2349,hop,O
2349,-,O
2349,1,O
2349,predictions,O
2349,.,O
2350,On,O
2350,the,O
2350,other,O
2350,hand,O
2350,",",O
2350,we,O
2350,propose,O
2350,an,O
2350,end,O
2350,-,O
2350,to,B
2350,-,O
2350,end,O
2350,MRC,O
2350,model,O
2350,named,B
2350,as,O
2350,Knowledge,O
2350,Aided,O
2350,Reader,O
2350,(,O
2350,KAR,O
2350,),O
2350,",",O
2350,which,O
2350,explicitly,B
2350,uses,I
2350,the,O
2350,above,O
2350,extracted,B
2350,general,I
2350,knowledge,O
2350,to,O
2350,assist,O
2350,its,O
2350,attention,B
2350,mechanisms,I
2350,.,O
2351,We,O
2351,tokenize,B
2351,the,O
2351,MRC,B
2351,dataset,I
2351,with,B
2351,spa,B
2351,Cy,I
2351,2.0.13,I
2351,",",O
2351,manipulate,B
2351,WordNet,B
2351,3.0,I
2351,with,O
2351,NLTK,B
2351,3.3,I
2351,",",O
2351,and,O
2351,implement,B
2351,KAR,B
2351,with,O
2351,TensorFlow,B
2351,1.11.0,I
2351,.,O
2352,For,B
2352,the,I
2352,dense,B
2352,layers,I
2352,and,I
2352,the,O
2352,BiLSTMs,O
2352,",",O
2352,we,O
2352,set,B
2352,the,O
2352,dimensionality,B
2352,unit,I
2352,d,I
2352,to,B
2352,600,B
2352,.,O
2353,For,O
2353,model,B
2353,optimization,I
2353,",",I
2353,we,O
2353,apply,B
2353,the,O
2353,Adam,B
2353,(,I
2353,Kingma,I
2353,and,I
2353,Ba,I
2353,",",O
2353,2014,O
2353,),O
2353,optimizer,O
2353,with,B
2353,a,O
2353,learning,B
2353,rate,I
2353,of,B
2353,0.0005,B
2353,and,O
2353,a,O
2353,minibatch,B
2353,size,I
2353,of,O
2353,32,B
2353,.,O
2354,To,B
2354,avoid,O
2354,overfitting,B
2354,",",O
2354,we,O
2354,apply,B
2354,dropout,B
2354,to,O
2354,the,O
2354,dense,B
2354,layers,I
2354,and,O
2354,the,O
2354,BiLSTMs,B
2354,with,B
2354,a,O
2354,dropout,O
2354,rate,O
2354,of,B
2354,0.3,B
2354,.,O
2355,To,O
2355,boost,O
2355,the,O
2355,performance,B
2355,",",O
2355,we,O
2355,apply,B
2355,exponential,B
2355,moving,I
2355,average,I
2355,with,B
2355,a,O
2355,decay,B
2355,rate,I
2355,of,B
2355,0.999,B
2355,.,O
2356,Explicit,O
2356,Utilization,O
2356,of,O
2356,General,O
2356,Knowledge,O
2356,in,O
2356,Machine,B
2356,Reading,I
2356,Comprehension,I
2357,To,O
2357,bridge,O
2357,the,O
2357,gap,O
2357,between,O
2357,Machine,B
2357,Reading,I
2357,Comprehension,I
2357,(,I
2357,MRC,B
2357,),I
2357,models,O
2357,and,O
2357,human,O
2357,beings,O
2357,",",O
2357,which,O
2357,is,O
2357,mainly,O
2357,reflected,O
2357,in,O
2357,the,O
2357,hunger,O
2357,for,O
2357,data,O
2357,and,O
2357,the,O
2357,robustness,O
2357,to,O
2357,noise,O
2357,",",O
2357,in,O
2357,this,O
2357,paper,O
2357,",",O
2357,we,O
2357,explore,O
2357,how,O
2357,to,O
2357,integrate,O
2357,the,O
2357,neural,O
2357,networks,O
2357,of,O
2357,MRC,O
2357,models,O
2357,with,O
2357,the,O
2357,general,O
2357,knowledge,O
2357,of,O
2357,human,O
2357,beings,O
2357,.,O
2358,Finally,O
2358,we,O
2358,find,O
2358,that,O
2358,after,O
2358,only,O
2358,one,O
2358,epoch,O
2358,of,B
2358,training,O
2358,",",O
2358,KAR,B
2358,already,O
2358,achieves,B
2358,an,O
2358,EM,O
2358,of,O
2358,71.9,B
2358,and,O
2358,an,O
2358,F,B
2358,1,I
2358,score,I
2358,of,O
2358,80.8,B
2358,on,B
2358,the,O
2358,development,B
2358,set,I
2358,",",O
2358,which,O
2358,is,O
2358,even,B
2358,better,I
2358,than,B
2358,the,O
2358,final,B
2358,performance,I
2358,of,O
2358,several,B
2358,strong,I
2358,baselines,I
2358,",",O
2358,such,B
2358,as,I
2358,DCN,B
2358,(,I
2358,EM,O
2358,/,O
2358,F1,O
2358,:,O
2358,65.4,O
2358,/,O
2358,75.6,O
2358,),O
2358,and,O
2358,BiDAF,B
2358,(,O
2358,EM,O
2358,/,O
2358,F1,O
2358,:,O
2358,67.7,O
2358,/,O
2358,77.3,O
2358,),O
2358,.,O
2359,Note,O
2359,that,O
2359,TF,B
2359,-,I
2359,IDF,I
2359,is,B
2359,by,O
2359,far,O
2359,the,O
2359,most,B
2359,impactful,I
2359,feature,I
2359,",",O
2359,leading,B
2359,to,I
2359,a,O
2359,large,B
2359,drop,I
2359,of,B
2359,12,B
2359,points,I
2359,in,O
2359,performance,O
2359,.,O
2360,We,O
2360,also,O
2360,run,B
2360,an,O
2360,ensemble,B
2360,of,B
2360,our,O
2360,position,B
2360,-,I
2360,aware,I
2360,attention,I
2360,model,I
2360,which,O
2360,takes,B
2360,majority,B
2360,votes,I
2360,from,B
2360,5,B
2360,runs,I
2360,with,B
2360,random,B
2360,initializations,I
2360,and,O
2360,it,O
2360,further,B
2360,pushes,I
2360,the,O
2360,F,B
2360,1,I
2360,score,I
2360,up,O
2360,by,B
2360,1.6,B
2360,%,I
2360,.,O
2361,We,O
2361,compare,O
2361,our,O
2361,model,O
2361,",",O
2361,WEBQA,O
2361,",",O
2361,to,O
2361,STAGG,B
2361,and,I
2361,COMPQ,I
2361,",",O
2361,which,B
2361,are,I
2361,to,O
2361,the,O
2361,best,O
2361,of,O
2361,our,O
2361,knowledge,O
2361,the,O
2361,highest,B
2361,performing,I
2361,semantic,I
2361,parsing,I
2361,models,I
2361,on,B
2361,both,O
2361,COMPLEXQUESTIONS,B
2361,and,O
2361,WEBQUES,O
2361,-,O
2361,TIONS,O
2361,.,O
2362,WEBQA,B
2362,obtained,B
2362,32.6,B
2362,F,I
2362,1,I
2362,(,O
2362,33.5,O
2362,p@1,O
2362,",",O
2362,42.4,O
2362,MRR,O
2362,),O
2362,compared,B
2362,to,I
2362,40.9,B
2362,F,O
2362,1,O
2362,of,B
2362,COMPQ,B
2362,.,O
2363,Our,O
2363,candidate,B
2363,extraction,I
2363,step,I
2363,finds,B
2363,the,O
2363,correct,B
2363,answer,I
2363,in,B
2363,the,O
2363,top,B
2363,-,I
2363,K,I
2363,candidates,I
2363,in,O
2363,65.9,B
2363,%,I
2363,of,B
2363,development,B
2363,examples,I
2363,and,O
2363,62.7,B
2363,%,O
2363,of,O
2363,test,B
2363,examples,O
2363,.,O
2364,Thus,O
2364,",",O
2364,our,O
2364,test,B
2364,F,I
2364,1,I
2364,on,B
2364,examples,B
2364,for,B
2364,which,I
2364,candidate,B
2364,extraction,I
2364,succeeded,I
2364,(,I
2364,WEBQA,I
2364,-,I
2364,SUBSET,I
2364,),I
2364,is,B
2364,51.9,B
2364,(,O
2364,53.4,O
2364,p@1,O
2364,",",O
2364,67.5,O
2364,MRR,O
2364,),O
2364,.,O
2365,In,O
2365,this,O
2365,setup,O
2365,",",O
2365,COMPQ,B
2365,obtained,B
2365,42.2,B
2365,F,I
2365,1,I
2365,on,I
2365,the,O
2365,test,B
2365,set,I
2365,(,O
2365,compared,B
2365,to,I
2365,40.9,B
2365,F,O
2365,1,O
2365,",",O
2365,when,B
2365,training,I
2365,on,O
2365,COM,B
2365,-,I
2365,PLEXQUESTIONS,I
2365,only,I
2365,",",O
2365,as,O
2365,we,O
2365,do,O
2365,),O
2365,.,O
2366,Restricting,B
2366,the,O
2366,predictions,B
2366,to,B
2366,the,O
2366,subset,O
2366,for,B
2366,which,I
2366,candidate,B
2366,extraction,I
2366,succeeded,B
2366,",",O
2366,the,O
2366,F,O
2366,1,O
2366,of,B
2366,COMPQ,B
2366,-,I
2366,SUBSET,O
2366,is,B
2366,48.5,B
2366,",",O
2366,which,O
2366,is,O
2366,3.4,B
2366,F,O
2366,1,O
2366,points,O
2366,lower,O
2366,than,B
2366,WEBQA,B
2366,-,O
2366,SUBSET,O
2366,",",O
2366,which,O
2366,was,O
2366,trained,O
2366,on,O
2366,less,O
2366,data,O
2366,.,O
2367,We,O
2367,develop,B
2367,a,O
2367,simple,B
2367,log,I
2367,-,I
2367,linear,I
2367,model,I
2367,",",O
2367,in,B
2367,the,I
2367,spirit,I
2367,of,I
2367,traditional,B
2367,web,I
2367,-,O
2367,based,O
2367,QA,O
2367,systems,O
2367,",",O
2367,that,B
2367,answers,B
2367,questions,I
2367,by,B
2367,querying,B
2367,the,O
2367,web,O
2367,and,O
2367,extracting,B
2367,the,O
2367,answer,B
2367,from,B
2367,returned,B
2367,web,O
2367,snippets,O
2367,.,O
2368,Thus,O
2368,",",O
2368,our,B
2368,evaluation,I
2368,scheme,I
2368,is,O
2368,suitable,B
2368,for,I
2368,semantic,B
2368,parsing,I
2368,benchmarks,I
2368,in,B
2368,which,I
2368,the,O
2368,knowledge,B
2368,required,B
2368,for,O
2368,answering,B
2368,questions,I
2368,is,O
2368,covered,B
2368,by,I
2368,the,O
2368,web,B
2368,(,O
2368,in,O
2368,contrast,O
2368,with,O
2368,virtual,O
2368,assitants,O
2368,for,O
2368,which,O
2368,the,O
2368,knowledge,O
2368,is,O
2368,specific,O
2368,to,O
2368,an,O
2368,application,O
2368,),O
2368,.,O
2369,Evaluating,O
2369,Semantic,B
2369,Parsing,I
2369,against,O
2369,a,O
2369,Simple,O
2369,Web,O
2369,-,O
2369,based,O
2369,Question,O
2369,Answering,O
2369,Model,O
2370,We,O
2370,find,B
2370,that,O
2370,:,O
2370,(,O
2370,1,O
2370,),O
2370,by,O
2370,only,O
2370,training,B
2370,our,B
2370,logistic,I
2370,regression,I
2370,model,I
2370,on,B
2370,TACRED,B
2370,(,O
2370,in,O
2370,contrast,O
2370,to,O
2370,on,O
2370,the,O
2370,2,B
2370,million,I
2370,bootstrapped,I
2370,examples,I
2370,used,B
2370,in,O
2370,the,O
2370,2015,B
2370,Stanford,I
2370,system,I
2370,),O
2370,and,O
2370,combining,B
2370,it,I
2370,with,I
2370,patterns,B
2370,",",O
2370,we,O
2370,obtain,O
2370,a,O
2370,higher,O
2370,hop,O
2370,-,O
2370,0,O
2370,F,O
2370,1,O
2370,score,O
2370,than,O
2370,the,O
2370,2015,O
2370,Stanford,O
2370,sys,O
2370,-,O
2371,These,O
2371,ablation,O
2371,results,O
2371,are,O
2371,shown,O
2371,in,O
2371,and,O
2371,4,O
2371,",",O
2371,all,O
2371,based,B
2371,on,I
2371,the,O
2371,Multi,B
2371,-,I
2371,NLI,I
2371,development,I
2371,sets,I
2371,.,O
2372,As,O
2372,shown,O
2372,",",O
2372,each,B
2372,added,I
2372,layer,I
2372,model,I
2372,improves,B
2372,the,O
2372,accuracy,B
2372,and,I
2372,we,O
2372,achieve,B
2372,a,O
2372,substantial,B
2372,improvement,I
2372,in,B
2372,accuracy,O
2372,(,O
2372,around,O
2372,2,O
2372,%,O
2372,),O
2372,on,B
2372,both,O
2372,matched,B
2372,and,O
2372,mismatched,O
2372,settings,O
2372,",",O
2372,compared,B
2372,to,I
2372,the,O
2372,single,B
2372,-,I
2372,layer,O
2372,biLSTM,O
2372,in,O
2372,.,O
2373,The,O
2373,last,B
2373,ablation,I
2373,in,O
2373,shows,B
2373,that,I
2373,a,O
2373,classifier,B
2373,with,B
2373,two,B
2373,layers,I
2373,of,I
2373,relu,I
2373,is,B
2373,preferable,B
2373,than,O
2373,other,O
2373,options,O
2373,.,O
2374,Next,O
2374,",",O
2374,in,O
2374,",",O
2374,we,O
2374,show,B
2374,that,O
2374,the,O
2374,shortcut,B
2374,connections,I
2374,among,B
2374,the,O
2374,biLSTM,B
2374,layers,I
2374,is,B
2374,also,O
2374,an,O
2374,important,B
2374,contributor,I
2374,to,B
2374,accuracy,B
2374,improvement,I
2374,(,O
2374,around,B
2374,1.5,B
2374,%,I
2374,on,B
2374,top,I
2374,of,I
2374,the,O
2374,full,B
2374,3,I
2374,-,I
2374,layered,I
2374,stacked,I
2374,-,O
2374,RNN,O
2374,model,O
2374,),O
2374,.,O
2375,Next,O
2375,",",O
2375,in,B
2375,",",O
2375,we,O
2375,show,B
2375,that,I
2375,fine,B
2375,-,I
2375,tuning,I
2375,the,O
2375,word,B
2375,embeddings,I
2375,also,O
2375,improves,B
2375,results,B
2375,",",O
2375,again,O
2375,for,B
2375,both,I
2375,the,O
2375,in,O
2375,-,O
2375,domain,O
2375,task,O
2375,and,O
2375,cross,O
2375,-,O
2375,domain,O
2375,tasks,O
2375,(,O
2375,the,O
2375,ablation,O
2375,results,O
2375,are,O
2375,based,O
2375,on,O
2375,a,O
2375,smaller,O
2375,model,O
2375,with,O
2375,a,O
2375,128,O
2375,+256,O
2375,2,O
2375,-,O
2375,layer,O
2375,biLSTM,O
2375,),O
2375,.,O
2376,Github,O
2376,Code,O
2376,Link,O
2376,:,O
2376,https://github.com/,B
2376,easonnie/multiNLI_encoder,I
2377,We,O
2377,use,B
2377,cross,B
2377,-,I
2377,entropy,I
2377,loss,I
2377,as,B
2377,the,O
2377,training,B
2377,objective,I
2377,with,B
2377,Adam,B
2377,-,O
2377,based,O
2377,opti-Model,O
2377,Accuracy,O
2377,SNLI,O
2377,Multi,O
2377,-,O
2377,NLI,O
2377,Matched,O
2377,Multi,O
2377,-,O
2377,NLI,O
2377,Mismatched,O
2377,CBOW,O
2377,80.6,O
2377,65.2,O
2377,64.6,O
2377,biLSTM,O
2377,Encoder,O
2377,81.5,O
2377,67.5,O
2377,67.1,O
2377,300D,O
2377,Tree,O
2377,-,O
2377,CNN,O
2377,Encoder,O
2377,82.1,O
2377,--300D,O
2377,SPINN,O
2377,-,O
2377,PI,O
2377,Encoder,O
2377,83.2,O
2377,--300D,O
2377,NSE,O
2377,Encoder,O
2377,84.6,O
2377,--biLSTM,O
2377,-Max,O
2377,Encoder,O
2377,84,O
2377,.,O
2378,mization,O
2378,with,B
2378,32,B
2378,batch,I
2378,size,I
2378,.,O
2379,The,O
2379,starting,B
2379,learning,I
2379,rate,I
2379,is,B
2379,0.0002,B
2379,with,B
2379,half,B
2379,decay,I
2379,every,B
2379,two,B
2379,epochs,I
2379,.,O
2380,The,O
2380,number,B
2380,of,I
2380,hidden,I
2380,units,I
2380,for,B
2380,MLP,B
2380,in,B
2380,classifier,B
2380,is,B
2380,1600,B
2380,.,O
2381,Dropout,O
2381,layer,O
2381,is,O
2381,also,O
2381,applied,B
2381,on,I
2381,the,O
2381,output,B
2381,of,I
2381,each,B
2381,layer,O
2381,of,O
2381,MLP,O
2381,",",O
2381,with,B
2381,dropout,O
2381,rate,O
2381,set,B
2381,to,I
2381,0.1,B
2381,.,O
2382,Due,O
2382,to,O
2382,training,O
2382,time,O
2382,constraints,O
2382,",",O
2382,some,B
2382,parameters,I
2382,have,O
2382,been,O
2382,fixed,B
2382,to,O
2382,reasonable,B
2382,and,I
2382,empirical,I
2382,values,I
2382,",",O
2382,such,B
2382,as,I
2382,the,O
2382,size,B
2382,of,I
2382,convolutions,I
2382,(,I
2382,5,I
2382,5,O
2382,pixels,O
2382,",",O
2382,32,O
2382,feature,O
2382,maps,O
2382,),O
2382,and,O
2382,the,O
2382,size,O
2382,of,O
2382,subsamplings,O
2382,(,O
2382,2,O
2382,2,O
2382,pixels,O
2382,using,O
2382,max,O
2382,pooling,O
2382,),O
2382,.,O
2383,We,O
2383,used,B
2383,pre-trained,B
2383,300D,I
2383,Glove,I
2383,840B,I
2383,vectors,I
2383,to,B
2383,initialize,I
2383,the,O
2383,word,B
2383,embeddings,I
2383,.,O
2384,In,O
2384,this,O
2384,paper,O
2384,",",O
2384,we,O
2384,follow,B
2384,the,O
2384,former,B
2384,approach,I
2384,of,B
2384,encoding,B
2384,-,I
2384,based,I
2384,models,I
2384,",",O
2384,and,O
2384,propose,B
2384,a,O
2384,novel,B
2384,yet,I
2384,simple,I
2384,sequential,I
2384,sentence,I
2384,encoder,I
2384,for,B
2384,the,O
2384,Multi,B
2384,-,O
2384,NLI,O
2384,problem,O
2384,.,O
2385,It,O
2385,is,O
2385,basically,O
2385,a,O
2385,stacked,B
2385,(,I
2385,multi-layered,I
2385,),I
2385,bidirectional,I
2385,LSTM,I
2385,-,I
2385,RNN,I
2385,with,B
2385,shortcut,B
2385,connections,I
2385,(,O
2385,feeding,O
2385,all,O
2385,previous,O
2385,layers,O
2385,',O
2385,outputs,O
2385,and,O
2385,word,B
2385,embeddings,O
2385,to,O
2385,each,O
2385,layer,O
2385,),O
2385,and,O
2385,word,O
2385,embedding,O
2385,fine,O
2385,-,O
2385,tuning,O
2385,.,O
2386,The,O
2386,over,B
2386,all,I
2386,supervised,I
2386,model,I
2386,uses,B
2386,these,O
2386,shortcutstacked,B
2386,encoders,I
2386,to,B
2386,encode,I
2386,two,B
2386,input,I
2386,sentences,I
2386,into,B
2386,two,O
2386,vectors,O
2386,",",O
2386,and,O
2386,then,O
2386,we,O
2386,use,B
2386,a,O
2386,classifier,B
2386,over,O
2386,the,O
2386,vector,B
2386,combination,I
2386,to,O
2386,label,O
2386,the,O
2386,relationship,B
2386,between,B
2386,these,O
2386,two,O
2386,sentences,O
2386,as,B
2386,that,O
2386,of,O
2386,entailment,B
2386,",",O
2386,contradiction,B
2386,",",O
2386,or,O
2386,neural,B
2386,(,O
2386,similar,O
2386,to,O
2386,the,O
2386,classifier,O
2386,setup,O
2386,of,O
2386,and,O
2386,),O
2386,.,O
2387,Shortcut,O
2387,-,O
2387,Stacked,O
2387,Sentence,O
2387,Encoders,O
2387,for,O
2387,Multi-,B
2387,Domain,I
2387,Inference,I
2388,We,O
2388,present,O
2388,a,O
2388,simple,O
2388,sequential,O
2388,sentence,O
2388,encoder,O
2388,for,O
2388,multi-domain,B
2388,natural,I
2388,language,I
2388,inference,I
2388,.,O
2389,Natural,O
2389,language,O
2389,inference,O
2389,(,O
2389,NLI,O
2389,),O
2389,or,O
2389,recognizing,B
2389,textual,I
2389,entailment,I
2389,(,O
2389,RTE,O
2389,),O
2389,is,O
2389,a,O
2389,fundamental,O
2389,semantic,O
2389,task,O
2389,in,O
2389,the,O
2389,field,O
2389,of,O
2389,natural,O
2389,language,O
2389,processing,O
2389,.,O
2390,First,O
2390,for,B
2390,Multi,B
2390,-,I
2390,NLI,I
2390,",",O
2390,we,O
2390,improve,B
2390,substantially,B
2390,over,B
2390,the,O
2390,CBOW,B
2390,and,I
2390,biL,I
2390,-,O
2390,STM,O
2390,Encoder,O
2390,baselines,O
2390,reported,O
2390,in,O
2390,the,O
2390,dataset,O
2390,paper,O
2390,.,O
2391,We,O
2391,also,O
2391,show,B
2391,that,I
2391,our,B
2391,final,I
2391,shortcut,I
2391,-,I
2391,based,I
2391,stacked,I
2391,encoder,I
2391,achieves,B
2391,around,B
2391,3,I
2391,%,I
2391,improvement,I
2391,as,O
2391,compared,B
2391,to,I
2391,the,O
2391,1,B
2391,layer,I
2391,biLSTM,I
2391,-,O
2391,Max,O
2391,Encoder,O
2391,in,O
2391,the,O
2391,second,O
2391,last,O
2391,row,O
2391,(,O
2391,using,O
2391,the,O
2391,exact,O
2391,same,O
2391,classifier,O
2391,and,O
2391,optimizer,O
2391,settings,O
2391,),O
2391,.,O
2392,Our,O
2392,shortcut,B
2392,-,I
2392,encoder,I
2392,was,B
2392,also,O
2392,the,O
2392,top,B
2392,singe,I
2392,-,O
2392,model,O
2392,(,O
2392,non-ensemble,O
2392,),O
2392,result,O
2392,on,B
2392,the,O
2392,EMNLP,B
2392,RepEval,I
2392,Shared,I
2392,Task,I
2392,leaderboard,I
2392,.,O
2393,All,O
2393,layers,O
2393,use,B
2393,ReLU,B
2393,units,I
2393,",",O
2393,except,B
2393,of,I
2393,softmax,B
2393,being,O
2393,used,B
2393,in,I
2393,the,O
2393,output,B
2393,layer,I
2393,.,O
2394,Next,O
2394,",",O
2394,for,O
2394,SNLI,B
2394,",",O
2394,we,O
2394,compare,B
2394,our,O
2394,shortcutstacked,B
2394,encoder,I
2394,with,B
2394,the,I
2394,current,B
2394,state,I
2394,-,I
2394,of,I
2394,-,O
2394,the,O
2394,-,O
2394,art,O
2394,encoders,O
2394,from,B
2394,the,O
2394,SNLI,O
2394,leaderboard,O
2394,(,O
2394,https,O
2394,://,O
2394,nlp.stanford.edu/projects/snli/,O
2394,),O
2394,.,O
2395,We,O
2395,also,O
2395,compare,B
2395,to,I
2395,the,O
2395,recent,B
2395,biLSTM,I
2395,-,I
2395,Max,I
2395,Encoder,I
2395,of,O
2395,",",O
2395,which,O
2395,served,O
2395,as,O
2395,our,O
2395,model,O
2395,'s,O
2395,1,O
2395,-,O
2395,layer,O
2395,starting,O
2395,point,O
2395,.,O
2396,The,O
2396,results,B
2396,indicate,B
2396,that,O
2396,',O
2396,Our,B
2396,Shortcut,I
2396,-,I
2396,Stacked,I
2396,Encoder,I
2396,',O
2396,sur-passes,B
2396,all,B
2396,the,O
2396,previous,O
2396,state,O
2396,-,O
2396,of,O
2396,-,O
2396,the,O
2396,-,O
2396,art,O
2396,encoders,O
2396,",",O
2396,and,O
2396,achieves,B
2396,the,O
2396,new,B
2396,best,I
2396,encoding,I
2396,-,O
2396,based,O
2396,result,O
2396,on,B
2396,SNLI,B
2396,",",O
2396,suggesting,O
2396,the,O
2396,general,O
2396,effectiveness,O
2396,of,O
2396,simple,O
2396,shortcut,O
2396,-,O
2396,connected,O
2396,stacked,O
2396,layers,O
2396,in,O
2396,sentence,O
2396,encoders,O
2396,.,O
2397,For,O
2397,the,O
2397,setting,O
2397,of,O
2397,hyper,O
2397,-,O
2397,parameters,O
2397,",",O
2397,we,O
2397,set,B
2397,the,O
2397,number,B
2397,of,O
2397,bins,O
2397,as,B
2397,600,B
2397,",",O
2397,word,B
2397,embedding,I
2397,dimension,I
2397,as,O
2397,700,B
2397,for,O
2397,a,O
2397,NNM,B
2397,-,O
2397,1,O
2397,",",O
2397,the,O
2397,number,O
2397,of,O
2397,bins,O
2397,as,O
2397,200,B
2397,",",O
2397,word,O
2397,embedding,O
2397,dimension,O
2397,as,O
2397,700,O
2397,for,O
2397,a,O
2397,NNM,O
2397,-,O
2397,2,O
2397,after,O
2397,we,O
2397,tune,O
2397,hyper,O
2397,-,O
2397,parameters,O
2397,on,O
2397,the,O
2397,provided,O
2397,DEV,O
2397,set,O
2397,of,O
2397,TREC,O
2397,QA,O
2397,data,O
2397,.,O
2398,To,O
2398,handle,O
2398,these,O
2398,issues,O
2398,in,O
2398,the,O
2398,existing,O
2398,deep,O
2398,learning,O
2398,architectures,O
2398,for,O
2398,ranking,O
2398,answers,O
2398,",",O
2398,we,O
2398,propose,B
2398,an,O
2398,attention,B
2398,based,I
2398,neural,I
2398,matching,I
2398,model,I
2398,(,I
2398,a,I
2398,NMM,I
2398,),I
2398,.,O
2399,We,O
2399,introduce,B
2399,a,O
2399,novel,B
2399,value,I
2399,-,I
2399,shared,I
2399,weighting,I
2399,scheme,I
2399,in,B
2399,deep,B
2399,neural,I
2399,networks,I
2399,as,O
2399,a,O
2399,counterpart,O
2399,of,O
2399,the,O
2399,position,O
2399,-,O
2399,shared,O
2399,weighting,O
2399,scheme,O
2399,in,O
2399,CNNs,O
2399,",",O
2399,based,O
2399,on,O
2399,the,O
2399,idea,O
2399,that,O
2399,semantic,O
2399,matching,O
2399,between,O
2399,a,O
2399,question,O
2399,and,O
2399,answer,O
2399,is,O
2399,mainly,O
2399,about,O
2399,the,O
2399,(,O
2399,semantic,O
2399,similarity,O
2399,),O
2399,value,O
2399,regularities,O
2399,rather,O
2399,than,O
2399,spatial,O
2399,regularities,O
2399,.,O
2400,We,O
2400,incorporate,B
2400,the,O
2400,attention,B
2400,scheme,I
2400,over,B
2400,the,O
2400,question,B
2400,terms,I
2400,using,B
2400,a,O
2400,gating,B
2400,function,I
2400,",",O
2400,so,O
2400,that,O
2400,we,O
2400,can,O
2400,explicitly,O
2400,discriminate,O
2400,the,O
2400,question,O
2400,term,O
2400,importance,O
2400,.,O
2401,As,O
2401,an,O
2401,alternative,O
2401,to,O
2401,question,B
2401,answering,I
2401,methods,O
2401,based,O
2401,on,O
2401,feature,O
2401,engineering,O
2401,",",O
2401,deep,O
2401,learning,O
2401,approaches,O
2401,such,O
2401,as,O
2401,convolutional,O
2401,neural,O
2401,networks,O
2401,(,O
2401,CNNs,O
2401,),O
2401,and,O
2401,Long,O
2401,Short,O
2401,-,O
2401,Term,O
2401,Memory,O
2401,Models,O
2401,(,O
2401,LSTMs,O
2401,),O
2401,have,O
2401,recently,O
2401,been,O
2401,proposed,O
2401,for,O
2401,semantic,O
2401,matching,O
2401,of,O
2401,questions,O
2401,and,O
2401,answers,O
2401,.,O
2402,The,O
2402,learning,B
2402,rate,I
2402,is,O
2402,fixed,B
2402,to,I
2402,?,O
2403,=,O
2403,0.01,O
2403,and,O
2403,not,B
2403,subject,I
2403,to,I
2403,model,B
2403,selection,I
2403,as,O
2403,it,O
2403,would,O
2403,significantly,O
2403,prolong,O
2403,the,O
2403,model,O
2403,selection,O
2403,.,O
2404,Many,O
2404,of,O
2404,current,O
2404,QA,B
2404,systems,O
2404,use,O
2404,a,O
2404,learning,O
2404,to,O
2404,rank,O
2404,approach,O
2404,that,O
2404,encodes,O
2404,question,O
2404,/,O
2404,answer,O
2404,pairs,O
2404,with,O
2404,complex,O
2404,linguistic,O
2404,features,O
2404,including,O
2404,lexical,O
2404,",",O
2404,syntactic,O
2404,and,O
2404,semantic,O
2404,features,O
2404,.,O
2405,We,O
2405,can,O
2405,see,B
2405,a,O
2405,NMM,B
2405,trained,B
2405,with,I
2405,TRAIN,B
2405,-,I
2405,ALL,B
2405,set,I
2405,beats,B
2405,all,O
2405,the,O
2405,previous,O
2405,state,O
2405,-,O
2405,of,O
2405,-,O
2405,the,O
2405,art,O
2405,systems,O
2405,including,B
2405,both,B
2405,methods,I
2405,using,B
2405,feature,B
2405,engineering,I
2405,and,I
2405,deep,I
2405,learning,I
2405,models,I
2405,.,O
2406,Furthermore,O
2406,",",O
2406,even,O
2406,without,B
2406,combining,I
2406,additional,B
2406,features,I
2406,",",O
2406,a,O
2406,NMM,B
2406,still,O
2406,performs,B
2406,well,B
2406,for,B
2406,answer,B
2406,ranking,I
2406,",",O
2406,showing,B
2406,significant,B
2406,improvements,I
2406,over,B
2406,previous,B
2406,deep,I
2406,learning,I
2406,model,I
2406,with,B
2406,no,I
2406,additional,O
2406,features,O
2406,and,O
2406,linguistic,B
2406,feature,I
2406,engineering,I
2406,methods,I
2406,.,O
2407,Random,B
2407,Selects,B
2407,a,O
2407,random,O
2407,candidate,O
2407,;,O
2407,note,O
2407,that,O
2407,the,O
2407,number,O
2407,of,O
2407,candidates,O
2407,differs,O
2407,between,O
2407,samples,O
2407,.,O
2408,Predicts,B
2408,the,O
2408,most,B
2408,frequently,I
2408,mentioned,I
2408,candidate,I
2408,in,B
2408,the,O
2408,support,B
2408,documents,I
2409,Predicts,B
2409,the,O
2409,candidate,B
2409,c,O
2409,?,O
2410,C,O
2410,q,O
2410,that,B
2410,was,I
2410,most,B
2410,frequently,I
2410,observed,I
2410,as,B
2410,the,O
2410,true,B
2410,answer,I
2410,in,O
2410,the,O
2410,training,O
2410,set,O
2410,",",O
2410,given,O
2410,the,O
2410,query,O
2410,type,O
2410,of,O
2410,q,O
2410,.,O
2411,The,O
2411,entire,B
2411,database,I
2411,has,O
2411,been,O
2411,randomly,B
2411,split,I
2411,into,I
2411,a,O
2411,60%,B
2411,/,I
2411,20,I
2411,%,I
2411,/,O
2411,20,O
2411,%,O
2411,training,O
2411,/,O
2411,validation,O
2411,/,O
2411,test,O
2411,ratio,O
2411,.,O
2412,Retrieval,O
2412,-,O
2412,based,O
2412,models,O
2412,are,B
2412,known,B
2412,to,I
2412,be,I
2412,strong,B
2412,QA,I
2412,baselines,I
2412,if,B
2412,candidate,B
2412,answers,I
2412,are,O
2412,provided,B
2412,.,O
2413,(,O
2413,1,O
2413,),O
2413,Document,B
2413,-,I
2413,cue,I
2413,During,O
2413,dataset,O
2413,construction,O
2413,we,O
2413,observed,O
2413,that,B
2413,certain,I
2413,document,O
2413,-,O
2413,answer,O
2413,pairs,O
2413,appear,O
2413,more,O
2413,frequently,O
2413,than,O
2413,others,O
2413,",",O
2413,to,O
2413,the,O
2413,effect,B
2413,that,O
2413,the,O
2413,correct,B
2413,candidate,I
2413,is,O
2413,often,O
2413,indicated,B
2413,solely,I
2413,by,I
2413,the,O
2413,presence,B
2413,of,I
2413,certain,O
2413,documents,O
2413,in,O
2413,Sq,O
2413,.,O
2414,The,O
2414,first,O
2414,",",O
2414,WIKIHOP,B
2414,",",O
2414,uses,B
2414,sets,B
2414,of,B
2414,WIKIPEDIA,B
2414,articles,I
2414,where,B
2414,answers,B
2414,to,B
2414,queries,B
2414,about,B
2414,specific,B
2414,properties,I
2414,of,O
2414,an,O
2414,entity,B
2414,can,B
2414,not,I
2414,be,I
2414,located,I
2414,in,I
2414,the,O
2414,entity,O
2414,'s,O
2414,article,O
2414,.,O
2415,In,O
2415,the,O
2415,second,O
2415,dataset,O
2415,",",O
2415,MEDHOP,B
2415,",",O
2415,the,O
2415,goal,B
2415,is,O
2415,to,B
2415,establish,I
2415,drug,I
2415,-,I
2415,drug,O
2415,interactions,O
2415,based,B
2415,on,I
2415,scientific,B
2415,findings,I
2415,about,B
2415,drugs,B
2415,and,I
2415,proteins,I
2415,and,O
2415,their,O
2415,interactions,O
2415,",",O
2415,found,B
2415,across,I
2415,multiple,B
2415,MEDLINE,I
2415,abstracts,I
2415,.,O
2416,For,O
2416,both,O
2416,datasets,O
2416,we,O
2416,draw,B
2416,upon,I
2416,existing,B
2416,Knowledge,I
2416,Bases,I
2416,(,I
2416,KBs,I
2416,),I
2416,",",O
2416,WIKIDATA,B
2416,and,I
2416,DRUG,I
2416,-,I
2416,BANK,I
2416,",",O
2416,as,O
2416,ground,O
2416,truth,O
2416,",",O
2416,utilizing,O
2416,distant,O
2416,supervision,O
2416,),O
2416,to,O
2416,induce,O
2416,the,O
2416,data,O
2416,-,O
2416,similar,O
2416,to,O
2416,and,O
2416,.,O
2417,Constructing,O
2417,Datasets,O
2417,for,O
2417,Multi-hop,B
2417,Reading,I
2417,Comprehension,I
2417,Across,O
2417,Documents,O
2418,Most,O
2418,Reading,B
2418,Comprehension,I
2418,methods,O
2418,limit,O
2418,themselves,O
2418,to,O
2418,queries,O
2418,which,O
2418,can,O
2418,be,O
2418,answered,O
2418,using,O
2418,a,O
2418,single,O
2418,sentence,O
2418,",",O
2418,paragraph,O
2418,",",O
2418,or,O
2418,document,O
2418,.,O
2419,Contemporary,O
2419,end,O
2419,-,O
2419,to,O
2419,-,O
2419,end,O
2419,Reading,B
2419,Comprehension,I
2419,(,I
2419,RC,I
2419,),I
2419,methods,O
2419,can,O
2419,learn,O
2419,to,O
2419,extract,O
2419,the,O
2419,correct,O
2419,answer,O
2419,span,O
2419,within,O
2419,a,O
2419,given,O
2419,text,O
2419,and,O
2419,approach,O
2419,human,O
2419,-,O
2419,level,O
2419,performance,O
2419,.,O
2420,The,O
2420,Document,O
2420,-,O
2420,cue,O
2420,baseline,O
2420,can,O
2420,predict,B
2420,more,B
2420,than,I
2420,a,I
2420,third,I
2420,of,I
2420,the,O
2420,samples,O
2420,correctly,B
2420,",",O
2420,for,B
2420,both,O
2420,datasets,O
2420,",",O
2420,even,O
2420,after,B
2420,sub,I
2420,-,O
2420,sampling,O
2420,frequent,B
2420,document,O
2420,-,O
2420,answer,O
2420,pairs,O
2420,for,O
2420,WIKIHOP,B
2420,.,O
2421,Stochastic,O
2421,gradient,O
2421,descent,O
2421,with,B
2421,a,O
2421,batch,B
2421,size,I
2421,of,B
2421,500,B
2421,is,O
2421,used,O
2421,.,O
2422,Both,O
2422,neural,O
2422,RC,O
2422,models,O
2422,are,B
2422,able,B
2422,to,I
2422,largely,B
2422,retain,I
2422,or,I
2422,even,I
2422,improve,I
2422,their,O
2422,strong,B
2422,performance,I
2422,when,B
2422,answers,B
2422,are,O
2422,masked,B
2422,:,O
2422,they,O
2422,are,O
2422,able,O
2422,to,O
2422,leverage,O
2422,the,O
2422,textual,O
2422,context,O
2422,of,O
2422,the,O
2422,candidate,O
2422,expressions,O
2422,.,O
2423,In,B
2423,the,O
2423,masked,B
2423,setup,I
2423,all,B
2423,baseline,I
2423,models,I
2423,reliant,B
2423,on,I
2423,lexical,B
2423,cues,I
2423,fail,B
2423,in,O
2423,the,O
2423,face,O
2423,of,O
2423,the,O
2423,randomized,O
2423,answer,O
2423,expressions,O
2423,",",O
2423,since,O
2423,the,O
2423,same,O
2423,answer,O
2423,option,O
2423,has,O
2423,different,O
2423,placeholders,O
2423,in,O
2423,different,O
2423,samples,O
2423,.,O
2424,In,B
2424,contrast,O
2424,",",O
2424,for,B
2424,the,O
2424,open,B
2424,-,I
2424,domain,I
2424,setting,I
2424,of,B
2424,WIKIHOP,B
2424,",",O
2424,a,O
2424,reduction,B
2424,of,O
2424,the,O
2424,answer,B
2424,vocabulary,I
2424,to,I
2424,100,B
2424,random,I
2424,single,I
2424,-,O
2424,token,O
2424,mask,O
2424,expressions,O
2424,clearly,O
2424,helps,B
2424,the,O
2424,model,B
2424,in,O
2424,selecting,O
2424,a,O
2424,candidate,O
2424,span,O
2424,",",O
2424,compared,B
2424,to,O
2424,the,O
2424,multi-token,B
2424,candidate,O
2424,expressions,O
2424,in,O
2424,the,O
2424,unmasked,B
2424,setting,O
2424,.,O
2425,We,O
2425,see,B
2425,the,O
2425,full,B
2425,features,I
2425,integration,I
2425,obtain,B
2425,the,O
2425,best,B
2425,performance,I
2425,",",O
2425,which,O
2425,demonstrates,O
2425,the,O
2425,necessity,O
2425,of,O
2425,combining,O
2425,all,O
2425,the,O
2425,features,O
2425,into,O
2425,consideration,O
2425,.,O
2426,Among,B
2426,all,B
2426,the,I
2426,feature,I
2426,ablations,I
2426,",",O
2426,the,O
2426,Part,B
2426,-,I
2426,Of,I
2426,-,O
2426,Speech,O
2426,",",O
2426,Exact,B
2426,Match,I
2426,",",O
2426,Qtype,B
2426,features,I
2426,drop,B
2426,much,B
2426,more,I
2426,than,I
2426,the,O
2426,other,B
2426,features,O
2426,",",O
2426,which,O
2426,shows,O
2426,the,O
2426,importance,O
2426,of,O
2426,these,O
2426,three,O
2426,features,O
2426,.,O
2427,As,O
2427,for,O
2427,the,O
2427,final,B
2427,ablation,I
2427,of,B
2427,POS,B
2427,and,I
2427,NER,I
2427,",",O
2427,we,O
2427,can,B
2427,see,I
2427,the,O
2427,performance,B
2427,decays,I
2427,over,B
2427,3,B
2427,%,I
2427,point,I
2427,",",O
2427,which,O
2427,clearly,O
2427,proves,O
2427,the,O
2427,usefulness,O
2427,of,O
2427,the,O
2427,comprehensive,O
2427,lexical,O
2427,information,O
2427,.,O
2428,We,O
2428,first,O
2428,replace,B
2428,our,B
2428,input,I
2428,gate,I
2428,mechanism,I
2428,into,B
2428,simplified,B
2428,feature,I
2428,concatenation,I
2428,strategy,I
2428,",",O
2428,the,O
2428,performance,B
2428,drops,B
2428,nearly,B
2428,2.3,I
2428,%,I
2428,on,B
2428,the,O
2428,EM,B
2428,score,I
2428,",",O
2428,which,O
2428,proves,O
2428,the,O
2428,effectiveness,O
2428,of,O
2428,our,O
2428,proposed,O
2428,dynamic,O
2428,input,O
2428,gating,O
2428,mechanism,O
2428,.,O
2429,The,O
2429,result,B
2429,proves,O
2429,that,O
2429,our,O
2429,modification,O
2429,of,O
2429,employing,B
2429,question,B
2429,influence,I
2429,on,B
2429,the,O
2429,passage,B
2429,encoding,I
2429,can,O
2429,boost,B
2429,the,O
2429,result,O
2429,up,B
2429,to,I
2429,1.3,I
2429,%,I
2429,on,O
2429,the,O
2429,EM,B
2429,score,I
2429,.,O
2430,We,O
2430,preprocess,B
2430,each,B
2430,passage,I
2430,and,I
2430,question,I
2430,using,B
2430,the,O
2430,library,B
2430,of,I
2430,nltk,I
2430,and,O
2430,exploit,B
2430,the,O
2430,popular,B
2430,pretrained,I
2430,word,I
2430,embedding,I
2430,GloVe,I
2430,with,B
2430,100,B
2430,-,I
2430,dimensional,I
2430,vectors,I
2430,(,O
2430,Pennington,O
2430,",",O
2430,Socher,O
2430,",",O
2430,and,O
2430,Manning,O
2430,2014,O
2430,),O
2430,for,B
2430,both,O
2430,questions,B
2430,and,O
2430,passages,O
2430,.,O
2431,The,O
2431,size,B
2431,of,B
2431,char,B
2431,-,I
2431,level,I
2431,embedding,I
2431,is,O
2431,also,O
2431,set,B
2431,as,I
2431,100,B
2431,-,O
2431,dimensional,O
2431,and,O
2431,is,O
2431,obtained,B
2431,by,I
2431,CNN,B
2431,filters,I
2431,under,O
2431,the,O
2431,instruction,O
2431,of,O
2431,(,O
2431,Kim,O
2431,2014,O
2431,),O
2431,.,O
2432,Each,O
2432,model,B
2432,was,O
2432,trained,B
2432,for,I
2432,50,B
2432,epochs,I
2432,in,B
2432,the,O
2432,model,O
2432,selection,O
2432,.,O
2433,The,O
2433,batch,B
2433,size,I
2433,is,O
2433,set,B
2433,to,I
2433,be,I
2433,48,B
2433,for,B
2433,both,O
2433,the,O
2433,SQuAD,B
2433,and,I
2433,TriviaQA,I
2433,datasets,I
2433,.,O
2434,We,O
2434,adopt,B
2434,the,O
2434,AdaDelta,B
2434,(,I
2434,Zeiler,I
2434,2012,I
2434,),I
2434,optimizer,I
2434,for,B
2434,training,B
2434,with,B
2434,an,O
2434,initial,B
2434,learning,I
2434,rate,I
2434,of,B
2434,0.0005,B
2434,.,O
2435,We,O
2435,also,O
2435,apply,B
2435,dropout,O
2435,(,O
2435,Srivastava,O
2435,et,O
2435,al.,O
2436,2014,O
2436,),O
2436,between,B
2436,layers,B
2436,with,B
2436,a,O
2436,dropout,B
2436,rate,I
2436,of,B
2436,0.2,B
2436,.,O
2437,For,B
2437,the,O
2437,multi-hop,B
2437,reasoning,I
2437,",",O
2437,we,O
2437,set,B
2437,the,O
2437,number,B
2437,of,I
2437,hops,I
2437,as,B
2437,2,B
2437,which,O
2437,is,O
2437,imitating,B
2437,human,B
2437,reading,I
2437,procedure,I
2437,on,B
2437,skimming,B
2437,and,I
2437,scanning,I
2437,.,O
2438,During,B
2438,training,B
2438,",",O
2438,we,O
2438,set,B
2438,the,O
2438,moving,B
2438,averages,I
2438,of,B
2438,all,B
2438,weights,I
2438,as,B
2438,the,O
2438,exponential,B
2438,decay,I
2438,rate,I
2438,of,O
2438,0.999,B
2438,.,O
2439,In,O
2439,this,O
2439,paper,O
2439,",",O
2439,we,O
2439,propose,B
2439,the,O
2439,novel,B
2439,framework,I
2439,named,B
2439,Smarnet,B
2439,with,O
2439,the,O
2439,hope,O
2439,that,O
2439,it,O
2439,can,O
2439,become,O
2439,as,O
2439,smart,O
2439,as,O
2439,humans,O
2439,.,O
2440,Specifically,O
2440,",",O
2440,we,O
2440,first,O
2440,introduce,B
2440,the,O
2440,Smarnet,B
2440,framework,I
2440,that,O
2440,exploits,B
2440,fine,B
2440,-,I
2440,grained,I
2440,word,I
2440,understanding,I
2440,with,B
2440,various,B
2440,attribution,I
2440,discriminations,I
2440,",",O
2440,like,O
2440,humans,O
2440,recite,O
2440,words,O
2440,with,O
2440,corresponding,O
2440,properties,O
2440,.,O
2441,We,O
2441,then,O
2441,develop,B
2441,the,O
2441,interactive,B
2441,attention,I
2441,with,B
2441,memory,B
2441,network,I
2441,to,B
2441,mimic,I
2441,human,B
2441,reading,I
2441,procedure,I
2441,.,O
2442,We,O
2442,also,O
2442,add,B
2442,a,O
2442,checking,B
2442,layer,I
2442,on,B
2442,the,O
2442,answer,B
2442,refining,I
2442,in,O
2442,order,O
2442,to,B
2442,ensure,I
2442,the,O
2442,accuracy,B
2442,.,O
2443,The,O
2443,same,O
2443,considerations,O
2443,apply,B
2443,to,I
2443,the,O
2443,momentum,B
2443,",",O
2443,which,O
2443,is,O
2443,fixed,B
2443,to,O
2443,=,B
2443,0.9,I
2443,.,O
2444,Many,O
2444,existing,O
2444,approaches,O
2444,on,O
2444,MC,B
2444,task,O
2444,are,O
2444,suffering,O
2444,the,O
2444,inefficiency,O
2444,in,O
2444,some,O
2444,bottlenecks,O
2444,",",O
2444,such,O
2444,as,O
2444,insufficient,O
2444,lexical,O
2444,understanding,O
2444,",",O
2444,complex,O
2444,question,O
2444,-,O
2444,passage,O
2444,interaction,O
2444,",",O
2444,incorrect,O
2444,answer,O
2444,extraction,O
2444,and,O
2444,soon,O
2444,.,O
2445,Recently,O
2445,machine,B
2445,comprehension,I
2445,task,O
2445,accumulates,O
2445,much,O
2445,concern,O
2445,among,O
2445,NLP,O
2445,researchers,O
2445,.,O
2446,From,O
2446,the,O
2446,tables,O
2446,1,O
2446,and,O
2446,2,O
2446,we,O
2446,can,B
2446,see,I
2446,our,B
2446,single,I
2446,model,I
2446,achieves,B
2446,an,O
2446,EM,B
2446,score,I
2446,of,B
2446,71.415,B
2446,%,I
2446,and,O
2446,a,O
2446,F1,B
2446,score,O
2446,of,O
2446,80.160,B
2446,%,O
2446,and,O
2446,the,O
2446,ensemble,B
2446,model,O
2446,improves,B
2446,to,B
2446,EM,O
2446,75.989,B
2446,%,O
2446,and,O
2446,F1,O
2446,83.,O
2447,475,O
2447,%,O
2447,",",O
2447,which,O
2447,are,O
2447,both,O
2447,only,O
2447,after,O
2447,the,O
2447,r-net,O
2447,method,O
2447,at,O
2447,the,O
2447,time,O
2447,of,B
2447,submission,O
2447,.,O
2448,We,O
2448,also,O
2448,compare,O
2448,our,O
2448,models,O
2448,on,B
2448,the,O
2448,recently,O
2448,proposed,O
2448,dataset,O
2448,Trivia,O
2448,QA.,O
2449,shows,O
2449,the,O
2449,performance,O
2449,comparison,O
2449,on,B
2449,the,O
2449,test,B
2449,set,I
2449,of,B
2449,Trivia,B
2449,QA,I
2449,.,O
2450,We,O
2450,can,B
2450,see,I
2450,our,B
2450,Smarnet,I
2450,model,I
2450,outperforms,B
2450,the,O
2450,other,B
2450,baselines,I
2450,on,B
2450,both,O
2450,wikipedia,B
2450,domain,I
2450,and,O
2450,web,B
2450,domain,O
2450,.,O
2451,We,O
2451,present,O
2451,a,O
2451,new,O
2451,task,O
2451,and,O
2451,dataset,O
2451,",",O
2451,which,O
2451,we,O
2451,call,B
2451,NarrativeQA,B
2451,",",O
2451,which,O
2451,will,O
2451,test,O
2451,and,O
2451,reward,O
2451,artificial,O
2451,agents,O
2451,approaching,O
2451,this,O
2451,level,O
2451,of,O
2451,competence,O
2451,(,O
2451,Section,O
2451,3,O
2451,),O
2451,.,O
2452,The,O
2452,dataset,O
2452,consists,B
2452,of,I
2452,stories,B
2452,",",O
2452,which,B
2452,are,I
2452,books,B
2452,and,I
2452,movie,I
2452,scripts,I
2452,",",O
2452,with,B
2452,human,B
2452,written,I
2452,questions,I
2452,and,O
2452,answers,O
2452,based,B
2452,solely,I
2452,on,I
2452,human,O
2452,-,O
2452,generated,O
2452,abstractive,O
2452,summaries,O
2452,.,O
2453,For,O
2453,the,O
2453,RC,O
2453,tasks,O
2453,",",O
2453,questions,B
2453,maybe,B
2453,answered,B
2453,using,B
2453,just,O
2453,the,O
2453,summaries,B
2453,or,O
2453,the,O
2453,full,B
2453,story,I
2453,text,I
2453,.,O
2454,This,O
2454,is,O
2454,indeed,O
2454,the,O
2454,case,O
2454,",",O
2454,with,O
2454,the,O
2454,neural,B
2454,span,I
2454,prediction,I
2454,model,I
2454,significantly,B
2454,outperforming,I
2454,all,B
2454,other,I
2454,proposed,I
2454,methods,I
2454,.,O
2455,We,O
2455,propose,B
2455,a,O
2455,simple,B
2455,bi,I
2455,-,I
2455,LSTM,I
2455,based,I
2455,model,I
2455,which,B
2455,generates,I
2455,span,I
2455,representations,I
2455,for,B
2455,each,B
2455,possible,I
2455,span,O
2455,.,O
2456,The,O
2456,model,O
2456,is,O
2456,implemented,B
2456,using,I
2456,Lasagne,B
2456,4,O
2456,and,O
2456,the,O
2456,generated,B
2456,CUDA,B
2456,code,I
2456,is,O
2456,executed,B
2456,on,I
2456,a,O
2456,Tesla,B
2456,K40c,I
2456,9,O
2456,as,O
2456,training,O
2456,on,O
2456,a,O
2456,GPU,O
2456,allows,O
2456,to,O
2456,perform,O
2456,a,O
2456,comprehensive,O
2456,model,O
2456,selection,O
2456,in,O
2456,a,O
2456,feasible,O
2456,amount,O
2456,of,O
2456,time,O
2456,.,O
2457,Both,O
2457,the,O
2457,plain,O
2457,sequence,O
2457,to,O
2457,sequence,O
2457,model,O
2457,and,O
2457,the,O
2457,AS,O
2457,Reader,O
2457,",",O
2457,successfully,O
2457,applied,O
2457,to,O
2457,the,O
2457,CNN,O
2457,/,O
2457,DailyMail,O
2457,reading,O
2457,comprehension,O
2457,task,O
2457,",",O
2457,also,O
2457,perform,B
2457,well,B
2457,on,O
2457,this,O
2457,task,O
2457,.,O
2458,An,O
2458,additional,B
2458,inductive,I
2458,bias,I
2458,results,B
2458,in,I
2458,higher,B
2458,performance,I
2458,for,B
2458,the,O
2458,span,B
2458,prediction,I
2458,model,I
2458,.,O
2459,summarizes,O
2459,the,O
2459,results,O
2459,on,B
2459,the,O
2459,full,B
2459,Narra,I
2459,-,I
2459,tive,I
2459,QA,I
2459,task,I
2459,",",O
2459,where,B
2459,the,O
2459,context,B
2459,documents,I
2459,are,B
2459,full,O
2459,stories,O
2459,.,O
2460,As,O
2460,expected,O
2460,(,O
2460,and,O
2460,desired,O
2460,),O
2460,",",O
2460,we,O
2460,observe,B
2460,a,O
2460,decline,B
2460,in,B
2460,performance,B
2460,of,B
2460,the,O
2460,span-,B
2460,selection,I
2460,oracle,I
2460,IR,I
2460,model,I
2460,",",O
2460,compared,O
2460,with,O
2460,the,O
2460,results,O
2460,on,O
2460,summaries,O
2460,.,O
2461,The,O
2461,AS,B
2461,Reader,I
2461,",",O
2461,which,O
2461,was,O
2461,the,O
2461,better,O
2461,-,O
2461,performing,O
2461,model,O
2461,on,O
2461,the,O
2461,summaries,O
2461,task,O
2461,",",O
2461,underperforms,B
2461,the,O
2461,simple,B
2461,no,I
2461,-context,I
2461,Seq2Seq,I
2461,baseline,I
2461,(,O
2461,shown,O
2461,in,B
2461,),O
2461,in,O
2461,terms,O
2461,of,O
2461,MRR,B
2461,.,O
2462,As,O
2462,with,O
2462,the,O
2462,AS,O
2462,Reader,O
2462,",",O
2462,we,O
2462,observed,B
2462,no,B
2462,significant,I
2462,differences,I
2462,for,B
2462,varying,B
2462,number,B
2462,of,I
2462,chunks,I
2462,.,O
2463,The,O
2463,NarrativeQA,O
2463,Reading,B
2463,Comprehension,I
2463,Challenge,O
2464,Question,O
2464,answering,O
2464,is,O
2464,conventionally,O
2464,used,O
2464,to,O
2464,assess,O
2464,RC,B
2464,ability,O
2464,",",O
2464,in,O
2464,both,O
2464,artificial,O
2464,agents,O
2464,and,O
2464,children,O
2464,learning,O
2464,to,O
2464,read,O
2464,.,O
2465,contains,B
2465,the,O
2465,four,B
2465,parameters,I
2465,to,B
2465,be,I
2465,optimized,B
2465,:,O
2465,the,O
2465,number,B
2465,of,I
2465,convolutions,I
2465,",",O
2465,the,O
2465,number,O
2465,of,O
2465,hidden,O
2465,layers,O
2465,",",O
2465,the,O
2465,number,O
2465,of,O
2465,units,O
2465,per,O
2465,hidden,O
2465,layer,O
2465,and,O
2465,the,O
2465,dropout,B
2465,factor,I
2465,.,O
2466,RUM,B
2466,utilizes,B
2466,a,O
2466,different,B
2466,representation,I
2466,of,I
2466,memory,I
2466,that,B
2466,outperforms,B
2466,those,B
2466,of,O
2466,LSTM,B
2466,and,I
2466,GRU,I
2466,;,O
2466,2,O
2466,.,O
2467,RUM,B
2467,solves,B
2467,the,O
2467,task,B
2467,completely,B
2467,",",O
2467,despite,O
2467,its,O
2467,update,O
2467,gate,O
2467,",",O
2467,which,O
2467,does,O
2467,not,O
2467,allow,O
2467,all,O
2467,of,O
2467,the,O
2467,information,O
2467,encoded,O
2467,in,O
2467,the,O
2467,hidden,O
2467,stay,O
2467,to,O
2467,pass,O
2467,through,O
2467,.,O
2468,All,O
2468,the,O
2468,models,O
2468,have,B
2468,the,O
2468,same,B
2468,hidden,I
2468,state,I
2468,N,I
2468,h,I
2468,=,I
2468,50,I
2468,for,B
2468,different,B
2468,lengths,I
2468,T,I
2468,.,O
2469,We,O
2469,use,B
2469,a,O
2469,batch,B
2469,size,I
2469,128,B
2469,.,O
2470,The,O
2470,optimizer,B
2470,is,B
2470,RMSProp,B
2470,with,B
2470,a,O
2470,learning,B
2470,rate,I
2470,0.001,B
2470,.,O
2471,We,O
2471,find,B
2471,that,I
2471,LSTM,B
2471,fails,B
2471,to,B
2471,learn,I
2471,the,O
2471,task,B
2471,",",O
2471,because,O
2471,of,B
2471,its,O
2471,lack,O
2471,of,O
2471,sufficient,O
2471,memory,O
2471,capacity,O
2471,.,O
2472,NTM,O
2472,and,O
2472,Fast,O
2472,-,O
2472,weight,O
2472,RNN,O
2472,fail,B
2472,longer,B
2472,tasks,I
2472,",",O
2472,which,O
2472,means,O
2472,they,O
2472,can,O
2472,not,O
2472,learn,O
2472,to,O
2472,manipulate,O
2472,their,O
2472,memory,O
2472,efficiently,O
2472,.,O
2473,We,O
2473,compare,O
2473,our,O
2473,model,O
2473,with,O
2473,several,O
2473,baselines,O
2473,:,O
2473,a,O
2473,simple,B
2473,LSTM,I
2473,",",O
2473,an,O
2473,End,O
2473,-,O
2473,to,O
2473,-,O
2473,end,O
2473,Memory,O
2473,Network,O
2473,),O
2473,and,O
2473,a,O
2473,GORU,B
2473,.,O
2474,The,O
2474,input,B
2474,images,I
2474,are,O
2474,fed,B
2474,into,I
2474,a,I
2474,convolution,B
2474,comprising,B
2474,a,O
2474,convolutional,B
2474,and,I
2474,a,O
2474,subsampling,O
2474,layer,O
2474,.,O
2475,We,O
2475,find,B
2475,that,I
2475,RUM,B
2475,outperforms,B
2475,significantly,I
2475,LSTM,B
2475,and,I
2475,GORU,I
2475,and,O
2475,achieves,B
2475,competitive,B
2475,result,I
2475,with,B
2475,those,B
2475,of,I
2475,MemN2N,I
2475,",",O
2475,which,O
2475,has,O
2475,an,O
2475,attention,B
2475,mechanism,I
2475,.,O
2476,FS,O
2476,-,O
2476,RUM,O
2476,-,O
2476,2,O
2476,generalizes,B
2476,better,I
2476,than,B
2476,other,B
2476,gated,I
2476,models,I
2476,",",O
2476,such,B
2476,as,I
2476,GRU,B
2476,and,I
2476,LSTM,I
2476,",",O
2476,because,O
2476,it,O
2476,learns,O
2476,efficient,O
2476,patterns,O
2476,for,O
2476,activation,O
2476,in,O
2476,its,O
2476,kernels,O
2476,.,O
2477,Here,O
2477,",",O
2477,we,O
2477,propose,B
2477,a,O
2477,novel,B
2477,RNN,I
2477,cell,I
2477,that,O
2477,resolves,B
2477,simultaneously,I
2477,those,O
2477,weaknesses,B
2477,of,B
2477,basic,B
2477,RNN,O
2477,.,O
2478,The,O
2478,Rotational,B
2478,Unit,I
2478,of,I
2478,Memory,I
2478,is,B
2478,a,O
2478,modified,B
2478,gated,I
2478,model,I
2478,whose,B
2478,rotational,O
2478,operation,O
2478,acts,B
2478,as,I
2478,associative,B
2478,memory,O
2478,and,O
2478,is,O
2478,strictly,O
2478,an,O
2478,orthogonal,B
2478,matrix,I
2478,.,O
2479,The,O
2479,concepts,O
2479,of,O
2479,unitary,O
2479,evolution,O
2479,matrices,O
2479,and,O
2479,associative,O
2479,memory,O
2479,have,O
2479,boosted,O
2479,the,O
2479,field,O
2479,of,O
2479,Recurrent,B
2479,Neural,I
2479,Networks,I
2479,(,I
2479,RNN,I
2479,),I
2479,to,O
2479,state,O
2479,-,O
2479,of,O
2479,-,O
2479,the,O
2479,-,O
2479,art,O
2479,performance,O
2479,in,O
2479,a,O
2479,variety,O
2479,of,O
2479,sequential,O
2479,tasks,O
2479,.,O
2480,However,O
2480,",",O
2480,RNN,B
2480,still,O
2480,have,O
2480,a,O
2480,limited,O
2480,capacity,O
2480,to,O
2480,manipulate,O
2480,long,O
2480,-,O
2480,term,O
2480,memory,O
2480,.,O
2481,applied,B
2481,BiDAF,B
2481,++,I
2481,",",O
2481,a,O
2481,strong,B
2481,extractive,I
2481,QA,I
2481,model,I
2481,to,B
2481,QuAC,B
2481,dataset,I
2481,.,O
2482,Here,O
2482,we,O
2482,briefly,O
2482,describe,O
2482,the,O
2482,ablated,O
2482,systems,O
2482,:,O
2482,"""",O
2482,-,B
2482,FLOW,B
2482,"""",O
2482,removes,B
2482,the,O
2482,flow,O
2482,component,O
2482,from,B
2482,IF,B
2482,layer,I
2482,(,O
2482,Eq.,O
2483,2,O
2483,in,O
2483,Section,O
2483,3.2,O
2483,),O
2483,",",O
2483,"""",O
2483,-,O
2483,QHIER,O
2483,-,O
2483,RNN,O
2483,"""",O
2483,removes,B
2483,the,O
2483,hierarchical,B
2483,LSTM,I
2483,layers,I
2483,on,B
2483,final,B
2483,question,I
2483,vectors,I
2483,(,O
2483,Eq.,O
2484,That,O
2484,convolution,B
2484,maybe,O
2484,followed,B
2484,by,I
2484,more,B
2484,convolutions,I
2484,to,B
2484,become,I
2484,gradually,O
2484,more,O
2484,invariant,O
2484,to,O
2484,distortions,B
2484,in,B
2484,the,O
2484,input,B
2484,.,O
2485,We,O
2485,present,B
2485,FLOWQA,B
2485,",",O
2485,a,O
2485,model,O
2485,designed,B
2485,for,I
2485,conversational,B
2485,machine,I
2485,comprehension,I
2485,.,O
2486,FLOWQA,B
2486,consists,B
2486,of,I
2486,two,B
2486,main,I
2486,components,I
2486,:,O
2486,a,O
2486,base,B
2486,neural,I
2486,model,I
2486,for,B
2486,single,B
2486,-,I
2486,turn,I
2486,MC,I
2486,and,O
2486,a,O
2486,FLOW,B
2486,mechanism,I
2486,that,O
2486,encodes,B
2486,the,O
2486,conversation,B
2486,history,I
2486,.,O
2487,This,O
2487,FLOW,B
2487,mechanism,I
2487,is,B
2487,also,O
2487,remarkably,B
2487,effective,I
2487,at,B
2487,tracking,I
2487,the,O
2487,world,B
2487,states,I
2487,for,B
2487,sequential,B
2487,instruction,I
2487,understanding,I
2487,(,O
2487,Long,O
2487,et,O
2487,al.,O
2488,",",O
2488,2016,O
2488,),O
2488,:,O
2488,after,O
2488,mapping,O
2488,world,B
2488,states,I
2488,as,O
2488,context,O
2488,and,O
2488,instructions,O
2488,as,O
2488,questions,O
2488,",",O
2488,FLOWQA,O
2488,can,O
2488,interpret,O
2488,a,O
2488,sequence,O
2488,of,O
2488,inter-connected,O
2488,instructions,O
2488,and,O
2488,generate,O
2488,corresponding,O
2488,world,O
2488,state,O
2488,changes,O
2488,as,O
2488,answers,O
2488,.,O
2489,The,O
2489,FLOW,O
2489,mechanism,O
2489,can,B
2489,be,I
2489,viewed,B
2489,as,B
2489,stacking,B
2489,single,I
2489,-,I
2489,turn,I
2489,QA,I
2489,models,I
2489,along,B
2489,the,O
2489,dialog,B
2489,progression,I
2489,(,O
2489,i.e.,O
2490,",",O
2490,the,O
2490,question,O
2490,turns,O
2490,),O
2490,and,O
2490,building,B
2490,information,B
2490,flow,I
2490,along,B
2490,the,O
2490,dialog,B
2490,.,O
2491,This,O
2491,information,O
2491,transfer,O
2491,happens,B
2491,for,I
2491,each,B
2491,context,I
2491,word,I
2491,",",O
2491,allowing,B
2491,rich,B
2491,information,O
2491,in,B
2491,the,O
2491,reasoning,B
2491,process,I
2491,to,B
2491,flow,B
2491,.,O
2492,Instead,O
2492,of,B
2492,using,O
2492,the,O
2492,shallow,O
2492,history,O
2492,",",O
2492,i.e.,O
2493,",",O
2493,previous,O
2493,questions,O
2493,and,O
2493,answers,O
2493,",",O
2493,we,O
2493,feed,B
2493,the,O
2493,model,O
2493,with,O
2493,the,O
2493,entire,B
2493,hidden,I
2493,representations,I
2493,generated,B
2493,during,I
2493,the,O
2493,process,B
2493,of,B
2493,answering,B
2493,previous,O
2493,questions,O
2493,.,O
2494,To,O
2494,handle,O
2494,this,O
2494,issue,O
2494,",",O
2494,we,O
2494,propose,B
2494,an,O
2494,alternating,B
2494,parallel,I
2494,processing,I
2494,structure,I
2494,",",O
2494,which,B
2494,alternates,B
2494,between,B
2494,sequentially,B
2494,processing,O
2494,one,B
2494,dimension,I
2494,in,B
2494,parallel,O
2494,of,O
2494,the,O
2494,other,B
2494,dimension,O
2494,",",O
2494,and,O
2494,thus,O
2494,speeds,B
2494,up,I
2494,training,B
2494,significantly,B
2494,.,O
2495,FLOWQA,O
2495,:,O
2495,GRASPING,O
2495,FLOW,O
2495,IN,O
2495,HISTORY,O
2495,FOR,O
2495,CONVERSATIONAL,B
2495,MACHINE,I
2495,COMPREHENSION,I
2496,Recently,O
2496,proposed,O
2496,conversational,B
2496,machine,I
2496,comprehension,I
2496,(,I
2496,MC,I
2496,),I
2496,datasets,O
2496,aim,O
2496,to,O
2496,enable,O
2496,models,O
2496,to,O
2496,assist,O
2496,in,O
2496,such,O
2496,information,O
2496,seeking,O
2496,dialogs,O
2496,.,O
2497,The,O
2497,novelty,B
2497,of,I
2497,this,O
2497,approach,O
2497,is,B
2497,that,O
2497,the,O
2497,exact,B
2497,number,I
2497,of,O
2497,convolutions,O
2497,",",O
2497,number,O
2497,of,O
2497,hidden,O
2497,layers,O
2497,and,O
2497,size,O
2497,of,O
2497,hidden,O
2497,layers,O
2497,are,B
2497,not,B
2497,fixed,I
2497,but,O
2497,subject,B
2497,to,I
2497,extensive,O
2497,model,B
2497,selection,I
2497,in,O
2497,Sec.,O
2498,FLOWQA,B
2498,yields,B
2498,substantial,B
2498,improvement,I
2498,over,B
2498,existing,B
2498,models,I
2498,on,B
2498,both,B
2498,datasets,I
2498,(,O
2498,+,B
2498,7.2,I
2498,%,I
2498,F,I
2498,1,I
2498,on,O
2498,CoQA,B
2498,",",O
2498,+,O
2498,4.0,O
2498,%,O
2498,F,O
2498,1,O
2498,on,O
2498,QuAC,B
2498,),O
2498,.,O
2499,We,O
2499,find,B
2499,that,I
2499,FLOW,B
2499,is,B
2499,a,O
2499,critical,B
2499,component,I
2499,.,O
2500,Removing,B
2500,QHier,B
2500,-,I
2500,RNN,I
2500,has,O
2500,a,O
2500,minor,B
2500,impact,I
2500,(,O
2500,0.1,B
2500,%,I
2500,on,B
2500,both,B
2500,datasets,I
2500,),O
2500,",",O
2500,while,O
2500,removing,O
2500,FLOW,B
2500,results,B
2500,in,I
2500,a,O
2500,substantial,B
2500,performance,I
2500,drop,I
2500,",",O
2500,with,B
2500,or,I
2500,without,I
2500,using,I
2500,QHierRNN,B
2500,(,O
2500,2,B
2500,-,O
2500,3,O
2500,%,O
2500,on,O
2500,QuAC,B
2500,",",O
2500,4.1,B
2500,%,O
2500,on,O
2500,CoQA,B
2500,),O
2500,.,O
2501,By,O
2501,comparing,B
2501,0,B
2501,-,I
2501,Ans,I
2501,and,I
2501,1,I
2501,-,O
2501,Ans,O
2501,on,B
2501,two,B
2501,datasets,I
2501,",",O
2501,we,O
2501,can,O
2501,see,O
2501,that,O
2501,providing,B
2501,gold,B
2501,answers,I
2501,is,B
2501,more,B
2501,crucial,I
2501,for,B
2501,QuAC,B
2501,.,O
2502,Based,O
2502,on,B
2502,the,O
2502,training,B
2502,time,I
2502,each,B
2502,epoch,I
2502,takes,B
2502,(,O
2502,i.e.,O
2503,",",O
2503,time,O
2503,needed,O
2503,for,O
2503,passing,O
2503,through,O
2503,the,O
2503,data,O
2503,once,O
2503,),O
2503,",",O
2503,the,O
2503,speedup,B
2503,is,B
2503,8.1x,B
2503,on,B
2503,CoQA,B
2503,and,O
2503,4.2,B
2503,x,I
2503,on,O
2503,QuAC,B
2503,.,O
2504,In,O
2504,this,O
2504,paper,O
2504,",",O
2504,we,O
2504,improve,O
2504,the,O
2504,model,O
2504,of,O
2504,by,O
2504,providing,B
2504,the,O
2504,ability,B
2504,to,B
2504,answer,I
2504,more,B
2504,complicated,I
2504,questions,I
2504,.,O
2505,s,O
2505,The,O
2505,main,O
2505,contributions,O
2505,of,B
2505,the,O
2505,paper,O
2505,are,O
2505,:,O
2505,(,O
2505,1,O
2505,),O
2505,a,O
2505,more,B
2505,sophisticated,I
2505,inference,I
2505,procedure,I
2505,that,O
2505,is,B
2505,both,O
2505,efficient,B
2505,and,O
2505,can,O
2505,consider,B
2505,longer,B
2505,paths,I
2505,(,O
2505,considered,O
2505,only,O
2505,answers,B
2505,directly,O
2505,connected,O
2505,to,O
2505,the,O
2505,question,B
2505,in,O
2505,the,O
2505,graph,O
2505,),O
2505,;,O
2505,and,O
2505,(,O
2505,2,O
2505,),O
2505,a,O
2505,richer,B
2505,representation,I
2505,of,O
2505,the,O
2505,answers,O
2505,which,O
2505,encodes,B
2505,the,O
2505,question,O
2505,-,O
2505,answer,O
2505,path,O
2505,and,O
2505,surrounding,B
2505,subgraph,I
2505,of,O
2505,the,O
2505,KB,B
2505,.,O
2506,This,O
2506,paper,O
2506,presents,O
2506,a,O
2506,system,O
2506,which,O
2506,learns,O
2506,to,O
2506,answer,B
2506,questions,I
2506,on,I
2506,a,O
2506,broad,O
2506,range,O
2506,of,O
2506,topics,O
2506,from,O
2506,a,O
2506,knowledge,O
2506,base,O
2506,using,O
2506,few,O
2506,handcrafted,O
2506,features,O
2506,.,O
2507,Teaching,O
2507,machines,O
2507,how,O
2507,to,O
2507,automatically,B
2507,answer,I
2507,questions,I
2507,asked,I
2507,in,I
2507,natural,I
2507,language,I
2507,on,I
2507,any,I
2507,topic,I
2507,or,I
2507,in,O
2507,any,O
2507,domain,O
2507,has,O
2507,always,O
2507,been,O
2507,along,O
2507,standing,O
2507,goal,O
2507,in,O
2507,Artificial,O
2507,Intelligence,O
2507,.,O
2508,In,B
2508,the,O
2508,second,B
2508,stage,I
2508,",",O
2508,a,O
2508,regular,B
2508,neural,I
2508,network,I
2508,follows,B
2508,the,O
2508,convolutions,B
2508,in,O
2508,order,O
2508,to,B
2508,discriminate,I
2508,the,O
2508,features,B
2508,learned,B
2508,by,I
2508,the,O
2508,convolutions,O
2508,.,O
2509,These,O
2509,KBs,O
2509,",",O
2509,such,O
2509,as,O
2509,Freebase,O
2509,encompass,O
2509,huge,O
2509,ever,O
2509,growing,O
2509,amounts,O
2509,of,O
2509,information,O
2509,and,O
2509,ease,O
2509,open,B
2509,QA,I
2509,by,O
2509,organizing,O
2509,a,O
2509,great,O
2509,variety,O
2509,of,O
2509,answers,O
2509,in,O
2509,a,O
2509,structured,O
2509,format,O
2509,.,O
2510,Replacing,B
2510,C,B
2510,2,I
2510,by,B
2510,C,O
2510,1,O
2510,induces,B
2510,a,O
2510,large,B
2510,drop,I
2510,in,B
2510,performance,B
2510,because,O
2510,many,O
2510,questions,O
2510,do,O
2510,not,O
2510,have,O
2510,answers,O
2510,that,O
2510,are,O
2510,directly,O
2510,connected,O
2510,to,O
2510,their,O
2510,inluded,O
2510,entity,O
2510,(,O
2510,not,O
2510,in,O
2510,C,O
2510,1,O
2510,),O
2510,.,O
2511,However,O
2511,",",O
2511,using,B
2511,all,B
2511,2,I
2511,-,I
2511,hops,I
2511,connections,I
2511,as,B
2511,a,O
2511,candidate,B
2511,set,I
2511,is,B
2511,also,O
2511,detrimental,B
2511,",",O
2511,because,O
2511,the,O
2511,larger,O
2511,number,O
2511,of,O
2511,candidates,O
2511,confuses,O
2511,(,O
2511,and,O
2511,slows,O
2511,a,O
2511,lot,O
2511,),O
2511,our,O
2511,ranking,O
2511,based,O
2511,inference,O
2511,.,O
2512,Our,O
2512,results,O
2512,also,O
2512,verify,B
2512,our,O
2512,hypothesis,B
2512,of,O
2512,Section,O
2512,3.1,O
2512,",",O
2512,that,B
2512,a,O
2512,richer,B
2512,representation,I
2512,for,B
2512,answers,B
2512,(,O
2512,using,O
2512,the,O
2512,local,O
2512,subgraph,O
2512,),O
2512,can,O
2512,store,B
2512,more,B
2512,pertinent,I
2512,information,I
2512,.,O
2513,Finally,O
2513,",",O
2513,we,O
2513,demonstrate,B
2513,that,O
2513,we,O
2513,greatly,B
2513,improve,I
2513,upon,B
2513,the,O
2513,model,B
2513,of,O
2513,",",O
2513,which,O
2513,actually,O
2513,corresponds,B
2513,to,I
2513,a,O
2513,setting,B
2513,with,B
2513,the,O
2513,Path,B
2513,representation,I
2513,and,O
2513,C,B
2513,1,I
2513,as,B
2513,candidate,B
2513,set,I
2513,.,O
2514,The,O
2514,ensemble,B
2514,improves,B
2514,the,O
2514,state,B
2514,-,I
2514,of,I
2514,-,O
2514,the,O
2514,-,O
2514,art,O
2514,",",O
2514,and,O
2514,indicates,O
2514,that,O
2514,our,O
2514,models,O
2514,are,O
2514,significantly,O
2514,different,O
2514,in,O
2514,their,O
2514,design,O
2514,.,O
2515,We,O
2515,were,O
2515,notable,O
2515,to,O
2515,achieve,B
2515,good,B
2515,convergence,I
2515,with,B
2515,deeper,B
2515,models,I
2515,.,O
2516,It,O
2516,can,O
2516,be,O
2516,seen,B
2516,that,I
2516,all,B
2516,tasks,I
2516,benefit,B
2516,from,I
2516,deeper,B
2516,models,I
2516,",",O
2516,in,O
2516,particular,O
2516,XNLI,O
2516,and,O
2516,Tatoeba,O
2516,",",O
2516,suggesting,O
2516,that,O
2516,a,O
2516,single,O
2516,layer,O
2516,BiLSTM,O
2516,has,O
2516,not,O
2516,enough,O
2516,capacity,O
2516,to,O
2516,encode,O
2516,so,O
2516,many,O
2516,languages,O
2516,.,O
2517,The,O
2517,output,B
2517,layer,I
2517,consists,B
2517,of,I
2517,two,B
2517,units,I
2517,for,B
2517,smile,I
2517,or,I
2517,no,I
2517,smile,O
2517,.,O
2518,As,O
2518,shown,O
2518,in,B
2518,",",O
2518,the,O
2518,NLI,O
2518,objective,O
2518,leads,B
2518,to,I
2518,a,O
2518,better,B
2518,performance,I
2518,on,B
2518,the,O
2518,English,B
2518,NLI,O
2518,test,O
2518,set,O
2518,",",O
2518,but,O
2518,this,O
2518,comes,B
2518,at,I
2518,the,O
2518,cost,B
2518,of,B
2518,a,O
2518,worse,B
2518,cross,I
2518,-,I
2518,lingual,I
2518,transfer,I
2518,performance,O
2518,in,O
2518,XNLI,B
2518,and,I
2518,Tatoeba,I
2518,.,O
2519,Our,O
2519,implementation,O
2519,",",O
2519,the,O
2519,pretrained,O
2519,encoder,O
2519,and,O
2519,the,O
2519,multilingual,O
2519,test,O
2519,set,O
2519,are,O
2519,available,O
2519,at,O
2519,https://github.com,B
2519,/,I
2519,facebookresearch/LASER,I
2519,.,O
2520,9,O
2520,Our,B
2520,proposed,I
2520,method,I
2520,obtains,B
2520,the,O
2520,best,B
2520,results,I
2520,in,B
2520,zero,B
2520,-,I
2520,shot,I
2520,cross,I
2520,-,O
2520,lingual,O
2520,transfer,O
2520,for,B
2520,all,B
2520,languages,I
2520,but,I
2520,Spanish,I
2520,.,O
2521,Moreover,O
2521,",",O
2521,our,O
2521,transfer,B
2521,results,I
2521,are,B
2521,strong,B
2521,and,I
2521,homogeneous,I
2521,across,B
2521,all,B
2521,languages,I
2521,:,O
2522,for,O
2522,11,O
2522,of,O
2522,them,O
2522,",",O
2522,the,O
2522,zero,B
2522,-,I
2522,short,I
2522,performance,I
2522,is,B
2522,(,B
2522,at,I
2522,most,I
2522,),I
2522,5,I
2522,%,I
2522,lower,I
2522,than,B
2522,the,O
2522,one,O
2522,on,B
2522,English,B
2522,",",O
2522,including,B
2522,distant,B
2522,languages,I
2522,like,B
2522,Arabic,B
2522,",",O
2522,Chinese,O
2522,and,O
2522,Vietnamese,O
2522,",",O
2522,and,O
2522,we,O
2522,also,O
2522,achieve,B
2522,remarkable,B
2522,good,I
2522,results,I
2522,on,O
2522,low,B
2522,-,O
2522,resource,O
2522,languages,O
2522,like,O
2522,Swahili,B
2522,.,O
2523,10,O
2523,Finally,O
2523,",",O
2523,we,O
2523,also,O
2523,outperform,B
2523,all,B
2523,baselines,I
2523,of,O
2523,Conneau,O
2523,et,O
2523,al.,O
2524,by,B
2524,a,O
2524,substantial,B
2524,margin,I
2524,",",O
2524,with,O
2524,the,O
2524,additional,O
2524,advantage,O
2524,that,O
2524,we,O
2524,use,O
2524,a,O
2524,single,O
2524,pre-trained,O
2524,encoder,O
2524,",",O
2524,whereas,O
2524,X,O
2524,-,O
2524,BiLSTM,O
2524,learns,O
2524,a,O
2524,separate,O
2524,encoder,O
2524,for,O
2524,each,O
2524,language,O
2524,.,O
2525,As,O
2525,shown,O
2525,in,O
2525,",",O
2525,our,B
2525,system,I
2525,obtains,B
2525,the,I
2525,best,B
2525,published,I
2525,results,I
2525,for,B
2525,5,B
2525,of,I
2525,the,O
2525,7,O
2525,transfer,O
2525,languages,O
2525,.,O
2526,Deep,O
2526,Learning,O
2526,For,O
2526,Smile,B
2526,Recognition,I
2527,As,O
2527,shown,O
2527,in,O
2527,",",O
2527,our,B
2527,system,I
2527,establishes,B
2527,a,O
2527,new,B
2527,state,I
2527,-,I
2527,of,I
2527,-,O
2527,the,O
2527,-,O
2527,art,O
2527,for,B
2527,all,B
2527,language,I
2527,pairs,I
2527,with,B
2527,the,O
2527,exception,O
2527,of,O
2527,English,B
2527,-,O
2527,Chinese,O
2527,test,O
2527,.,O
2528,We,O
2528,also,O
2528,outperform,B
2528,Artetxe,B
2528,and,I
2528,Schwenk,I
2528,(,I
2528,2018,I
2528,),I
2528,themselves,O
2528,",",O
2528,who,O
2528,use,O
2528,two,O
2528,separate,O
2528,models,O
2528,covering,O
2528,4,O
2528,languages,O
2528,each,O
2528,.,O
2529,Contrasting,O
2529,these,O
2529,results,O
2529,with,B
2529,those,O
2529,of,O
2529,XNLI,O
2529,",",O
2529,one,O
2529,would,O
2529,assume,O
2529,that,O
2529,similarity,B
2529,error,I
2529,rates,I
2529,below,B
2529,5,I
2529,%,I
2529,are,B
2529,indicative,O
2529,of,O
2529,strong,O
2529,downstream,O
2529,performance,O
2529,.,O
2530,11,O
2530,This,O
2530,is,O
2530,the,O
2530,case,O
2530,for,B
2530,37,B
2530,languages,I
2530,",",O
2530,while,O
2530,there,O
2530,are,O
2530,48,B
2530,languages,O
2530,with,B
2530,an,O
2530,error,B
2530,rate,I
2530,below,B
2530,10,I
2530,%,I
2530,and,O
2530,55,B
2530,with,O
2530,less,B
2530,than,I
2530,20,I
2530,%,O
2530,.,O
2531,There,O
2531,are,O
2531,only,O
2531,15,B
2531,languages,I
2531,with,B
2531,error,I
2531,rates,I
2531,above,B
2531,50,I
2531,%,I
2531,.,O
2532,In,O
2532,this,O
2532,work,O
2532,",",O
2532,we,O
2532,are,O
2532,interested,O
2532,in,O
2532,universal,B
2532,language,I
2532,agnostic,I
2532,sentence,I
2532,embeddings,I
2532,",",O
2532,that,B
2532,is,I
2532,",",O
2532,vector,B
2532,representations,I
2532,of,B
2532,sentences,B
2532,that,O
2532,are,O
2532,general,B
2532,with,B
2532,respect,I
2532,to,I
2532,two,B
2532,dimensions,I
2532,:,O
2532,the,O
2532,input,B
2532,language,O
2532,and,O
2532,the,O
2532,NLP,B
2532,task,I
2532,.,O
2533,To,O
2533,that,O
2533,end,O
2533,",",O
2533,we,O
2533,train,B
2533,a,O
2533,single,B
2533,encoder,I
2533,to,O
2533,handle,O
2533,multiple,B
2533,languages,I
2533,",",O
2533,so,O
2533,that,O
2533,semantically,O
2533,similar,O
2533,sentences,O
2533,in,O
2533,different,O
2533,languages,O
2533,are,O
2533,close,O
2533,in,O
2533,the,O
2533,embedding,O
2533,space,O
2533,.,O
2534,We,O
2534,introduce,O
2534,an,O
2534,architecture,O
2534,to,O
2534,learn,O
2534,joint,B
2534,multilingual,I
2534,sentence,I
2534,representations,I
2534,for,O
2534,93,O
2534,languages,O
2534,",",O
2534,belonging,O
2534,to,O
2534,more,O
2534,than,O
2534,30,O
2534,different,O
2534,families,O
2534,and,O
2534,written,O
2534,in,O
2534,28,O
2534,different,O
2534,scripts,O
2534,.,O
2535,Inspired,O
2535,by,O
2535,recent,O
2535,successes,O
2535,of,O
2535,deep,O
2535,learning,O
2535,in,O
2535,computer,O
2535,vision,O
2535,",",O
2535,we,O
2535,propose,O
2535,a,O
2535,novel,O
2535,application,O
2535,of,O
2535,deep,O
2535,convolutional,O
2535,neural,O
2535,networks,O
2535,to,O
2535,facial,B
2535,expression,I
2535,recognition,I
2535,",",O
2535,in,O
2535,particular,O
2535,smile,O
2535,recognition,O
2535,.,O
2536,We,O
2536,built,B
2536,ASNQ,B
2536,",",O
2536,a,O
2536,dataset,O
2536,for,B
2536,AS2,B
2536,",",O
2536,by,B
2536,transforming,I
2536,the,O
2536,recently,B
2536,released,I
2536,Natural,I
2536,Questions,I
2536,(,I
2536,NQ,I
2536,),I
2536,corpus,I
2536,),O
2536,from,B
2536,MR,B
2536,to,B
2536,AS2,O
2536,task,O
2536,.,O
2537,We,O
2537,adopt,B
2537,Adam,B
2537,optimizer,I
2537,(,O
2537,Kingma,O
2537,and,O
2537,Ba,O
2537,2014,O
2537,),O
2537,with,B
2537,a,O
2537,learning,B
2537,rate,I
2537,of,B
2537,2e,B
2537,-,I
2537,5,I
2537,for,B
2537,the,O
2537,transfer,B
2537,step,I
2537,on,B
2537,the,O
2537,ASNQ,B
2537,dataset,I
2537,and,O
2537,a,O
2537,learning,O
2537,rate,O
2537,of,O
2537,1e,B
2537,-,O
2537,6,O
2537,for,O
2537,the,O
2537,adapt,B
2537,step,O
2537,on,O
2537,the,O
2537,target,B
2537,dataset,O
2537,.,O
2538,We,O
2538,apply,B
2538,early,B
2538,stopping,I
2538,on,B
2538,the,O
2538,dev.,O
2539,set,O
2539,of,B
2539,the,O
2539,target,B
2539,corpus,I
2539,for,O
2539,both,O
2539,steps,O
2539,based,O
2539,on,B
2539,the,O
2539,highest,O
2539,MAP,O
2539,score,O
2539,.,O
2540,We,O
2540,set,B
2540,the,O
2540,max,B
2540,number,I
2540,of,I
2540,epochs,I
2540,equal,B
2540,to,I
2540,3,B
2540,and,I
2540,9,I
2540,for,B
2540,adapt,B
2540,and,O
2540,transfer,O
2540,steps,O
2540,",",O
2540,respectively,O
2540,.,O
2541,We,O
2541,set,O
2541,the,O
2541,maximum,B
2541,sequence,I
2541,length,I
2541,for,B
2541,BERT,B
2541,/,I
2541,RoBERTa,I
2541,to,B
2541,128,B
2541,tokens,I
2541,.,O
2542,In,O
2542,this,O
2542,paper,O
2542,",",O
2542,we,O
2542,study,B
2542,the,O
2542,use,O
2542,of,B
2542,Transformer,B
2542,-,I
2542,based,I
2542,models,I
2542,for,B
2542,AS2,B
2542,and,O
2542,provide,B
2542,effective,B
2542,solutions,I
2542,to,B
2542,tackle,I
2542,the,O
2542,data,B
2542,scarceness,I
2542,problem,I
2542,for,O
2542,AS2,O
2542,and,O
2542,the,O
2542,instability,B
2542,of,O
2542,the,O
2542,finetuning,B
2542,step,I
2542,.,O
2543,We,O
2543,improve,B
2543,stability,B
2543,of,B
2543,Transformer,B
2543,models,I
2543,by,B
2543,adding,I
2543,an,O
2543,intermediate,B
2543,fine,I
2543,-,I
2543,tuning,I
2543,step,I
2543,",",O
2543,which,O
2543,aims,B
2543,at,I
2543,specializing,B
2543,them,O
2543,to,B
2543,the,O
2543,target,B
2543,task,I
2543,(,I
2543,AS2,I
2543,),I
2543,",",O
2543,i.e.,O
2544,",",O
2544,this,O
2544,step,O
2544,transfers,O
2544,a,O
2544,pretrained,O
2544,language,O
2544,model,O
2544,to,B
2544,a,O
2544,model,O
2544,for,O
2544,the,O
2544,target,O
2544,task,O
2544,.,O
2545,We,O
2545,show,B
2545,that,O
2545,the,O
2545,transferred,B
2545,model,I
2545,can,B
2545,be,I
2545,effectively,B
2545,adapted,I
2545,to,B
2545,the,O
2545,target,B
2545,domain,I
2545,with,B
2545,a,O
2545,subsequent,B
2545,finetuning,I
2545,step,I
2545,",",O
2545,even,O
2545,when,B
2545,using,I
2545,target,O
2545,data,O
2545,of,B
2545,small,B
2545,size,I
2545,.,O
2546,TANDA,O
2546,:,O
2546,Transfer,O
2546,and,O
2546,Adapt,O
2546,Pre-Trained,O
2546,Transformer,O
2546,Models,O
2546,for,O
2546,Answer,B
2546,Sentence,I
2546,Selection,I
2547,We,O
2547,demonstrate,O
2547,the,O
2547,benefits,O
2547,of,O
2547,our,O
2547,approach,O
2547,for,O
2547,answer,O
2547,sentence,O
2547,selection,O
2547,",",O
2547,which,O
2547,is,O
2547,a,O
2547,well,O
2547,-,O
2547,known,O
2547,inference,O
2547,task,O
2547,in,O
2547,Question,B
2547,Answering,I
2547,.,O
2548,1,O
2548,),O
2548,NVDM,O
2548,:,O
2548,Since,O
2548,NVDM,O
2548,and,O
2548,our,O
2548,proposed,O
2548,Bayesian,O
2548,SMM,O
2548,share,O
2548,similarities,O
2548,",",O
2548,we,O
2548,chose,O
2548,to,O
2548,extract,B
2548,the,O
2548,embeddings,B
2548,from,I
2548,NVDM,O
2548,and,O
2548,use,B
2548,them,I
2548,for,I
2548,training,B
2548,linear,I
2548,classifiers,I
2548,.,O
2549,This,O
2549,has,O
2549,renewed,O
2549,the,O
2549,research,O
2549,interest,O
2549,in,O
2549,Question,B
2549,Answering,I
2549,(,I
2549,QA,I
2549,),I
2549,and,O
2549,",",O
2549,in,O
2549,particular,O
2549,",",O
2549,in,O
2549,two,O
2549,main,O
2549,tasks,O
2549,:,O
2550,(,O
2550,i,O
2550,),O
2550,answer,B
2550,sentence,I
2550,selection,I
2550,(,O
2550,AS2,O
2550,),O
2550,",",O
2550,which,O
2550,",",O
2550,given,O
2550,a,O
2550,question,O
2550,and,O
2550,a,O
2550,set,O
2550,of,O
2550,answer,O
2550,sentence,O
2550,candidates,O
2550,",",O
2550,consists,O
2550,in,O
2550,selecting,O
2550,sentences,O
2550,(,O
2550,e.g.,O
2551,Even,O
2551,though,O
2551,the,O
2551,latter,O
2551,is,O
2551,gaining,O
2551,more,O
2551,and,O
2551,more,O
2551,popularity,O
2551,",",O
2551,AS2,B
2551,is,O
2551,more,O
2551,relevant,O
2551,to,O
2551,a,O
2551,production,O
2551,scenario,O
2551,since,O
2551,",",O
2551,a,O
2551,combination,O
2551,of,O
2551,a,O
2551,search,O
2551,engine,O
2551,and,O
2551,an,O
2551,AS2,O
2551,model,O
2551,already,O
2551,implements,O
2551,an,O
2551,initial,O
2551,QA,B
2551,system,O
2551,.,O
2552,TANDA,B
2552,provides,B
2552,a,O
2552,large,B
2552,improvement,I
2552,over,B
2552,the,I
2552,state,B
2552,of,I
2552,the,O
2552,art,O
2552,",",O
2552,which,O
2552,has,O
2552,been,O
2552,regularly,O
2552,contributed,O
2552,to,O
2552,by,O
2552,hundreds,O
2552,of,O
2552,researchers,O
2552,.,O
2553,TANDA,O
2553,improves,B
2553,all,B
2553,the,I
2553,models,I
2553,:,O
2553,BERT,B
2553,-,I
2553,Base,I
2553,",",O
2553,RoBERTa-,B
2553,Base,O
2553,",",O
2553,BERT,O
2553,-,O
2553,Large,O
2553,and,O
2553,RoBERTa,B
2553,-,O
2553,Large,O
2553,",",O
2553,outperforming,B
2553,the,O
2553,previous,B
2553,state,I
2553,of,I
2553,the,O
2553,art,O
2553,with,O
2553,all,O
2553,of,O
2553,them,O
2553,.,O
2554,RoBERTa-,O
2554,Large,O
2554,TANDA,O
2554,using,B
2554,ASNQ,B
2554,?,O
2555,Wiki,O
2555,QA,O
2555,establish,B
2555,an,O
2555,impressive,B
2555,new,I
2555,state,I
2555,of,B
2555,the,I
2555,art,I
2555,for,B
2555,AS2,B
2555,on,B
2555,WikiQA,B
2555,of,O
2555,0.920,B
2555,and,I
2555,0.933,I
2555,in,B
2555,MAP,B
2555,and,O
2555,MRR,O
2555,",",O
2555,respectively,O
2555,.,O
2556,RoBERTa,O
2556,-,O
2556,Large,O
2556,TANDA,O
2556,with,B
2556,ASNQ,B
2556,?,O
2557,TREC,O
2557,-,O
2557,QA,O
2557,again,O
2557,establishes,B
2557,an,O
2557,impressive,B
2557,performance,I
2557,of,I
2557,0.943,B
2557,in,B
2557,MAP,B
2557,and,O
2557,0.974,B
2557,in,O
2557,MRR,B
2557,",",O
2557,outperforming,B
2557,the,I
2557,previous,B
2557,state,I
2557,of,O
2557,the,O
2557,art,O
2557,by,O
2557,.,O
2558,Each,O
2558,tree,B
2558,node,O
2558,is,O
2558,implemented,B
2558,with,I
2558,a,O
2558,tree,O
2558,-,O
2558,LSTM,O
2558,block,O
2558,same,O
2558,as,O
2558,in,O
2558,model,O
2558,.,O
2559,The,O
2559,span,B
2559,representations,I
2559,are,O
2559,used,O
2559,to,B
2559,perform,I
2559,entity,B
2559,mention,I
2559,detection,I
2559,on,B
2559,all,B
2559,spans,I
2559,in,B
2559,parallel,B
2559,.,O
2560,2,O
2560,),O
2560,SMM,O
2560,:,O
2560,Our,O
2560,second,O
2560,baseline,O
2560,system,O
2560,is,B
2560,non-Bayesian,B
2560,SMM,O
2560,with,O
2560,1,O
2560,regularization,O
2560,over,O
2560,the,O
2560,rows,O
2560,in,O
2560,T,O
2560,matrix,O
2560,",",O
2560,i.e.,O
2561,",",O
2561,1,O
2561,SMM,B
2561,.,O
2562,shows,O
2562,that,O
2562,with,O
2562,this,O
2562,replacement,O
2562,",",O
2562,the,O
2562,performance,B
2562,drops,B
2562,to,B
2562,88.2,B
2562,%,I
2562,.,O
2563,If,O
2563,we,O
2563,remove,B
2563,the,O
2563,pooling,B
2563,layer,I
2563,in,B
2563,inference,B
2563,composition,I
2563,and,O
2563,replace,B
2563,it,I
2563,with,I
2563,summation,B
2563,as,O
2563,in,O
2563,",",O
2563,the,O
2563,accuracy,B
2563,drops,B
2563,to,B
2563,87.1,B
2563,%,I
2563,.,O
2564,If,O
2564,we,O
2564,remove,O
2564,the,O
2564,difference,B
2564,and,I
2564,elementwise,I
2564,product,I
2564,from,B
2564,the,O
2564,local,B
2564,inference,I
2564,enhancement,I
2564,layer,I
2564,",",O
2564,the,O
2564,accuracy,B
2564,drops,B
2564,to,B
2564,87.0,B
2564,%,I
2564,.,O
2565,If,O
2565,we,O
2565,remove,O
2565,the,O
2565,premise,B
2565,-,I
2565,based,I
2565,attention,I
2565,from,B
2565,ESIM,B
2565,(,O
2565,model,O
2565,23,O
2565,),O
2565,",",O
2565,the,O
2565,accuracy,B
2565,drops,B
2565,to,B
2565,87.2,B
2565,%,I
2565,on,B
2565,the,O
2565,test,B
2565,set,I
2565,.,O
2566,To,B
2566,provide,O
2566,some,O
2566,detailed,O
2566,comparison,O
2566,with,B
2566,",",O
2566,replacing,B
2566,bidirectional,B
2566,LSTMs,I
2566,in,B
2566,inference,B
2566,composition,I
2566,and,I
2566,also,O
2566,input,B
2566,encoding,I
2566,with,O
2566,feedforward,B
2566,neural,I
2566,network,I
2566,reduces,B
2566,the,O
2566,accuracy,B
2566,to,O
2566,87.3,B
2566,%,I
2566,and,O
2566,86.3,O
2566,%,O
2566,respectively,O
2566,.,O
2567,Removing,B
2567,the,O
2567,hypothesis,B
2567,-,I
2567,based,I
2567,attention,I
2567,(,I
2567,model,I
2567,24,I
2567,),I
2567,decrease,B
2567,the,O
2567,accuracy,B
2567,to,B
2567,86.5,B
2567,%,I
2567,",",O
2567,where,O
2567,hypothesis,O
2567,-,O
2567,based,O
2567,attention,O
2567,is,O
2567,the,O
2567,attention,O
2567,performed,O
2567,on,O
2567,the,O
2567,other,O
2567,direction,O
2567,for,O
2567,the,O
2567,sentence,O
2567,pairs,O
2567,.,O
2568,We,O
2568,use,B
2568,the,O
2568,Adam,B
2568,method,I
2568,(,O
2568,Kingma,O
2568,and,O
2568,Ba,O
2568,",",O
2568,2014,O
2568,),O
2568,for,B
2568,optimization,B
2568,.,O
2569,We,O
2569,use,O
2569,dropout,B
2569,with,B
2569,a,O
2569,rate,B
2569,of,B
2569,0.5,B
2569,",",O
2569,which,O
2569,is,O
2569,applied,B
2569,to,I
2569,all,B
2569,feedforward,I
2569,connections,I
2569,.,O
2570,We,O
2570,use,O
2570,pre-trained,B
2570,300,I
2570,-,I
2570,D,I
2570,Glove,I
2570,840B,I
2570,vectors,I
2570,to,B
2570,initialize,I
2570,our,B
2570,word,I
2570,embeddings,I
2570,.,O
2571,The,O
2571,first,B
2571,momentum,I
2571,is,O
2571,set,B
2571,to,I
2571,be,I
2571,0.9,B
2571,and,O
2571,the,O
2571,second,B
2571,0.999,B
2571,.,O
2572,3,O
2572,),O
2572,ULMFiT,B
2572,:,O
2572,The,O
2572,third,O
2572,baseline,O
2572,system,O
2572,is,B
2572,the,O
2572,universal,B
2572,language,I
2572,model,I
2572,fine,B
2572,-,I
2572,tuned,I
2572,for,I
2572,classification,B
2572,(,O
2572,ULMFiT,O
2572,),O
2572,.,O
2573,The,O
2573,initial,B
2573,learning,I
2573,rate,I
2573,is,B
2573,0.0004,B
2573,and,O
2573,the,O
2573,batch,B
2573,size,I
2573,is,O
2573,32,B
2573,.,O
2574,All,O
2574,hidden,B
2574,states,I
2574,of,B
2574,LSTMs,I
2574,",",O
2574,tree,B
2574,-,I
2574,LSTMs,O
2574,",",O
2574,and,O
2574,word,B
2574,embeddings,I
2574,have,B
2574,300,B
2574,dimensions,I
2574,.,O
2575,Out,O
2575,-,O
2575,of,O
2575,-,O
2575,vocabulary,O
2575,(,O
2575,OOV,O
2575,),O
2575,words,O
2575,are,O
2575,initialized,B
2575,randomly,B
2575,with,B
2575,Gaussian,B
2575,samples,I
2575,.,O
2576,While,O
2576,some,O
2576,previous,O
2576,top,O
2576,-,O
2576,performing,O
2576,models,O
2576,use,O
2576,rather,O
2576,complicated,O
2576,network,O
2576,architectures,O
2576,to,O
2576,achieve,O
2576,the,O
2576,state,O
2576,-,O
2576,of,O
2576,-,O
2576,the,O
2576,-,O
2576,art,O
2576,results,O
2576,",",O
2576,we,O
2576,demonstrate,O
2576,in,O
2576,this,O
2576,paper,O
2576,that,O
2576,enhancing,B
2576,sequential,B
2576,inference,I
2576,models,O
2576,based,B
2576,on,I
2576,chain,B
2576,models,O
2576,can,O
2576,outperform,O
2576,all,O
2576,previous,O
2576,results,O
2576,",",O
2576,suggesting,O
2576,that,O
2576,the,O
2576,potentials,O
2576,of,O
2576,such,O
2576,sequential,O
2576,inference,O
2576,approaches,O
2576,have,O
2576,not,O
2576,been,O
2576,fully,O
2576,exploited,O
2576,yet,O
2576,.,O
2577,We,O
2577,show,O
2577,that,O
2577,by,O
2577,explicitly,B
2577,encoding,I
2577,parsing,B
2577,information,I
2577,with,B
2577,recursive,B
2577,networks,I
2577,in,B
2577,both,O
2577,local,B
2577,inference,B
2577,modeling,I
2577,and,O
2577,inference,O
2577,composition,O
2577,and,O
2577,by,O
2577,incorporating,O
2577,it,O
2577,into,O
2577,our,O
2577,framework,O
2577,",",O
2577,we,O
2577,achieve,O
2577,additional,O
2577,improvement,O
2577,",",O
2577,increasing,O
2577,the,O
2577,performance,O
2577,to,O
2577,a,O
2577,new,O
2577,state,O
2577,of,O
2577,the,O
2577,art,O
2577,with,O
2577,an,O
2577,88.6,O
2577,%,O
2577,accuracy,O
2577,.,O
2578,Enhanced,O
2578,LSTM,O
2578,for,O
2578,Natural,B
2578,Language,I
2578,Inference,I
2579,Specifically,O
2579,",",O
2579,natural,B
2579,language,I
2579,inference,I
2579,(,I
2579,NLI,I
2579,),I
2579,is,O
2579,concerned,O
2579,with,O
2579,determining,O
2579,whether,O
2579,a,O
2579,naturallanguage,O
2579,hypothesis,O
2579,h,O
2579,can,O
2579,be,O
2579,inferred,O
2579,from,O
2579,a,O
2579,premise,O
2579,p,O
2579,",",O
2579,as,O
2579,depicted,O
2579,in,O
2579,the,O
2579,following,O
2579,example,O
2579,from,O
2579,MacCartney,O
2579,(,O
2579,2009,O
2579,),O
2579,",",O
2579,where,O
2579,the,O
2579,hypothesis,O
2579,is,O
2579,regarded,O
2579,to,O
2579,be,O
2579,entailed,O
2579,from,O
2579,the,O
2579,premise,O
2579,.,O
2580,Exploring,O
2580,syntax,O
2580,for,O
2580,NLI,B
2580,is,O
2580,very,O
2580,attractive,O
2580,to,O
2580,us,O
2580,.,O
2581,Our,O
2581,final,O
2581,model,O
2581,achieves,B
2581,the,O
2581,accuracy,B
2581,of,B
2581,88.6,B
2581,%,I
2581,",",O
2581,the,O
2581,best,B
2581,result,I
2581,observed,B
2581,on,I
2581,SNLI,B
2581,",",O
2581,while,O
2581,our,O
2581,enhanced,O
2581,sequential,O
2581,encoding,O
2581,model,O
2581,attains,B
2581,an,O
2581,accuracy,O
2581,of,O
2581,88.0,B
2581,%,O
2581,",",O
2581,which,O
2581,also,O
2581,outperform,B
2581,the,O
2581,previous,B
2581,models,I
2581,.,O
2582,4,O
2582,),O
2582,TF,B
2582,-,I
2582,IDF,I
2582,:,O
2583,The,O
2583,table,O
2583,shows,O
2583,that,O
2583,our,B
2583,ESIM,I
2583,model,I
2583,achieves,B
2583,an,O
2583,accuracy,B
2583,of,B
2583,88.0,B
2583,%,I
2583,",",O
2583,which,O
2583,has,O
2583,already,O
2583,outperformed,B
2583,all,O
2583,the,O
2583,previous,B
2583,models,I
2583,",",O
2583,including,B
2583,those,O
2583,using,O
2583,much,O
2583,more,B
2583,complicated,I
2583,network,I
2583,architectures,I
2583,.,O
2584,In,O
2584,general,O
2584,",",O
2584,adding,B
2584,intra-sentence,B
2584,attention,I
2584,yields,B
2584,further,B
2584,improvement,I
2584,",",O
2584,which,O
2584,is,O
2584,not,O
2584,very,O
2584,surprising,O
2584,as,O
2584,it,O
2584,could,O
2584,help,O
2584,align,O
2584,the,O
2584,relevant,O
2584,text,O
2584,spans,O
2584,between,O
2584,premise,O
2584,and,O
2584,hypothesis,O
2584,.,O
2585,We,O
2585,ensemble,B
2585,our,B
2585,ESIM,I
2585,model,I
2585,with,B
2585,syntactic,B
2585,tree,I
2585,-,I
2585,LSTMs,I
2585,based,B
2585,on,I
2585,syntactic,O
2585,parse,O
2585,trees,O
2585,and,O
2585,achieve,B
2585,significant,B
2585,improvement,I
2585,over,B
2585,our,O
2585,best,O
2585,sequential,O
2585,encoding,O
2585,model,O
2585,ESIM,O
2585,",",O
2585,attaining,B
2585,an,O
2585,accuracy,B
2585,of,B
2585,88.6,B
2585,%,I
2585,.,O
2586,In,O
2586,this,O
2586,paper,O
2586,",",O
2586,we,O
2586,study,B
2586,the,O
2586,task,B
2586,of,I
2586,learning,B
2586,universal,B
2586,representations,I
2586,of,O
2586,sentences,O
2586,",",O
2586,i.e.,O
2587,",",O
2587,a,O
2587,sentence,B
2587,encoder,I
2587,model,I
2587,that,O
2587,is,O
2587,trained,B
2587,on,I
2587,a,O
2587,large,B
2587,corpus,I
2587,and,O
2587,subsequently,B
2587,transferred,I
2587,to,I
2587,other,B
2587,tasks,I
2587,.,O
2588,Here,O
2588,",",O
2588,we,O
2588,investigate,B
2588,whether,O
2588,supervised,B
2588,learning,I
2588,can,B
2588,be,I
2588,leveraged,B
2588,instead,O
2588,",",O
2588,taking,O
2588,inspiration,O
2588,from,O
2588,previous,O
2588,results,O
2588,in,O
2588,computer,O
2588,vision,O
2588,",",O
2588,where,O
2588,many,O
2588,models,O
2588,are,O
2588,pretrained,O
2588,on,O
2588,the,O
2588,ImageNet,O
2588,),O
2588,before,O
2588,being,O
2588,transferred,O
2588,.,O
2589,Hence,O
2589,",",O
2589,we,O
2589,investigate,O
2589,the,O
2589,impact,B
2589,of,B
2589,the,O
2589,sentence,B
2589,encoding,I
2589,architecture,I
2589,on,B
2589,representational,B
2589,transferability,I
2589,",",O
2589,and,O
2589,compare,B
2589,convolutional,B
2589,",",O
2589,recurrent,O
2589,and,O
2589,even,O
2589,simpler,O
2589,word,O
2589,composition,O
2589,schemes,O
2589,.,O
2590,For,B
2590,all,O
2590,our,O
2590,models,B
2590,trained,B
2590,on,I
2590,SNLI,B
2590,",",O
2590,we,O
2590,use,B
2590,SGD,B
2590,with,B
2590,a,O
2590,learning,B
2590,rate,I
2590,of,B
2590,0.1,B
2590,and,O
2590,a,O
2590,weight,B
2590,decay,I
2590,of,O
2590,0.99,B
2590,.,O
2591,For,O
2591,the,O
2591,classifier,B
2591,",",O
2591,we,O
2591,use,B
2591,a,O
2591,multi,B
2591,-,I
2591,layer,I
2591,perceptron,I
2591,with,B
2591,1,B
2591,hidden,I
2591,-,O
2591,layer,O
2591,of,B
2591,512,B
2591,hidden,O
2591,units,O
2591,.,O
2592,At,B
2592,each,B
2592,epoch,I
2592,",",O
2592,we,O
2592,divide,B
2592,the,O
2592,learning,B
2592,rate,I
2592,by,B
2592,5,B
2592,if,B
2592,the,O
2592,dev,B
2592,accuracy,I
2592,decreases,B
2592,.,O
2593,We,O
2593,use,B
2593,minibatches,B
2593,of,I
2593,size,I
2593,64,B
2593,and,O
2593,training,B
2593,is,B
2593,stopped,B
2593,when,B
2593,the,O
2593,learning,B
2593,rate,I
2593,goes,B
2593,under,I
2593,the,O
2593,threshold,B
2593,of,O
2593,10,O
2593,?5,O
2593,.,O
2594,The,O
2594,fourth,O
2594,baseline,O
2594,system,O
2594,is,B
2594,a,I
2594,standard,B
2594,term,I
2594,frequency,I
2594,-,I
2594,inverse,I
2594,document,I
2594,frequency,O
2594,(,O
2594,TF,O
2594,-,O
2594,IDF,O
2594,),O
2594,based,O
2594,document,O
2594,representation,O
2594,",",O
2594,followed,B
2594,by,I
2594,multi-class,B
2594,logistic,I
2594,regression,I
2594,(,O
2594,LR,O
2594,),O
2594,.,O
2595,We,O
2595,use,O
2595,opensource,B
2595,GloVe,I
2595,vectors,I
2595,trained,B
2595,on,I
2595,Common,B
2595,Crawl,I
2595,840B,I
2595,with,B
2595,300,B
2595,dimensions,I
2595,as,B
2595,fixed,B
2595,word,I
2595,embeddings,I
2595,.,O
2596,The,O
2596,BiLSTM,B
2596,-,I
2596,4096,I
2596,with,B
2596,the,O
2596,max,B
2596,-,O
2596,pooling,O
2596,operation,O
2596,performs,B
2596,best,B
2596,on,B
2596,both,O
2596,SNLI,B
2596,and,I
2596,transfer,I
2596,tasks,I
2596,.,O
2597,Looking,O
2597,at,O
2597,the,O
2597,micro,B
2597,and,I
2597,macro,I
2597,averages,I
2597,",",O
2597,we,O
2597,see,O
2597,that,O
2597,it,O
2597,performs,B
2597,significantly,B
2597,better,I
2597,than,B
2597,the,O
2597,other,B
2597,models,I
2597,LSTM,B
2597,",",O
2597,GRU,B
2597,",",O
2597,BiGRU,B
2597,-,I
2597,last,I
2597,",",O
2597,BiLSTM,B
2597,-,O
2597,Mean,O
2597,",",O
2597,inner-attention,B
2597,and,O
2597,the,O
2597,hierarchical,O
2597,-,O
2597,ConvNet.,O
2598,also,O
2598,shows,O
2598,that,O
2598,better,O
2598,performance,O
2598,on,O
2598,the,O
2598,training,O
2598,task,O
2598,does,O
2598,not,O
2598,necessarily,O
2598,translate,O
2598,in,O
2598,better,O
2598,results,O
2598,on,O
2598,the,O
2598,transfer,O
2598,tasks,O
2598,like,O
2598,when,O
2598,comparing,O
2598,inner-attention,B
2598,and,O
2598,BiLSTM,B
2598,-,I
2598,Mean,I
2598,for,O
2598,instance,O
2598,.,O
2599,For,O
2599,a,O
2599,given,O
2599,model,O
2599,",",O
2599,the,O
2599,transfer,B
2599,quality,I
2599,is,O
2599,also,O
2599,sensitive,B
2599,to,I
2599,the,O
2599,optimization,B
2599,algorithm,I
2599,:,O
2599,when,B
2599,training,I
2599,with,I
2599,Adam,B
2599,instead,B
2599,of,I
2599,SGD,B
2599,",",O
2599,we,O
2599,observed,B
2599,that,O
2599,the,O
2599,BiLSTM,B
2599,-,I
2599,max,I
2599,converged,B
2599,faster,B
2599,on,B
2599,SNLI,B
2599,(,O
2599,5,O
2599,epochs,O
2599,instead,O
2599,of,O
2599,10,O
2599,),O
2599,",",O
2599,but,O
2599,obtained,B
2599,worse,B
2599,results,I
2599,on,O
2599,the,O
2599,transfer,O
2599,tasks,O
2599,",",O
2599,most,O
2599,likely,O
2599,because,O
2599,of,O
2599,the,O
2599,model,O
2599,and,O
2599,classifier,O
2599,'s,O
2599,increased,O
2599,capability,O
2599,to,O
2599,over-specialize,O
2599,on,O
2599,the,O
2599,training,O
2599,task,O
2599,.,O
2600,Since,O
2600,it,O
2600,is,O
2600,easier,O
2600,to,O
2600,linearly,O
2600,separate,O
2600,in,O
2600,high,O
2600,dimension,O
2600,",",O
2600,especially,O
2600,with,O
2600,logistic,O
2600,regression,O
2600,",",O
2600,it,O
2600,is,O
2600,not,O
2600,surprising,O
2600,that,O
2600,increased,B
2600,embedding,I
2600,sizes,I
2600,lead,B
2600,to,O
2600,increased,O
2600,performance,O
2600,for,B
2600,almost,B
2600,all,I
2600,models,I
2600,.,O
2601,With,B
2601,much,B
2601,less,I
2601,data,I
2601,(,I
2601,570,I
2601,k,I
2601,compared,I
2601,to,I
2601,64M,I
2601,sentences,I
2601,),I
2601,but,O
2601,with,O
2601,high,B
2601,-,I
2601,quality,I
2601,supervision,I
2601,from,B
2601,the,O
2601,SNLI,B
2601,dataset,I
2601,",",O
2601,we,O
2601,are,O
2601,able,B
2601,to,O
2601,consistently,B
2601,outperform,I
2601,the,O
2601,results,B
2601,obtained,B
2601,by,I
2601,SkipThought,B
2601,vectors,I
2601,.,O
2602,The,O
2602,embedding,B
2602,dimension,I
2602,was,O
2602,chosen,B
2602,from,B
2602,K,O
2602,=,O
2602,{,O
2602,100,O
2602,",",O
2602,.,O
2603,",",O
2603,800,O
2603,},O
2603,",",O
2603,and,O
2603,regularization,B
2603,weight,I
2603,from,B
2603,?,O
2604,Our,O
2604,BiLSTM,O
2604,-,O
2604,max,O
2604,trained,B
2604,on,B
2604,SNLI,B
2604,performs,B
2604,much,B
2604,better,I
2604,than,B
2604,released,B
2604,SkipThought,I
2604,vectors,I
2604,on,O
2604,MR,B
2604,",",O
2604,CR,B
2604,",",O
2604,MPQA,B
2604,",",O
2604,SST,B
2604,",",O
2604,MRPC,B
2604,-,O
2604,accuracy,O
2604,",",O
2604,SICK,B
2604,-,O
2604,R,O
2604,",",O
2604,SICK,O
2604,-,O
2604,E,O
2604,and,O
2604,STS14,O
2604,(,O
2604,see,O
2604,),O
2604,.,O
2605,Except,O
2605,for,O
2605,the,O
2605,SUBJ,B
2605,dataset,I
2605,",",O
2605,it,O
2605,also,O
2605,performs,B
2605,better,B
2605,than,B
2605,SkipThought,B
2605,-,O
2605,LN,O
2605,on,B
2605,MR,B
2605,",",O
2605,CR,B
2605,and,O
2605,MPQA,B
2605,.,O
2606,We,O
2606,also,O
2606,observe,B
2606,by,O
2606,looking,B
2606,at,I
2606,the,O
2606,STS14,B
2606,results,I
2606,that,O
2606,the,O
2606,cosine,B
2606,metrics,I
2606,in,B
2606,our,B
2606,embedding,I
2606,space,I
2606,is,B
2606,much,O
2606,more,B
2606,semantically,I
2606,informative,I
2606,than,B
2606,in,O
2606,SkipThought,B
2606,embedding,O
2606,space,O
2606,(,O
2606,pearson,O
2606,score,O
2606,of,O
2606,0.68,O
2606,compared,O
2606,to,O
2606,0.29,O
2606,and,O
2606,0.44,O
2606,for,O
2606,ST,O
2606,and,O
2606,ST,O
2606,-,O
2606,LN,O
2606,),O
2606,.,O
2607,Our,O
2607,findings,O
2607,indicate,B
2607,that,O
2607,our,O
2607,model,O
2607,trained,B
2607,on,I
2607,SNLI,B
2607,obtains,B
2607,much,B
2607,better,I
2607,over,I
2607,all,I
2607,results,I
2607,than,B
2607,models,B
2607,trained,O
2607,on,O
2607,other,B
2607,supervised,I
2607,tasks,I
2607,such,B
2607,as,I
2607,COCO,B
2607,",",O
2607,dictionary,B
2607,definitions,I
2607,",",O
2607,NMT,B
2607,",",O
2607,PPDB,B
2607,and,O
2607,SST,B
2607,.,O
2608,Our,O
2608,transfer,O
2608,learning,O
2608,approach,O
2608,obtains,B
2608,better,B
2608,results,I
2608,than,B
2608,previous,B
2608,state,I
2608,-,I
2608,of,I
2608,-,O
2608,the,O
2608,-,O
2608,art,O
2608,on,O
2608,the,O
2608,SICK,O
2608,task,O
2608,-,O
2608,can,O
2608,be,O
2608,seen,O
2608,as,O
2608,an,O
2608,out,O
2608,-,O
2608,domain,O
2608,version,O
2608,of,O
2608,SNLI,O
2608,-,O
2608,for,O
2608,both,O
2608,entailment,O
2608,and,O
2608,relatedness,O
2608,.,O
2609,We,O
2609,also,O
2609,significantly,B
2609,outperformed,I
2609,previous,B
2609,transfer,I
2609,learning,I
2609,approaches,I
2609,on,B
2609,SICK,B
2609,-,I
2609,E,I
2609,(,O
2609,Bowman,O
2609,et,O
2609,al.,O
2610,",",O
2610,2015,O
2610,),O
2610,that,B
2610,used,I
2610,the,O
2610,parameters,B
2610,of,B
2610,an,O
2610,LSTM,B
2610,model,I
2610,trained,B
2610,on,I
2610,SNLI,B
2610,to,B
2610,fine,I
2610,-,I
2610,tune,I
2610,on,O
2610,SICK,B
2610,(,O
2610,80.8,O
2610,%,O
2610,accuracy,O
2610,),O
2610,.,O
2611,We,O
2611,obtain,B
2611,a,O
2611,pearson,B
2611,score,I
2611,of,B
2611,0.885,B
2611,on,B
2611,SICK,B
2611,-,I
2611,R,I
2611,while,B
2611,obtained,B
2611,0.868,O
2611,",",O
2611,and,O
2611,we,O
2611,obtain,O
2611,86.3,B
2611,%,I
2611,test,I
2611,accuracy,I
2611,on,O
2611,SICK,O
2611,-,O
2611,E,O
2611,while,O
2611,previous,B
2611,best,I
2611,handengineered,I
2611,models,I
2611,obtained,O
2611,84.5,B
2611,%,O
2611,.,O
2612,In,O
2612,this,O
2612,paper,O
2612,",",O
2612,we,O
2612,present,B
2612,Bayesian,I
2612,subspace,I
2612,multinomial,I
2612,model,I
2612,(,I
2612,Bayesian,O
2612,SMM,O
2612,),O
2612,as,B
2612,a,I
2612,generative,B
2612,model,O
2612,for,B
2612,bag,B
2612,-,I
2612,ofwords,I
2612,representation,I
2612,of,I
2612,documents,I
2612,.,O
2613,When,O
2613,trained,B
2613,with,I
2613,ResNet,B
2613,features,I
2613,and,I
2613,30,I
2613,k,I
2613,more,I
2613,training,I
2613,data,I
2613,",",O
2613,the,O
2613,SkipThought,B
2613,vectors,I
2613,perform,B
2613,significantly,B
2613,better,I
2613,than,B
2613,the,O
2613,original,B
2613,setting,I
2613,",",O
2613,going,B
2613,from,B
2613,33.8,B
2613,to,I
2613,37.9,I
2613,for,B
2613,caption,B
2613,retrieval,I
2613,R@1,I
2613,",",O
2613,and,O
2613,from,O
2613,25.9,B
2613,to,O
2613,30.6,O
2613,on,B
2613,image,B
2613,retrieval,O
2613,R@1,O
2613,.,O
2614,Our,O
2614,approach,O
2614,pushes,B
2614,the,O
2614,results,B
2614,even,B
2614,further,I
2614,",",O
2614,from,B
2614,37.9,B
2614,to,B
2614,42.4,B
2614,on,B
2614,cap-tion,B
2614,retrieval,I
2614,",",O
2614,and,O
2614,30.6,B
2614,to,O
2614,33.2,B
2614,on,O
2614,image,B
2614,retrieval,O
2614,.,O
2615,We,O
2615,observe,B
2615,a,O
2615,significant,B
2615,boost,I
2615,in,B
2615,performance,B
2615,over,I
2615,all,I
2615,compared,B
2615,to,I
2615,the,O
2615,model,B
2615,trained,B
2615,only,I
2615,on,I
2615,SLNI,B
2615,.,O
2616,Our,O
2616,model,O
2616,even,O
2616,reaches,B
2616,AdaSent,B
2616,performance,I
2616,on,B
2616,CR,B
2616,",",O
2616,suggesting,O
2616,that,O
2616,having,O
2616,a,O
2616,larger,O
2616,coverage,O
2616,for,O
2616,the,O
2616,training,O
2616,task,O
2616,helps,O
2616,learn,O
2616,even,O
2616,better,O
2616,general,O
2616,representations,O
2616,.,O
2617,In,O
2617,contrast,O
2617,",",O
2617,we,O
2617,are,O
2617,proposing,B
2617,an,O
2617,attentive,B
2617,neural,I
2617,network,I
2617,that,O
2617,is,O
2617,capable,B
2617,of,B
2617,reasoning,B
2617,over,B
2617,entailments,B
2617,of,O
2617,pairs,B
2617,of,O
2617,words,B
2617,and,I
2617,phrases,I
2617,by,B
2617,processing,I
2617,the,O
2617,hypothesis,B
2617,conditioned,B
2617,on,I
2617,the,O
2617,premise,B
2617,.,O
2618,Our,O
2618,contributions,O
2618,are,O
2618,threefold,O
2618,:,O
2618,(,O
2618,i,O
2618,),O
2618,We,O
2618,present,B
2618,a,O
2618,neural,B
2618,model,I
2618,based,B
2618,on,I
2618,LSTMs,B
2618,that,O
2618,reads,B
2618,two,B
2618,sentences,I
2618,in,B
2618,one,B
2618,go,I
2618,to,B
2618,determine,O
2618,entailment,O
2618,",",O
2618,as,O
2618,opposed,O
2618,to,O
2618,mapping,O
2618,each,O
2618,sentence,O
2618,independently,O
2618,into,O
2618,a,O
2618,semantic,O
2618,space,O
2618,(,O
2618,2.2,O
2618,),O
2618,",",O
2618,(,O
2618,ii,O
2618,),O
2618,We,O
2618,extend,B
2618,this,O
2618,model,O
2618,with,O
2618,a,O
2618,neural,O
2618,word,O
2618,-,O
2618,by,O
2618,-,O
2618,word,O
2618,attention,O
2618,mechanism,O
2618,to,O
2618,encourage,O
2618,reasoning,B
2618,over,B
2618,entailments,B
2618,of,B
2618,pairs,B
2618,of,O
2618,words,B
2618,and,I
2618,phrases,I
2618,(,O
2618,2.4,O
2618,),O
2618,",",O
2618,and,O
2618,(,O
2618,iii,O
2618,),O
2618,We,O
2618,provide,O
2618,a,O
2618,detailed,O
2618,qualitative,O
2618,analysis,O
2618,of,O
2618,neural,O
2618,attention,O
2618,for,O
2618,RTE,O
2618,(,O
2618,4.1,O
2618,),O
2618,.,O
2619,This,O
2619,task,O
2619,is,O
2619,important,O
2619,since,O
2619,many,O
2619,natural,O
2619,language,O
2619,processing,O
2619,(,O
2619,NLP,O
2619,),O
2619,problems,O
2619,",",O
2619,such,O
2619,as,O
2619,information,O
2619,extraction,O
2619,",",O
2619,relation,O
2619,extraction,O
2619,",",O
2619,text,O
2619,summarization,O
2619,or,O
2619,machine,O
2619,translation,O
2619,",",O
2619,rely,O
2619,on,O
2619,it,O
2619,explicitly,O
2619,or,O
2619,implicitly,O
2619,and,O
2619,could,O
2619,benefit,O
2619,from,O
2619,more,O
2619,accurate,O
2619,RTE,B
2619,systems,O
2619,.,O
2620,We,O
2620,found,O
2620,that,O
2620,processing,B
2620,the,O
2620,hypothesis,B
2620,conditioned,B
2620,on,I
2620,the,O
2620,premise,B
2620,instead,O
2620,of,B
2620,encoding,O
2620,each,O
2620,sentence,O
2620,independently,O
2620,gives,B
2620,an,O
2620,improvement,B
2620,of,O
2620,3.3,B
2620,percentage,I
2620,points,I
2620,in,B
2620,accuracy,B
2620,over,B
2620,Bowman,O
2620,et,O
2620,al.,O
2621,We,O
2621,show,O
2621,that,O
2621,our,O
2621,model,O
2621,can,O
2621,learn,B
2621,to,I
2621,represent,I
2621,each,B
2621,document,I
2621,in,I
2621,the,I
2621,form,I
2621,of,I
2621,a,O
2621,Gaussian,B
2621,distribution,I
2621,",",O
2621,thereby,O
2621,encoding,B
2621,the,O
2621,uncertainty,B
2621,in,O
2621,its,O
2621,covariance,O
2621,.,O
2622,Our,O
2622,LSTM,O
2622,outperforms,B
2622,a,O
2622,simple,B
2622,lexicalized,I
2622,classifier,I
2622,by,B
2622,2.7,B
2622,percentage,I
2622,points,I
2622,.,O
2623,By,O
2623,incorporating,B
2623,an,O
2623,attention,B
2623,mechanism,I
2623,we,O
2623,found,B
2623,a,O
2623,0.9,B
2623,percentage,I
2623,point,I
2623,improvement,B
2623,over,B
2623,a,O
2623,single,B
2623,LSTM,I
2623,with,O
2623,a,O
2623,hidden,O
2623,size,O
2623,of,O
2623,159,O
2623,",",O
2623,and,O
2623,a,O
2623,1.4,B
2623,percentage,O
2623,point,O
2623,increase,B
2623,over,O
2623,a,O
2623,benchmark,B
2623,model,I
2623,that,O
2623,uses,B
2623,two,B
2623,LSTMs,I
2623,for,B
2623,conditional,B
2623,encoding,I
2623,(,O
2623,one,O
2623,for,O
2623,the,O
2623,premise,O
2623,and,O
2623,one,O
2623,for,O
2623,the,O
2623,hypothesis,O
2623,conditioned,O
2623,on,O
2623,the,O
2623,representation,O
2623,of,O
2623,the,O
2623,premise,O
2623,),O
2623,.,O
2624,Enabling,B
2624,the,O
2624,model,B
2624,to,I
2624,attend,B
2624,over,O
2624,output,O
2624,vectors,O
2624,of,B
2624,the,O
2624,premise,B
2624,for,B
2624,every,B
2624,word,I
2624,in,B
2624,the,O
2624,hypothesis,B
2624,yields,B
2624,another,B
2624,1.2,I
2624,percentage,I
2624,point,I
2624,improvement,B
2624,compared,B
2624,to,O
2624,attending,B
2624,based,B
2624,only,I
2624,on,I
2624,the,O
2624,last,B
2624,output,O
2624,vector,O
2624,of,O
2624,the,O
2624,premise,O
2624,.,O
2625,Allowing,B
2625,the,O
2625,model,B
2625,to,O
2625,also,O
2625,attend,B
2625,over,O
2625,the,O
2625,hypothesis,B
2625,based,B
2625,on,I
2625,the,O
2625,premise,B
2625,does,O
2625,not,B
2625,seem,O
2625,to,O
2625,improve,B
2625,performance,B
2625,for,B
2625,RTE,B
2625,.,O
2626,Our,O
2626,work,O
2626,exploits,O
2626,this,O
2626,in,B
2626,the,O
2626,context,B
2626,of,B
2626,a,O
2626,simple,B
2626,one,I
2626,-,I
2626,to,I
2626,-,O
2626,many,O
2626,multi,O
2626,-task,O
2626,learning,O
2626,(,O
2626,MTL,O
2626,),O
2626,framework,O
2626,",",O
2626,wherein,B
2626,a,O
2626,single,B
2626,recurrent,I
2626,sentence,I
2626,encoder,I
2626,is,O
2626,shared,B
2626,across,I
2626,multiple,B
2626,tasks,I
2626,.,O
2627,While,O
2627,our,O
2627,work,O
2627,aims,B
2627,at,I
2627,learning,B
2627,fixed,B
2627,-,I
2627,length,I
2627,distributed,I
2627,sentence,I
2627,representations,I
2627,",",O
2627,it,O
2627,is,O
2627,not,O
2627,always,O
2627,practical,O
2627,to,O
2627,assume,O
2627,that,O
2627,the,O
2627,entire,O
2627,"""",O
2627,meaning,O
2627,"""",O
2627,of,O
2627,a,O
2627,sentence,O
2627,can,O
2627,be,O
2627,encoded,O
2627,into,O
2627,a,O
2627,fixed,O
2627,-,O
2627,length,O
2627,vector,O
2627,.,O
2628,The,O
2628,primary,O
2628,contribution,O
2628,of,B
2628,our,O
2628,work,O
2628,is,O
2628,to,O
2628,combine,B
2628,the,O
2628,benefits,B
2628,of,O
2628,diverse,B
2628,sentence,I
2628,-,I
2628,representation,I
2628,learning,I
2628,objectives,I
2628,into,B
2628,a,O
2628,single,B
2628,multi-task,I
2628,framework,I
2628,.,O
2629,Published,O
2629,as,O
2629,a,O
2629,conference,O
2629,paper,O
2629,at,O
2629,ICLR,O
2629,2018,O
2629,LEARNING,B
2629,GENERAL,I
2629,PURPOSE,I
2629,DISTRIBUTED,I
2629,SEN,I
2629,-,I
2629,TENCE,I
2629,REPRESENTATIONS,I
2629,VIA,O
2629,LARGE,O
2629,SCALE,O
2629,MULTI,O
2629,-,O
2629,TASK,O
2629,LEARNING,O
2630,A,O
2630,lot,O
2630,of,O
2630,the,O
2630,recent,O
2630,success,O
2630,in,O
2630,natural,O
2630,language,O
2630,processing,O
2630,(,O
2630,NLP,O
2630,),O
2630,has,O
2630,been,O
2630,driven,O
2630,by,O
2630,distributed,B
2630,vector,I
2630,representations,I
2630,of,O
2630,words,O
2630,trained,O
2630,on,O
2630,large,O
2630,amounts,O
2630,of,O
2630,text,O
2630,in,O
2630,an,O
2630,unsupervised,O
2630,manner,O
2630,.,O
2631,However,O
2631,",",O
2631,extending,O
2631,this,O
2631,success,O
2631,to,O
2631,learning,B
2631,representations,I
2631,of,I
2631,sequences,I
2631,of,O
2631,words,O
2631,",",O
2631,such,O
2631,as,O
2631,sentences,O
2631,",",O
2631,remains,O
2631,an,O
2631,open,O
2631,problem,O
2631,.,O
2632,Further,O
2632,",",O
2632,we,O
2632,propose,B
2632,a,O
2632,generative,B
2632,Gaussian,I
2632,classifier,I
2632,that,O
2632,exploits,B
2632,this,O
2632,uncertainty,B
2632,for,B
2632,topic,B
2632,identification,I
2632,(,I
2632,ID,I
2632,),I
2632,.,O
2633,Some,O
2633,recent,O
2633,work,O
2633,has,O
2633,addressed,O
2633,this,O
2633,by,O
2633,learning,B
2633,general,I
2633,-,I
2633,purpose,I
2633,sentence,I
2633,representations,I
2633,.,O
2634,It,O
2634,is,O
2634,evident,O
2634,from,O
2634,that,O
2634,adding,B
2634,more,B
2634,tasks,I
2634,improves,B
2634,the,O
2634,transfer,B
2634,performance,I
2634,of,B
2634,our,B
2634,model,I
2634,.,O
2635,Increasing,B
2635,the,O
2635,capacity,B
2635,our,B
2635,sentence,I
2635,encoder,I
2635,with,B
2635,more,B
2635,hidden,I
2635,units,I
2635,(,I
2635,+,I
2635,L,I
2635,),I
2635,as,I
2635,well,I
2635,as,O
2635,an,O
2635,additional,B
2635,layer,I
2635,(,O
2635,+,O
2635,2L,O
2635,),O
2635,also,O
2635,lead,B
2635,to,I
2635,improved,B
2635,transfer,I
2635,performance,I
2635,.,O
2636,We,O
2636,observe,B
2636,gains,B
2636,of,B
2636,1.1,B
2636,-,I
2636,2.0,I
2636,%,I
2636,on,B
2636,the,O
2636,sentiment,B
2636,classification,I
2636,tasks,I
2636,(,O
2636,MR,B
2636,",",O
2636,CR,B
2636,",",O
2636,SUBJ,B
2636,&,O
2636,MPQA,B
2636,),O
2636,over,B
2636,Infersent,B
2636,.,O
2637,For,O
2637,example,O
2637,",",O
2637,we,O
2637,observe,O
2637,a,O
2637,0.2-0.5,B
2637,%,I
2637,improvement,I
2637,over,B
2637,the,O
2637,decomposable,B
2637,attention,I
2637,model,I
2637,.,O
2638,We,O
2638,demonstrate,B
2638,substantial,B
2638,gains,I
2638,on,B
2638,TREC,B
2638,(,O
2638,6,B
2638,%,I
2638,over,B
2638,Infersent,B
2638,and,O
2638,roughly,B
2638,2,I
2638,%,O
2638,over,O
2638,the,O
2638,CNN,B
2638,-,I
2638,LSTM,I
2638,),O
2638,",",O
2638,outperforming,B
2638,even,O
2638,a,O
2638,competitive,B
2638,supervised,I
2638,baseline,I
2638,.,O
2639,We,O
2639,see,B
2639,similar,B
2639,gains,I
2639,(,I
2639,2.3,B
2639,%,I
2639,),I
2639,on,B
2639,paraphrase,B
2639,identification,I
2639,(,O
2639,MPRC,O
2639,),O
2639,",",O
2639,closing,B
2639,the,O
2639,gap,B
2639,on,O
2639,supervised,B
2639,approaches,I
2639,trained,B
2639,from,I
2639,scratch,B
2639,.,O
2640,The,O
2640,addition,B
2640,of,I
2640,constituency,B
2640,parsing,I
2640,improves,B
2640,performance,B
2640,on,B
2640,sentence,B
2640,relatedness,I
2640,(,I
2640,SICK,I
2640,-,I
2640,R,I
2640,),I
2640,and,O
2640,entailment,B
2640,(,O
2640,SICK,O
2640,-,O
2640,E,O
2640,),O
2640,consistent,O
2640,with,O
2640,observations,O
2640,made,O
2640,by,O
2640,.,O
2641,In,O
2641,",",O
2641,we,O
2641,show,B
2641,that,B
2641,simply,O
2641,training,B
2641,an,O
2641,MLP,B
2641,on,B
2641,top,I
2641,of,I
2641,our,B
2641,fixed,I
2641,sentence,I
2641,representations,I
2641,outperforms,B
2641,several,B
2641,strong,I
2641,&,I
2641,complex,I
2641,supervised,I
2641,approaches,I
2641,that,O
2641,use,O
2641,attention,B
2641,mechanisms,I
2641,",",O
2641,even,O
2641,on,O
2641,this,O
2641,fairly,O
2641,large,O
2641,dataset,O
2641,.,O
2642,When,O
2642,using,B
2642,only,O
2642,a,O
2642,small,B
2642,fraction,I
2642,of,B
2642,the,O
2642,training,O
2642,data,O
2642,",",O
2642,indicated,O
2642,by,O
2642,the,O
2642,columns,O
2642,1,O
2642,k,O
2642,-,O
2642,25,O
2642,k,O
2642,",",O
2642,we,O
2642,are,O
2642,able,B
2642,to,I
2642,outperform,B
2642,the,O
2642,Siamese,B
2642,and,I
2642,Multi,I
2642,-,O
2642,Perspective,O
2642,CNN,O
2642,using,O
2642,roughly,B
2642,6,I
2642,%,I
2642,of,O
2642,the,O
2642,available,B
2642,training,O
2642,set,O
2642,.,O
2643,The,O
2643,proposed,B
2643,VB,I
2643,framework,I
2643,can,B
2643,be,O
2643,extended,B
2643,in,I
2643,a,O
2643,straightforward,O
2643,way,O
2643,for,B
2643,subspace,B
2643,n-gram,B
2643,model,I
2643,",",O
2643,that,O
2643,can,O
2643,model,O
2643,n-gram,O
2643,distribution,O
2643,of,O
2643,words,O
2643,in,O
2643,sentences,O
2643,.,O
2644,We,O
2644,also,O
2644,outperform,B
2644,the,O
2644,Deconv,B
2644,LVM,I
2644,model,I
2644,proposed,O
2644,by,O
2644,in,O
2644,this,O
2644,low,O
2644,-,O
2644,resource,O
2644,setting,O
2644,.,O
2645,Representations,B
2645,learned,B
2645,solely,I
2645,from,I
2645,NLI,B
2645,do,O
2645,appear,B
2645,to,I
2645,encode,I
2645,syntax,B
2645,but,O
2645,incorporation,B
2645,into,I
2645,our,B
2645,multi-task,I
2645,framework,I
2645,does,B
2645,not,I
2645,amplify,B
2645,this,O
2645,signal,B
2645,.,O
2646,Somewhat,O
2646,surprisingly,O
2646,",",O
2646,in,O
2646,we,O
2646,observe,B
2646,that,I
2646,the,O
2646,learned,B
2646,word,I
2646,embeddings,I
2646,are,B
2646,competitive,B
2646,with,B
2646,popular,B
2646,methods,I
2646,such,B
2646,as,I
2646,GloVe,B
2646,",",O
2646,word2vec,B
2646,",",O
2646,and,O
2646,fasttext,B
2646,on,O
2646,the,O
2646,benchmarks,O
2646,presented,O
2646,by,O
2646,and,O
2646,.,O
2647,Similarly,O
2647,",",O
2647,we,O
2647,observe,O
2647,that,O
2647,sentence,B
2647,characteristics,I
2647,such,B
2647,as,I
2647,length,B
2647,and,I
2647,word,I
2647,order,I
2647,are,B
2647,better,B
2647,encoded,I
2647,with,O
2647,the,O
2647,addition,B
2647,of,I
2647,parsing,B
2647,.,O
2648,First,O
2648,",",O
2648,under,B
2648,the,O
2648,Siamese,B
2648,framework,I
2648,",",O
2648,we,O
2648,implement,B
2648,two,B
2648,baseline,I
2648,models,I
2648,:,O
2648,"""",O
2648,Siamese,O
2648,-,O
2648,CNN,O
2648,"""",O
2648,and,O
2648,"""",O
2648,Siamese,O
2648,-,O
2648,LSTM,O
2648,"""",O
2648,.,O
2649,Second,O
2649,",",O
2649,based,O
2649,on,B
2649,the,O
2649,two,B
2649,baseline,I
2649,models,I
2649,",",O
2649,we,O
2649,implement,B
2649,two,O
2649,more,O
2649,baseline,O
2649,models,O
2649,"""",O
2649,Multi,B
2649,-,I
2649,Perspective,I
2649,-,O
2649,CNN,O
2649,"""",O
2649,and,O
2649,"""",O
2649,Multi,O
2649,-,O
2649,Perspective,O
2649,-,O
2649,LSTM,O
2649,"""",O
2649,.,O
2650,Third,O
2650,",",O
2650,we,O
2650,re-implement,B
2650,the,O
2650,"""",O
2650,L.D.C.,O
2650,"""",O
2651,model,B
2651,proposed,O
2651,by,O
2651,",",O
2651,which,O
2651,is,B
2651,a,O
2651,model,O
2651,under,B
2651,the,O
2651,"""",O
2651,matchingaggregation,O
2651,"""",O
2651,framework,O
2651,and,O
2651,acquires,O
2651,the,O
2651,state,O
2651,-,O
2651,of,O
2651,-,O
2651,the,O
2651,-,O
2651,art,O
2651,performance,O
2651,on,B
2651,several,O
2651,tasks,O
2651,.,O
2652,In,O
2652,this,O
2652,Sub-section,O
2652,",",O
2652,we,O
2652,compare,O
2652,our,O
2652,model,O
2652,with,O
2652,state,O
2652,-,O
2652,of,O
2652,-,O
2652,theart,O
2652,models,O
2652,on,O
2652,the,O
2652,paraphrase,B
2652,identification,I
2652,task,I
2652,.,O
2653,We,O
2653,still,O
2653,experiment,B
2653,on,I
2653,the,O
2653,"""",O
2653,Quora,O
2653,Question,O
2653,Pairs,O
2653,"""",O
2653,dataset,O
2653,",",O
2653,and,O
2653,use,O
2653,the,O
2653,same,O
2653,dataset,O
2653,partition,O
2653,as,O
2653,Sub-section,O
2653,4.2,O
2653,.,O
2654,We,O
2654,can,O
2654,see,B
2654,that,I
2654,"""",I
2654,Multi,I
2654,-,I
2654,Perspective,I
2654,-,O
2654,CNN,O
2654,"""",O
2654,(,O
2654,or,O
2654,"""",O
2654,Multi-,O
2654,Perspective,O
2654,-,O
2654,LSTM,O
2654,"""",O
2654,),O
2654,works,B
2654,much,B
2654,better,I
2654,than,B
2654,"""",O
2654,Siamese,O
2654,-,O
2654,CNN,O
2654,"""",O
2654,(,O
2654,or,O
2654,"""",O
2654,Siamese,O
2654,-,O
2654,LSTM,O
2654,"""",O
2654,),O
2654,",",O
2654,which,O
2654,further,O
2654,indicates,O
2654,that,O
2654,our,O
2654,multi-perspective,O
2654,cosine,O
2654,matching,O
2654,func,O
2654,-,O
2654,Models,O
2654,Accuracy,O
2654,81.4,O
2654,82.1,O
2654,83.5,O
2654,85.0,O
2654,85.1,O
2654,86.1,O
2654,86.3,O
2654,86.8,O
2654,87.3,O
2654,87.5,O
2654,tion,O
2654,(,O
2654,Eq.,O
2654,),O
2655,Our,O
2655,"""",O
2655,BiMPM,O
2655,"""",O
2655,model,O
2655,outperforms,B
2655,the,O
2655,"""",O
2655,L.D.C.,O
2655,"""",O
2656,model,O
2656,by,B
2656,more,B
2656,than,I
2656,two,I
2656,percent,I
2656,.,O
2657,In,O
2657,this,O
2657,Sub-section,O
2657,",",O
2657,we,O
2657,evaluate,O
2657,our,O
2657,model,O
2657,on,O
2657,the,O
2657,natural,B
2657,language,I
2657,inference,I
2657,task,I
2657,over,B
2657,the,O
2657,SNLI,B
2657,dataset,I
2657,.,O
2658,First,O
2658,",",O
2658,we,O
2658,can,O
2658,see,B
2658,that,I
2658,"""",O
2658,Only,O
2658,P,O
2658,?,O
2659,Q,O
2659,"""",O
2659,works,B
2659,significantly,I
2659,better,I
2659,than,B
2659,"""",O
2659,Only,O
2659,P,O
2659,?,O
2660,Q,O
2660,"""",O
2660,",",O
2660,which,O
2660,tells,B
2660,us,O
2660,that,O
2660,",",O
2660,for,O
2660,natural,O
2660,language,O
2660,inference,O
2660,",",O
2660,matching,B
2660,the,I
2660,hypothesis,I
2660,against,B
2660,the,O
2660,premise,B
2660,is,B
2660,more,B
2660,effective,I
2660,than,B
2660,the,O
2660,other,B
2660,way,I
2660,around,I
2660,.,O
2661,Second,O
2661,",",O
2661,our,B
2661,"""",I
2661,BiMPM,I
2661,"""",O
2661,model,O
2661,works,B
2661,much,B
2661,better,I
2661,than,B
2661,"""",O
2661,Only,O
2661,P,O
2661,?,O
2662,Therefore,O
2662,",",O
2662,our,B
2662,models,I
2662,achieve,B
2662,the,I
2662,state,B
2662,-,I
2662,of,I
2662,-,O
2662,the,O
2662,-,O
2662,art,O
2662,performance,O
2662,in,B
2662,both,I
2662,single,B
2662,and,I
2662,ensemble,I
2662,scenarios,I
2662,for,B
2662,the,O
2662,natural,B
2662,language,I
2662,inference,I
2662,task,I
2662,.,O
2663,Finally,O
2663,",",O
2663,comparing,O
2663,our,B
2663,models,I
2663,with,I
2663,all,O
2663,the,O
2663,state,B
2663,-,I
2663,of,I
2663,-,O
2663,the,O
2663,-,O
2663,art,O
2663,models,O
2663,",",O
2663,we,O
2663,can,O
2663,observe,B
2663,that,I
2663,our,O
2663,single,O
2663,model,O
2663,"""",O
2663,BiMPM,O
2663,"""",O
2663,is,O
2663,on,B
2663,par,I
2663,with,O
2663,the,O
2663,state,O
2663,-,O
2663,of,O
2663,-,O
2663,the,O
2663,-,O
2663,art,O
2663,single,O
2663,models,O
2663,",",O
2663,and,O
2663,our,O
2663,',O
2663,BiMPM,O
2663,(,O
2663,Ensemble,B
2663,),I
2663,"""",O
2663,works,B
2663,much,B
2663,better,I
2663,than,B
2663,"""",O
2663,(,O
2663,Ensemble,O
2663,),O
2663,"""",O
2663,.,O
2664,In,O
2664,this,O
2664,Sub-section,O
2664,",",O
2664,we,O
2664,study,O
2664,the,O
2664,effectiveness,O
2664,of,O
2664,our,O
2664,model,O
2664,for,B
2664,answer,B
2664,sentence,I
2664,selection,I
2664,tasks,I
2664,.,O
2665,We,O
2665,experiment,B
2665,on,I
2665,two,B
2665,datasets,I
2665,:,O
2665,TREC,B
2665,-,I
2665,QA,I
2665,and,O
2665,WikiQA,B
2665,.,O
2666,We,O
2666,can,O
2666,see,B
2666,that,I
2666,the,I
2666,performance,B
2666,from,B
2666,our,B
2666,model,I
2666,is,B
2666,on,B
2666,par,I
2666,with,B
2666,the,O
2666,state,B
2666,-,I
2666,of,I
2666,-,O
2666,the,O
2666,-,O
2666,art,O
2666,models,O
2666,.,O
2667,We,O
2667,initialize,B
2667,word,I
2667,embeddings,I
2667,in,B
2667,the,O
2667,word,O
2667,representation,O
2667,layer,O
2667,with,B
2667,the,O
2667,300,B
2667,-,I
2667,dimensional,I
2667,GloVe,I
2667,word,O
2667,vectors,O
2667,pretrained,B
2667,from,I
2667,the,O
2667,840B,B
2667,Common,I
2667,Crawl,I
2667,corpus,I
2667,.,O
2668,The,O
2668,same,O
2668,span,O
2668,representations,O
2668,are,O
2668,then,O
2668,used,O
2668,to,O
2668,perform,O
2668,relation,B
2668,extraction,I
2668,on,B
2668,all,B
2668,pairs,I
2668,of,B
2668,detected,B
2668,entity,I
2668,mentions,I
2668,.,O
2669,We,O
2669,also,O
2669,present,O
2669,a,O
2669,generative,O
2669,Gaussian,O
2669,linear,O
2669,classifier,O
2669,for,O
2669,topic,B
2669,identification,I
2669,that,O
2669,exploits,O
2669,the,O
2669,uncertainty,O
2669,in,O
2669,document,O
2669,embeddings,O
2669,.,O
2670,For,B
2670,the,O
2670,out,B
2670,-,I
2670,of,I
2670,-,O
2670,vocabulary,O
2670,(,O
2670,OOV,O
2670,),O
2670,words,O
2670,",",O
2670,we,O
2670,initialize,B
2670,the,O
2670,word,B
2670,embeddings,I
2670,randomly,B
2670,.,O
2671,For,O
2671,the,O
2671,charactercomposed,B
2671,embeddings,I
2671,",",O
2671,we,O
2671,initialize,B
2671,each,B
2671,character,I
2671,as,B
2671,a,O
2671,20,B
2671,-,I
2671,dimensional,I
2671,vector,I
2671,",",O
2671,and,O
2671,compose,B
2671,each,O
2671,word,O
2671,into,B
2671,a,O
2671,50,B
2671,dimensional,O
2671,vector,O
2671,with,B
2671,a,O
2671,LSTM,B
2671,layer,I
2671,.,O
2672,We,O
2672,set,B
2672,the,O
2672,hidden,B
2672,size,I
2672,as,B
2672,100,B
2672,for,B
2672,all,B
2672,BiLSTM,I
2672,layers,I
2672,.,O
2673,We,O
2673,set,O
2673,the,O
2673,learning,B
2673,rate,I
2673,as,B
2673,0.001,B
2673,.,O
2674,We,O
2674,apply,B
2674,dropout,B
2674,to,B
2674,every,B
2674,layers,I
2674,in,O
2674,",",O
2674,and,O
2674,set,B
2674,the,O
2674,dropout,O
2674,ratio,O
2674,as,B
2674,0.1,B
2674,.,O
2675,To,O
2675,train,O
2675,the,O
2675,model,O
2675,",",O
2675,we,O
2675,minimize,B
2675,the,O
2675,cross,B
2675,entropy,I
2675,of,B
2675,the,O
2675,training,B
2675,set,I
2675,",",O
2675,and,O
2675,use,B
2675,the,O
2675,ADAM,B
2675,optimizer,I
2675,[,O
2675,Kingma,O
2675,and,O
2675,Ba,O
2675,",",O
2675,2014,O
2675,],O
2675,to,O
2675,update,O
2675,parameters,B
2675,.,O
2676,During,B
2676,training,B
2676,",",O
2676,we,O
2676,do,B
2676,not,I
2676,update,I
2676,the,O
2676,pre-trained,B
2676,word,I
2676,embeddings,I
2676,.,O
2677,In,O
2677,this,O
2677,paper,O
2677,",",O
2677,to,O
2677,tackle,O
2677,these,O
2677,limitations,O
2677,",",O
2677,we,O
2677,propose,B
2677,a,O
2677,bilateral,B
2677,multi-perspective,I
2677,matching,I
2677,(,I
2677,BiMPM,I
2677,),I
2677,model,I
2677,for,B
2677,NLSM,B
2677,tasks,I
2677,.,O
2678,Our,O
2678,model,O
2678,essentially,O
2678,belongs,B
2678,to,I
2678,the,O
2678,"""",O
2678,matching,O
2678,aggregation,O
2678,"""",O
2678,framework,O
2678,.,O
2679,Then,O
2679,",",O
2679,another,O
2679,BiLSTM,B
2679,layer,I
2679,is,O
2679,utilized,B
2679,to,I
2679,aggregate,B
2679,the,O
2679,matching,O
2679,results,O
2679,into,B
2679,a,O
2679,fixed,B
2679,-,I
2679,length,I
2679,matching,O
2679,vector,O
2679,.,O
2680,Finally,O
2680,",",O
2680,based,B
2680,on,I
2680,the,O
2680,matching,B
2680,vector,I
2680,",",O
2680,a,O
2680,decision,B
2680,is,O
2680,made,B
2680,through,I
2680,a,O
2680,fully,B
2680,connected,I
2680,layer,I
2680,.,O
2681,For,O
2681,example,O
2681,",",O
2681,in,O
2681,a,O
2681,paraphrase,O
2681,identification,O
2681,task,O
2681,",",O
2681,NLSM,B
2681,is,O
2681,used,O
2681,to,O
2681,determine,O
2681,whether,O
2681,two,O
2681,sentences,O
2681,are,O
2681,paraphrase,O
2681,or,O
2681,not,O
2681,.,O
2682,As,O
2682,can,O
2682,be,O
2682,seen,O
2682,from,O
2682,the,O
2682,table,O
2682,",",O
2682,the,O
2682,use,B
2682,of,I
2682,convolutions,B
2682,in,B
2682,the,O
2682,encoders,B
2682,is,B
2682,crucial,B
2682,:,O
2682,both,B
2682,F1,I
2682,and,I
2682,EM,I
2682,drop,B
2682,drastically,I
2682,by,B
2682,almost,B
2682,3,I
2682,percent,I
2682,if,B
2682,it,O
2682,is,O
2682,removed,B
2682,.,O
2683,Self-,O
2683,attention,O
2683,in,B
2683,the,O
2683,encoders,B
2683,is,B
2683,also,O
2683,a,O
2683,necessary,B
2683,component,I
2683,that,B
2683,contributes,I
2683,1.4/1.3,B
2683,gain,I
2683,of,I
2683,EM,I
2683,/,I
2683,F1,I
2683,to,B
2683,the,O
2683,ultimate,B
2683,performance,I
2683,.,O
2684,As,O
2684,the,O
2684,last,O
2684,block,O
2684,of,O
2684,rows,O
2684,in,B
2684,the,O
2684,table,O
2684,shows,O
2684,",",O
2684,data,B
2684,augmentation,I
2684,proves,B
2684,to,I
2684,be,I
2684,helpful,B
2684,in,O
2684,further,B
2684,boosting,I
2684,performance,I
2684,.,O
2685,Empirically,O
2685,",",O
2685,the,O
2685,ratio,B
2685,(,I
2685,3:1:1,I
2685,),I
2685,yields,B
2685,the,O
2685,best,B
2685,performance,I
2685,",",O
2685,with,B
2685,1.5/1.1,B
2685,gain,I
2685,over,B
2685,the,O
2685,base,B
2685,model,I
2685,on,B
2685,EM,B
2685,/,I
2685,F1,I
2685,.,O
2686,Making,B
2686,the,O
2686,training,B
2686,data,I
2686,twice,B
2686,as,I
2686,large,I
2686,by,B
2686,adding,I
2686,the,O
2686,En,O
2686,-,O
2686,Fr,O
2686,-,O
2686,En,O
2686,data,O
2686,only,O
2686,(,O
2686,ratio,O
2686,1:1,O
2686,between,O
2686,original,O
2686,training,O
2686,data,O
2686,and,O
2686,augmented,O
2686,data,O
2686,",",O
2686,as,O
2686,indicated,O
2686,by,O
2686,row,O
2686,"""",O
2686,data,O
2686,augmentation,O
2686,2,O
2686,(,O
2686,1:1:0,O
2686,),O
2686,"""",O
2686,),O
2686,yields,B
2686,an,O
2686,increase,B
2686,in,B
2686,the,O
2686,F1,B
2686,by,O
2686,0.5,B
2686,percent,I
2686,.,O
2687,Although,O
2687,injecting,O
2687,more,O
2687,data,O
2687,beyond,O
2687,3,O
2687,does,O
2687,not,O
2687,benefit,O
2687,the,O
2687,model,B
2687,",",O
2687,we,O
2687,observe,B
2687,that,I
2687,a,O
2687,good,B
2687,sampling,I
2687,ratio,I
2687,between,B
2687,the,O
2687,original,B
2687,and,I
2687,augmented,I
2687,data,O
2687,during,B
2687,training,B
2687,can,B
2687,further,I
2687,boost,B
2687,the,O
2687,model,O
2687,performance,O
2687,.,O
2688,presents,O
2688,the,O
2688,classification,O
2688,results,O
2688,on,O
2688,Fisher,B
2688,speech,I
2688,corpora,I
2688,with,B
2688,manual,B
2688,and,I
2688,automatic,I
2688,transcriptions,I
2688,",",O
2688,where,O
2688,the,O
2688,first,O
2688,two,O
2688,rows,O
2688,are,O
2688,the,O
2688,results,O
2688,from,O
2688,earlier,O
2688,published,O
2688,works,O
2688,.,O
2689,In,O
2689,particular,O
2689,",",O
2689,when,O
2689,we,O
2689,increase,B
2689,the,O
2689,sampling,B
2689,weight,I
2689,of,B
2689,augmented,B
2689,data,I
2689,from,B
2689,(,B
2689,1:1:1,I
2689,),I
2689,to,B
2689,(,O
2689,1:2:1,O
2689,),O
2689,",",O
2689,the,O
2689,EM,B
2689,/,I
2689,F1,I
2689,performance,I
2689,drops,B
2689,by,B
2689,0.5/0.3,B
2689,.,O
2690,EXPERIMENTS,O
2690,ON,B
2690,SQUAD,B
2691,We,O
2691,employ,B
2691,two,B
2691,types,I
2691,of,B
2691,standard,B
2691,regularizations,I
2691,.,O
2692,First,O
2692,",",O
2692,we,O
2692,use,B
2692,L2,B
2692,weight,I
2692,decay,I
2692,on,B
2692,all,B
2692,the,I
2692,trainable,I
2692,variables,I
2692,",",O
2692,with,B
2692,parameter,I
2692,?,O
2693,We,O
2693,additionally,O
2693,use,O
2693,dropout,B
2693,on,B
2693,word,B
2693,",",O
2693,character,O
2693,embeddings,O
2693,and,O
2693,between,B
2693,layers,I
2693,",",O
2693,where,B
2693,the,O
2693,word,O
2693,and,O
2693,character,O
2693,dropout,O
2693,rates,O
2693,are,B
2693,0.1,B
2693,and,O
2693,0.05,O
2693,respectively,O
2693,",",O
2693,and,O
2693,the,O
2693,dropout,O
2693,rate,O
2693,between,O
2693,every,B
2693,two,I
2693,layers,O
2693,is,B
2693,0.1,O
2693,.,O
2694,We,O
2694,use,O
2694,the,O
2694,ADAM,B
2694,optimizer,I
2694,(,O
2694,Kingma,O
2694,&,O
2694,Ba,O
2694,",",O
2694,2014,O
2694,),O
2694,with,B
2694,?,O
2695,We,O
2695,use,O
2695,a,O
2695,learning,O
2695,rate,O
2695,warm,O
2695,-,O
2695,up,O
2695,scheme,O
2695,with,B
2695,an,O
2695,inverse,B
2695,exponential,I
2695,increase,B
2695,from,B
2695,0.0,B
2695,to,B
2695,0.001,B
2695,in,B
2695,the,O
2695,first,B
2695,1000,I
2695,steps,I
2695,",",O
2695,and,O
2695,then,B
2695,maintain,B
2695,a,O
2695,constant,B
2695,learning,O
2695,rate,O
2695,for,B
2695,the,O
2695,remainder,B
2695,of,I
2695,training,I
2695,.,O
2696,We,O
2696,also,O
2696,adopt,B
2696,the,O
2696,stochastic,B
2696,depth,I
2696,method,I
2696,(,I
2696,layer,I
2696,dropout,I
2696,),I
2696,within,B
2696,each,B
2696,embedding,I
2696,or,I
2696,model,I
2696,encoder,I
2696,layer,O
2696,",",O
2696,where,B
2696,sublayer,B
2696,l,I
2696,has,O
2696,survival,O
2696,probability,O
2696,pl,O
2696,=,B
2696,1,O
2696,?,O
2697,l,B
2697,L,O
2697,(,O
2697,1,O
2697,?,O
2698,p,O
2698,L,B
2698,),O
2698,where,B
2698,L,O
2698,is,B
2698,the,O
2698,last,B
2698,layer,I
2698,and,O
2698,p,O
2698,L,O
2698,=,B
2698,0.9,B
2698,.,O
2699,The,O
2699,hidden,B
2699,size,I
2699,and,I
2699,the,O
2699,convolution,O
2699,filter,O
2699,number,O
2699,are,B
2699,all,O
2699,128,B
2699,",",O
2699,the,O
2699,batch,B
2699,size,O
2699,is,B
2699,32,B
2699,",",O
2699,training,B
2699,steps,I
2699,are,O
2699,150,B
2699,K,I
2699,for,B
2699,original,B
2699,data,B
2699,",",O
2699,250,B
2699,K,O
2699,for,O
2699,"""",O
2699,data,O
2699,augmentation,O
2699,2,O
2699,"""",O
2699,",",O
2699,and,O
2699,340,B
2699,K,O
2699,for,O
2699,"""",O
2699,data,O
2699,augmentation,O
2699,3,O
2699,"""",O
2699,.,O
2700,The,O
2700,numbers,O
2700,of,O
2700,convolution,O
2700,layers,O
2700,in,B
2700,the,O
2700,embedding,B
2700,and,I
2700,modeling,I
2700,encoder,I
2700,are,B
2700,4,B
2700,and,O
2700,2,O
2700,",",O
2700,kernel,B
2700,sizes,I
2700,are,O
2700,7,O
2700,and,O
2700,5,O
2700,",",O
2700,and,O
2700,the,O
2700,block,B
2700,numbers,O
2700,for,B
2700,the,O
2700,encoders,B
2700,are,O
2700,1,B
2700,and,O
2700,7,O
2700,",",O
2700,respectively,O
2700,.,O
2701,We,O
2701,can,O
2701,see,B
2701,that,I
2701,our,B
2701,proposed,I
2701,systems,I
2701,achieve,B
2701,consistently,B
2701,better,I
2701,accuracies,I
2701,;,O
2701,notably,O
2701,",",O
2701,GLCU,B
2701,which,O
2701,exploits,B
2701,the,O
2701,uncertainty,B
2701,in,I
2701,document,I
2701,embeddings,I
2701,has,O
2701,much,B
2701,lower,I
2701,cross,I
2701,-,I
2701,entropy,I
2701,than,B
2701,its,O
2701,counterpart,O
2701,",",O
2701,GLC,B
2701,.,O
2702,Exponential,O
2702,moving,O
2702,average,O
2702,is,O
2702,applied,B
2702,on,I
2702,all,B
2702,trainable,I
2702,variables,I
2702,with,B
2702,a,O
2702,decay,B
2702,rate,I
2702,0.9999,I
2702,.,O
2703,Finally,O
2703,",",O
2703,we,O
2703,implement,B
2703,our,B
2703,model,I
2703,in,B
2703,Python,B
2703,using,B
2703,Tensorflow,B
2703,and,O
2703,carry,B
2703,out,I
2703,our,O
2703,experiments,O
2703,on,B
2703,an,O
2703,NVIDIA,B
2703,p,I
2703,100,I
2703,GPU,I
2703,.,O
2704,As,O
2704,can,O
2704,be,O
2704,seen,O
2704,from,O
2704,the,O
2704,table,O
2704,",",O
2704,the,O
2704,accuracy,B
2704,(,I
2704,EM,I
2704,/,I
2704,F1,I
2704,),I
2704,performance,I
2704,of,I
2704,our,B
2704,model,I
2704,is,B
2704,on,B
2704,par,I
2704,with,B
2704,the,O
2704,state,B
2704,-,I
2704,of,O
2704,-,O
2704,the,O
2704,-,O
2704,art,O
2704,models,O
2704,.,O
2705,In,O
2705,particular,O
2705,",",O
2705,our,B
2705,model,I
2705,trained,B
2705,on,I
2705,the,I
2705,original,B
2705,dataset,I
2705,outperforms,B
2705,all,B
2705,the,O
2705,documented,O
2705,results,O
2705,in,O
2705,the,O
2705,literature,O
2705,",",O
2705,in,O
2705,terms,O
2705,of,O
2705,both,O
2705,EM,B
2705,and,I
2705,F1,I
2705,scores,I
2705,(,O
2705,see,O
2705,second,O
2705,column,O
2705,of,O
2705,),O
2705,.,O
2706,When,O
2706,trained,B
2706,with,B
2706,the,O
2706,augmented,B
2706,data,I
2706,with,O
2706,proper,B
2706,sampling,I
2706,scheme,I
2706,",",O
2706,our,B
2706,model,I
2706,can,B
2706,get,I
2706,significant,B
2706,gain,I
2706,1.5/1.1,I
2706,on,B
2706,EM,B
2706,/,I
2706,F1,I
2706,.,O
2707,Finally,O
2707,",",O
2707,our,O
2707,result,O
2707,on,B
2707,the,O
2707,official,B
2707,test,I
2707,set,I
2707,is,B
2707,76.2/84.6,B
2707,",",O
2707,which,B
2707,significantly,B
2707,outperforms,I
2707,the,O
2707,best,B
2707,documented,I
2707,result,O
2707,73.2/81.8,O
2707,.,O
2708,In,O
2708,this,O
2708,paper,O
2708,",",O
2708,aiming,O
2708,to,B
2708,make,I
2708,the,O
2708,machine,B
2708,comprehension,I
2708,fast,B
2708,",",O
2708,we,O
2708,propose,O
2708,to,O
2708,remove,B
2708,the,O
2708,recurrent,B
2708,nature,I
2708,of,I
2708,these,I
2708,models,I
2708,.,O
2709,We,O
2709,instead,O
2709,exclusively,O
2709,use,B
2709,convolutions,B
2709,and,I
2709,self,I
2709,-,I
2709,attentions,I
2709,as,B
2709,the,O
2709,building,B
2709,blocks,I
2709,of,B
2709,encoders,B
2709,that,O
2709,separately,B
2709,encodes,I
2709,the,O
2709,query,B
2709,and,O
2709,context,O
2709,.,O
2710,Then,O
2710,we,O
2710,learn,B
2710,the,O
2710,interactions,B
2710,between,B
2710,context,B
2710,and,I
2710,question,I
2710,by,B
2710,standard,B
2710,attentions,I
2710,.,O
2711,The,O
2711,resulting,B
2711,representation,I
2711,is,B
2711,encoded,B
2711,again,I
2711,with,B
2711,our,B
2711,recurrency,I
2711,-,I
2711,free,I
2711,encoder,I
2711,before,B
2711,finally,O
2711,decoding,B
2711,to,B
2711,the,O
2711,probability,B
2711,of,B
2711,each,B
2711,position,I
2711,being,B
2711,the,O
2711,start,B
2711,or,I
2711,end,I
2711,of,O
2711,the,O
2711,answer,B
2711,span,I
2711,.,O
2712,presents,O
2712,classification,O
2712,results,O
2712,on,O
2712,20,B
2712,Newsgroups,I
2712,dataset,I
2712,.,O
2713,We,O
2713,call,B
2713,this,O
2713,architecture,B
2713,QANet,I
2713,",",O
2713,which,O
2713,is,O
2713,shown,O
2713,in,O
2713,.,O
2714,COMBINING,O
2714,LOCAL,O
2714,CONVOLUTION,O
2714,WITH,O
2714,GLOBAL,O
2714,SELF,O
2714,-,O
2714,ATTENTION,O
2714,FOR,O
2714,READING,B
2714,COMPRE,I
2714,-,O
2714,HENSION,O
2715,Current,O
2715,end,O
2715,-,O
2715,to,O
2715,-,O
2715,end,O
2715,machine,B
2715,reading,I
2715,and,I
2715,question,I
2715,answering,I
2715,(,I
2715,Q&A,I
2715,),I
2715,models,O
2715,are,O
2715,primarily,O
2715,based,O
2715,on,O
2715,recurrent,O
2715,neural,O
2715,networks,O
2715,(,O
2715,RNNs,O
2715,),O
2715,with,O
2715,attention,O
2715,.,O
2716,There,O
2716,is,O
2716,growing,O
2716,interest,O
2716,in,O
2716,the,O
2716,tasks,O
2716,of,O
2716,machine,B
2716,reading,I
2716,comprehension,I
2716,and,O
2716,automated,B
2716,question,I
2716,answering,I
2716,.,O
2717,In,O
2717,this,O
2717,paper,O
2717,",",O
2717,aiming,O
2717,to,O
2717,make,O
2717,the,O
2717,machine,B
2717,comprehension,I
2717,fast,O
2717,",",O
2717,we,O
2717,propose,O
2717,to,O
2717,remove,O
2717,the,O
2717,recurrent,O
2717,nature,O
2717,of,O
2717,these,O
2717,models,O
2717,.,O
2718,YahooCQA,B
2719,-,I
2719,The,O
2719,key,B
2719,competitors,I
2719,of,O
2719,this,O
2719,dataset,O
2719,are,B
2719,the,O
2719,Neural,B
2719,Tensor,I
2719,LSTM,I
2719,(,I
2719,NTN,I
2719,-,O
2719,LSTM,O
2719,),O
2719,and,O
2719,HD,B
2719,-,O
2719,LSTM,O
2719,from,B
2719,Tay,B
2719,et,I
2719,al.,I
2720,along,O
2720,with,O
2720,their,O
2720,implementation,B
2720,of,B
2720,the,O
2720,Convolutional,B
2720,Neural,I
2720,Tensor,I
2720,Network,I
2720,",",O
2720,vanilla,B
2720,CNN,I
2720,model,I
2720,",",O
2720,and,O
2720,the,O
2720,Okapi,B
2720,BM,I
2720,-,I
2720,25,I
2720,benchmark,I
2720,.,O
2721,Additionally,O
2721,",",O
2721,we,O
2721,also,O
2721,report,O
2721,our,O
2721,own,O
2721,implementations,O
2721,of,B
2721,QA,O
2721,-,O
2721,BiLSTM,O
2721,",",O
2721,QA,O
2721,-,O
2721,CNN,O
2721,",",O
2721,AP,O
2721,-,O
2721,BiLSTM,O
2721,and,O
2721,AP,O
2721,-,O
2721,CNN,O
2721,on,O
2721,this,O
2721,dataset,O
2721,based,O
2721,on,O
2721,our,O
2721,experimental,O
2721,setup,O
2721,.,O
2722,WikiQA,B
2723,-,O
2723,The,O
2723,key,B
2723,competitors,I
2723,of,O
2723,this,O
2723,dataset,O
2723,are,B
2723,the,O
2723,Paragraph,B
2723,Vector,I
2723,(,I
2723,PV,B
2723,),I
2723,and,I
2723,PV,O
2723,+,O
2723,Cnt,O
2723,models,O
2723,of,O
2723,Le,B
2723,and,O
2723,Mikolv,O
2723,",",O
2723,CNN,B
2723,+,O
2723,Cnt,O
2723,model,O
2723,from,B
2723,Yu,B
2723,et,I
2723,al.,I
2724,and,O
2724,LCLR,B
2724,(,I
2724,Yih,I
2724,et,I
2724,al,I
2724,.,I
2724,),I
2725,We,O
2725,see,B
2725,that,I
2725,the,I
2725,topic,B
2725,ID,I
2725,systems,I
2725,based,I
2725,on,I
2725,Bayesian,I
2725,SMM,I
2725,and,I
2725,logistic,I
2725,regression,I
2725,is,O
2725,better,B
2725,than,I
2725,all,B
2725,the,O
2725,other,O
2725,models,O
2725,",",O
2725,except,B
2725,for,I
2725,the,O
2725,purely,B
2725,discriminative,I
2725,CNN,I
2725,model,I
2725,.,O
2726,For,O
2726,the,O
2726,clean,O
2726,version,O
2726,of,O
2726,this,O
2726,dataset,O
2726,",",O
2726,we,O
2726,also,O
2726,compare,B
2726,with,I
2726,AP,B
2726,-,I
2726,CNN,I
2726,and,O
2726,QA,B
2726,-,O
2726,BiLSTM,O
2726,/,O
2726,CNN,O
2726,.,O
2727,Hyper,O
2727,QA,O
2727,is,O
2727,implemented,B
2727,in,I
2727,Tensor,B
2727,-,I
2727,Flow,I
2727,.,O
2728,The,O
2728,batch,B
2728,size,I
2728,is,B
2728,tuned,B
2728,amongst,B
2728,{,B
2728,50,I
2728,",",I
2728,100,I
2728,",",O
2728,200,O
2728,},O
2728,.,O
2729,Models,B
2729,are,B
2729,trained,B
2729,for,I
2729,25,B
2729,epochs,I
2729,and,O
2729,the,O
2729,model,B
2729,parameters,I
2729,are,O
2729,saved,B
2729,each,B
2729,time,I
2729,the,O
2729,performance,B
2729,on,B
2729,the,O
2729,validation,B
2729,set,I
2729,is,B
2729,topped,B
2729,.,O
2730,The,O
2730,dimension,B
2730,of,B
2730,the,O
2730,projection,B
2730,layer,I
2730,is,B
2730,tuned,B
2730,amongst,B
2730,{,B
2730,100,I
2730,",",I
2730,200,I
2730,",",O
2730,300,O
2730,",",O
2730,400,O
2730,},O
2730,.,O
2731,L2,O
2731,regularization,O
2731,is,B
2731,tuned,B
2731,amongst,B
2731,{,O
2731,0.001,O
2731,",",O
2731,0.0001,O
2731,",",O
2731,0.00001,O
2731,}.,O
2732,The,O
2732,negative,B
2732,sampling,I
2732,rate,I
2732,is,B
2732,tuned,B
2732,from,B
2732,2,B
2732,to,I
2732,8,I
2732,.,O
2733,We,O
2733,adopt,B
2733,the,O
2733,AdaGrad,B
2733,optimizer,I
2733,with,B
2733,initial,B
2733,learning,I
2733,rate,I
2733,tuned,B
2733,amongst,I
2733,{,B
2733,0.2,I
2733,",",I
2733,0.1,I
2733,",",O
2733,0.05,O
2733,",",O
2733,0.01,O
2733,},O
2733,.,O
2734,In,O
2734,this,O
2734,paper,O
2734,",",O
2734,we,O
2734,propose,B
2734,an,O
2734,extremely,B
2734,simple,I
2734,neural,I
2734,ranking,I
2734,model,I
2734,for,B
2734,question,B
2734,answering,I
2734,that,O
2734,achieves,O
2734,highly,O
2734,competitive,O
2734,results,O
2734,on,O
2734,several,O
2734,benchmarks,O
2734,with,O
2734,only,O
2734,a,O
2734,fraction,O
2734,of,O
2734,the,O
2734,runtime,O
2734,and,O
2734,only,O
2734,40K,O
2734,-,O
2734,90,O
2734,K,O
2734,parameters,O
2734,(,O
2734,as,O
2734,opposed,O
2734,to,O
2734,millions,O
2734,),O
2734,.,O
2735,Our,O
2735,neural,B
2735,ranking,I
2735,models,B
2735,the,O
2735,relationships,B
2735,between,B
2735,QA,B
2735,pairs,I
2735,in,B
2735,Hyperbolic,B
2735,space,I
2735,instead,B
2735,of,I
2735,Euclidean,B
2735,space,O
2735,.,O
2736,We,O
2736,can,O
2736,also,O
2736,see,O
2736,that,O
2736,all,O
2736,the,O
2736,topic,B
2736,ID,I
2736,systems,I
2736,based,I
2736,on,I
2736,Bayesian,I
2736,SMM,I
2736,are,O
2736,consistently,B
2736,better,I
2736,than,I
2736,variational,B
2736,auto,I
2736,encoder,I
2736,inspired,I
2736,NVDM,I
2736,",",I
2736,and,I
2736,(,I
2736,non-Bayesian,I
2736,),I
2736,SMM,O
2736,.,O
2737,Hyperbolic,O
2737,space,O
2737,is,B
2737,an,O
2737,embedding,B
2737,space,O
2737,with,B
2737,a,O
2737,constant,B
2737,negative,I
2737,curvature,I
2737,in,B
2737,which,I
2737,the,O
2737,distance,B
2737,towards,B
2737,the,O
2737,border,B
2737,is,O
2737,increasing,B
2737,exponentially,I
2737,.,O
2738,Hyperbolic,O
2738,Representation,O
2738,Learning,O
2738,for,O
2738,Fast,O
2738,and,O
2738,Efficient,O
2738,Neural,B
2738,Question,I
2738,Answering,I
2739,reports,O
2739,the,O
2739,experimental,O
2739,results,O
2739,on,B
2739,SemEvalCQA,B
2739,.,O
2740,Our,O
2740,proposed,B
2740,approach,I
2740,achieves,B
2740,highly,B
2740,competitive,I
2740,performance,I
2740,on,O
2740,this,O
2740,dataset,O
2740,.,O
2741,The,O
2741,performance,B
2741,of,B
2741,our,B
2741,model,I
2741,on,B
2741,MAP,B
2741,is,B
2741,marginally,B
2741,short,I
2741,from,B
2741,the,O
2741,best,B
2741,performing,I
2741,model,O
2741,.,O
2742,Specifically,O
2742,",",O
2742,we,O
2742,have,O
2742,obtained,B
2742,the,I
2742,best,B
2742,P@1,B
2742,performance,I
2742,over,I
2742,all,I
2742,",",O
2742,outperforming,B
2742,the,O
2742,state,B
2742,-,I
2742,of,I
2742,-,O
2742,the,O
2742,-,O
2742,art,O
2742,AI,O
2742,-,O
2742,CNN,O
2742,model,O
2742,by,B
2742,3,B
2742,%,I
2742,in,B
2742,terms,I
2742,of,O
2742,P@1,O
2742,.,O
2743,reports,O
2743,the,O
2743,results,O
2743,on,B
2743,TrecQA,B
2743,(,I
2743,raw,I
2743,),I
2743,.,O
2744,Hyper,O
2744,QA,O
2744,achieves,B
2744,very,O
2744,competitive,B
2744,performance,I
2744,on,O
2744,both,O
2744,MAP,B
2744,and,I
2744,MRR,I
2744,metrics,I
2744,.,O
2745,Specifically,O
2745,",",O
2745,Hyper,O
2745,QA,O
2745,outperforms,B
2745,the,O
2745,basic,B
2745,CNN,I
2745,model,I
2745,of,I
2745,(,I
2745,S&M,I
2745,),I
2745,by,B
2745,2,O
2745,%,O
2745,?,O
2746,3,O
2746,%,O
2746,in,B
2746,terms,I
2746,of,I
2746,MAP,B
2746,/,I
2746,MRR,I
2746,.,O
2747,Similarly,O
2747,",",O
2747,reports,O
2747,the,O
2747,results,O
2747,on,O
2747,TrecQA,B
2747,(,I
2747,clean,I
2747,),I
2747,.,O
2748,As,O
2748,expected,O
2748,",",O
2748,running,B
2748,a,O
2748,transitive,B
2748,closure,I
2748,module,I
2748,after,B
2748,the,O
2748,temporal,B
2748,rule,I
2748,-,I
2748,based,I
2748,sieve,I
2748,(,I
2748,RB,I
2748,+,I
2748,TR,I
2748,),I
2748,results,B
2748,in,I
2748,improving,B
2748,recall,I
2748,",",O
2748,but,O
2748,the,O
2748,over,O
2748,all,O
2748,performance,O
2748,is,O
2748,still,O
2748,lacking,O
2748,(,O
2748,less,O
2748,than,O
2748,.30,O
2748,F1-score,O
2748,),O
2748,.,O
2749,Similarly,O
2749,",",O
2749,Hyper,B
2749,QA,B
2749,also,O
2749,outperforms,B
2749,MP,B
2749,-,I
2749,CNN,I
2749,",",O
2749,AP,B
2749,-,O
2749,CNN,O
2749,and,O
2749,QA,O
2749,-,O
2749,CNN,O
2749,.,O
2750,To,O
2750,address,O
2750,this,O
2750,",",O
2750,this,O
2750,paper,O
2750,introduces,B
2750,the,O
2750,Stanford,B
2750,Natural,I
2750,Language,I
2750,Inference,I
2750,(,I
2750,SNLI,I
2750,),I
2750,corpus,I
2750,",",O
2750,a,O
2750,collection,B
2750,of,B
2750,sentence,B
2750,pairs,I
2750,labeled,B
2750,for,I
2750,entailment,B
2750,",",O
2750,contradiction,B
2750,",",O
2750,and,O
2750,semantic,B
2750,independence,I
2750,.,O
2751,At,B
2751,"570,152",B
2751,sentence,I
2751,pairs,I
2751,",",O
2751,SNLI,B
2751,is,B
2751,two,B
2751,orders,I
2751,of,B
2751,magnitude,I
2751,larger,I
2751,than,B
2751,all,O
2751,other,B
2751,resources,I
2751,of,O
2751,its,B
2751,type,I
2751,.,O
2752,And,O
2752,",",O
2752,in,B
2752,contrast,O
2752,to,O
2752,many,O
2752,such,O
2752,resources,O
2752,",",O
2752,all,O
2752,of,O
2752,its,O
2752,sentences,B
2752,and,O
2752,labels,O
2752,were,O
2752,written,B
2752,by,I
2752,humans,B
2752,in,O
2752,a,O
2752,grounded,B
2752,",",O
2752,naturalistic,O
2752,context,O
2752,.,O
2753,In,B
2753,a,O
2753,separate,B
2753,validation,I
2753,phase,I
2753,",",O
2753,we,O
2753,collected,B
2753,four,B
2753,additional,I
2753,judgments,I
2753,for,B
2753,each,B
2753,label,I
2753,for,O
2753,"56,941",B
2753,of,B
2753,the,O
2753,examples,B
2753,.,O
2754,Of,B
2754,these,O
2754,",",O
2754,98,B
2754,%,I
2754,of,O
2754,cases,B
2754,emerge,B
2754,with,I
2754,a,O
2754,threeannotator,B
2754,consensus,I
2754,",",O
2754,and,O
2754,58,B
2754,%,O
2754,see,B
2754,a,O
2754,unanimous,B
2754,consensus,O
2754,from,B
2754,all,B
2754,five,I
2754,annotators,I
2754,.,O
2755,A,O
2755,large,O
2755,annotated,O
2755,corpus,O
2755,for,O
2755,learning,O
2755,natural,B
2755,language,I
2755,inference,I
2756,Thus,O
2756,",",O
2756,natural,B
2756,language,I
2756,inference,I
2756,(,I
2756,NLI,I
2756,),I
2756,-,O
2756,characterizing,O
2756,and,O
2756,using,O
2756,these,O
2756,relations,O
2756,in,O
2756,computational,O
2756,systems,O
2756,),O
2756,-,O
2756,is,O
2756,essential,O
2756,in,O
2756,tasks,O
2756,ranging,O
2756,from,O
2756,information,O
2756,retrieval,O
2756,to,O
2756,semantic,O
2756,parsing,O
2756,to,O
2756,commonsense,O
2756,reasoning,O
2756,.,O
2757,NLI,B
2757,has,O
2757,been,O
2757,addressed,O
2757,using,O
2757,a,O
2757,variety,O
2757,of,O
2757,techniques,O
2757,",",O
2757,including,O
2757,those,O
2757,based,O
2757,on,O
2757,symbolic,O
2757,logic,O
2757,",",O
2757,knowledge,O
2757,bases,O
2757,",",O
2757,and,O
2757,neural,O
2757,networks,O
2757,.,O
2758,The,O
2758,sum,B
2758,of,I
2758,words,I
2758,model,I
2758,performed,B
2758,slightly,B
2758,worse,I
2758,than,B
2758,the,O
2758,fundamentally,B
2758,similar,I
2758,lexicalized,I
2758,classifier,I
2758,while,O
2758,the,O
2758,sum,O
2758,of,O
2758,words,O
2758,model,O
2758,can,O
2758,use,O
2758,pretrained,O
2758,word,O
2758,embeddings,O
2758,to,O
2758,better,O
2758,handle,O
2758,rare,O
2758,words,O
2758,",",O
2758,it,O
2758,lacks,O
2758,even,O
2758,the,O
2758,rudimentary,O
2758,sensitivity,O
2758,to,O
2758,word,O
2758,order,O
2758,that,O
2758,the,O
2758,lexicalized,O
2758,model,O
2758,'s,O
2758,bigram,O
2758,features,O
2758,provide,O
2758,.,O
2759,Combining,B
2759,rule,B
2759,-,I
2759,based,I
2759,and,I
2759,machine,I
2759,-,O
2759,learned,O
2759,sieves,O
2759,(,O
2759,RB,O
2759,+,O
2759,ML,O
2759,),O
2759,yields,B
2759,a,O
2759,slight,B
2759,improvement,I
2759,compared,B
2759,with,I
2759,enabling,B
2759,only,I
2759,the,I
2759,machine,O
2759,-,O
2759,learned,O
2759,sieve,O
2759,in,B
2759,the,O
2759,system,B
2759,(,O
2759,ML,O
2759,),O
2759,.,O
2760,While,O
2760,the,O
2760,lexicalized,O
2760,model,O
2760,fits,O
2760,the,O
2760,training,O
2760,set,O
2760,almost,O
2760,perfectly,O
2760,",",O
2760,the,O
2760,gap,B
2760,between,B
2760,train,B
2760,and,I
2760,test,I
2760,set,O
2760,accuracy,O
2760,is,B
2760,relatively,B
2760,small,I
2760,for,B
2760,all,B
2760,three,I
2760,neural,I
2760,network,I
2760,models,I
2760,",",O
2760,suggesting,O
2760,that,O
2760,research,O
2760,into,O
2760,significantly,O
2760,higher,O
2760,capacity,O
2760,versions,O
2760,of,O
2760,these,O
2760,models,O
2760,would,O
2760,be,O
2760,productive,O
2760,.,O
2761,In,O
2761,addition,O
2761,",",O
2761,though,O
2761,the,O
2761,LSTM,B
2761,and,O
2761,the,O
2761,lexicalized,O
2761,model,O
2761,show,O
2761,similar,O
2761,performance,O
2761,when,O
2761,trained,O
2761,on,B
2761,the,O
2761,current,O
2761,full,O
2761,corpus,O
2761,",",O
2761,the,O
2761,somewhat,B
2761,steeper,I
2761,slope,I
2761,for,B
2761,the,O
2761,LSTM,O
2761,hints,B
2761,that,I
2761,its,O
2761,ability,B
2761,to,I
2761,learn,I
2761,arbitrarily,B
2761,structured,I
2761,representations,I
2761,of,B
2761,sentence,B
2761,meaning,I
2761,may,O
2761,give,B
2761,it,I
2761,an,O
2761,advantage,B
2761,over,B
2761,the,O
2761,more,B
2761,constrained,I
2761,lexicalized,O
2761,model,O
2761,on,O
2761,still,O
2761,larger,B
2761,datasets,I
2761,.,O
2762,Of,B
2762,the,O
2762,two,B
2762,RNN,I
2762,models,I
2762,",",O
2762,the,O
2762,LSTM,B
2762,'s,I
2762,more,B
2762,robust,I
2762,ability,I
2762,to,B
2762,learn,I
2762,long,B
2762,-,I
2762,term,I
2762,dependencies,I
2762,serves,B
2762,it,O
2762,well,B
2762,",",O
2762,giving,O
2762,it,O
2762,a,O
2762,substantial,O
2762,advantage,O
2762,over,O
2762,the,O
2762,plain,O
2762,RNN,O
2762,",",O
2762,and,O
2762,resulting,B
2762,in,I
2762,performance,B
2762,that,B
2762,is,I
2762,essentially,B
2762,equivalent,I
2762,to,O
2762,the,O
2762,lexicalized,B
2762,classifier,I
2762,on,B
2762,the,O
2762,test,B
2762,set,I
2762,(,O
2762,LSTM,O
2762,performance,O
2762,near,O
2762,the,O
2762,stopping,O
2762,iteration,O
2762,varies,O
2762,by,O
2762,up,O
2762,to,O
2762,0.5,O
2762,%,O
2762,between,O
2762,evaluation,O
2762,steps,O
2762,),O
2762,.,O
2763,First,O
2763,",",O
2763,we,O
2763,explore,B
2763,the,O
2763,effect,B
2763,of,B
2763,additional,B
2763,information,I
2763,by,B
2763,adopting,I
2763,a,O
2763,pretrained,B
2763,language,I
2763,model,I
2763,(,I
2763,LM,I
2763,),I
2763,to,B
2763,compute,I
2763,the,O
2763,vector,B
2763,representation,I
2763,of,O
2763,the,O
2763,input,B
2763,text,I
2763,.,O
2764,Last,O
2764,",",O
2764,we,O
2764,explore,O
2764,the,O
2764,effect,O
2764,of,O
2764,different,B
2764,objective,I
2764,functions,I
2764,(,O
2764,listwise,B
2764,and,I
2764,pointwise,I
2764,learning,I
2764,),O
2764,.,O
2765,Following,O
2765,this,O
2765,study,O
2765,",",O
2765,we,O
2765,select,B
2765,an,O
2765,ELMo,B
2765,language,I
2765,model,I
2765,for,O
2765,this,O
2765,study,O
2765,.,O
2766,We,O
2766,investigate,B
2766,the,O
2766,applicability,B
2766,of,B
2766,transfer,B
2766,learning,I
2766,(,I
2766,TL,I
2766,),I
2766,using,B
2766,a,O
2766,large,B
2766,-,I
2766,scale,I
2766,corpus,I
2766,that,O
2766,is,O
2766,created,B
2766,for,I
2766,a,O
2766,relevant,B
2766,-,O
2766,sentence,O
2766,-,O
2766,selection,O
2766,task,O
2766,(,O
2766,i.e.,B
2767,",",O
2767,question,B
2767,-,I
2767,answering,I
2767,NLI,I
2767,(,I
2767,QNLI,I
2767,),I
2767,dataset,I
2767,),O
2767,.,O
2768,Second,O
2768,",",O
2768,we,O
2768,further,O
2768,enhance,B
2768,one,B
2768,of,I
2768,the,I
2768,baseline,I
2768,models,I
2768,",",O
2768,Comp,B
2768,-,I
2768,Clip,I
2768,(,I
2768,refer,O
2768,to,O
2768,the,O
2768,discussion,O
2768,in,O
2768,3.1,O
2768,),O
2768,",",O
2768,for,B
2768,the,O
2768,target,B
2768,QA,I
2768,task,I
2768,by,B
2768,proposing,I
2768,a,O
2768,novel,B
2768,latent,I
2768,clustering,I
2768,(,O
2768,LC,O
2768,),O
2768,method,O
2768,.,O
2769,The,O
2769,LC,B
2769,method,I
2769,computes,B
2769,latent,B
2769,cluster,I
2769,information,I
2769,for,B
2769,target,B
2769,samples,I
2769,by,B
2769,creating,I
2769,a,O
2769,latent,O
2769,memory,B
2769,space,I
2769,and,O
2769,calculating,B
2769,the,O
2769,similarity,B
2769,between,B
2769,the,O
2769,sample,B
2769,and,O
2769,the,O
2769,memory,O
2769,.,O
2770,By,B
2770,an,O
2770,endto,B
2770,-,I
2770,end,I
2770,learning,I
2770,process,I
2770,with,O
2770,the,O
2770,answer-selection,O
2770,task,O
2770,",",O
2770,the,O
2770,LC,O
2770,method,O
2770,assigns,B
2770,true,B
2770,-,O
2770,label,O
2770,question,O
2770,-,O
2770,answer,O
2770,pairs,O
2770,to,B
2770,similar,B
2770,clusters,I
2770,.,O
2771,Introducing,B
2771,the,O
2771,temporal,B
2771,reasoner,I
2771,module,I
2771,between,B
2771,the,O
2771,two,B
2771,sieves,I
2771,(,I
2771,RB,I
2771,+,I
2771,TR,I
2771,+,O
2771,ML,O
2771,),O
2771,proves,B
2771,to,I
2771,be,I
2771,even,B
2771,more,I
2771,beneficial,I
2771,.,O
2772,To,O
2772,implement,B
2772,the,O
2772,Comp,B
2772,-,I
2772,Clip,I
2772,model,I
2772,",",O
2772,we,O
2772,apply,B
2772,a,O
2772,context,B
2772,projection,I
2772,weight,I
2772,matrix,I
2772,with,B
2772,100,B
2772,dimensions,I
2772,that,O
2772,are,O
2772,shared,B
2772,between,I
2772,the,O
2772,question,B
2772,part,I
2772,and,O
2772,the,O
2772,answer,B
2772,part,O
2772,(,O
2772,eq.,O
2773,In,B
2773,the,O
2773,aggregation,B
2773,part,I
2773,",",O
2773,we,O
2773,use,B
2773,1,B
2773,-,I
2773,D,I
2773,CNN,I
2773,with,B
2773,a,O
2773,total,B
2773,of,I
2773,500,I
2773,filters,I
2773,",",O
2773,which,O
2773,involves,O
2773,five,O
2773,types,O
2773,of,O
2773,filters,O
2773,K,O
2773,?,O
2774,We,O
2774,select,B
2774,k,B
2774,(,O
2774,for,B
2774,the,O
2774,kmax,O
2774,-,O
2774,pool,O
2774,in,O
2774,equation,O
2774,5,O
2774,),O
2774,as,B
2774,6,B
2774,and,I
2774,4,I
2774,for,O
2774,the,O
2774,WikiQA,B
2774,and,O
2774,TREC,O
2774,-,O
2774,QA,O
2774,case,O
2774,",",O
2774,respectively,O
2774,.,O
2775,In,O
2775,both,O
2775,datasets,O
2775,",",O
2775,we,O
2775,apply,B
2775,8,B
2775,latent,I
2775,clusters,I
2775,.,O
2776,The,O
2776,vocabulary,B
2776,size,I
2776,in,B
2776,the,O
2776,WiKiQA,B
2776,",",I
2776,TREC,I
2776,-,I
2776,QA,I
2776,and,I
2776,QNLI,I
2776,dataset,I
2776,are,B
2776,"30,104",B
2776,",",O
2776,"56,908",O
2776,and,O
2776,"154,442",O
2776,",",O
2776,respectively,O
2776,.,O
2777,When,O
2777,applying,B
2777,the,O
2777,TL,B
2777,",",O
2777,the,O
2777,vocabulary,B
2777,size,I
2777,is,O
2777,set,B
2777,to,I
2777,"154,442",B
2777,",",O
2777,and,O
2777,the,O
2777,dimension,B
2777,of,B
2777,the,O
2777,context,B
2777,projection,I
2777,weight,I
2777,matrix,I
2777,is,O
2777,set,O
2777,to,O
2777,300,B
2777,.,O
2778,We,O
2778,use,B
2778,the,O
2778,Adam,B
2778,optimizer,I
2778,",",O
2778,including,B
2778,gradient,B
2778,clipping,I
2778,",",O
2778,by,B
2778,the,O
2778,norm,B
2778,at,B
2778,a,O
2778,threshold,B
2778,of,B
2778,5,B
2778,.,O
2779,For,B
2779,the,O
2779,purpose,O
2779,of,B
2779,regularization,B
2779,",",O
2779,we,O
2779,applied,B
2779,a,O
2779,dropout,B
2779,with,B
2779,a,O
2779,ratio,B
2779,of,O
2779,0.5,B
2779,..,O
2780,A,O
2780,Compare,O
2780,-,O
2780,Aggregate,O
2780,Model,O
2780,with,O
2780,Latent,O
2780,Clustering,O
2780,for,O
2780,Answer,B
2780,Selection,I
2781,In,O
2781,this,O
2781,paper,O
2781,",",O
2781,we,O
2781,propose,O
2781,a,O
2781,novel,O
2781,method,O
2781,for,O
2781,a,O
2781,sentence,B
2781,-,I
2781,level,I
2781,answer-,I
2781,selection,I
2781,task,O
2781,that,O
2781,is,O
2781,a,O
2781,fundamental,O
2781,problem,O
2781,in,O
2781,natural,O
2781,language,O
2781,processing,O
2781,.,O
2782,Span,O
2782,-,O
2782,Level,O
2782,Model,O
2782,for,O
2782,Relation,B
2782,Extraction,I
2783,The,O
2783,CATENA,B
2783,system,I
2783,includes,B
2783,two,B
2783,main,I
2783,classification,I
2783,modules,I
2783,",",O
2783,one,B
2783,for,I
2783,temporal,B
2783,and,O
2783,the,O
2783,other,B
2783,for,O
2783,causal,B
2783,relations,I
2783,between,O
2783,events,O
2783,.,O
2784,Wiki,O
2784,QA,O
2784,:,O
2784,For,B
2784,the,O
2784,WikiQA,B
2784,dataset,I
2784,",",O
2784,the,O
2784,pointwise,B
2784,learning,I
2784,approach,I
2784,shows,B
2784,a,O
2784,better,B
2784,performance,I
2784,than,B
2784,the,O
2784,listwise,B
2784,learning,O
2784,approach,O
2784,.,O
2785,We,O
2785,combine,B
2785,LM,I
2785,with,B
2785,the,O
2785,base,B
2785,model,I
2785,(,I
2785,Comp,I
2785,-,I
2785,Clip,I
2785,+,I
2785,LM,O
2785,),O
2785,and,O
2785,observe,B
2785,a,O
2785,significant,B
2785,improvement,I
2785,in,B
2785,performance,B
2785,in,O
2785,terms,O
2785,of,O
2785,MAP,B
2785,(,O
2785,0.714,O
2785,to,O
2785,0.746,O
2785,absolute,O
2785,),O
2785,.,O
2786,When,O
2786,we,O
2786,add,B
2786,the,O
2786,LC,O
2786,method,O
2786,(,O
2786,Comp,O
2786,-,O
2786,Clip,O
2786,+,O
2786,LM,O
2786,+,O
2786,LC,O
2786,),O
2786,",",O
2786,the,O
2786,best,B
2786,previous,I
2786,results,I
2786,are,B
2786,surpassed,B
2786,in,B
2786,terms,I
2786,of,I
2786,MAP,B
2786,(,O
2786,0.718,O
2786,to,O
2786,0.764,O
2786,absolute,O
2786,),O
2786,.,O
2787,The,O
2787,pointwise,B
2787,learning,I
2787,approach,I
2787,also,O
2787,shows,B
2787,excellent,B
2787,performance,I
2787,with,B
2787,the,O
2787,TREC,B
2787,-,I
2787,QA,I
2787,dataset,I
2787,.,O
2788,In,O
2788,particular,O
2788,",",O
2788,our,B
2788,model,I
2788,outperforms,B
2788,the,O
2788,best,B
2788,previous,I
2788,result,I
2788,when,O
2788,we,O
2788,add,B
2788,LC,I
2788,method,I
2788,",",O
2788,(,O
2788,Comp,O
2788,-,O
2788,Clip,O
2788,+,O
2788,LM,O
2788,+,O
2788,LC,O
2788,),O
2788,in,O
2788,terms,O
2788,of,O
2788,MAP,B
2788,(,O
2788,0.865,B
2788,to,B
2788,0.868,B
2788,),O
2788,.,O
2789,As,O
2789,in,B
2789,the,O
2789,WikiQA,O
2789,case,O
2789,",",O
2789,we,O
2789,achieve,B
2789,additional,B
2789,performance,I
2789,gains,I
2789,in,O
2789,terms,O
2789,of,O
2789,the,O
2789,MAP,B
2789,as,O
2789,we,O
2789,apply,B
2789,LM,B
2789,",",O
2789,LC,O
2789,",",O
2789,and,O
2789,TL,O
2789,(,O
2789,0.850,B
2789,",",O
2789,0.868,O
2789,and,O
2789,0.875,O
2789,",",O
2789,respectively,O
2789,),O
2789,.,O
2790,We,O
2790,found,B
2790,large,B
2790,drops,I
2790,when,O
2790,removing,B
2790,the,O
2790,context,B
2790,modeling,I
2790,component,I
2790,",",O
2790,indicating,O
2790,that,O
2790,the,O
2790,context,O
2790,information,O
2790,provided,O
2790,by,O
2790,the,O
2790,Bi,O
2790,-,O
2790,LSTMs,O
2790,is,O
2790,crucial,O
2790,for,O
2790,the,O
2790,following,O
2790,components,O
2790,(,O
2790,e.g.,O
2791,The,O
2791,use,B
2791,of,O
2791,our,O
2791,similarity,B
2791,focus,I
2791,layer,I
2791,is,B
2791,also,O
2791,beneficial,B
2791,",",O
2791,especially,O
2791,on,B
2791,the,O
2791,WikiQA,B
2791,data,I
2791,.,O
2792,When,O
2792,we,O
2792,replaced,B
2792,the,O
2792,entire,B
2792,similarity,I
2792,focus,I
2792,layer,I
2792,with,B
2792,a,O
2792,random,B
2792,dropout,I
2792,layer,O
2792,(,O
2792,p,O
2792,=,O
2792,0.3,O
2792,),O
2792,",",O
2792,the,O
2792,dropout,O
2792,layer,O
2792,hurts,B
2792,accuracy,B
2792,;,O
2792,this,O
2792,shows,O
2792,the,O
2792,importance,O
2792,of,O
2792,directing,O
2792,the,O
2792,model,O
2792,to,O
2792,focus,O
2792,on,O
2792,important,O
2792,pairwise,O
2792,word,O
2792,interactions,O
2792,",",O
2792,to,O
2792,better,O
2792,capture,O
2792,similarity,O
2792,.,O
2793,As,O
2793,shown,O
2793,in,O
2793,",",O
2793,they,O
2793,both,O
2793,take,B
2793,as,O
2793,input,O
2793,a,O
2793,document,B
2793,annotated,B
2793,with,I
2793,the,O
2793,so,O
2793,-,O
2793,called,O
2793,temporal,B
2793,entities,I
2793,according,B
2793,to,I
2793,TimeML,B
2793,guidelines,I
2793,",",O
2793,including,B
2793,the,O
2793,document,O
2793,creation,O
2793,time,O
2793,(,O
2793,DCT,O
2793,),O
2793,",",O
2793,events,B
2793,and,I
2793,time,O
2793,expressions,O
2793,(,O
2793,timexes,O
2793,),O
2793,.,O
2794,In,O
2794,contrast,O
2794,",",O
2794,we,O
2794,focus,B
2794,on,I
2794,capturing,B
2794,fine,B
2794,-,I
2794,grained,I
2794,word,I
2794,-,O
2794,level,O
2794,information,O
2794,directly,O
2794,.,O
2795,First,O
2795,",",O
2795,instead,B
2795,of,I
2795,using,I
2795,sentence,B
2795,modeling,I
2795,",",O
2795,we,O
2795,propose,B
2795,pairwise,B
2795,word,I
2795,interaction,I
2795,modeling,O
2795,that,B
2795,encourages,I
2795,explicit,B
2795,word,O
2795,context,O
2795,interactions,O
2795,across,B
2795,sentences,B
2795,.,O
2796,Second,O
2796,",",O
2796,based,B
2796,on,I
2796,the,O
2796,pairwise,B
2796,word,I
2796,interactions,I
2796,",",O
2796,we,O
2796,describe,B
2796,a,O
2796,novel,B
2796,similarity,B
2796,focus,I
2796,layer,I
2796,which,B
2796,helps,B
2796,the,O
2796,model,B
2796,selectively,B
2796,identify,I
2796,important,B
2796,word,O
2796,interactions,O
2796,depending,O
2796,on,O
2796,their,O
2796,importance,O
2796,for,B
2796,similarity,O
2796,measurement,O
2796,.,O
2797,For,B
2797,the,O
2797,SICK,B
2797,and,I
2797,MSRVID,I
2797,experiments,I
2797,",",O
2797,we,O
2797,used,B
2797,300,B
2797,-,I
2797,dimension,I
2797,Glo,B
2797,Ve,I
2797,word,I
2797,embeddings,I
2797,.,O
2798,For,O
2798,the,O
2798,STS2014,B
2798,",",I
2798,WikiQA,I
2798,",",O
2798,and,O
2798,TrecQA,O
2798,experiments,O
2798,",",O
2798,we,O
2798,used,B
2798,300,B
2798,dimension,I
2798,PARAGRAM,B
2798,-,I
2798,SL999,I
2798,embeddings,I
2798,from,B
2798,and,O
2798,the,O
2798,PARAGRAM,O
2798,-,O
2798,PHRASE,O
2798,embeddings,O
2798,from,O
2798,",",O
2798,trained,B
2798,on,I
2798,word,B
2798,pairs,I
2798,from,O
2798,the,O
2798,Paraphrase,B
2798,Database,I
2798,(,I
2798,PPDB,I
2798,),I
2798,.,O
2799,Our,O
2799,timing,O
2799,experiments,O
2799,were,O
2799,conducted,B
2799,on,I
2799,an,O
2799,Intel,B
2799,Xeon,I
2799,E5,I
2799,-,I
2799,2680,I
2799,CPU,I
2799,.,O
2800,Due,O
2800,to,B
2800,sentence,B
2800,length,I
2800,variations,I
2800,",",I
2800,for,B
2800,the,O
2800,SICK,B
2800,and,I
2800,MSRVID,I
2800,data,I
2800,we,O
2800,padded,B
2800,the,O
2800,sentences,B
2800,to,O
2800,32,B
2800,words,I
2800,;,O
2800,for,O
2800,the,O
2800,STS2014,B
2800,",",O
2800,WikiQA,O
2800,",",O
2800,and,O
2800,TrecQA,O
2800,data,O
2800,",",O
2800,we,O
2800,padded,O
2800,the,O
2800,sentences,O
2800,to,O
2800,48,B
2800,words,O
2800,..,O
2801,Pairwise,O
2801,Word,O
2801,Interaction,O
2801,Modeling,O
2801,with,O
2801,Deep,O
2801,Neural,O
2801,Networks,O
2801,for,O
2801,Semantic,B
2801,Similarity,I
2801,Measurement,I
2802,Given,O
2802,two,O
2802,pieces,O
2802,of,O
2802,text,O
2802,",",O
2802,measuring,O
2802,their,O
2802,semantic,B
2802,textual,I
2802,similarity,I
2802,(,I
2802,STS,I
2802,),I
2802,remains,O
2802,a,O
2802,fundamental,O
2802,problem,O
2802,in,O
2802,language,O
2802,research,O
2802,and,O
2802,lies,O
2802,at,O
2802,the,O
2802,core,O
2802,of,O
2802,many,O
2802,language,O
2802,processing,O
2802,tasks,O
2802,",",O
2802,including,O
2802,question,O
2802,answering,O
2802,",",O
2802,query,O
2802,ranking,O
2802,",",O
2802,and,O
2802,paraphrase,O
2802,generation,O
2802,.,O
2803,The,O
2803,output,B
2803,is,B
2803,the,O
2803,same,B
2803,document,I
2803,with,B
2803,temporal,B
2803,links,I
2803,(,I
2803,TLINKs,I
2803,),I
2803,set,B
2803,between,I
2803,pairs,B
2803,of,B
2803,temporal,O
2803,entities,O
2803,",",O
2803,each,O
2803,assigned,O
2803,to,O
2803,one,O
2803,of,O
2803,the,O
2803,TimeML,O
2803,temporal,O
2803,relation,O
2803,types,O
2803,",",O
2803,such,O
2803,as,O
2803,or,O
2803,SIMULTANEOUS,O
2803,",",O
2803,which,O
2803,denotes,O
2803,the,O
2803,temporal,O
2803,ordering,O
2803,.,O
2804,The,O
2804,neural,O
2804,network,O
2804,models,O
2804,in,O
2804,the,O
2804,table,O
2804,",",O
2804,paragraph,B
2804,vector,I
2804,(,I
2804,PV,I
2804,),I
2804,",",O
2804,CNN,O
2804,",",O
2804,and,O
2804,PV,O
2804,-,O
2804,Cnt,O
2804,/,O
2804,CNN,O
2804,-,O
2804,Cnt,O
2804,with,O
2804,word,O
2804,matching,O
2804,features,O
2804,",",O
2804,are,O
2804,mostly,O
2804,based,O
2804,on,O
2804,sentence,O
2804,modeling,O
2804,.,O
2805,Our,O
2805,model,O
2805,outperforms,B
2805,them,O
2805,all,O
2805,.,O
2806,Not,O
2806,surprisingly,O
2806,",",O
2806,the,O
2806,n-gram,B
2806,functionality,I
2806,is,B
2806,important,B
2806,",",O
2806,contributing,B
2806,almost,B
2806,5,I
2806,%,I
2806,accuracy,I
2806,improvement,I
2806,.,O
2807,The,O
2807,top,B
2807,N,I
2807,function,I
2807,contributes,B
2807,very,B
2807,little,I
2807,to,B
2807,the,O
2807,over,B
2807,all,I
2807,performance,I
2807,",",O
2807,suggesting,O
2807,that,O
2807,most,O
2807,multi,O
2807,questions,O
2807,have,O
2807,their,O
2807,evidence,O
2807,distributed,O
2807,across,O
2807,contiguous,O
2807,sentences,O
2807,.,O
2808,Simple,O
2808,word,O
2808,-,O
2808,by,O
2808,-,O
2808,word,O
2808,matching,O
2808,is,O
2808,obviously,O
2808,useful,B
2808,on,B
2808,MCTest,B
2808,.,O
2809,The,O
2809,sequential,B
2809,sliding,I
2809,window,I
2809,makes,B
2809,a,O
2809,3,B
2809,%,I
2809,contribution,I
2809,",",O
2809,highlighting,O
2809,the,O
2809,importance,O
2809,of,O
2809,word,O
2809,-,O
2809,distance,O
2809,measures,O
2809,.,O
2810,On,O
2810,the,O
2810,other,O
2810,hand,O
2810,",",O
2810,the,O
2810,dependency,B
2810,-,I
2810,based,I
2810,sliding,I
2810,window,I
2810,makes,B
2810,only,O
2810,a,O
2810,minor,B
2810,contribution,I
2810,.,O
2811,Finally,O
2811,",",O
2811,the,O
2811,exogenous,B
2811,word,I
2811,weights,I
2811,make,B
2811,a,O
2811,significant,B
2811,contribution,I
2811,of,B
2811,almost,B
2811,5,I
2811,%,I
2811,.,O
2812,Ablating,B
2812,the,O
2812,sentential,B
2812,component,I
2812,made,B
2812,the,O
2812,most,B
2812,significant,I
2812,difference,I
2812,",",O
2812,reducing,B
2812,performance,B
2812,by,B
2812,more,B
2812,than,I
2812,5,I
2812,%,I
2812,.,O
2813,The,O
2813,document,B
2813,is,O
2813,also,O
2813,annotated,B
2813,with,I
2813,causal,B
2813,relations,I
2813,(,I
2813,CLINKs,I
2813,),I
2813,between,B
2813,event,B
2813,pairs,I
2813,.,O
2814,For,B
2814,word,I
2814,vectors,I
2814,we,O
2814,use,B
2814,Google,B
2814,'s,I
2814,publicly,I
2814,available,I
2814,embeddings,I
2814,",",O
2814,trained,B
2814,with,I
2814,word2vec,B
2814,on,B
2814,the,O
2814,100,B
2814,-,I
2814,billion,I
2814,-,O
2814,word,O
2814,News,O
2814,corpus,O
2814,.,O
2815,These,O
2815,vectors,O
2815,are,O
2815,kept,B
2815,fixed,B
2815,throughout,B
2815,training,B
2815,",",O
2815,since,O
2815,we,O
2815,found,O
2815,that,O
2815,training,O
2815,them,O
2815,was,O
2815,not,O
2815,helpful,O
2815,(,O
2815,likely,O
2815,because,O
2815,of,O
2815,MCTest,O
2815,'s,O
2815,size,O
2815,),O
2815,.,O
2816,The,O
2816,vectors,O
2816,are,B
2816,300,B
2816,-,I
2816,dimensional,I
2816,(,O
2816,d,O
2816,=,O
2816,300,O
2816,),O
2816,.,O
2817,We,O
2817,found,O
2817,dropout,B
2817,to,O
2817,be,O
2817,particularly,O
2817,effective,O
2817,at,O
2817,improving,O
2817,generalization,O
2817,from,O
2817,the,O
2817,training,O
2817,to,O
2817,the,O
2817,test,O
2817,set,O
2817,",",O
2817,and,O
2817,used,B
2817,0.5,B
2817,as,B
2817,the,O
2817,dropout,O
2817,probability,O
2817,.,O
2818,We,O
2818,used,O
2818,the,O
2818,Adam,B
2818,optimizer,I
2818,with,B
2818,the,O
2818,standard,B
2818,settings,I
2818,(,O
2818,Kingma,O
2818,and,O
2818,Ba,O
2818,",",O
2818,2014,O
2818,),O
2818,and,O
2818,a,O
2818,learning,B
2818,rate,I
2818,of,B
2818,0.003,B
2818,.,O
2819,Dropout,B
2819,occurs,B
2819,after,I
2819,all,B
2819,neural,I
2819,-,I
2819,network,I
2819,transformations,I
2819,",",O
2819,if,O
2819,those,O
2819,transformations,O
2819,are,O
2819,allowed,B
2819,to,I
2819,change,B
2819,with,B
2819,training,B
2819,.,O
2820,We,O
2820,present,B
2820,a,O
2820,parallel,B
2820,-,I
2820,hierarchical,I
2820,approach,I
2820,to,I
2820,machine,B
2820,comprehension,I
2820,designed,B
2820,to,O
2820,work,B
2820,well,I
2820,in,B
2820,a,O
2820,data,B
2820,-,O
2820,limited,O
2820,setting,O
2820,.,O
2821,Our,O
2821,model,O
2821,learns,B
2821,to,I
2821,comprehend,B
2821,at,B
2821,a,O
2821,high,B
2821,level,I
2821,even,B
2821,when,I
2821,data,B
2821,is,B
2821,sparse,B
2821,.,O
2822,The,O
2822,key,O
2822,to,B
2822,our,O
2822,model,O
2822,is,O
2822,that,O
2822,it,O
2822,compares,B
2822,the,O
2822,question,B
2822,and,I
2822,answer,I
2822,candidates,I
2822,to,O
2822,the,O
2822,text,B
2822,using,B
2822,several,B
2822,distinct,I
2822,perspectives,I
2822,.,O
2823,The,O
2823,semantic,B
2823,perspective,I
2823,compares,B
2823,the,O
2823,hypothesis,B
2823,to,B
2823,sentences,B
2823,in,B
2823,the,O
2823,text,B
2823,viewed,B
2823,as,I
2823,single,B
2823,",",I
2823,self,I
2823,-,I
2823,contained,I
2823,thoughts,I
2823,;,O
2823,these,O
2823,are,O
2823,represented,B
2823,using,I
2823,a,O
2823,sum,B
2823,and,I
2823,transformation,I
2823,of,B
2823,word,B
2823,embedding,I
2823,vectors,I
2823,",",O
2823,similarly,O
2823,to,O
2823,in,O
2823,.,O
2824,The,O
2824,modules,B
2824,for,B
2824,temporal,B
2824,and,I
2824,causal,I
2824,relation,I
2824,classification,I
2824,rely,B
2824,both,I
2824,on,I
2824,a,O
2824,sieve,B
2824,-,I
2824,based,I
2824,architecture,I
2824,",",O
2824,in,B
2824,which,I
2824,the,O
2824,remaining,B
2824,unlabelled,I
2824,pairs,I
2824,-,O
2824,after,B
2824,running,I
2824,a,O
2824,rule,B
2824,-,O
2824,based,O
2824,component,O
2824,and,O
2824,/,O
2824,or,O
2824,a,O
2824,transitive,B
2824,reasoner,I
2824,are,O
2824,fed,B
2824,into,I
2824,a,O
2824,supervised,B
2824,classifier,I
2824,.,O
2825,The,O
2825,word,O
2825,-,O
2825,by,O
2825,-,O
2825,word,O
2825,perspective,O
2825,focuses,B
2825,on,I
2825,similarity,B
2825,matches,I
2825,between,B
2825,individual,B
2825,words,I
2825,from,B
2825,hypothesis,B
2825,and,I
2825,text,I
2825,",",O
2825,at,B
2825,various,B
2825,scales,I
2825,.,O
2826,As,O
2826,in,O
2826,the,O
2826,semantic,O
2826,perspective,O
2826,",",O
2826,we,O
2826,consider,B
2826,matches,B
2826,over,B
2826,complete,B
2826,sentences,I
2826,.,O
2827,We,O
2827,also,O
2827,use,B
2827,a,O
2827,sliding,B
2827,window,I
2827,acting,B
2827,on,I
2827,a,O
2827,subsentential,B
2827,scale,I
2827,(,O
2827,inspired,O
2827,by,O
2827,the,O
2827,work,O
2827,of,O
2827,),O
2827,",",O
2827,which,O
2827,implicitly,O
2827,considers,O
2827,the,O
2827,linear,O
2827,distance,O
2827,between,O
2827,matched,O
2827,words,O
2827,.,O
2828,A,O
2828,Parallel,O
2828,-,O
2828,Hierarchical,O
2828,Model,O
2828,for,O
2828,Machine,B
2828,Comprehension,I
2828,on,O
2828,Sparse,O
2828,Data,O
2829,On,B
2829,MCTest,B
2829,-,I
2829,500,I
2829,",",O
2829,the,O
2829,Parallel,B
2829,Hierarchical,I
2829,model,I
2829,significantly,B
2829,outperforms,I
2829,these,B
2829,methods,I
2829,on,O
2829,single,B
2829,questions,I
2829,(,I
2829,>,I
2829,2,I
2829,%,I
2829,),I
2829,and,O
2829,slightly,B
2829,outperforms,O
2829,the,O
2829,latter,B
2829,two,I
2829,on,O
2829,multi,O
2829,questions,O
2829,(,O
2829,?,O
2830,The,O
2830,method,B
2830,of,O
2830,achieves,B
2830,the,O
2830,best,B
2830,over,I
2830,all,I
2830,result,I
2830,on,B
2830,MCTest,B
2830,-,I
2830,160,I
2830,.,O
2831,Here,O
2831,we,O
2831,see,O
2831,our,B
2831,model,I
2831,outperforming,B
2831,the,O
2831,alternatives,B
2831,by,B
2831,a,O
2831,large,B
2831,margin,I
2831,across,B
2831,the,O
2831,board,B
2831,(,I
2831,>,I
2831,15,I
2831,%,I
2831,),I
2831,.,O
2832,From,O
2832,",",O
2832,we,O
2832,can,O
2832,see,B
2832,that,B
2832,the,O
2832,answer,O
2832,verification,O
2832,makes,B
2832,a,O
2832,great,B
2832,contribution,I
2832,to,B
2832,the,O
2832,over,B
2832,all,I
2832,improvement,I
2832,",",O
2832,which,O
2832,confirms,B
2832,our,B
2832,hypothesis,I
2832,that,O
2832,cross,B
2832,-,I
2832,passage,I
2832,answer,O
2832,verification,O
2832,is,O
2832,useful,B
2832,for,B
2832,the,O
2832,multi-passage,B
2832,MRC,I
2832,.,O
2833,We,O
2833,present,O
2833,CATENA,O
2833,",",O
2833,a,O
2833,sieve,O
2833,-,O
2833,based,O
2833,system,O
2833,to,O
2833,perform,O
2833,temporal,B
2833,and,I
2833,causal,I
2833,relation,I
2833,extraction,I
2833,and,O
2833,classification,O
2833,from,O
2833,English,O
2833,texts,O
2833,",",O
2833,exploiting,O
2833,the,O
2833,interaction,O
2833,between,O
2833,the,O
2833,temporal,O
2833,and,O
2833,the,O
2833,causal,O
2833,model,O
2833,.,O
2834,For,B
2834,the,O
2834,ablation,B
2834,of,B
2834,the,O
2834,content,B
2834,model,I
2834,",",O
2834,we,O
2834,analyze,B
2834,that,O
2834,it,O
2834,will,O
2834,not,B
2834,only,I
2834,affect,I
2834,the,O
2834,content,O
2834,score,O
2834,itself,O
2834,",",O
2834,but,O
2834,also,O
2834,violate,B
2834,the,O
2834,verification,B
2834,model,O
2834,since,O
2834,the,O
2834,content,O
2834,probabilities,O
2834,are,O
2834,necessary,O
2834,for,O
2834,the,O
2834,answer,O
2834,representation,O
2834,",",O
2834,which,O
2834,will,O
2834,be,O
2834,further,O
2834,analyzed,O
2834,in,O
2834,Section,O
2834,4.3,O
2834,.,O
2835,Another,O
2835,discovery,O
2835,is,O
2835,that,O
2835,jointly,B
2835,training,I
2835,the,O
2835,three,B
2835,models,I
2835,can,B
2835,provide,B
2835,great,B
2835,benefits,I
2835,",",O
2835,which,O
2835,shows,B
2835,that,O
2835,the,O
2835,three,O
2835,tasks,O
2835,are,B
2835,actually,O
2835,closely,B
2835,related,I
2835,and,O
2835,can,O
2835,boost,B
2835,each,B
2835,other,I
2835,with,B
2835,shared,B
2835,representations,I
2835,at,B
2835,bottom,B
2835,layers,I
2835,.,O
2836,At,O
2836,last,O
2836,",",O
2836,comparing,O
2836,our,O
2836,method,O
2836,with,O
2836,the,O
2836,baseline,O
2836,",",O
2836,we,O
2836,achieve,B
2836,an,O
2836,improvement,B
2836,of,B
2836,nearly,B
2836,3,I
2836,points,I
2836,without,B
2836,the,O
2836,yes,B
2836,/,I
2836,no,I
2836,classification,I
2836,.,O
2837,For,B
2837,MS,B
2837,-,I
2837,MARCO,I
2837,",",O
2837,we,O
2837,preprocess,B
2837,the,O
2837,corpus,B
2837,with,B
2837,the,O
2837,reversible,B
2837,tokenizer,I
2837,from,B
2837,Stanford,B
2837,CoreNLP,I
2837,and,O
2837,we,O
2837,choose,O
2837,the,O
2837,span,O
2837,that,O
2837,achieves,O
2837,the,O
2837,highest,O
2837,ROUGE,O
2837,-,O
2837,L,O
2837,score,O
2837,with,O
2837,the,O
2837,reference,O
2837,answers,O
2837,as,O
2837,the,O
2837,gold,O
2837,span,O
2837,for,O
2837,training,O
2837,.,O
2838,We,O
2838,employ,B
2838,the,O
2838,300,B
2838,-,I
2838,D,I
2838,pre-trained,I
2838,Glove,I
2838,embeddings,I
2838,and,O
2838,keep,O
2838,it,O
2838,fixed,B
2838,during,B
2838,training,B
2838,.,O
2839,The,O
2839,character,B
2839,embeddings,I
2839,are,B
2839,randomly,B
2839,initialized,I
2839,with,B
2839,its,O
2839,dimension,B
2839,as,B
2839,30,B
2839,.,O
2840,The,O
2840,over,O
2840,all,O
2840,framework,O
2840,of,B
2840,our,O
2840,model,O
2840,is,O
2840,demonstrated,O
2840,in,O
2840,",",O
2840,which,O
2840,consists,B
2840,of,O
2840,three,B
2840,modules,I
2840,.,O
2841,First,O
2841,",",O
2841,we,O
2841,follow,B
2841,the,O
2841,boundary,B
2841,-,I
2841,based,I
2841,MRC,I
2841,models,I
2841,to,B
2841,find,I
2841,an,O
2841,answer,B
2841,candidate,I
2841,for,B
2841,each,B
2841,passage,I
2841,by,B
2841,identifying,I
2841,the,O
2841,start,B
2841,and,I
2841,end,I
2841,position,I
2841,of,O
2841,the,O
2841,answer,O
2841,(,O
2841,.,O
2842,Second,O
2842,",",O
2842,we,O
2842,model,B
2842,the,O
2842,meanings,B
2842,of,B
2842,the,O
2842,answer,B
2842,candidates,B
2842,extracted,B
2842,from,I
2842,those,B
2842,passages,I
2842,and,O
2842,use,B
2842,the,O
2842,content,B
2842,scores,I
2842,to,B
2842,measure,I
2842,the,O
2842,quality,B
2842,of,O
2842,the,O
2842,candidates,O
2842,from,O
2842,a,O
2842,second,O
2842,perspective,O
2842,.,O
2843,Third,O
2843,",",O
2843,we,O
2843,conduct,B
2843,the,O
2843,answer,O
2843,verification,O
2843,by,B
2843,enabling,I
2843,each,B
2843,answer,O
2843,candidate,O
2843,to,B
2843,attend,I
2843,to,O
2843,the,O
2843,other,B
2843,candidates,I
2843,based,B
2843,on,I
2843,their,B
2843,representations,I
2843,.,O
2844,The,O
2844,evaluation,O
2844,shows,O
2844,that,O
2844,CATENA,B
2844,is,B
2844,the,O
2844,best,B
2844,performing,I
2844,system,I
2844,in,B
2844,both,B
2844,tasks,I
2844,",",O
2844,even,O
2844,if,O
2844,in,O
2844,Task,O
2844,C,O
2844,best,O
2844,precision,O
2844,and,O
2844,best,O
2844,recall,O
2844,are,O
2844,yielded,O
2844,by,O
2844,and,O
2844,",",O
2844,respectively,O
2844,.,O
2845,Therefore,O
2845,",",O
2845,the,O
2845,final,B
2845,answer,I
2845,is,O
2845,determined,B
2845,by,I
2845,three,B
2845,factors,I
2845,:,O
2845,the,O
2845,boundary,B
2845,",",O
2845,the,O
2845,content,B
2845,and,O
2845,the,O
2845,crosspassage,B
2845,answer,O
2845,verification,O
2845,.,O
2846,The,O
2846,three,O
2846,steps,O
2846,are,O
2846,modeled,B
2846,using,I
2846,different,B
2846,modules,I
2846,",",O
2846,which,O
2846,can,B
2846,be,I
2846,jointly,B
2846,trained,I
2846,in,B
2846,our,B
2846,end,I
2846,-,I
2846,to,I
2846,-,O
2846,end,O
2846,framework,O
2846,.,O
2847,Compared,O
2847,with,O
2847,MRC,B
2847,on,O
2847,a,O
2847,single,O
2847,passage,O
2847,",",O
2847,multi-passage,O
2847,MRC,O
2847,is,O
2847,more,O
2847,challenging,O
2847,",",O
2847,since,O
2847,we,O
2847,are,O
2847,likely,O
2847,to,O
2847,get,O
2847,multiple,O
2847,confusing,O
2847,answer,O
2847,candidates,O
2847,from,O
2847,different,O
2847,passages,O
2847,.,O
2848,Results,O
2848,on,B
2848,DuReader,B
2849,We,O
2849,can,O
2849,see,B
2849,that,I
2849,this,O
2849,paragraph,B
2849,ranking,I
2849,can,O
2849,boost,B
2849,the,O
2849,BiDAF,B
2849,baseline,I
2849,significantly,B
2849,.,O
2850,Finally,O
2850,",",O
2850,we,O
2850,implement,O
2850,our,B
2850,system,I
2850,based,O
2850,on,O
2850,this,O
2850,new,O
2850,strategy,O
2850,",",O
2850,and,O
2850,our,O
2850,system,O
2850,(,O
2850,single,O
2850,model,O
2850,),O
2850,achieves,B
2850,further,B
2850,improvement,I
2850,by,B
2850,a,O
2850,large,B
2850,margin,I
2850,.,O
2851,The,O
2851,passage,B
2851,-,I
2851,aligned,I
2851,question,I
2851,representation,I
2851,is,B
2851,crucial,B
2851,",",O
2851,since,O
2851,lexically,O
2851,similar,O
2851,regions,O
2851,of,O
2851,the,O
2851,passage,O
2851,provide,O
2851,strong,O
2851,signal,O
2851,for,O
2851,relevant,O
2851,answer,O
2851,spans,O
2851,.,O
2852,First,O
2852,",",O
2852,we,O
2852,observe,B
2852,general,B
2852,improvements,I
2852,when,B
2852,using,I
2852,labels,B
2852,that,B
2852,closely,B
2852,align,I
2852,with,B
2852,the,O
2852,task,B
2852,.,O
2853,If,O
2853,we,O
2853,consider,O
2853,the,O
2853,different,O
2853,entity,O
2853,pairs,O
2853,",",O
2853,CATENA,O
2853,performs,B
2853,best,B
2853,on,B
2853,timex,I
2853,-,I
2853,timex,O
2853,and,O
2853,event,O
2853,-,O
2853,timex,O
2853,relations,O
2853,",",O
2853,while,B
2853,CAEVO,B
2853,still,O
2853,achieves,B
2853,the,O
2853,best,O
2853,results,O
2853,on,O
2853,event,O
2853,-,O
2853,DCT,O
2853,and,O
2853,event,O
2853,-,O
2853,event,O
2853,pairs,O
2853,.,O
2854,Second,O
2854,",",O
2854,we,O
2854,observe,O
2854,the,O
2854,importance,O
2854,of,O
2854,allowing,O
2854,interactions,B
2854,between,I
2854,the,O
2854,endpoints,O
2854,using,B
2854,the,O
2854,spanlevel,B
2854,FFNN,I
2854,.,O
2855,RASOR,B
2855,outperforms,B
2855,the,O
2855,endpoint,B
2855,prediction,I
2855,model,I
2855,by,B
2855,1.1,B
2855,in,B
2855,exact,B
2855,match,I
2855,",",O
2855,The,O
2855,interaction,O
2855,between,O
2855,endpoints,O
2855,enables,O
2855,RASOR,O
2855,to,O
2855,enforce,O
2855,consistency,O
2855,across,O
2855,its,O
2855,two,O
2855,substructures,O
2855,.,O
2856,We,O
2856,represent,B
2856,each,O
2856,of,B
2856,the,O
2856,words,O
2856,in,B
2856,the,O
2856,question,B
2856,and,I
2856,document,I
2856,using,B
2856,300,B
2856,dimensional,I
2856,GloVe,I
2856,embeddings,I
2856,trained,B
2856,on,I
2856,a,O
2856,corpus,B
2856,of,O
2856,840,B
2856,bn,I
2856,words,O
2856,.,O
2857,These,O
2857,embeddings,O
2857,cover,B
2857,200,B
2857,k,I
2857,words,I
2857,and,O
2857,all,B
2857,out,I
2857,of,I
2857,vocabulary,I
2857,(,I
2857,OOV,I
2857,),I
2857,words,O
2857,are,O
2857,projected,B
2857,onto,I
2857,one,B
2857,of,O
2857,1,B
2857,m,I
2857,randomly,I
2857,initialized,I
2857,300d,I
2857,embeddings,O
2857,.,O
2858,We,O
2858,couple,B
2858,the,O
2858,input,B
2858,and,I
2858,forget,I
2858,gates,I
2858,in,B
2858,our,B
2858,LSTMs,I
2858,",",O
2858,as,O
2858,described,O
2858,in,O
2858,",",O
2858,and,O
2858,we,O
2858,use,B
2858,a,O
2858,single,B
2858,dropout,B
2858,mask,I
2858,to,B
2858,apply,I
2858,dropout,O
2858,across,B
2858,all,B
2858,LSTM,I
2858,time,I
2858,-,I
2858,steps,I
2858,as,O
2858,proposed,O
2858,by,O
2858,.,O
2859,Hidden,O
2859,layers,O
2859,in,B
2859,the,O
2859,feed,B
2859,forward,I
2859,neural,I
2859,networks,I
2859,use,B
2859,rectified,B
2859,linear,I
2859,units,I
2859,.,O
2860,Answer,O
2860,candidates,O
2860,are,O
2860,limited,B
2860,to,I
2860,spans,B
2860,with,B
2860,at,B
2860,most,I
2860,30,I
2860,words,I
2860,.,O
2861,The,O
2861,best,B
2861,model,I
2861,uses,B
2861,50d,B
2861,LSTM,I
2861,states,I
2861,;,O
2861,two,B
2861,-,I
2861,layer,I
2861,BiLSTMs,I
2861,for,B
2861,the,O
2861,span,B
2861,encoder,I
2861,and,O
2861,the,O
2861,passage,B
2861,-,O
2861,independent,O
2861,question,O
2861,representation,O
2861,;,O
2861,dropout,B
2861,of,B
2861,0.1,B
2861,throughout,O
2861,;,O
2861,and,O
2861,a,O
2861,learning,B
2861,rate,I
2861,decay,I
2861,of,O
2861,5,B
2861,%,I
2861,every,I
2861,10,I
2861,k,I
2861,steps,I
2861,.,O
2862,All,O
2862,models,B
2862,are,O
2862,implemented,B
2862,using,I
2862,TensorFlow,B
2862,3,O
2862,and,O
2862,trained,B
2862,on,B
2862,the,O
2862,SQUAD,B
2862,training,I
2862,set,I
2862,using,O
2862,the,O
2862,ADAM,B
2862,optimizer,I
2862,with,B
2862,a,O
2862,mini-batch,B
2862,size,I
2862,of,B
2862,4,B
2862,and,O
2862,trained,O
2862,using,O
2862,10,B
2862,asynchronous,I
2862,training,O
2862,threads,O
2862,on,O
2862,a,O
2862,single,B
2862,machine,I
2862,.,O
2863,To,O
2863,choose,O
2863,the,O
2863,final,B
2863,model,I
2863,configuration,I
2863,",",I
2863,we,O
2863,ran,B
2863,grid,B
2863,searches,I
2863,over,B
2863,:,O
2863,the,O
2863,dimensionality,B
2863,of,B
2863,the,O
2863,LSTM,O
2863,hidden,O
2863,states,O
2863,;,O
2863,the,O
2863,width,B
2863,and,I
2863,depth,I
2863,of,O
2863,the,O
2863,feed,B
2863,forward,I
2863,neural,I
2863,networks,I
2863,;,O
2863,dropout,B
2863,for,B
2863,the,O
2863,LSTMs,B
2863,;,O
2863,the,O
2863,number,B
2863,of,O
2863,stacked,B
2863,LSTM,O
2863,layers,O
2863,;,O
2863,and,O
2863,the,O
2863,decay,B
2863,multiplier,I
2863,[,I
2863,0.9,I
2863,",",O
2863,0.95,O
2863,",",O
2863,1.0,O
2863,],O
2863,with,O
2863,which,O
2863,we,O
2863,multiply,B
2863,the,O
2863,learning,B
2863,rate,I
2863,every,I
2863,10,I
2863,k,I
2863,steps,I
2863,.,O
2864,In,O
2864,this,O
2864,paper,O
2864,",",O
2864,we,O
2864,propose,B
2864,a,O
2864,structured,B
2864,learning,I
2864,approach,I
2864,to,B
2864,temporal,B
2864,relation,I
2864,extraction,I
2864,",",O
2864,where,B
2864,local,B
2864,models,I
2864,are,B
2864,updated,B
2864,based,B
2864,on,I
2864,feedback,B
2864,from,B
2864,global,B
2864,inferences,I
2864,.,O
2865,To,O
2865,overcome,O
2865,this,O
2865,",",O
2865,we,O
2865,present,B
2865,a,O
2865,novel,B
2865,neural,I
2865,architecture,I
2865,called,B
2865,RASOR,B
2865,that,O
2865,builds,B
2865,fixed,B
2865,-,I
2865,length,I
2865,span,I
2865,representations,I
2865,",",O
2865,reusing,B
2865,recurrent,B
2865,computations,I
2865,for,B
2865,shared,B
2865,substructures,I
2865,.,O
2866,We,O
2866,demonstrate,B
2866,that,O
2866,directly,B
2866,classifying,I
2866,each,B
2866,of,I
2866,the,O
2866,competing,B
2866,spans,I
2866,",",O
2866,and,O
2866,training,B
2866,with,B
2866,global,B
2866,normalization,I
2866,over,B
2866,all,B
2866,possible,I
2866,spans,O
2866,",",O
2866,leads,B
2866,to,I
2866,a,O
2866,significant,B
2866,increase,I
2866,in,B
2866,performance,B
2866,.,O
2867,LEARNING,O
2867,RECURRENT,O
2867,SPAN,O
2867,REPRESENTATIONS,O
2867,FOR,O
2867,EXTRACTIVE,B
2867,QUESTION,I
2867,ANSWERING,I
2868,In,O
2868,this,O
2868,paper,O
2868,",",O
2868,we,O
2868,focus,O
2868,on,O
2868,this,O
2868,answer,B
2868,extraction,I
2868,task,O
2868,",",O
2868,presenting,O
2868,a,O
2868,novel,O
2868,model,O
2868,architecture,O
2868,that,O
2868,efficiently,O
2868,builds,O
2868,fixed,O
2868,length,O
2868,representations,O
2868,of,O
2868,all,O
2868,spans,O
2868,in,O
2868,the,O
2868,evidence,O
2868,document,O
2868,with,O
2868,a,O
2868,recurrent,O
2868,network,O
2868,.,O
2869,Despite,O
2869,not,O
2869,having,O
2869,access,O
2869,to,O
2869,any,O
2869,external,O
2869,representation,O
2869,of,O
2869,linguistic,O
2869,structure,O
2869,",",O
2869,RASOR,B
2869,achieves,B
2869,an,O
2869,error,B
2869,reduction,I
2869,of,O
2869,more,B
2869,than,I
2869,50,I
2869,%,I
2869,over,O
2869,this,O
2869,baseline,O
2869,",",O
2869,both,O
2869,in,B
2869,terms,I
2869,of,O
2869,exact,B
2869,match,I
2869,and,I
2869,F1,I
2869,",",O
2869,relative,B
2869,to,O
2869,the,O
2869,human,B
2869,performance,I
2869,upper,I
2869,bound,I
2869,.,O
2870,In,O
2870,contrast,O
2870,",",O
2870,RASOR,O
2870,can,O
2870,efficiently,B
2870,and,I
2870,explicitly,I
2870,model,I
2870,the,O
2870,quadratic,B
2870,number,I
2870,of,I
2870,possible,I
2870,answers,I
2870,",",O
2870,which,O
2870,leads,B
2870,to,I
2870,a,O
2870,14,B
2870,%,I
2870,error,I
2870,reduction,I
2870,over,B
2870,the,O
2870,best,B
2870,performing,I
2870,Match,I
2870,-,I
2870,LSTM,I
2870,model,O
2870,.,O
2871,Both,O
2871,the,O
2871,coarse,O
2871,-,O
2871,grain,O
2871,module,O
2871,and,O
2871,the,O
2871,fine,O
2871,-,O
2871,grain,O
2871,module,O
2871,significantly,O
2871,contribute,B
2871,to,I
2871,model,B
2871,performance,I
2871,.,O
2872,The,O
2872,fine,B
2872,-,I
2872,grain,I
2872,-,O
2872,only,O
2872,model,O
2872,under-performs,B
2872,the,O
2872,coarse,B
2872,-,O
2872,grain,O
2872,-,O
2872,only,O
2872,model,O
2872,consistently,B
2872,across,B
2872,almost,B
2872,all,I
2872,length,I
2872,measures,I
2872,.,O
2873,However,O
2873,",",O
2873,the,O
2873,fine,O
2873,-,O
2873,grain,O
2873,-,O
2873,only,O
2873,model,O
2873,matches,B
2873,or,I
2873,outperforms,I
2873,the,O
2873,coarse,B
2873,-,O
2873,grain,O
2873,-,O
2873,only,O
2873,model,O
2873,on,B
2873,examples,B
2873,with,B
2873,a,O
2873,large,B
2873,number,I
2873,of,B
2873,support,I
2873,documents,I
2873,or,O
2873,with,O
2873,long,B
2873,support,O
2873,documents,O
2873,.,O
2874,Replacing,B
2874,selfattention,B
2874,layers,I
2874,with,B
2874,mean,B
2874,-,I
2874,pooling,I
2874,and,O
2874,the,O
2874,bidirectional,B
2874,GRUs,I
2874,with,O
2874,unidirectional,B
2874,GRUs,O
2874,result,B
2874,in,I
2874,less,B
2874,performance,I
2874,degradation,I
2874,.,O
2875,The,O
2875,structured,B
2875,approach,I
2875,also,O
2875,gives,B
2875,rise,I
2875,to,I
2875,a,O
2875,semisupervised,B
2875,method,I
2875,",",O
2875,making,O
2875,it,O
2875,possible,O
2875,to,O
2875,take,B
2875,advantage,I
2875,of,I
2875,the,O
2875,readily,B
2875,available,I
2875,unlabeled,I
2875,data,I
2875,.,O
2876,Replacing,B
2876,the,O
2876,encoder,B
2876,with,B
2876,a,O
2876,projection,B
2876,over,B
2876,word,B
2876,embeddings,I
2876,result,B
2876,in,I
2876,significant,B
2876,performance,I
2876,drop,I
2876,",",O
2876,which,O
2876,suggests,O
2876,that,O
2876,contextual,O
2876,encodings,O
2876,that,O
2876,capture,O
2876,positional,O
2876,information,O
2876,is,O
2876,crucial,O
2876,to,O
2876,this,O
2876,task,O
2876,.,O
2877,MULTI,O
2877,-,O
2877,EVIDENCE,O
2877,QUESTION,O
2877,ANSWERING,O
2877,ON,B
2877,WIKIHOP,B
2878,We,O
2878,tokenize,B
2878,the,O
2878,data,O
2878,using,B
2878,Stanford,B
2878,CoreNLP,I
2878,.,O
2879,We,O
2879,use,B
2879,fixed,B
2879,Glo,I
2879,Ve,I
2879,embeddings,I
2879,as,I
2879,well,I
2879,as,O
2879,character,B
2879,ngram,I
2879,embeddings,O
2879,.,O
2880,We,O
2880,split,B
2880,symbolic,B
2880,query,I
2880,relations,I
2880,into,B
2880,words,B
2880,.,O
2881,All,O
2881,models,O
2881,are,O
2881,trained,B
2881,using,I
2881,ADAM,B
2881,.,O
2882,The,O
2882,CFC,B
2882,achieves,B
2882,state,B
2882,-,I
2882,of,B
2882,-,O
2882,the,O
2882,-,O
2882,art,O
2882,results,O
2882,on,B
2882,both,O
2882,the,O
2882,masked,B
2882,and,I
2882,unmasked,I
2882,versions,I
2882,of,O
2882,WikiHop,B
2882,.,O
2883,In,O
2883,particular,O
2883,",",O
2883,on,B
2883,the,O
2883,blind,B
2883,",",O
2883,held,O
2883,-,O
2883,out,O
2883,WikiHop,O
2883,test,O
2883,set,O
2883,",",O
2883,the,O
2883,CFC,B
2883,achieves,B
2883,a,O
2883,new,B
2883,best,I
2883,accuracy,I
2883,of,B
2883,70.6,B
2883,%,I
2883,.,O
2884,RERANKING,O
2884,EXTRACTIVE,O
2884,QUESTION,O
2884,ANSWERING,O
2884,ON,B
2884,TRIVIAQA,B
2885,Our,O
2885,experimental,O
2885,results,O
2885,in,O
2885,show,B
2885,that,O
2885,reranking,B
2885,using,I
2885,the,O
2885,CFC,B
2885,provides,B
2885,consistent,B
2885,performance,I
2885,gains,I
2885,over,B
2885,only,I
2885,using,O
2885,the,O
2885,span,B
2885,extraction,I
2885,question,I
2885,answering,I
2885,model,I
2885,.,O
2886,This,O
2886,paper,O
2886,focuses,O
2886,on,O
2886,Relation,B
2886,Extraction,I
2886,(,I
2886,RE,I
2886,),I
2886,",",O
2886,which,O
2886,is,O
2886,the,O
2886,task,O
2886,of,O
2886,entity,O
2886,mention,O
2886,detection,O
2886,and,O
2886,classifying,O
2886,the,O
2886,relations,O
2886,between,O
2886,each,O
2886,pair,O
2886,of,O
2886,those,O
2886,mentions,O
2886,.,O
2887,The,O
2887,first,O
2887,is,O
2887,the,O
2887,regularized,B
2887,averaged,I
2887,perceptron,I
2887,(,I
2887,AP,I
2887,),I
2887,implemented,B
2887,in,I
2887,the,O
2887,LBJava,B
2887,package,I
2887,and,O
2887,is,O
2887,a,O
2887,local,O
2887,method,O
2887,.,O
2888,In,O
2888,particular,O
2888,",",O
2888,reranking,B
2888,using,B
2888,the,O
2888,CFC,B
2888,improves,B
2888,performance,B
2888,regardless,O
2888,of,O
2888,whether,O
2888,the,O
2888,candidate,O
2888,answer,O
2888,set,O
2888,obtained,O
2888,from,O
2888,the,O
2888,span,O
2888,extraction,O
2888,model,O
2888,contains,O
2888,correct,O
2888,answers,O
2888,.,O
2889,On,B
2889,the,O
2889,whole,B
2889,Trivia,I
2889,QA,I
2889,dev,I
2889,set,I
2889,",",O
2889,reranking,B
2889,using,B
2889,the,O
2889,CFC,B
2889,results,B
2889,in,I
2889,again,B
2889,of,B
2889,3.1,B
2889,%,I
2889,EM,I
2889,and,I
2889,3.0,I
2889,%,O
2889,F1,O
2889,",",O
2889,which,O
2889,suggests,O
2889,that,O
2889,the,O
2889,CFC,O
2889,can,O
2889,be,O
2889,used,O
2889,to,O
2889,further,O
2889,refine,O
2889,the,O
2889,outputs,O
2889,produced,O
2889,by,O
2889,span,O
2889,extraction,O
2889,question,O
2889,answering,O
2889,models,O
2889,.,O
2890,Our,O
2890,multi-evidence,O
2890,QA,O
2890,model,O
2890,",",O
2890,the,O
2890,Coarse,B
2890,-,I
2890,grain,I
2890,Fine,I
2890,-,O
2890,grain,O
2890,Coattention,O
2890,Network,O
2890,(,O
2890,CFC,O
2890,),O
2890,",",O
2890,selects,B
2890,among,I
2890,a,O
2890,set,B
2890,of,B
2890,candidate,B
2890,answers,I
2890,given,B
2890,a,O
2890,set,O
2890,of,O
2890,support,B
2890,documents,I
2890,and,O
2890,a,O
2890,query,B
2890,.,O
2891,The,O
2891,CFC,B
2891,is,O
2891,inspired,B
2891,by,I
2891,coarse,B
2891,-,I
2891,grain,I
2891,reasoning,I
2891,and,O
2891,fine,B
2891,-,O
2891,grain,O
2891,reasoning,O
2891,.,O
2892,Each,O
2892,module,O
2892,employs,B
2892,a,O
2892,novel,B
2892,hierarchical,I
2892,attention,I
2892,-,I
2892,a,O
2892,hierarchy,B
2892,of,B
2892,coattention,B
2892,and,O
2892,self,B
2892,-,O
2892,attention,O
2892,-,O
2892,to,B
2892,combine,I
2892,information,B
2892,from,B
2892,the,O
2892,support,B
2892,documents,I
2892,conditioned,B
2892,on,I
2892,the,O
2892,query,B
2892,and,O
2892,candidates,B
2892,.,O
2893,In,B
2893,coarse,B
2893,-,I
2893,grain,I
2893,reasoning,I
2893,",",O
2893,the,O
2893,model,B
2893,builds,B
2893,a,O
2893,coarse,O
2893,summary,O
2893,of,B
2893,support,B
2893,documents,I
2893,conditioned,B
2893,on,I
2893,the,O
2893,query,B
2893,without,O
2893,knowing,O
2893,what,O
2893,candidates,O
2893,are,O
2893,available,O
2893,",",O
2893,then,O
2893,scores,O
2893,each,O
2893,candidate,O
2893,.,O
2894,In,O
2894,fine,B
2894,-,I
2894,grain,I
2894,reasoning,I
2894,",",O
2894,the,O
2894,model,B
2894,matches,B
2894,specific,B
2894,finegrain,I
2894,contexts,I
2894,in,O
2894,which,O
2894,the,O
2894,candidate,B
2894,is,O
2894,mentioned,O
2894,with,O
2894,the,O
2894,query,O
2894,in,O
2894,order,O
2894,to,B
2894,gauge,I
2894,the,O
2894,relevance,B
2894,of,B
2894,the,O
2894,candidate,O
2894,.,O
2895,COARSE,O
2895,-,O
2895,GRAIN,O
2895,FINE,O
2895,-,O
2895,GRAIN,O
2895,COATTENTION,O
2895,NET,O
2895,-,O
2895,WORK,O
2895,FOR,O
2895,MULTI,B
2895,-,O
2895,EVIDENCE,O
2895,QUESTION,O
2895,ANSWERING,O
2896,End,O
2896,-,O
2896,to,O
2896,-,O
2896,end,O
2896,neural,O
2896,models,O
2896,have,O
2896,made,O
2896,significant,O
2896,progress,O
2896,in,O
2896,question,B
2896,answering,I
2896,",",O
2896,however,O
2896,recent,O
2896,studies,O
2896,show,O
2896,that,O
2896,these,O
2896,models,O
2896,implicitly,O
2896,assume,O
2896,that,O
2896,the,O
2896,answer,O
2896,and,O
2896,evidence,O
2896,appear,O
2896,close,O
2896,together,O
2896,in,O
2896,a,O
2896,single,O
2896,document,O
2896,.,O
2897,A,O
2897,requirement,O
2897,of,O
2897,scalable,O
2897,and,O
2897,practical,O
2897,question,B
2897,answering,I
2897,(,I
2897,QA,I
2897,),I
2897,systems,O
2897,is,O
2897,the,O
2897,ability,O
2897,to,O
2897,reason,O
2897,over,O
2897,multiple,O
2897,documents,O
2897,and,O
2897,combine,O
2897,their,O
2897,information,O
2897,to,O
2897,answer,O
2897,questions,O
2897,.,O
2898,On,O
2898,top,O
2898,of,O
2898,the,O
2898,first,B
2898,baseline,I
2898,",",O
2898,we,O
2898,performed,B
2898,global,B
2898,inference,I
2898,in,O
2898,Eq,O
2898,.,O
2899,Although,O
2899,existing,O
2899,datasets,O
2899,enabled,O
2899,the,O
2899,development,O
2899,of,O
2899,effective,O
2899,end,O
2899,-,O
2899,to,O
2899,-,O
2899,end,O
2899,neural,B
2899,question,I
2899,answering,I
2899,systems,O
2899,",",O
2899,they,O
2899,tend,O
2899,to,O
2899,focus,O
2899,on,O
2899,reasoning,O
2899,over,O
2899,localized,O
2899,sections,O
2899,of,O
2899,a,O
2899,single,O
2899,document,O
2899,.,O
2900,We,O
2900,train,B
2900,the,O
2900,model,B
2900,with,B
2900,the,O
2900,Adadelta,B
2900,optimizer,I
2900,(,I
2900,Zeiler,I
2900,",",I
2900,2012,I
2900,),I
2900,with,O
2900,a,O
2900,batch,B
2900,size,I
2900,60,B
2900,for,B
2900,Triv,B
2900,-,I
2900,ia,I
2900,QA,I
2900,and,O
2900,45,B
2900,for,O
2900,SQuAD,B
2900,.,O
2901,The,O
2901,Glo,B
2901,Ve,I
2901,300,I
2901,dimensional,I
2901,word,B
2901,vectors,I
2901,released,O
2901,by,O
2901,are,O
2901,used,B
2901,for,I
2901,word,O
2901,embeddings,O
2901,.,O
2902,On,B
2902,SQuAD,B
2902,",",O
2902,we,O
2902,use,B
2902,a,O
2902,dimensionality,B
2902,of,B
2902,size,I
2902,100,B
2902,for,B
2902,the,O
2902,GRUs,B
2902,and,O
2902,of,O
2902,size,O
2902,200,B
2902,for,O
2902,the,O
2902,linear,B
2902,layers,I
2902,employed,B
2902,after,I
2902,each,B
2902,attention,I
2902,mechanism,I
2902,.,O
2903,We,O
2903,find,O
2903,for,B
2903,TriviaQA,B
2903,",",O
2903,likely,O
2903,because,O
2903,there,O
2903,is,B
2903,more,O
2903,data,O
2903,",",O
2903,using,B
2903,a,O
2903,larger,B
2903,dimensionality,I
2903,of,B
2903,140,B
2903,for,O
2903,each,B
2903,GRU,I
2903,and,O
2903,280,B
2903,for,O
2903,the,O
2903,linear,B
2903,layers,I
2903,is,O
2903,beneficial,B
2903,.,O
2904,During,B
2904,training,B
2904,",",O
2904,we,O
2904,maintain,B
2904,an,O
2904,exponential,B
2904,moving,I
2904,average,I
2904,of,B
2904,the,O
2904,weights,B
2904,with,B
2904,a,O
2904,decay,B
2904,rate,I
2904,of,O
2904,0.999,B
2904,.,O
2905,In,O
2905,this,O
2905,paper,O
2905,we,O
2905,start,O
2905,by,O
2905,proposing,B
2905,an,O
2905,improved,B
2905,pipelined,I
2905,method,I
2905,which,O
2905,achieves,O
2905,state,O
2905,-,O
2905,of,O
2905,-,O
2905,the,O
2905,-,O
2905,art,O
2905,results,O
2905,.,O
2906,Then,O
2906,we,O
2906,introduce,B
2906,a,O
2906,method,B
2906,for,B
2906,training,I
2906,models,B
2906,to,B
2906,produce,I
2906,accurate,B
2906,per-paragraph,I
2906,confidence,I
2906,scores,I
2906,",",O
2906,and,O
2906,we,O
2906,show,O
2906,how,O
2906,combining,O
2906,this,O
2906,method,O
2906,with,O
2906,multiple,O
2906,paragraph,O
2906,selection,O
2906,further,O
2906,increases,O
2906,performance,O
2906,.,O
2907,We,O
2907,propose,B
2907,a,O
2907,TF,B
2907,-,I
2907,IDF,I
2907,heuristic,I
2907,to,B
2907,select,I
2907,which,O
2907,paragraphs,B
2907,to,O
2907,train,B
2907,and,I
2907,test,I
2907,on,I
2907,.,O
2908,To,O
2908,handle,O
2908,the,O
2908,noise,O
2908,this,O
2908,creates,O
2908,",",O
2908,we,O
2908,use,B
2908,a,O
2908,summed,B
2908,objective,I
2908,function,I
2908,that,B
2908,marginalizes,I
2908,the,O
2908,model,B
2908,'s,I
2908,output,I
2908,over,B
2908,all,B
2908,locations,I
2908,the,O
2908,answer,B
2908,text,I
2908,occurs,B
2908,.,O
2909,Both,O
2909,of,O
2909,them,O
2909,used,B
2909,the,O
2909,same,B
2909,feature,I
2909,set,I
2909,(,O
2909,i.e.,O
2910,",",O
2910,as,B
2910,designed,O
2910,in,O
2910,),O
2910,as,O
2910,in,O
2910,the,O
2910,proposed,B
2910,structured,I
2910,perceptron,I
2910,(,I
2910,SP,I
2910,),O
2910,and,O
2910,CoDL,B
2910,for,O
2910,fair,O
2910,comparisons,O
2910,.,O
2911,We,O
2911,then,O
2911,use,O
2911,a,O
2911,shared,B
2911,-,I
2911,normalization,I
2911,objective,I
2911,where,B
2911,paragraphs,I
2911,are,O
2911,processed,B
2911,independently,B
2911,",",O
2911,but,O
2911,the,O
2911,probability,B
2911,of,B
2911,an,O
2911,answer,B
2911,candidate,I
2911,is,B
2911,marginalized,B
2911,over,B
2911,all,B
2911,paragraphs,O
2911,sampled,B
2911,from,I
2911,the,O
2911,same,B
2911,document,I
2911,.,O
2912,We,O
2912,resolve,O
2912,these,O
2912,problems,O
2912,by,O
2912,sampling,B
2912,paragraphs,B
2912,from,B
2912,the,O
2912,context,B
2912,documents,I
2912,",",O
2912,including,B
2912,paragraphs,O
2912,that,O
2912,do,B
2912,not,I
2912,contain,I
2912,an,O
2912,answer,B
2912,",",O
2912,to,B
2912,train,B
2912,on,I
2912,.,O
2913,Simple,O
2913,and,O
2913,Effective,O
2913,Multi,B
2913,-,I
2913,Paragraph,I
2913,Reading,I
2913,Comprehension,I
2914,We,O
2914,consider,O
2914,the,O
2914,problem,O
2914,of,O
2914,adapting,O
2914,neural,B
2914,paragraph,I
2914,-,I
2914,level,I
2914,question,I
2914,answering,I
2914,models,O
2914,to,O
2914,the,O
2914,case,O
2914,where,O
2914,entire,O
2914,documents,O
2914,are,O
2914,given,O
2914,as,O
2914,input,O
2914,.,O
2915,The,O
2915,recent,O
2915,success,O
2915,of,O
2915,neural,O
2915,models,O
2915,at,O
2915,answering,B
2915,questions,I
2915,given,I
2915,a,I
2915,related,I
2915,paragraph,I
2915,suggests,O
2915,neural,O
2915,models,O
2915,have,O
2915,the,O
2915,potential,O
2915,to,O
2915,be,O
2915,a,O
2915,key,O
2915,part,O
2915,of,O
2915,a,O
2915,solution,O
2915,to,O
2915,this,O
2915,problem,O
2915,.,O
2916,We,O
2916,find,B
2916,both,O
2916,TF,B
2916,-,I
2916,IDF,I
2916,ranking,I
2916,and,O
2916,the,O
2916,sum,B
2916,objective,I
2916,to,B
2916,be,I
2916,effective,B
2916,;,O
2916,even,O
2916,without,O
2916,changing,O
2916,the,O
2916,model,O
2916,we,O
2916,achieve,O
2916,state,O
2916,-,O
2916,of,O
2916,-,O
2916,the,O
2916,-,O
2916,art,O
2916,results,O
2916,.,O
2917,Using,B
2917,our,O
2917,refined,B
2917,model,I
2917,increases,B
2917,the,O
2917,gain,B
2917,by,B
2917,another,B
2917,4,I
2917,points,I
2917,.,O
2918,The,O
2918,shared,B
2918,-,I
2918,norm,I
2918,",",I
2918,merge,B
2918,",",O
2918,and,O
2918,no-answer,O
2918,training,O
2918,methods,O
2918,improve,B
2918,the,O
2918,model,B
2918,'s,I
2918,ability,I
2918,to,B
2918,utilize,I
2918,more,B
2918,text,I
2918,",",O
2918,with,B
2918,the,O
2918,shared,O
2918,-,O
2918,norm,O
2918,method,O
2918,being,B
2918,significantly,B
2918,ahead,I
2918,of,B
2918,the,O
2918,others,B
2918,on,B
2918,the,O
2918,verified,B
2918,set,I
2918,and,O
2918,tied,B
2918,with,O
2918,the,O
2918,merge,O
2918,approach,O
2918,on,O
2918,the,O
2918,general,B
2918,set,O
2918,.,O
2919,A,O
2919,Structured,O
2919,Learning,O
2919,Approach,O
2919,to,O
2919,Temporal,B
2919,Relation,I
2919,Extraction,I
2920,Note,O
2920,the,O
2920,base,B
2920,model,I
2920,starts,B
2920,to,I
2920,lose,B
2920,performance,B
2920,as,B
2920,more,B
2920,paragraphs,I
2920,are,B
2920,used,B
2920,",",O
2920,showing,O
2920,that,O
2920,errors,O
2920,are,O
2920,being,O
2920,caused,O
2920,by,O
2920,the,O
2920,model,O
2920,being,O
2920,overly,O
2920,confident,O
2920,in,O
2920,incorrect,O
2920,extractions,O
2920,.,O
2921,SQuAD,B
2922,While,O
2922,all,B
2922,our,I
2922,approaches,I
2922,had,O
2922,some,B
2922,benefit,I
2922,",",O
2922,the,O
2922,shared,B
2922,-,I
2922,norm,I
2922,model,I
2922,is,B
2922,the,O
2922,strongest,B
2922,",",O
2922,and,O
2922,is,O
2922,the,O
2922,only,O
2922,one,O
2922,to,O
2922,not,B
2922,lose,I
2922,performance,B
2922,as,B
2922,large,B
2922,numbers,I
2922,of,I
2922,paragraphs,I
2922,are,B
2922,used,B
2922,.,O
2923,Our,O
2923,paragraph,O
2923,-,O
2923,level,O
2923,model,O
2923,is,B
2923,competitive,B
2923,on,O
2923,this,O
2923,task,O
2923,",",O
2923,and,O
2923,our,O
2923,variations,O
2923,to,B
2923,handle,I
2923,the,O
2923,multi-paragraph,B
2923,setting,I
2923,only,O
2923,cause,B
2923,a,O
2923,minor,B
2923,loss,I
2923,of,B
2923,performance,B
2923,.,O
2924,The,O
2924,base,B
2924,model,I
2924,starts,B
2924,to,I
2924,drop,B
2924,in,B
2924,performance,B
2924,once,B
2924,more,B
2924,than,I
2924,two,I
2924,paragraphs,I
2924,are,B
2924,used,B
2924,.,O
2925,However,O
2925,",",O
2925,the,O
2925,shared,B
2925,-,I
2925,norm,I
2925,approach,I
2925,is,O
2925,able,B
2925,to,I
2925,reach,B
2925,a,O
2925,peak,B
2925,performance,I
2925,of,B
2925,72.37,B
2925,F1,I
2925,and,O
2925,64.08,B
2925,EM,I
2925,given,B
2925,15,B
2925,paragraphs,I
2925,.,O
2926,Code,O
2926,to,O
2926,reproduce,O
2926,all,O
2926,experiments,O
2926,can,O
2926,be,O
2926,found,O
2926,at,O
2926,github.com/rasmusbergpalm/recurrent-relationalnetworks.,B
2927,Surprisingly,O
2927,",",O
2927,we,O
2927,find,O
2927,that,O
2927,we,O
2927,only,O
2927,need,B
2927,a,O
2927,single,B
2927,step,I
2927,of,I
2927,relational,I
2927,reasoning,I
2927,to,B
2927,solve,I
2927,all,B
2927,the,I
2927,bAbI,I
2927,tasks,I
2927,.,O
2928,Regardless,O
2928,",",O
2928,it,O
2928,appears,B
2928,multiple,B
2928,steps,I
2928,of,I
2928,relational,I
2928,reasoning,I
2928,are,O
2928,not,B
2928,important,B
2928,for,B
2928,the,O
2928,bAbI,B
2928,dataset,I
2928,.,O
2929,Mirroring,O
2929,the,O
2929,results,O
2929,from,O
2929,the,O
2929,"""",O
2929,Sort,O
2929,-,O
2929,of,O
2929,-,O
2929,CLEVR,O
2929,"""",O
2929,dataset,O
2929,the,O
2929,MLP,B
2929,perfectly,B
2929,solves,I
2929,the,O
2929,non-relational,B
2929,questions,I
2929,",",O
2929,but,O
2929,struggle,B
2929,with,B
2929,even,O
2929,single,B
2929,jump,I
2929,questions,O
2929,and,O
2929,seem,O
2929,to,O
2929,lower,O
2929,bound,O
2929,the,O
2929,performance,O
2929,of,O
2929,the,O
2929,relational,O
2929,networks,O
2929,.,O
2930,The,O
2930,relational,B
2930,network,I
2930,solves,B
2930,the,O
2930,non-relational,B
2930,questions,I
2930,as,I
2930,well,I
2930,as,O
2930,the,O
2930,ones,B
2930,requiring,B
2930,a,O
2930,single,B
2930,jump,I
2930,",",O
2930,but,O
2930,the,O
2930,accuracy,B
2930,sharply,B
2930,drops,I
2930,off,I
2930,with,B
2930,more,B
2930,jumps,I
2930,.,O
2931,Sudoku,B
2932,Our,O
2932,network,O
2932,learns,B
2932,to,I
2932,solve,B
2932,94.1,B
2932,%,I
2932,of,B
2932,even,B
2932,the,I
2932,hardest,I
2932,17,I
2932,-,I
2932,givens,I
2932,Sudokus,I
2932,after,B
2932,32,B
2932,steps,I
2932,.,O
2933,Our,O
2933,network,O
2933,outperforms,B
2933,loopy,B
2933,belief,I
2933,propagation,I
2933,",",O
2933,with,B
2933,parallel,B
2933,and,I
2933,random,I
2933,messages,I
2933,passing,B
2933,updates,B
2933,.,O
2934,It,O
2934,also,O
2934,outperforms,O
2934,a,O
2934,version,B
2934,of,B
2934,loopy,B
2934,belief,I
2934,propagation,I
2934,modified,B
2934,specifically,I
2934,for,B
2934,solving,I
2934,Sudokus,B
2934,that,B
2934,uses,I
2934,250,B
2934,steps,I
2934,",",O
2934,Sinkhorn,O
2934,balancing,O
2934,every,O
2934,two,O
2934,steps,O
2934,and,O
2934,iteratively,O
2934,picks,O
2934,the,O
2934,most,O
2934,probable,O
2934,digit,O
2934,.,O
2935,Finally,O
2935,we,O
2935,outperform,B
2935,Park,B
2935,which,O
2935,treats,B
2935,the,O
2935,Sudoku,B
2935,as,B
2935,a,O
2935,9x9,B
2935,image,I
2935,",",O
2935,uses,O
2935,10,B
2935,convolutional,I
2935,layers,I
2935,",",O
2935,iteratively,O
2935,picks,O
2935,the,O
2935,most,O
2935,probable,O
2935,digit,O
2935,",",O
2935,and,O
2935,evaluate,O
2935,on,O
2935,easier,O
2935,Sudokus,O
2935,with,O
2935,24,O
2935,-,O
2935,36,O
2935,givens,O
2935,.,O
2936,We,O
2936,can,O
2936,see,B
2936,that,I
2936,even,B
2936,simple,I
2936,Sudokus,I
2936,with,B
2936,33,B
2936,givens,I
2936,require,B
2936,upwards,B
2936,of,B
2936,10,I
2936,steps,I
2936,of,O
2936,relational,B
2936,reasoning,I
2936,",",O
2936,whereas,O
2936,the,O
2936,harder,B
2936,17,B
2936,givens,O
2936,continue,B
2936,to,I
2936,improve,B
2936,even,O
2936,after,B
2936,32,B
2936,steps,O
2936,.,O
2937,At,B
2937,64,B
2937,steps,I
2937,the,O
2937,accuracy,B
2937,for,B
2937,the,O
2937,17,B
2937,givens,I
2937,puzzles,I
2937,increases,B
2937,to,B
2937,96.6,B
2937,%,I
2937,.,O
2938,The,O
2938,fundamental,O
2938,tasks,O
2938,in,O
2938,temporal,B
2938,processing,I
2938,",",O
2938,as,O
2938,identified,O
2938,in,O
2938,the,O
2938,TE,O
2938,workshops,O
2938,",",O
2938,are,O
2938,1,O
2938,),O
2938,time,O
2938,expression,O
2938,(,O
2938,the,O
2938,so,O
2938,-,O
2938,called,O
2938,"""",O
2938,timex,O
2938,"""",O
2938,),O
2938,extraction,O
2938,and,O
2938,normalization,O
2938,and,O
2938,2,O
2938,),O
2938,temporal,O
2938,relation,O
2938,(,O
2938,also,O
2938,known,O
2938,as,O
2938,TLINKs,O
2938,),O
2938,extraction,O
2938,.,O
2939,Toward,O
2939,generally,O
2939,realizing,O
2939,the,O
2939,ability,B
2939,to,B
2939,methodically,I
2939,reason,I
2939,about,I
2939,objects,B
2939,and,O
2939,their,O
2939,interactions,B
2939,over,B
2939,many,B
2939,steps,I
2939,",",O
2939,this,O
2939,paper,O
2939,introduces,B
2939,a,O
2939,composite,B
2939,function,I
2939,",",O
2939,the,O
2939,recurrent,B
2939,relational,I
2939,network,I
2939,.,O
2940,It,O
2940,serves,B
2940,as,O
2940,a,O
2940,modular,B
2940,component,I
2940,for,B
2940,many,B
2940,-,I
2940,step,I
2940,relational,I
2940,reasoning,I
2940,in,B
2940,end,I
2940,-,O
2940,to,O
2940,-,O
2940,end,O
2940,differentiable,O
2940,learning,O
2940,systems,O
2940,.,O
2941,It,O
2941,encodes,B
2941,the,O
2941,inductive,B
2941,biases,I
2941,that,B
2941,1,O
2941,),O
2941,objects,B
2941,exists,B
2941,in,I
2941,the,O
2941,world,B
2941,2,O
2941,),O
2941,they,O
2941,can,O
2941,be,O
2941,sufficiently,O
2941,described,B
2941,by,I
2941,properties,B
2941,3,O
2941,),O
2941,properties,O
2941,can,O
2941,changeover,B
2941,time,B
2941,4,O
2941,),O
2941,objects,O
2941,can,O
2941,affect,B
2941,each,B
2941,other,I
2941,and,O
2941,5,O
2941,),O
2941,given,O
2941,the,O
2941,properties,O
2941,",",O
2941,the,O
2941,effects,O
2941,object,O
2941,have,O
2941,on,O
2941,each,O
2941,other,O
2941,is,O
2941,invariant,B
2941,to,I
2941,time,O
2941,.,O
2942,An,O
2942,important,O
2942,insight,O
2942,from,O
2942,the,O
2942,work,O
2942,of,O
2942,is,O
2942,to,O
2942,decompose,B
2942,a,O
2942,function,B
2942,for,B
2942,relational,B
2942,reasoning,I
2942,into,B
2942,two,B
2942,components,I
2942,or,O
2942,"""",O
2942,modules,O
2942,"""",O
2942,:,O
2943,a,O
2943,perceptual,B
2943,front,I
2943,-,I
2943,end,I
2943,",",O
2943,which,O
2943,is,O
2943,tasked,O
2943,to,B
2943,recognize,I
2943,objects,B
2943,in,B
2943,the,O
2943,raw,B
2943,input,I
2943,and,O
2943,represent,B
2943,them,I
2943,as,I
2943,vectors,B
2943,",",O
2943,and,O
2943,a,O
2943,relational,B
2943,reasoning,I
2943,module,I
2943,",",O
2943,which,O
2943,uses,B
2943,the,O
2943,representation,B
2943,to,O
2943,reason,O
2943,about,O
2943,the,O
2943,objects,O
2943,and,O
2943,their,O
2943,interactions,O
2943,.,O
2944,Both,O
2944,modules,O
2944,are,O
2944,trained,B
2944,jointly,B
2944,end,I
2944,-,I
2944,to,I
2944,-,O
2944,end,O
2944,.,O
2945,In,O
2945,computer,O
2945,science,O
2945,parlance,O
2945,",",O
2945,the,O
2945,relational,B
2945,reasoning,I
2945,module,I
2945,implements,B
2945,an,O
2945,interface,B
2945,:,O
2945,it,O
2945,operates,B
2945,on,I
2945,a,O
2945,graph,B
2945,of,B
2945,nodes,B
2945,and,I
2945,directed,I
2945,edges,I
2945,",",O
2945,where,B
2945,the,O
2945,nodes,O
2945,are,O
2945,represented,B
2945,by,I
2945,real,B
2945,valued,I
2945,vectors,I
2945,",",O
2945,and,O
2945,is,B
2945,differentiable,B
2945,.,O
2946,We,O
2946,introduce,O
2946,the,O
2946,recurrent,B
2946,relational,I
2946,network,I
2946,",",O
2946,a,O
2946,general,O
2946,purpose,O
2946,module,O
2946,that,O
2946,operates,O
2946,on,O
2946,a,O
2946,graph,O
2946,representation,O
2946,of,O
2946,objects,O
2946,.,O
2947,shows,B
2947,the,I
2947,performance,B
2947,of,B
2947,a,O
2947,logistic,B
2947,regression,I
2947,model,I
2947,trained,B
2947,using,B
2947,all,I
2947,the,O
2947,features,O
2947,(,O
2947,All,O
2947,),O
2947,and,O
2947,then,O
2947,using,O
2947,individual,B
2947,feature,I
2947,-,I
2947,groups,I
2947,.,O
2948,We,O
2948,can,O
2948,see,B
2948,that,I
2948,the,O
2948,features,B
2948,extracted,B
2948,from,I
2948,the,O
2948,aspect,B
2948,analyzing,B
2948,the,O
2948,event,B
2948,-,I
2948,sequence,I
2948,have,B
2948,the,O
2948,strongest,B
2948,predictive,I
2948,power,I
2948,",",O
2948,followed,B
2948,by,I
2948,those,O
2948,characterizing,B
2948,Sentiment,B
2948,-,O
2948,trajectory,O
2948,.,O
2949,The,O
2949,features,B
2949,measuring,B
2949,top,B
2949,-,I
2949,ical,I
2949,consistency,I
2949,result,B
2949,in,I
2949,lowest,B
2949,accuracy,I
2949,but,O
2949,they,O
2949,still,O
2949,perform,B
2949,better,I
2949,than,B
2949,random,B
2949,on,O
2949,the,O
2949,task,O
2949,.,O
2950,DSSM,B
2950,:,O
2950,It,O
2950,trains,B
2950,two,B
2950,deep,I
2950,neural,I
2950,networks,I
2950,to,B
2950,project,I
2950,the,I
2950,context,B
2950,and,I
2950,the,O
2950,ending,O
2950,-,O
2950,options,O
2950,into,B
2950,the,O
2950,same,B
2950,vector,I
2950,space,I
2950,.,O
2951,Msap,B
2951,:,O
2952,It,O
2952,trains,B
2952,a,O
2952,logistic,B
2952,regression,I
2952,based,I
2952,on,I
2952,stylistic,B
2952,and,I
2952,languagemodel,I
2952,based,O
2952,features,O
2952,.,O
2953,LR,B
2953,:,O
2953,Our,O
2953,next,O
2953,baseline,O
2953,is,B
2953,a,O
2953,simple,B
2953,logistic,I
2953,regression,I
2953,model,I
2953,which,O
2953,is,O
2953,agnostic,B
2953,to,I
2953,the,O
2953,fact,O
2953,that,O
2953,there,O
2953,are,O
2953,multiple,B
2953,types,I
2953,of,I
2953,aspects,I
2953,.,O
2954,This,O
2954,ensemble,B
2954,method,I
2954,uses,B
2954,the,O
2954,features,B
2954,extracted,B
2954,for,I
2954,each,O
2954,of,O
2954,the,O
2954,K,B
2954,=,I
2954,3,I
2954,aspects,I
2954,",",O
2954,to,B
2954,train,I
2954,K,O
2954,separate,O
2954,logistic,O
2954,regression,O
2954,models,O
2954,.,O
2955,This,O
2955,baseline,O
2955,also,O
2955,learns,B
2955,K,B
2955,different,I
2955,aspect,I
2955,-,I
2955,specific,I
2955,classifiers,I
2955,.,O
2956,We,O
2956,can,O
2956,see,B
2956,that,O
2956,UT,B
2956,-,I
2956,Time,I
2956,is,B
2956,about,I
2956,3,B
2956,%,I
2956,better,B
2956,than,I
2956,AP,B
2956,-,O
2956,1,O
2956,in,B
2956,the,O
2956,absolute,B
2956,value,I
2956,of,I
2956,F,I
2956,1,O
2956,",",O
2956,which,O
2956,is,O
2956,expected,O
2956,since,O
2956,UTTime,O
2956,included,O
2956,more,O
2956,advanced,O
2956,features,O
2956,derived,O
2956,from,O
2956,syntactic,O
2956,parse,O
2956,trees,O
2956,.,O
2957,Like,O
2957,the,O
2957,voting,O
2957,methods,O
2957,",",O
2957,this,O
2957,baseline,O
2957,also,O
2957,trains,B
2957,K,B
2957,different,I
2957,aspectspecific,I
2957,classifiers,I
2957,.,O
2958,In,O
2958,this,O
2958,paper,O
2958,we,O
2958,explore,B
2958,three,B
2958,semantic,I
2958,aspects,I
2958,of,B
2958,story,B
2958,understanding,I
2958,:,O
2958,(,O
2958,i,O
2958,),O
2958,the,O
2958,sequence,B
2958,of,O
2958,events,O
2958,described,O
2958,in,O
2958,the,O
2958,story,O
2958,",",O
2958,(,O
2958,ii,O
2958,),O
2958,the,O
2958,evolution,B
2958,of,O
2958,sentiment,B
2958,and,I
2958,emotional,I
2958,trajectories,I
2958,",",O
2958,and,O
2958,(,O
2958,iii,O
2958,),O
2958,topical,B
2958,consistency,I
2958,.,O
2959,The,O
2959,first,B
2959,aspect,I
2959,is,O
2959,motivated,B
2959,from,I
2959,approaches,O
2959,in,O
2959,semantic,B
2959,script,I
2959,induction,I
2959,",",O
2959,and,O
2959,evaluates,B
2959,if,I
2959,events,I
2959,described,B
2959,in,O
2959,an,O
2959,ending,B
2959,-,I
2959,alternative,I
2959,are,O
2959,likely,B
2959,to,I
2959,occur,B
2959,within,B
2959,the,O
2959,sequence,B
2959,of,I
2959,events,O
2959,described,O
2959,in,O
2959,the,O
2959,preceding,B
2959,context,I
2959,.,O
2960,Our,O
2960,model,O
2960,captures,O
2960,this,O
2960,by,O
2960,evaluating,B
2960,if,I
2960,the,O
2960,sentiment,B
2960,described,B
2960,in,I
2960,an,O
2960,ending,B
2960,option,I
2960,makes,B
2960,sense,I
2960,considering,B
2960,the,O
2960,context,B
2960,of,B
2960,the,O
2960,story,B
2960,.,O
2961,Our,O
2961,model,O
2961,accounts,O
2961,for,O
2961,that,O
2961,by,O
2961,analyzing,B
2961,if,I
2961,the,O
2961,topic,B
2961,of,B
2961,an,O
2961,ending,B
2961,option,I
2961,is,O
2961,consistent,B
2961,with,I
2961,the,O
2961,preceding,B
2961,context,I
2961,.,O
2962,We,O
2962,present,B
2962,a,O
2962,log,B
2962,-,I
2962,linear,I
2962,model,I
2962,that,O
2962,is,O
2962,used,B
2962,to,I
2962,weigh,B
2962,the,O
2962,various,B
2962,aspects,I
2962,of,B
2962,the,O
2962,story,B
2962,using,B
2962,a,O
2962,hidden,B
2962,variable,I
2962,.,O
2963,For,O
2963,these,O
2963,reasons,O
2963,",",O
2963,automatically,B
2963,understanding,I
2963,stories,I
2963,is,O
2963,an,O
2963,interesting,O
2963,but,O
2963,challenging,O
2963,task,O
2963,for,O
2963,Computational,O
2963,Linguists,O
2963,.,O
2964,On,O
2964,top,O
2964,of,O
2964,AP,B
2964,-,I
2964,2,I
2964,",",O
2964,a,O
2964,global,B
2964,inference,I
2964,step,I
2964,enforcing,B
2964,symmetry,B
2964,and,I
2964,transitivity,I
2964,constraints,I
2964,(,O
2964,"""",O
2964,AP,O
2964,+,O
2964,ILP,O
2964,"""",O
2964,),O
2964,can,O
2964,further,B
2964,improve,I
2964,the,O
2964,F,B
2964,1,I
2964,score,I
2964,by,B
2964,9.3,B
2964,%,I
2964,",",O
2964,which,O
2964,is,O
2964,consistent,O
2964,with,O
2964,previous,O
2964,observations,O
2964,.,O
2965,Recently,O
2965,",",O
2965,introduced,O
2965,the,O
2965,story,B
2965,-,I
2965,cloze,I
2965,task,O
2965,for,O
2965,testing,O
2965,this,O
2965,ability,O
2965,",",O
2965,albeit,O
2965,without,O
2965,the,O
2965,aspect,O
2965,of,O
2965,language,O
2965,generation,O
2965,.,O
2966,First,O
2966,",",O
2966,we,O
2966,add,B
2966,ELMo,B
2966,which,O
2966,is,B
2966,the,O
2966,weighted,O
2966,sum,O
2966,of,O
2966,hidden,O
2966,layers,O
2966,of,O
2966,language,O
2966,model,O
2966,with,O
2966,regularization,O
2966,as,O
2966,an,O
2966,additional,O
2966,feature,O
2966,to,B
2966,our,O
2966,word,O
2966,embeddings,O
2966,.,O
2967,This,O
2967,helped,B
2967,our,B
2967,model,I
2967,(,I
2967,MAMCN,I
2967,+,I
2967,ELMo,I
2967,),I
2967,to,B
2967,improve,I
2967,F1,B
2967,to,O
2967,85.13,B
2967,and,O
2967,EM,B
2967,to,O
2967,77.44,B
2967,and,O
2967,is,O
2967,the,O
2967,best,B
2967,among,B
2967,the,O
2967,models,B
2967,only,B
2967,with,I
2967,the,O
2967,additional,B
2967,feature,I
2967,augmentation,I
2967,.,O
2968,We,O
2968,replace,B
2968,all,O
2968,the,O
2968,BiGRU,B
2968,units,I
2968,with,B
2968,this,O
2968,embedding,B
2968,block,I
2968,except,B
2968,the,O
2968,controller,B
2968,layer,I
2968,in,B
2968,our,B
2968,model,I
2968,(,I
2968,MAMCN,I
2968,+,I
2968,ELMo,I
2968,+,O
2968,DC,O
2968,),O
2968,.,O
2969,We,O
2969,achieve,B
2969,the,I
2969,state,B
2969,of,I
2969,the,O
2969,art,O
2969,performance,O
2969,",",O
2969,86.73,B
2969,F1,I
2969,and,I
2969,79.69,I
2969,EM,I
2969,",",O
2969,with,O
2969,the,O
2969,help,O
2969,of,O
2969,this,O
2969,em-bedding,O
2969,block,O
2969,.,O
2970,We,O
2970,develop,B
2970,MAMCN,B
2970,using,B
2970,Tensorflow,B
2970,1,I
2970,deep,I
2970,learning,I
2970,framework,I
2970,and,O
2970,Sonnet,B
2970,2,I
2970,library,I
2970,.,O
2971,For,B
2971,the,O
2971,word,B
2971,-,I
2971,level,I
2971,embedding,I
2971,",",O
2971,we,O
2971,tokenize,B
2971,the,O
2971,documents,B
2971,using,B
2971,NLTK,B
2971,toolkit,I
2971,and,O
2971,substitute,B
2971,words,B
2971,with,B
2971,GloVe,B
2971,6B,I
2971,43.16,O
2971,46.90,O
2971,49.28,O
2971,55.83,O
2971,BiDAF,O
2971,40.32,O
2971,45.91,O
2971,44.86,O
2971,50.71,O
2971,hidden,O
2971,size,O
2971,is,O
2971,set,O
2971,to,O
2971,200,O
2971,for,O
2971,QUASAR,O
2971,-,O
2971,T,O
2971,and,O
2971,Triv,O
2971,-,O
2971,iaQA,O
2971,",",O
2971,and,O
2971,100,O
2971,for,O
2971,SQuAD,O
2971,.,O
2972,In,B
2972,the,O
2972,memory,O
2972,controller,O
2972,",",O
2972,we,O
2972,use,B
2972,100,B
2972,x,I
2972,36,I
2972,size,I
2972,memory,O
2972,initialized,B
2972,with,I
2972,zeros,B
2972,",",O
2972,4,B
2972,read,B
2972,heads,I
2972,and,O
2972,1,B
2972,write,B
2972,head,I
2972,.,O
2973,The,O
2973,optimizer,B
2973,is,B
2973,AdaDelta,B
2973,(,I
2973,Zeiler,I
2973,",",I
2973,2012,I
2973,),I
2973,with,B
2973,an,O
2973,initial,B
2973,learning,I
2973,rate,I
2973,of,B
2973,0.5,B
2973,.,O
2974,We,O
2974,train,B
2974,our,O
2974,model,B
2974,for,B
2974,12,B
2974,epochs,I
2974,",",O
2974,and,O
2974,batch,B
2974,size,I
2974,is,O
2974,set,B
2974,to,I
2974,30,B
2974,.,O
2975,SP,O
2975,+,O
2975,ILP,O
2975,further,B
2975,improved,I
2975,the,O
2975,performance,B
2975,in,B
2975,precision,B
2975,",",I
2975,recall,I
2975,",",O
2975,and,O
2975,F,B
2975,1,I
2975,significantly,O
2975,(,O
2975,per,O
2975,the,O
2975,McNemar,O
2975,'s,O
2975,test,O
2975,with,O
2975,p,O
2975,<,O
2975,0.0005,O
2975,),O
2975,",",O
2975,reaching,B
2975,an,O
2975,F,O
2975,1,O
2975,score,O
2975,of,B
2975,67.2,B
2975,%,I
2975,.,O
2976,During,B
2976,the,O
2976,training,B
2976,",",O
2976,we,O
2976,keep,B
2976,the,O
2976,exponential,B
2976,moving,I
2976,average,I
2976,of,B
2976,weights,B
2976,with,B
2976,0.001,B
2976,decay,I
2976,and,O
2976,use,B
2976,these,O
2976,averages,B
2976,at,B
2976,test,B
2976,time,I
2976,.,O
2977,In,O
2977,this,O
2977,work,O
2977,",",O
2977,we,O
2977,build,B
2977,a,O
2977,QA,B
2977,model,I
2977,that,O
2977,can,O
2977,understand,B
2977,long,B
2977,documents,I
2977,by,B
2977,utilizing,I
2977,Memory,B
2977,Augmented,I
2977,Neural,I
2977,Networks,I
2977,(,I
2977,MANNs,I
2977,),I
2977,.,O
2978,This,O
2978,type,O
2978,of,O
2978,neural,O
2978,networks,O
2978,decouples,B
2978,the,O
2978,memory,B
2978,capacity,I
2978,from,B
2978,the,O
2978,number,B
2978,of,O
2978,model,O
2978,parameters,O
2978,.,O
2979,A,O
2979,Multi,O
2979,-,O
2979,Stage,O
2979,Memory,O
2979,Augmented,O
2979,Neural,O
2979,Network,O
2979,for,O
2979,Machine,B
2979,Reading,I
2979,Comprehension,I
2980,In,O
2980,recent,O
2980,years,O
2980,",",O
2980,several,O
2980,end,O
2980,-,O
2980,to,O
2980,-,O
2980,end,O
2980,neural,O
2980,network,O
2980,models,O
2980,have,O
2980,been,O
2980,proposed,O
2980,to,O
2980,solve,O
2980,RC,B
2980,tasks,O
2980,.,O
2981,One,O
2981,possible,O
2981,way,O
2981,of,O
2981,measuring,O
2981,RC,O
2981,is,O
2981,by,O
2981,formulating,O
2981,it,O
2981,as,O
2981,answer,B
2981,span,I
2981,prediction,I
2981,style,I
2981,Question,I
2981,Answering,I
2981,(,I
2981,QA,I
2981,),I
2981,task,O
2981,",",O
2981,which,O
2981,is,O
2981,finding,O
2981,an,O
2981,answer,O
2981,to,O
2981,the,O
2981,question,O
2981,based,O
2981,on,O
2981,the,O
2981,given,O
2981,document,O
2981,(,O
2981,s,O
2981,),O
2981,.,O
2982,Recently,O
2982,",",O
2982,influential,O
2982,deep,O
2982,learning,O
2982,approaches,O
2982,have,O
2982,been,O
2982,proposed,O
2982,to,O
2982,solve,O
2982,this,O
2982,QA,B
2982,task,O
2982,.,O
2983,As,O
2983,described,O
2983,in,O
2983,",",O
2983,the,O
2983,baseline,O
2983,(,O
2983,BiDAF,O
2983,+,O
2983,DNC,O
2983,),O
2983,results,O
2983,in,O
2983,a,O
2983,reasonable,O
2983,gain,O
2983,",",O
2983,however,O
2983,",",O
2983,our,B
2983,proposed,I
2983,memory,I
2983,controller,I
2983,gives,B
2983,more,B
2983,performance,I
2983,improvement,I
2983,.,O
2984,Since,O
2984,",",O
2984,work,O
2984,on,O
2984,RE,B
2984,has,O
2984,revolved,O
2984,around,O
2984,end,O
2984,-,O
2984,to,O
2984,-,O
2984,end,O
2984,systems,O
2984,:,O
2984,single,O
2984,models,O
2984,which,O
2984,first,O
2984,perform,O
2984,entity,O
2984,mention,O
2984,detection,O
2984,and,O
2984,then,O
2984,relation,O
2984,extraction,O
2984,.,O
2985,We,O
2985,achieve,B
2985,68.13,B
2985,EM,I
2985,and,I
2985,70.32,I
2985,F1,I
2985,for,B
2985,short,B
2985,documents,I
2985,and,O
2985,63.44,B
2985,and,O
2985,65.19,O
2985,for,O
2985,long,B
2985,documents,O
2985,which,O
2985,are,O
2985,the,O
2985,current,O
2985,best,O
2985,results,O
2985,.,O
2986,TriviaQA,B
2986,:,O
2986,We,O
2986,compare,O
2986,proposed,O
2986,model,O
2986,with,O
2986,all,O
2986,the,O
2986,previously,O
2986,suggested,O
2986,approaches,O
2986,as,O
2986,shown,O
2986,in,O
2986,.,O
2987,Our,O
2987,model,O
2987,achieves,B
2987,the,I
2987,state,B
2987,of,I
2987,the,O
2987,art,O
2987,performance,O
2987,over,O
2987,the,O
2987,existing,O
2987,approaches,O
2987,as,O
2987,shown,O
2987,in,O
2987,77.58,O
2987,84.16,O
2987,O,O
2987,-,O
2987,QANet,O
2987,76.24,O
2987,84.60,O
2987,O,O
2987,O,O
2987,SAN,O
2987,76.83,O
2987,84.40,O
2987,O,O
2987,O,O
2987,Fusion,O
2987,Net,O
2987,75.97,O
2987,83.90,O
2987,O,O
2987,O,O
2987,RaSoR,O
2987,+,O
2987,TR,O
2987,75.79,O
2987,83.26,O
2987,O,O
2987,-,O
2987,Conducter-,O
2987,net,O
2987,74.41,O
2987,82.74,O
2987,O,O
2987,O,O
2987,Reinforced,O
2987,Mnemonic,O
2987,Reader,O
2987,73.20,O
2987,81.80,O
2987,O,O
2987,O,O
2987,BiDAF,O
2987,+,O
2987,Self-attention,O
2987,72.14,O
2987,81.05,O
2987,-,O
2987,O,O
2987,MEMEN,O
2987,70.98,O
2987,80.36,O
2987,O,O
2987,-,O
2987,MAMCN,O
2987,70.99,O
2987,79.94,O
2987,-r-,O
2987,net,O
2987,71.30,O
2987,79.70,O
2987,-,O
2987,O,O
2987,Document,O
2987,Reader,O
2987,70.73,O
2987,79.35,O
2987,O,O
2987,-,O
2987,FastQAExt,O
2987,70,O
2987,.,O
2988,The,O
2988,architecture,B
2988,was,O
2988,implemented,B
2988,using,I
2988,PyTorch,B
2988,.,O
2989,The,O
2989,sentence,B
2989,embeddings,I
2989,have,B
2989,hidden,B
2989,size,B
2989,of,B
2989,600,B
2989,for,B
2989,both,B
2989,direction,I
2989,(,I
2989,except,O
2989,for,O
2989,SentEval,O
2989,test,O
2989,",",O
2989,where,O
2989,we,O
2989,test,O
2989,models,O
2989,with,O
2989,600D,O
2989,and,O
2989,1200D,O
2989,per,O
2989,direction,O
2989,),O
2989,and,O
2989,the,O
2989,3,B
2989,-,I
2989,layer,I
2989,multilayer,I
2989,perceptron,I
2989,(,O
2989,MLP,O
2989,),O
2989,have,O
2989,the,O
2989,size,O
2989,of,O
2989,600,O
2989,dimensions,O
2989,.,O
2990,For,O
2990,all,O
2990,of,O
2990,our,O
2990,models,O
2990,we,O
2990,used,B
2990,a,O
2990,gradient,B
2990,descent,I
2990,optimization,I
2990,algorithm,I
2990,based,B
2990,on,I
2990,the,O
2990,Adam,B
2990,update,I
2990,rule,I
2990,",",O
2990,which,O
2990,is,O
2990,pre-implemented,B
2990,in,I
2990,PyTorch,B
2990,.,O
2991,We,O
2991,used,O
2991,a,O
2991,learning,B
2991,rate,I
2991,of,B
2991,5e,B
2991,-,I
2991,4,I
2991,for,O
2991,all,O
2991,our,O
2991,models,O
2991,.,O
2992,The,O
2992,learning,O
2992,rate,O
2992,was,O
2992,decreased,B
2992,by,I
2992,the,O
2992,factor,B
2992,of,B
2992,0.2,B
2992,after,B
2992,each,B
2992,epoch,I
2992,if,B
2992,the,O
2992,model,B
2992,did,O
2992,not,B
2992,improve,B
2992,.,O
2993,We,O
2993,used,O
2993,a,O
2993,batch,B
2993,size,I
2993,of,B
2993,64,B
2993,.,O
2994,The,O
2994,improvement,B
2994,of,I
2994,SP,B
2994,+,I
2994,ILP,I
2994,(,O
2994,line,O
2994,4,O
2994,),O
2994,over,B
2994,AP,B
2994,(,O
2994,line,O
2994,2,O
2994,),O
2994,was,B
2994,small,B
2994,and,O
2994,AP,O
2994,+,O
2994,ILP,O
2994,(,O
2994,line,O
2994,3,O
2994,),O
2994,was,O
2994,even,B
2994,worse,I
2994,than,I
2994,AP,O
2994,",",O
2994,which,O
2994,necessitates,O
2994,the,O
2994,use,O
2994,of,O
2994,a,O
2994,better,O
2994,approach,O
2994,towards,O
2994,vague,O
2994,TLINKs,O
2994,.,O
2995,We,O
2995,use,B
2995,pre-trained,B
2995,Glo,I
2995,Ve,I
2995,word,I
2995,embeddings,I
2995,of,B
2995,size,B
2995,300,B
2995,dimensions,I
2995,(,O
2995,Glo,O
2995,Ve,O
2995,840B,O
2995,300D,O
2995,;,O
2995,",",O
2995,which,O
2995,were,O
2995,fine,O
2995,-,O
2995,tuned,O
2995,during,O
2995,training,O
2995,.,O
2996,We,O
2996,use,O
2996,a,O
2996,dropout,B
2996,of,B
2996,0.1,B
2996,between,B
2996,the,O
2996,MLP,B
2996,layers,I
2996,(,O
2996,except,O
2996,just,O
2996,before,O
2996,the,O
2996,final,O
2996,layer,O
2996,),O
2996,.,O
2997,Our,O
2997,models,O
2997,were,O
2997,trained,B
2997,using,I
2997,one,B
2997,NVIDIA,I
2997,Tesla,I
2997,P100,I
2997,GPU,I
2997,.,O
2998,With,O
2998,the,O
2998,goal,O
2998,of,O
2998,obtaining,O
2998,general,O
2998,-,O
2998,purpose,O
2998,sentence,B
2998,representations,O
2998,in,O
2998,mind,O
2998,",",O
2998,we,O
2998,opt,B
2998,for,I
2998,the,O
2998,sentence,O
2998,encoding,O
2998,approach,O
2998,.,O
2999,Motivated,O
2999,by,O
2999,the,O
2999,success,O
2999,of,B
2999,the,O
2999,InferSent,B
2999,architecture,I
2999,we,O
2999,extend,B
2999,their,O
2999,architecture,O
2999,with,B
2999,a,O
2999,hierarchylike,B
2999,structure,I
2999,of,O
2999,bidirectional,B
2999,LSTM,I
2999,(,I
2999,BiLSTM,I
2999,),I
2999,layers,I
2999,with,O
2999,max,B
2999,pooling,I
2999,.,O
3000,It,O
3000,clearly,B
3000,outperforms,I
3000,the,I
3000,similar,O
3000,but,O
3000,non-hierarchical,B
3000,BiLSTM,I
3000,models,I
3000,reported,O
3000,in,B
3000,the,O
3000,literature,O
3000,and,O
3000,fares,B
3000,well,B
3000,in,O
3000,comparison,O
3000,to,O
3000,other,B
3000,state,I
3000,of,I
3000,the,O
3000,art,O
3000,architectures,O
3000,in,O
3000,the,O
3000,sentence,B
3000,encoding,I
3000,category,I
3000,.,O
3001,In,O
3001,particular,O
3001,",",O
3001,our,O
3001,results,O
3001,are,O
3001,close,B
3001,to,I
3001,the,I
3001,current,B
3001,state,I
3001,of,B
3001,the,O
3001,art,O
3001,on,O
3001,SNLI,B
3001,in,O
3001,this,O
3001,category,O
3001,and,O
3001,strong,B
3001,on,O
3001,both,O
3001,",",O
3001,the,O
3001,matched,B
3001,and,O
3001,mismatched,O
3001,test,O
3001,sets,O
3001,of,O
3001,MultiNLI,B
3001,.,O
3002,Finally,O
3002,",",O
3002,on,B
3002,SciTail,B
3002,",",O
3002,we,O
3002,achieve,B
3002,the,I
3002,new,B
3002,state,I
3002,of,B
3002,the,O
3002,art,O
3002,with,B
3002,an,O
3002,accuracy,B
3002,of,O
3002,86.0,B
3002,%,I
3002,.,O
3003,By,O
3003,applying,B
3003,the,O
3003,postfiltering,B
3003,method,I
3003,proposed,O
3003,in,O
3003,Sec.,O
3004,4,O
3004,",",O
3004,we,O
3004,were,O
3004,able,B
3004,to,I
3004,achieve,I
3004,better,B
3004,performances,I
3004,using,B
3004,SP,B
3004,+,I
3004,ILP,I
3004,(,O
3004,line,O
3004,5,O
3004,),O
3004,",",O
3004,which,O
3004,shows,O
3004,the,O
3004,effectiveness,O
3004,of,O
3004,this,O
3004,strategy,O
3004,.,O
3005,For,B
3005,the,O
3005,SNLI,B
3005,dataset,I
3005,",",O
3005,our,B
3005,model,I
3005,provides,B
3005,the,O
3005,test,B
3005,accuracy,I
3005,of,B
3005,86.6,B
3005,%,I
3005,after,B
3005,4,B
3005,epochs,I
3005,of,O
3005,training,B
3005,.,O
3006,For,O
3006,the,O
3006,MultiNLI,O
3006,matched,O
3006,test,B
3006,set,I
3006,(,I
3006,MultiNLI,O
3006,-,O
3006,m,O
3006,),O
3006,our,B
3006,model,I
3006,achieves,B
3006,a,O
3006,test,O
3006,accuracy,O
3006,of,O
3006,73.7,B
3006,%,I
3006,after,B
3006,3,B
3006,epochs,I
3006,of,O
3006,training,B
3006,",",O
3006,which,B
3006,is,I
3006,0.8,B
3006,%,O
3006,points,O
3006,lower,O
3006,than,B
3006,the,O
3006,state,B
3006,of,O
3006,the,O
3006,art,O
3006,74.5,O
3006,%,O
3006,by,O
3006,.,O
3007,For,O
3007,the,O
3007,mismatched,B
3007,test,B
3007,set,I
3007,(,I
3007,MultiNLI,I
3007,-,I
3007,mm,I
3007,),I
3007,our,B
3007,model,I
3007,achieves,B
3007,a,O
3007,test,O
3007,accuracy,O
3007,of,O
3007,73.0,B
3007,%,I
3007,after,B
3007,3,B
3007,epochs,I
3007,of,O
3007,training,B
3007,",",O
3007,which,B
3007,is,I
3007,0.6,B
3007,%,O
3007,points,O
3007,lower,O
3007,than,B
3007,the,O
3007,state,B
3007,of,O
3007,the,O
3007,art,O
3007,73.6,O
3007,%,O
3007,by,O
3007,Chen,O
3007,",",O
3007,Zhu,O
3007,",",O
3007,Ling,O
3007,",",O
3007,Wei,O
3007,",",O
3007,Jiang,O
3007,",",O
3007,and,O
3007,Inkpen,O
3007,(,O
3007,2017,O
3007,b,O
3007,),O
3007,.,O
3008,On,B
3008,the,O
3008,SciTail,B
3008,dataset,I
3008,we,O
3008,compared,B
3008,our,B
3008,model,I
3008,also,O
3008,against,B
3008,non-sentence,B
3008,embedding,I
3008,-,I
3008,based,I
3008,models,I
3008,",",O
3008,as,O
3008,no,O
3008,results,O
3008,have,O
3008,been,O
3008,previously,O
3008,published,O
3008,which,O
3008,are,O
3008,based,O
3008,on,O
3008,independent,O
3008,sentence,O
3008,embeddings,O
3008,.,O
3009,We,O
3009,obtain,B
3009,a,O
3009,score,B
3009,of,I
3009,86.0,B
3009,%,I
3009,after,B
3009,4,B
3009,epochs,I
3009,of,O
3009,training,B
3009,",",O
3009,which,O
3009,is,B
3009,+,O
3009,2.7,B
3009,%,O
3009,points,O
3009,absolute,O
3009,improvement,O
3009,on,B
3009,the,I
3009,previous,B
3009,published,I
3009,state,I
3009,of,O
3009,the,O
3009,art,O
3009,by,O
3009,.,O
3010,Our,O
3010,model,O
3010,also,O
3010,outperforms,B
3010,In,B
3010,-,I
3010,fer,I
3010,Sent,I
3010,which,B
3010,achieves,B
3010,an,O
3010,accuracy,B
3010,of,O
3010,85.1,B
3010,%,I
3010,in,O
3010,our,O
3010,experiments,O
3010,.,O
3011,The,O
3011,results,O
3011,achieved,B
3011,by,I
3011,our,O
3011,proposed,B
3011,model,I
3011,are,B
3011,significantly,B
3011,higher,I
3011,than,B
3011,the,O
3011,previously,B
3011,published,I
3011,results,O
3011,.,O
3012,We,O
3012,learn,B
3012,the,O
3012,word,B
3012,vectors,I
3012,and,I
3012,paragraph,I
3012,vectors,O
3012,using,B
3012,"75,000",B
3012,training,I
3012,documents,I
3012,(,O
3012,"25,000",B
3012,labeled,I
3012,and,O
3012,"50,000",B
3012,unlabeled,I
3012,instances,I
3012,),O
3012,.,O
3013,The,O
3013,paragraph,B
3013,vectors,I
3013,for,B
3013,the,O
3013,"25,000",B
3013,labeled,I
3013,instances,I
3013,are,O
3013,then,O
3013,fed,B
3013,through,I
3013,a,O
3013,neural,B
3013,network,I
3013,with,B
3013,one,B
3013,hidden,I
3013,layer,I
3013,with,O
3013,50,B
3013,units,I
3013,and,O
3013,a,O
3013,logistic,B
3013,classifier,I
3013,to,B
3013,learn,O
3013,to,O
3013,predict,O
3013,the,O
3013,sentiment,B
3013,.,O
3014,In,O
3014,particular,O
3014,",",O
3014,we,O
3014,cross,O
3014,validate,O
3014,the,O
3014,window,O
3014,size,O
3014,",",O
3014,and,O
3014,the,O
3014,optimal,B
3014,window,O
3014,size,O
3014,is,B
3014,10,B
3014,words,I
3014,.,O
3015,The,O
3015,vector,B
3015,presented,B
3015,to,I
3015,the,O
3015,classifier,B
3015,is,O
3015,a,O
3015,concatenation,B
3015,of,I
3015,two,O
3015,vectors,O
3015,",",O
3015,one,O
3015,from,O
3015,PV,B
3015,-,I
3015,DBOW,I
3015,and,O
3015,one,O
3015,from,O
3015,PV,O
3015,-,O
3015,DM,O
3015,.,O
3016,In,O
3016,PV,O
3016,-,O
3016,DBOW,O
3016,",",O
3016,the,O
3016,learned,B
3016,vector,I
3016,representations,I
3016,have,B
3016,400,B
3016,dimensions,I
3016,.,O
3017,In,O
3017,PV,O
3017,-,O
3017,DM,O
3017,",",O
3017,the,O
3017,learned,B
3017,vector,I
3017,representations,I
3017,have,B
3017,400,B
3017,dimensions,I
3017,for,B
3017,both,O
3017,words,B
3017,and,I
3017,documents,I
3017,.,O
3018,Special,O
3018,characters,O
3018,such,B
3018,as,I
3018,",",O
3018,.!,O
3019,are,O
3019,treated,B
3019,as,I
3019,a,O
3019,normal,B
3019,word,I
3019,.,O
3020,To,O
3020,predict,O
3020,the,O
3020,10,B
3020,-,I
3020,th,I
3020,word,B
3020,",",O
3020,we,O
3020,concatenate,B
3020,the,O
3020,paragraph,B
3020,vectors,I
3020,and,O
3020,word,O
3020,vectors,O
3020,.,O
3021,In,O
3021,this,O
3021,paper,O
3021,",",O
3021,we,O
3021,propose,B
3021,Paragraph,B
3021,Vector,I
3021,",",O
3021,an,O
3021,unsupervised,B
3021,framework,I
3021,that,B
3021,learns,I
3021,continuous,B
3021,distributed,I
3021,vector,O
3021,representations,O
3021,for,B
3021,pieces,B
3021,of,I
3021,texts,I
3021,.,O
3022,The,O
3022,name,O
3022,Paragraph,B
3022,Vector,I
3022,is,O
3022,to,O
3022,emphasize,O
3022,the,O
3022,fact,O
3022,that,O
3022,the,O
3022,method,O
3022,can,B
3022,be,I
3022,applied,I
3022,to,O
3022,variable,B
3022,-,I
3022,length,I
3022,pieces,I
3022,of,I
3022,texts,I
3022,",",O
3022,anything,O
3022,from,O
3022,a,O
3022,phrase,O
3022,or,O
3022,sentence,O
3022,to,O
3022,a,O
3022,large,O
3022,document,O
3022,.,O
3023,In,B
3023,our,O
3023,model,O
3023,",",O
3023,the,O
3023,vector,B
3023,representation,I
3023,is,O
3023,trained,B
3023,to,I
3023,be,I
3023,useful,B
3023,for,B
3023,predicting,I
3023,words,B
3023,in,O
3023,a,O
3023,paragraph,B
3023,.,O
3024,Both,O
3024,word,O
3024,vectors,O
3024,and,O
3024,paragraph,O
3024,vectors,O
3024,are,O
3024,trained,B
3024,by,I
3024,the,O
3024,stochastic,B
3024,gradient,I
3024,descent,I
3024,and,O
3024,backpropagation,B
3024,.,O
3025,SP,O
3025,+,O
3025,ILP,O
3025,outperformed,B
3025,CAEVO,B
3025,and,O
3025,if,O
3025,additional,O
3025,unlabeled,O
3025,dataset,O
3025,TE3,O
3025,-,O
3025,SV,O
3025,was,O
3025,used,O
3025,",",O
3025,CoDL,O
3025,+,O
3025,ILP,O
3025,achieved,O
3025,the,O
3025,best,O
3025,score,O
3025,with,O
3025,a,O
3025,relative,O
3025,improvement,O
3025,in,O
3025,F,O
3025,1,O
3025,score,O
3025,being,O
3025,6.3,O
3025,%,O
3025,.,O
3026,While,O
3026,paragraph,B
3026,vectors,I
3026,are,B
3026,unique,B
3026,among,B
3026,paragraphs,B
3026,",",O
3026,the,O
3026,word,B
3026,vectors,O
3026,are,O
3026,shared,B
3026,.,O
3027,More,O
3027,precisely,O
3027,",",O
3027,we,O
3027,concatenate,B
3027,the,O
3027,paragraph,B
3027,vector,I
3027,with,B
3027,several,B
3027,word,I
3027,vectors,I
3027,from,B
3027,a,O
3027,paragraph,O
3027,and,O
3027,predict,B
3027,the,O
3027,following,B
3027,word,O
3027,in,B
3027,the,O
3027,given,B
3027,context,I
3027,.,O
3028,At,B
3028,prediction,B
3028,time,I
3028,",",O
3028,the,O
3028,paragraph,O
3028,vectors,O
3028,are,O
3028,inferred,B
3028,by,I
3028,fixing,B
3028,the,O
3028,word,B
3028,vectors,O
3028,and,O
3028,training,B
3028,the,O
3028,new,B
3028,paragraph,O
3028,vector,O
3028,until,B
3028,convergence,B
3028,.,O
3029,As,O
3029,can,O
3029,be,O
3029,seen,O
3029,from,O
3029,the,O
3029,for,B
3029,long,B
3029,documents,I
3029,",",O
3029,bag,B
3029,-,I
3029,of,I
3029,-,O
3029,words,O
3029,models,O
3029,perform,B
3029,quite,B
3029,well,I
3029,and,O
3029,it,O
3029,is,O
3029,difficult,B
3029,to,I
3029,improve,I
3029,upon,O
3029,them,O
3029,using,B
3029,word,B
3029,vectors,I
3029,.,O
3030,The,O
3030,combination,B
3030,of,I
3030,two,I
3030,models,I
3030,yields,B
3030,an,O
3030,improvement,B
3030,approximately,B
3030,1.5,I
3030,%,I
3030,in,B
3030,terms,I
3030,of,O
3030,error,B
3030,rates,I
3030,.,O
3031,The,O
3031,method,B
3031,described,I
3031,in,O
3031,this,O
3031,paper,O
3031,is,B
3031,the,O
3031,only,B
3031,approach,I
3031,that,O
3031,goes,B
3031,significantly,B
3031,beyond,I
3031,the,O
3031,barrier,O
3031,of,B
3031,10,B
3031,%,I
3031,error,I
3031,rate,I
3031,.,O
3032,It,O
3032,achieves,B
3032,7.42,B
3032,%,I
3032,which,B
3032,is,I
3032,another,B
3032,1.3,I
3032,%,O
3032,absolute,O
3032,improvement,O
3032,(,O
3032,or,O
3032,15,B
3032,%,O
3032,relative,O
3032,improvement,O
3032,),O
3032,over,B
3032,the,O
3032,best,B
3032,previous,I
3032,result,I
3032,of,O
3032,..,O
3033,We,O
3033,use,O
3033,this,O
3033,method,O
3033,to,O
3033,construct,B
3033,Swag,B
3033,:,O
3033,an,O
3033,adversarial,B
3033,dataset,I
3033,with,B
3033,113,B
3033,k,I
3033,multiple,I
3033,-,I
3033,choice,I
3033,questions,I
3033,.,O
3034,We,O
3034,start,B
3034,with,I
3034,pairs,B
3034,of,B
3034,temporally,B
3034,adjacent,I
3034,video,I
3034,captions,I
3034,",",O
3034,each,B
3034,with,O
3034,a,O
3034,context,B
3034,and,O
3034,a,O
3034,follow,B
3034,-,I
3034,up,I
3034,event,I
3034,that,O
3034,we,O
3034,know,B
3034,is,O
3034,physically,B
3034,possible,I
3034,.,O
3035,Motivated,O
3035,by,O
3035,the,O
3035,success,O
3035,of,O
3035,transfer,O
3035,learning,O
3035,",",O
3035,we,O
3035,apply,B
3035,BERT,B
3035,to,B
3035,negation,B
3035,detection,I
3035,and,I
3035,scope,I
3035,resolution,I
3035,.,O
3036,We,O
3036,then,O
3036,use,B
3036,a,O
3036,state,B
3036,-,I
3036,of,B
3036,-,O
3036,theart,O
3036,language,O
3036,model,O
3036,fine,B
3036,-,O
3036,tuned,O
3036,on,O
3036,this,O
3036,data,B
3036,to,B
3036,massively,I
3036,oversample,I
3036,a,O
3036,diverse,B
3036,set,I
3036,of,O
3036,possible,B
3036,negative,I
3036,sentence,I
3036,endings,I
3036,(,I
3036,or,I
3036,counterfactuals,I
3036,),I
3036,.,O
3037,Next,O
3037,",",O
3037,we,O
3037,filter,B
3037,these,O
3037,candidate,O
3037,endings,O
3037,aggressively,B
3037,and,I
3037,adversarially,I
3037,using,B
3037,a,O
3037,committee,B
3037,of,B
3037,trained,I
3037,models,I
3037,to,B
3037,obtain,I
3037,a,O
3037,population,B
3037,of,O
3037,de-biased,B
3037,endings,O
3037,with,B
3037,similar,B
3037,stylistic,I
3037,features,I
3037,to,O
3037,the,O
3037,real,B
3037,ones,I
3037,.,O
3038,Finally,O
3038,",",O
3038,these,O
3038,filtered,B
3038,counterfactuals,I
3038,are,O
3038,validated,B
3038,by,I
3038,crowd,B
3038,workers,I
3038,to,B
3038,further,I
3038,ensure,I
3038,data,B
3038,quality,I
3038,.,O
3039,Swag,O
3039,:,O
3039,A,O
3039,Large,O
3039,-,O
3039,Scale,O
3039,Adversarial,O
3039,Dataset,O
3039,for,O
3039,Grounded,B
3039,Commonsense,I
3039,Inference,I
3040,The,O
3040,best,B
3040,model,I
3040,that,O
3040,only,B
3040,uses,I
3040,the,O
3040,ending,B
3040,is,B
3040,the,O
3040,LSTM,B
3040,sequence,I
3040,model,O
3040,with,B
3040,ELMo,B
3040,embeddings,I
3040,",",O
3040,which,O
3040,obtains,B
3040,43.6,B
3040,%,I
3040,.,O
3041,This,O
3041,model,O
3041,",",O
3041,as,O
3041,with,B
3041,most,O
3041,models,O
3041,studied,O
3041,",",O
3041,greatly,B
3041,improves,I
3041,with,O
3041,more,B
3041,context,I
3041,:,O
3041,by,B
3041,3.1,B
3041,%,I
3041,when,O
3041,given,B
3041,the,O
3041,initial,B
3041,noun,I
3041,phrase,I
3041,",",O
3041,and,O
3041,by,O
3041,an,O
3041,ad-ditional,B
3041,4,I
3041,%,O
3041,when,O
3041,also,O
3041,given,O
3041,the,O
3041,first,B
3041,sentence,I
3041,.,O
3042,Further,O
3042,improvement,O
3042,is,O
3042,gained,B
3042,from,I
3042,models,B
3042,that,B
3042,compute,I
3042,pairwise,B
3042,representations,I
3042,of,B
3042,the,O
3042,inputs,B
3042,.,O
3043,While,O
3043,the,O
3043,simplest,B
3043,such,I
3043,model,I
3043,",",O
3043,Dual,B
3043,-,I
3043,BoW,I
3043,",",O
3043,obtains,B
3043,only,B
3043,35.1,I
3043,%,I
3043,accuracy,I
3043,",",O
3043,combining,B
3043,In,B
3043,-,O
3043,fer,O
3043,Sent,O
3043,sentence,O
3043,representations,O
3043,gives,B
3043,40.5,B
3043,%,O
3043,accuracy,O
3043,(,O
3043,InferSent,B
3043,-,O
3043,Bilinear,O
3043,),O
3043,.,O
3044,The,O
3044,best,B
3044,results,I
3044,come,B
3044,from,I
3044,pairwise,B
3044,NLI,I
3044,models,I
3044,:,O
3044,when,O
3044,fully,B
3044,trained,I
3044,on,I
3044,Swag,B
3044,",",I
3044,ESIM,I
3044,+,I
3044,ELMo,I
3044,obtains,B
3044,59.2,B
3044,%,I
3044,accuracy,I
3044,.,O
3045,We,O
3045,can,O
3045,see,B
3045,that,I
3045,all,B
3045,modifications,I
3045,lead,B
3045,to,I
3045,a,O
3045,new,B
3045,model,I
3045,and,O
3045,their,O
3045,differences,O
3045,are,O
3045,statistically,O
3045,significant,O
3045,with,O
3045,a,O
3045,p-value,O
3045,of,O
3045,<,O
3045,0.001,O
3045,over,O
3045,Chi,O
3045,square,O
3045,test,O
3045,.,O
3046,We,O
3046,explore,B
3046,the,O
3046,set,O
3046,of,O
3046,design,B
3046,choices,I
3046,involved,O
3046,",",O
3046,and,O
3046,experiment,B
3046,on,I
3046,all,O
3046,3,B
3046,public,I
3046,datasets,I
3046,available,I
3046,:,O
3046,the,O
3046,BioScope,B
3046,Corpus,I
3046,(,I
3046,Abstracts,I
3046,and,O
3046,Full,O
3046,Papers,O
3046,),O
3046,",",O
3046,the,O
3046,Sherlock,B
3046,Dataset,I
3046,and,O
3046,the,O
3046,SFU,B
3046,Review,I
3046,Corpus,O
3046,.,O
3047,Among,B
3047,all,B
3047,components,I
3047,",",O
3047,three,B
3047,of,I
3047,them,I
3047,have,B
3047,noticeable,B
3047,influences,I
3047,:,O
3047,max,B
3047,pooling,I
3047,",",O
3047,difference,B
3047,in,I
3047,the,I
3047,attention,I
3047,stage,I
3047,",",O
3047,and,O
3047,dependent,B
3047,reading,I
3047,.,O
3048,They,O
3048,illustrate,B
3048,the,O
3048,importance,B
3048,of,B
3048,our,B
3048,proposed,I
3048,dependent,I
3048,reading,I
3048,strategy,I
3048,which,O
3048,leads,B
3048,to,I
3048,significant,B
3048,improvement,I
3048,",",O
3048,specifically,O
3048,in,B
3048,the,O
3048,encoding,B
3048,stage,I
3048,.,O
3049,demonstrates,B
3049,that,O
3049,we,O
3049,achieve,O
3049,the,O
3049,best,B
3049,performance,I
3049,with,B
3049,450,B
3049,-,I
3049,dimensional,I
3049,BiLSTMs,I
3049,.,O
3050,We,O
3050,use,B
3050,pre-trained,B
3050,300,I
3050,-,I
3050,D,I
3050,Glove,I
3050,840B,I
3050,vectors,I
3050,to,B
3050,initialize,I
3050,our,B
3050,word,I
3050,embedding,I
3050,vectors,O
3050,.,O
3051,We,O
3051,use,O
3051,a,O
3051,fairly,B
3051,small,I
3051,batch,I
3051,size,I
3051,of,B
3051,32,B
3051,to,O
3051,provide,O
3051,more,O
3051,exploration,O
3051,power,O
3051,to,O
3051,the,O
3051,model,O
3051,.,O
3052,All,O
3052,hidden,O
3052,states,O
3052,of,B
3052,BiLSTMs,B
3052,during,B
3052,input,B
3052,encoding,I
3052,and,I
3052,inference,I
3052,have,B
3052,450,B
3052,dimensions,I
3052,(,O
3052,r,O
3052,=,O
3052,300,O
3052,and,O
3052,d,O
3052,=,O
3052,450,O
3052,),O
3052,.,O
3053,The,O
3053,weights,B
3053,are,O
3053,learned,B
3053,by,I
3053,minimizing,B
3053,the,O
3053,log,B
3053,-,I
3053,loss,I
3053,on,B
3053,the,O
3053,training,B
3053,data,I
3053,via,B
3053,the,O
3053,Adam,B
3053,optimizer,I
3053,(,O
3053,Kingma,O
3053,and,O
3053,Ba,O
3053,",",O
3053,2014,O
3053,),O
3053,.,O
3054,The,O
3054,initial,B
3054,learning,I
3054,rate,I
3054,is,B
3054,0.0004,B
3054,.,O
3055,To,O
3055,avoid,O
3055,overfitting,B
3055,",",O
3055,we,O
3055,use,B
3055,dropout,B
3055,with,B
3055,the,O
3055,rate,B
3055,of,B
3055,0.4,B
3055,for,B
3055,regularization,B
3055,",",O
3055,which,O
3055,is,O
3055,applied,O
3055,to,O
3055,all,B
3055,feedforward,I
3055,connections,I
3055,.,O
3056,During,B
3056,training,B
3056,",",O
3056,the,O
3056,word,B
3056,embeddings,I
3056,are,O
3056,updated,B
3056,to,I
3056,learn,I
3056,effective,B
3056,representations,I
3056,for,B
3056,the,O
3056,NLI,B
3056,task,I
3056,.,O
3057,We,O
3057,use,B
3057,Google,B
3057,'s,I
3057,BERT,I
3057,as,B
3057,the,O
3057,base,B
3057,model,I
3057,to,B
3057,generate,I
3057,contextual,B
3057,embeddings,I
3057,for,B
3057,the,O
3057,sentence,B
3057,.,O
3058,We,O
3058,propose,B
3058,a,O
3058,dependent,B
3058,reading,I
3058,bidirectional,I
3058,LSTM,I
3058,(,I
3058,DR,I
3058,-,I
3058,BiLSTM,I
3058,),I
3058,model,I
3058,to,O
3058,address,O
3058,these,O
3058,limitations,O
3058,.,O
3059,Given,O
3059,a,O
3059,premise,B
3059,u,I
3059,and,I
3059,a,O
3059,hypothesis,O
3059,v,O
3059,",",O
3059,our,O
3059,model,O
3059,first,B
3059,encodes,I
3059,them,O
3059,considering,B
3059,dependency,B
3059,on,B
3059,each,B
3059,other,I
3059,.,O
3060,Next,O
3060,",",O
3060,the,O
3060,model,O
3060,employs,B
3060,a,O
3060,soft,B
3060,attention,I
3060,mechanism,I
3060,to,B
3060,extract,I
3060,relevant,B
3060,information,I
3060,from,B
3060,these,B
3060,encodings,I
3060,.,O
3061,The,O
3061,augmented,B
3061,sentence,I
3061,representations,I
3061,are,O
3061,then,O
3061,passed,B
3061,to,I
3061,the,O
3061,inference,B
3061,stage,I
3061,",",O
3061,which,O
3061,uses,B
3061,a,O
3061,similar,B
3061,dependent,I
3061,reading,I
3061,strategy,I
3061,in,B
3061,both,B
3061,directions,I
3061,",",O
3061,i.e.,O
3062,Finally,O
3062,",",O
3062,a,O
3062,decision,B
3062,is,O
3062,made,B
3062,through,I
3062,a,O
3062,multi,B
3062,-,I
3062,layer,I
3062,perceptron,I
3062,(,I
3062,MLP,I
3062,),I
3062,based,B
3062,on,I
3062,the,O
3062,aggregated,B
3062,information,I
3062,.,O
3063,DR-,O
3063,BiLSTM,O
3063,:,O
3063,Dependent,O
3063,Reading,O
3063,Bidirectional,O
3063,LSTM,O
3063,for,O
3063,Natural,B
3063,Language,I
3063,Inference,I
3064,We,O
3064,present,O
3064,a,O
3064,novel,O
3064,deep,O
3064,learning,O
3064,architecture,O
3064,to,O
3064,address,O
3064,the,O
3064,natural,B
3064,language,I
3064,inference,I
3064,(,I
3064,NLI,I
3064,),I
3064,task,O
3064,.,O
3065,The,O
3065,goal,O
3065,of,O
3065,NLI,B
3065,is,O
3065,to,O
3065,identify,O
3065,the,O
3065,logical,O
3065,relationship,O
3065,(,O
3065,entailment,O
3065,",",O
3065,neutral,O
3065,",",O
3065,or,O
3065,contradiction,O
3065,),O
3065,between,O
3065,a,O
3065,premise,O
3065,and,O
3065,a,O
3065,corresponding,O
3065,hypothesis,O
3065,.,O
3066,DR,O
3066,-,O
3066,BiLSTM,O
3066,(,O
3066,Single,O
3066,),O
3066,achieves,B
3066,88.5,B
3066,%,I
3066,accuracy,I
3066,on,B
3066,the,O
3066,test,B
3066,set,I
3066,which,O
3066,is,B
3066,noticeably,O
3066,the,O
3066,best,B
3066,reported,I
3066,result,I
3066,among,B
3066,the,O
3066,existing,B
3066,single,O
3066,models,O
3066,for,O
3066,this,O
3066,task,O
3066,.,O
3067,DR,O
3067,-,O
3067,BiLSTM,O
3067,(,O
3067,Ensemble,O
3067,),O
3067,achieves,B
3067,the,O
3067,accuracy,B
3067,of,B
3067,89.3,B
3067,%,I
3067,",",O
3067,the,O
3067,best,B
3067,result,I
3067,observed,B
3067,on,I
3067,SNLI,B
3067,",",O
3067,while,O
3067,DR,O
3067,-,O
3067,BiLSTM,O
3067,(,O
3067,Single,O
3067,),O
3067,obtains,B
3067,the,O
3067,accuracy,O
3067,of,O
3067,88.5,B
3067,%,O
3067,",",O
3067,which,O
3067,considerably,B
3067,outperforms,I
3067,the,O
3067,previous,B
3067,non-ensemble,I
3067,models,I
3067,.,O
3068,We,O
3068,then,O
3068,use,O
3068,a,O
3068,vector,B
3068,of,B
3068,dimension,B
3068,R,I
3068,H,I
3068,x,I
3068,N_C,I
3068,to,B
3068,compute,I
3068,scores,B
3068,per,I
3068,token,I
3068,",",O
3068,for,O
3068,the,O
3068,classification,O
3068,task,O
3068,at,O
3068,hand,O
3068,.,O
3069,Our,O
3069,ensemble,B
3069,model,I
3069,considerably,B
3069,outperforms,I
3069,the,I
3069,current,B
3069,state,I
3069,-,I
3069,of,I
3069,-,O
3069,the,O
3069,-,O
3069,art,O
3069,by,B
3069,obtaining,I
3069,89.3,B
3069,%,I
3069,accuracy,I
3069,.,O
3070,We,O
3070,can,O
3070,see,O
3070,that,O
3070,our,B
3070,preprocessing,B
3070,mechanism,I
3070,leads,B
3070,to,I
3070,further,B
3070,improvements,I
3070,of,B
3070,0.4,B
3070,%,I
3070,and,I
3070,0.3,I
3070,%,O
3070,on,B
3070,the,O
3070,SNLI,B
3070,test,I
3070,set,I
3070,for,B
3070,our,O
3070,single,O
3070,and,O
3070,ensemble,O
3070,models,O
3070,respectively,O
3070,.,O
3071,In,O
3071,fact,O
3071,",",O
3071,our,B
3071,single,I
3071,model,I
3071,(,I
3071,"""",O
3071,DR,B
3071,-,I
3071,BiLSTM,I
3071,(,O
3071,Single,O
3071,),O
3071,+,O
3071,Process,O
3071,"""",O
3071,),O
3071,obtains,B
3071,the,I
3071,state,B
3071,-,O
3071,of,O
3071,-,O
3071,the,O
3071,-,O
3071,art,O
3071,performance,O
3071,over,B
3071,both,O
3071,reported,B
3071,single,O
3071,and,O
3071,ensemble,O
3071,models,O
3071,by,B
3071,performing,I
3071,a,O
3071,simple,B
3071,preprocessing,I
3071,step,I
3071,.,O
3072,+,O
3072,Process,O
3072,"""",O
3072,outperforms,B
3072,the,I
3072,existing,B
3072,state,I
3072,-,I
3072,of,I
3072,-,O
3072,the,O
3072,-,O
3072,art,O
3072,remarkably,B
3072,(,O
3072,0.7,B
3072,%,I
3072,improvement,I
3072,),O
3072,.,O
3073,Also,O
3073,",",O
3073,utilizing,B
3073,a,O
3073,trivial,B
3073,preprocessing,I
3073,step,I
3073,yields,B
3073,to,I
3073,further,B
3073,improvements,I
3073,of,B
3073,0.4,B
3073,%,I
3073,and,I
3073,0.3,I
3073,%,O
3073,for,B
3073,single,B
3073,and,O
3073,ensemble,O
3073,DR,O
3073,-,O
3073,BiLSTM,O
3073,models,O
3073,respectively,O
3073,.,O
3074,We,O
3074,compute,O
3074,a,O
3074,vector,O
3074,gate,O
3074,as,O
3074,a,O
3074,linear,O
3074,projection,O
3074,of,O
3074,the,O
3074,token,O
3074,features,O
3074,followed,O
3074,1,O
3074,Code,O
3074,is,O
3074,available,O
3074,at,O
3074,https://github.com/kimiyoung/fg-gating,B
3074,1,O
3074,ar,O
3074,Xiv:,O
3074,1611.01724v2,O
3074,[,O
3074,cs.CL,O
3074,],O
3074,11,O
3074,Sep,O
3074,2017,O
3075,In,O
3075,this,O
3075,work,O
3075,",",O
3075,we,O
3075,present,B
3075,a,O
3075,fine,B
3075,-,I
3075,grained,I
3075,gating,I
3075,mechanism,I
3075,to,B
3075,combine,I
3075,the,O
3075,word,B
3075,-,O
3075,level,O
3075,and,O
3075,characterlevel,O
3075,representations,O
3075,.,O
3076,We,O
3076,compute,B
3076,a,O
3076,vector,B
3076,gate,I
3076,as,B
3076,a,O
3076,linear,B
3076,projection,I
3076,of,B
3076,the,O
3076,token,B
3076,features,I
3076,followed,O
3076,1,O
3076,Code,O
3076,is,O
3076,available,O
3076,at,O
3076,https://github.com/kimiyoung/fg-gating,O
3076,1,O
3076,ar,O
3076,Xiv:,O
3076,1611.01724v2,O
3076,[,O
3076,cs.CL,O
3076,],O
3076,11,O
3076,Sep,O
3076,2017,O
3077,We,O
3077,then,O
3077,multiplicatively,B
3077,apply,B
3077,the,O
3077,gate,B
3077,to,B
3077,the,O
3077,character,B
3077,-,I
3077,level,I
3077,and,I
3077,wordlevel,I
3077,representations,I
3077,.,O
3078,Each,O
3078,dimension,O
3078,of,B
3078,the,O
3078,gate,B
3078,controls,B
3078,how,B
3078,much,I
3078,information,I
3078,is,O
3078,flowed,B
3078,from,I
3078,the,O
3078,word,B
3078,-,I
3078,level,I
3078,and,I
3078,character,I
3078,-,O
3078,level,O
3078,representations,O
3078,respectively,O
3078,.,O
3079,We,O
3079,use,O
3079,early,B
3079,stopping,I
3079,on,B
3079,dev,B
3079,data,I
3079,for,B
3079,6,B
3079,epochs,I
3079,as,B
3079,tolerance,B
3079,and,O
3079,F,B
3079,1,I
3079,score,I
3079,as,O
3079,the,O
3079,early,O
3079,stopping,O
3079,metric,O
3079,",",O
3079,use,O
3079,the,O
3079,Adam,B
3079,optimizer,I
3079,with,B
3079,an,O
3079,initial,B
3079,learning,I
3079,rate,I
3079,of,B
3079,3,B
3079,e,I
3079,-,I
3079,5,I
3079,",",O
3079,and,O
3079,the,O
3079,Categorical,B
3079,Cross,I
3079,Entropy,I
3079,Loss,I
3079,with,O
3079,class,O
3079,weights,O
3079,as,O
3079,described,O
3079,above,O
3079,to,B
3079,avoid,I
3079,training,B
3079,on,O
3079,the,O
3079,padded,B
3079,label,I
3079,outputs,I
3079,.,O
3080,More,O
3080,generally,O
3080,",",O
3080,our,B
3080,fine,I
3080,-,I
3080,grained,I
3080,gating,I
3080,mechanism,I
3080,can,O
3080,be,O
3080,used,B
3080,to,I
3080,model,B
3080,multiple,B
3080,levels,I
3080,of,O
3080,structure,B
3080,in,B
3080,language,B
3080,",",O
3080,including,B
3080,words,B
3080,",",O
3080,characters,B
3080,",",O
3080,phrases,B
3080,",",O
3080,sentences,B
3080,and,O
3080,paragraphs,B
3080,.,O
3081,We,O
3081,use,B
3081,named,B
3081,entity,I
3081,tags,I
3081,",",O
3081,part,B
3081,-,I
3081,ofspeech,I
3081,tags,O
3081,",",O
3081,document,B
3081,frequencies,I
3081,",",O
3081,and,O
3081,word,B
3081,-,O
3081,level,O
3081,representations,O
3081,as,O
3081,the,O
3081,features,O
3081,for,B
3081,token,B
3081,properties,I
3081,which,O
3081,determine,B
3081,the,O
3081,gate,B
3081,.,O
3082,FINE,O
3082,-,O
3082,GRAINED,O
3082,GATING,O
3082,FOR,O
3082,READING,B
3082,COMPREHENSION,I
3083,First,O
3083,",",O
3083,as,O
3083,an,O
3083,effort,O
3083,to,O
3083,study,O
3083,the,O
3083,coverage,O
3083,of,O
3083,existing,O
3083,systems,O
3083,and,O
3083,the,O
3083,possibility,O
3083,to,O
3083,train,O
3083,jointly,O
3083,on,O
3083,different,O
3083,data,O
3083,sources,O
3083,via,O
3083,multitasking,O
3083,",",O
3083,we,O
3083,collected,B
3083,the,O
3083,first,O
3083,large,O
3083,-,O
3083,scale,O
3083,dataset,O
3083,of,O
3083,questions,O
3083,and,O
3083,answers,O
3083,based,B
3083,on,O
3083,a,O
3083,KB,B
3083,",",O
3083,called,B
3083,SimpleQuestions,B
3083,.,O
3084,This,O
3084,dataset,O
3084,",",O
3084,which,O
3084,is,O
3084,presented,O
3084,in,O
3084,Section,O
3084,2,O
3084,",",O
3084,contains,B
3084,more,B
3084,than,I
3084,100,I
3084,k,I
3084,questions,I
3084,written,O
3084,by,O
3084,human,O
3084,anno-What,O
3084,American,O
3084,cartoonist,O
3084,is,O
3084,the,O
3084,creator,O
3084,of,O
3084,Andy,O
3084,Lippincott,O
3084,?,O
3085,The,O
3085,embedding,B
3085,dimension,I
3085,and,I
3085,the,O
3085,learning,O
3085,rate,O
3085,were,O
3085,chosen,B
3085,among,I
3085,{,O
3085,64,O
3085,",",O
3085,128,O
3085,",",O
3085,256,O
3085,},O
3085,and,O
3085,{,O
3085,1,O
3085,",",O
3085,0.1,O
3085,",",O
3085,...,O
3085,",",O
3085,1.0e,O
3085,?,O
3086,4,O
3086,},O
3086,respectively,O
3086,",",O
3086,and,O
3086,the,O
3086,margin,B
3086,?,O
3087,was,O
3087,set,B
3087,to,I
3087,0.1,B
3087,.,O
3088,Second,O
3088,",",O
3088,in,O
3088,sections,O
3088,3,O
3088,and,O
3088,4,O
3088,",",O
3088,we,O
3088,present,B
3088,an,O
3088,embedding,B
3088,-,I
3088,based,I
3088,QA,I
3088,system,I
3088,developed,B
3088,under,I
3088,the,O
3088,framework,B
3088,of,I
3088,Memory,I
3088,Networks,I
3088,(,I
3088,Mem,I
3088,NNs,I
3088,),I
3088,.,O
3089,Memory,O
3089,Networks,O
3089,are,B
3089,learning,B
3089,systems,I
3089,centered,B
3089,around,I
3089,a,O
3089,memory,O
3089,component,O
3089,that,O
3089,can,B
3089,be,I
3089,read,B
3089,and,I
3089,written,I
3089,to,I
3089,",",I
3089,with,O
3089,a,O
3089,particular,O
3089,focus,B
3089,on,I
3089,cases,I
3089,where,I
3089,the,I
3089,relationship,B
3089,between,B
3089,the,O
3089,input,B
3089,and,O
3089,response,O
3089,languages,O
3089,(,O
3089,here,O
3089,natural,O
3089,language,O
3089,),O
3089,and,O
3089,the,O
3089,storage,B
3089,language,O
3089,(,O
3089,here,O
3089,",",O
3089,the,O
3089,facts,O
3089,from,O
3089,KBs,O
3089,),O
3089,is,O
3089,performed,B
3089,by,I
3089,embedding,B
3089,all,O
3089,of,O
3089,them,O
3089,in,B
3089,the,O
3089,same,B
3089,vector,I
3089,space,I
3089,.,O
3090,The,O
3090,setting,B
3090,of,B
3090,the,O
3090,simple,B
3090,QA,I
3090,corresponds,B
3090,to,I
3090,the,O
3090,elementary,B
3090,operation,I
3090,of,O
3090,performing,O
3090,a,O
3090,single,B
3090,lookup,I
3090,in,B
3090,the,O
3090,memory,B
3090,.,O
3091,Our,O
3091,proposed,O
3091,model,O
3091,achieves,B
3091,a,O
3091,new,B
3091,SOTA,I
3091,on,B
3091,RE,B
3091,with,B
3091,a,O
3091,F,B
3091,1,I
3091,of,B
3091,62.,O
3092,83,O
3092,",",O
3092,more,O
3092,than,O
3092,2.3,O
3092,F,B
3092,1,I
3092,above,O
3092,the,O
3092,previous,O
3092,SOTA,O
3092,.,O
3093,For,B
3093,all,O
3093,other,O
3093,corpuses,O
3093,",",O
3093,we,O
3093,use,O
3093,a,O
3093,default,B
3093,70,I
3093,-,I
3093,15,I
3093,-,O
3093,15,O
3093,split,O
3093,for,O
3093,the,O
3093,train,B
3093,-,O
3093,dev,O
3093,-,O
3093,test,O
3093,data,O
3093,.,O
3094,Training,O
3094,large,B
3094,-,I
3094,scale,I
3094,question,I
3094,answering,I
3094,systems,O
3094,is,O
3094,complicated,O
3094,because,O
3094,training,O
3094,sources,O
3094,usually,O
3094,cover,O
3094,a,O
3094,small,O
3094,portion,O
3094,of,O
3094,the,O
3094,range,O
3094,of,O
3094,possible,O
3094,questions,O
3094,.,O
3095,This,O
3095,paper,O
3095,studies,O
3095,the,O
3095,impact,O
3095,of,O
3095,multitask,O
3095,and,O
3095,transfer,O
3095,learning,O
3095,for,O
3095,simple,B
3095,question,I
3095,answering,I
3095,;,O
3095,a,O
3095,setting,O
3095,for,O
3095,which,O
3095,the,O
3095,reasoning,O
3095,required,O
3095,to,O
3095,answer,O
3095,is,O
3095,quite,O
3095,easy,O
3095,",",O
3095,as,O
3095,long,O
3095,as,O
3095,one,O
3095,can,O
3095,retrieve,O
3095,the,O
3095,correct,O
3095,evidence,O
3095,given,O
3095,a,O
3095,question,O
3095,",",O
3095,which,O
3095,can,O
3095,be,O
3095,difficult,O
3095,in,O
3095,large,O
3095,-,O
3095,scale,O
3095,conditions,O
3095,.,O
3096,However,O
3096,",",O
3096,while,O
3096,most,O
3096,recent,O
3096,efforts,O
3096,have,O
3096,focused,O
3096,on,O
3096,designing,O
3096,systems,O
3096,with,O
3096,higher,O
3096,reasoning,O
3096,capabilities,O
3096,",",O
3096,that,O
3096,could,O
3096,jointly,O
3096,retrieve,O
3096,and,O
3096,use,O
3096,multiple,O
3096,facts,O
3096,to,O
3096,answer,O
3096,",",O
3096,the,O
3096,simpler,O
3096,problem,O
3096,of,O
3096,answering,O
3096,questions,O
3096,that,O
3096,refer,O
3096,to,O
3096,a,O
3096,single,O
3096,fact,O
3096,of,O
3096,the,O
3096,KB,O
3096,",",O
3096,which,O
3096,we,O
3096,call,O
3096,Simple,B
3096,Question,I
3096,Answering,O
3096,in,O
3096,this,O
3096,paper,O
3096,",",O
3096,is,O
3096,still,O
3096,far,O
3096,from,O
3096,solved,O
3096,.,O
3097,On,B
3097,WebQuestions,B
3097,",",O
3097,not,O
3097,specifically,O
3097,designed,O
3097,as,O
3097,a,O
3097,simple,O
3097,QA,O
3097,dataset,O
3097,",",O
3097,86,B
3097,%,I
3097,of,I
3097,the,I
3097,questions,I
3097,can,O
3097,now,O
3097,be,O
3097,answered,B
3097,with,I
3097,a,O
3097,single,B
3097,supporting,I
3097,fact,I
3097,",",O
3097,and,O
3097,performance,B
3097,increases,B
3097,significantly,I
3097,(,O
3097,from,B
3097,36.2,B
3097,%,O
3097,to,B
3097,41.0,B
3097,%,O
3097,F1-score,O
3097,),O
3097,.,O
3098,Using,B
3098,the,O
3098,bigger,B
3098,FB5M,I
3098,as,I
3098,KB,I
3098,does,O
3098,not,B
3098,change,I
3098,performance,B
3098,on,B
3098,SimpleQuestions,B
3098,because,O
3098,it,O
3098,was,O
3098,based,O
3098,on,O
3098,FB2M,O
3098,",",O
3098,but,O
3098,the,O
3098,results,O
3098,show,O
3098,that,O
3098,our,O
3098,model,O
3098,is,O
3098,robust,O
3098,to,O
3098,the,O
3098,addition,O
3098,of,O
3098,more,O
3098,entities,O
3098,than,O
3098,necessary,O
3098,.,O
3099,Our,O
3099,best,B
3099,results,I
3099,are,B
3099,67,B
3099,%,I
3099,accuracy,I
3099,(,O
3099,and,O
3099,68,B
3099,%,O
3099,for,B
3099,the,O
3099,ensemble,B
3099,of,I
3099,5,I
3099,models,I
3099,),O
3099,",",O
3099,which,O
3099,are,O
3099,better,O
3099,than,O
3099,the,O
3099,54,O
3099,%,O
3099,of,O
3099,the,O
3099,original,O
3099,paper,O
3099,and,O
3099,close,O
3099,to,O
3099,the,O
3099,stateof,O
3099,-,O
3099,the,O
3099,-,O
3099,art,O
3099,73,O
3099,%,O
3099,of,O
3099,.,O
3100,We,O
3100,first,O
3100,notice,B
3100,that,O
3100,models,B
3100,trained,B
3100,on,B
3100,a,O
3100,single,B
3100,QA,I
3100,dataset,I
3100,perform,B
3100,poorly,B
3100,on,O
3100,the,O
3100,other,B
3100,datasets,I
3100,(,O
3100,e.g.,O
3101,46.6,O
3101,%,O
3101,accuracy,O
3101,on,B
3101,SimpleQuestions,O
3101,for,O
3101,the,O
3101,model,O
3101,trained,B
3101,on,O
3101,WebQuestions,O
3101,only,O
3101,),O
3101,",",O
3101,which,O
3101,shows,O
3101,that,O
3101,the,O
3101,performance,O
3101,on,O
3101,We-bQuestions,O
3101,does,O
3101,not,O
3101,necessarily,O
3101,guarantee,O
3101,high,O
3101,coverage,O
3101,for,O
3101,simple,O
3101,QA,O
3101,.,O
3102,On,O
3102,the,O
3102,other,O
3102,hand,O
3102,",",O
3102,training,O
3102,on,O
3102,both,B
3102,datasets,I
3102,only,O
3102,improves,B
3102,performance,B
3102,;,O
3102,in,O
3102,particular,O
3102,",",O
3102,the,O
3102,model,O
3102,is,O
3102,able,O
3102,to,O
3102,capture,O
3102,all,O
3102,question,O
3102,patterns,O
3102,of,O
3102,the,O
3102,two,O
3102,datasets,O
3102,;,O
3102,there,O
3102,is,O
3102,no,O
3102,"""",O
3102,negative,O
3102,interaction,O
3102,"""",O
3102,.,O
3103,The,O
3103,input,B
3103,to,I
3103,the,O
3103,BERT,B
3103,model,I
3103,is,B
3103,a,O
3103,sequence,B
3103,of,B
3103,tokenized,I
3103,and,I
3103,encoded,I
3103,tokens,I
3103,of,O
3103,a,O
3103,sentence,B
3103,.,O
3104,While,O
3104,paraphrases,B
3104,do,O
3104,not,B
3104,seem,I
3104,to,I
3104,help,B
3104,much,I
3104,on,B
3104,WebQuestions,B
3104,and,I
3104,SimpleQuestions,I
3104,",",O
3104,except,B
3104,when,I
3104,training,B
3104,only,B
3104,with,I
3104,synthetic,B
3104,questions,I
3104,",",O
3104,they,O
3104,have,B
3104,a,O
3104,dramatic,B
3104,impact,I
3104,on,O
3104,the,O
3104,performance,B
3104,on,O
3104,Reverb,B
3104,.,O
3105,In,O
3105,this,O
3105,work,O
3105,",",O
3105,we,O
3105,explore,B
3105,the,O
3105,supervised,B
3105,learning,I
3105,of,B
3105,task,B
3105,-,I
3105,specific,I
3105,",",O
3105,dynamic,O
3105,meta-embeddings,O
3105,",",O
3105,and,O
3105,apply,B
3105,the,O
3105,technique,O
3105,to,O
3105,sentence,B
3105,representations,I
3105,.,O
3106,First,O
3106,",",O
3106,it,O
3106,is,B
3106,embedding,B
3106,-,I
3106,agnostic,I
3106,",",O
3106,meaning,O
3106,that,O
3106,one,O
3106,of,O
3106,the,O
3106,main,O
3106,(,O
3106,and,O
3106,perhaps,O
3106,most,O
3106,important,O
3106,),O
3106,hyperparameters,O
3106,in,O
3106,NLP,O
3106,pipelines,O
3106,is,O
3106,made,O
3106,obsolete,O
3106,.,O
3107,Dynamic,O
3107,Meta,O
3107,-,O
3107,Embeddings,O
3107,for,O
3107,Improved,B
3107,Sentence,I
3107,Representations,I
3108,In,O
3108,this,O
3108,work,O
3108,",",O
3108,we,O
3108,explore,O
3108,the,O
3108,supervised,O
3108,learning,O
3108,of,O
3108,task,O
3108,-,O
3108,specific,O
3108,",",O
3108,dynamic,O
3108,meta-embeddings,O
3108,",",O
3108,and,O
3108,apply,O
3108,the,O
3108,technique,O
3108,to,O
3108,sentence,B
3108,representations,I
3108,.,O
3109,In,O
3109,this,O
3109,study,O
3109,",",O
3109,we,O
3109,propose,B
3109,Masque,B
3109,",",O
3109,a,O
3109,generative,B
3109,model,I
3109,for,B
3109,multi-passage,B
3109,RC,I
3109,.,O
3110,We,O
3110,introduce,B
3110,the,O
3110,pointer,B
3110,-,I
3110,generator,I
3110,mechanism,I
3110,for,B
3110,generating,I
3110,an,O
3110,abstractive,B
3110,answer,I
3110,from,B
3110,the,O
3110,question,B
3110,and,O
3110,multiple,B
3110,passages,I
3110,",",O
3110,which,O
3110,covers,B
3110,various,B
3110,answer,O
3110,styles,O
3110,.,O
3111,We,O
3111,introduce,O
3111,multi-style,B
3111,learning,I
3111,that,B
3111,enables,I
3111,our,B
3111,model,I
3111,to,B
3111,control,I
3111,answer,B
3111,styles,I
3111,and,O
3111,improves,B
3111,RC,B
3111,for,B
3111,all,B
3111,styles,O
3111,involved,O
3111,.,O
3112,We,O
3112,extend,B
3112,the,O
3112,mechanism,B
3112,to,B
3112,a,O
3112,Transformer,B
3112,based,I
3112,one,I
3112,that,B
3112,allows,I
3112,words,B
3112,to,O
3112,be,O
3112,generated,O
3112,from,O
3112,a,O
3112,vocabulary,B
3112,and,O
3112,to,O
3112,be,O
3112,copied,O
3112,from,O
3112,the,O
3112,question,B
3112,and,O
3112,passages,B
3112,.,O
3113,BERT,B
3113,outputs,B
3113,a,O
3113,vector,B
3113,of,B
3113,size,B
3113,R,B
3113,H,I
3113,per,I
3113,token,I
3113,of,O
3113,the,O
3113,input,O
3113,",",O
3113,which,O
3113,we,O
3113,feed,B
3113,to,I
3113,a,O
3113,common,B
3113,classification,I
3113,layer,I
3113,of,O
3113,dimen-sion,B
3113,R,O
3113,Hx5,O
3113,for,B
3113,cue,B
3113,detection,I
3113,and,O
3113,R,O
3113,Hx2,O
3113,for,O
3113,scope,B
3113,resolution,I
3113,.,O
3114,We,O
3114,also,O
3114,extend,O
3114,the,O
3114,pointer,B
3114,-,I
3114,generator,I
3114,to,I
3114,a,O
3114,conditional,B
3114,decoder,I
3114,by,O
3114,introducing,B
3114,an,O
3114,artificial,B
3114,token,I
3114,corresponding,B
3114,to,O
3114,each,B
3114,style,I
3114,",",O
3114,as,O
3114,in,O
3114,.,O
3115,For,B
3115,each,B
3115,decoding,I
3115,step,I
3115,",",O
3115,it,O
3115,controls,B
3115,the,O
3115,mixture,B
3115,weights,I
3115,over,B
3115,three,B
3115,distributions,I
3115,with,O
3115,the,O
3115,given,O
3115,style,O
3115,(,O
3115,),O
3115,.,O
3116,Multi,O
3116,-,O
3116,Style,O
3116,Generative,B
3116,Reading,I
3116,Comprehension,I
3117,This,O
3117,study,O
3117,tackles,O
3117,generative,B
3117,reading,I
3117,comprehension,I
3117,(,I
3117,RC,I
3117,),I
3117,",",O
3117,which,O
3117,consists,O
3117,of,O
3117,answering,O
3117,questions,O
3117,based,O
3117,on,O
3117,textual,O
3117,evidence,O
3117,and,O
3117,natural,O
3117,language,O
3117,generation,O
3117,(,O
3117,NLG,O
3117,),O
3117,.,O
3118,Recently,O
3118,",",O
3118,reading,B
3118,comprehension,I
3118,(,I
3118,RC,I
3118,),I
3118,",",O
3118,a,O
3118,challenge,O
3118,to,O
3118,answer,O
3118,a,O
3118,question,O
3118,given,O
3118,textual,O
3118,evidence,O
3118,provided,O
3118,in,O
3118,a,O
3118,document,O
3118,set,O
3118,",",O
3118,has,O
3118,received,O
3118,much,O
3118,attention,O
3118,.,O
3119,Current,O
3119,mainstream,O
3119,studies,O
3119,have,O
3119,treated,O
3119,RC,B
3119,as,O
3119,a,O
3119,process,O
3119,of,O
3119,extracting,O
3119,an,O
3119,answer,O
3119,span,O
3119,from,O
3119,one,O
3119,passage,O
3119,or,O
3119,multiple,O
3119,passages,O
3119,",",O
3119,which,O
3119,is,O
3119,usually,O
3119,done,O
3119,by,O
3119,predicting,O
3119,the,O
3119,start,O
3119,and,O
3119,end,O
3119,positions,O
3119,of,O
3119,the,O
3119,answer,O
3119,.,O
3120,In,O
3120,this,O
3120,study,O
3120,",",O
3120,we,O
3120,propose,O
3120,Masque,O
3120,",",O
3120,a,O
3120,generative,O
3120,model,O
3120,for,O
3120,multi-passage,B
3120,RC,I
3120,.,O
3121,shows,B
3121,that,O
3121,our,B
3121,single,I
3121,model,I
3121,",",O
3121,trained,B
3121,with,I
3121,two,B
3121,styles,I
3121,and,O
3121,controlled,B
3121,with,O
3121,the,O
3121,NQA,B
3121,style,I
3121,",",O
3121,pushed,B
3121,forward,I
3121,the,O
3121,state,B
3121,-,I
3121,of,I
3121,-,O
3121,the,O
3121,-,O
3121,art,O
3121,by,B
3121,a,O
3121,significant,B
3121,margin,I
3121,.,O
3122,The,O
3122,evaluation,B
3122,scores,I
3122,of,B
3122,the,O
3122,model,B
3122,controlled,B
3122,with,I
3122,the,O
3122,NLG,B
3122,style,I
3122,were,B
3122,low,B
3122,because,O
3122,the,O
3122,two,O
3122,styles,O
3122,are,O
3122,different,O
3122,.,O
3123,Also,O
3123,",",O
3123,our,B
3123,model,I
3123,without,B
3123,multi-style,B
3123,learning,I
3123,(,O
3123,trained,O
3123,with,O
3123,only,O
3123,the,O
3123,NQA,O
3123,style,O
3123,),O
3123,outperformed,B
3123,the,O
3123,baselines,B
3123,in,B
3123,terms,I
3123,of,I
3123,ROUGE,B
3123,-,I
3123,L,I
3123,.,O
3124,We,O
3124,perform,B
3124,cue,B
3124,detection,I
3124,and,I
3124,scope,I
3124,resolution,I
3124,for,B
3124,all,B
3124,3,I
3124,datasets,I
3124,",",O
3124,and,O
3124,train,B
3124,on,I
3124,1,B
3124,and,O
3124,test,B
3124,on,O
3124,all,O
3124,datasets,O
3124,.,O
3125,We,O
3125,can,O
3125,see,O
3125,that,O
3125,removing,B
3125,any,B
3125,components,I
3125,from,B
3125,the,O
3125,MPCM,B
3125,model,I
3125,decreases,B
3125,the,O
3125,performance,B
3125,significantly,B
3125,.,O
3126,Among,B
3126,all,B
3126,the,I
3126,layers,I
3126,",",O
3126,the,O
3126,Aggregation,B
3126,Layer,I
3126,is,B
3126,the,O
3126,most,B
3126,crucial,I
3126,layer,O
3126,.,O
3127,Among,O
3127,all,B
3127,the,I
3127,matching,I
3127,strategies,I
3127,",",O
3127,Maxpooling,B
3127,-,I
3127,Matching,O
3127,has,O
3127,the,O
3127,biggest,B
3127,effect,I
3127,.,O
3128,We,O
3128,process,B
3128,the,O
3128,corpus,B
3128,with,B
3128,the,O
3128,tokenizer,B
3128,from,B
3128,Stanford,B
3128,CorNLP,I
3128,.,O
3129,To,O
3129,initialize,B
3129,the,O
3129,word,O
3129,embeddings,O
3129,in,B
3129,the,O
3129,word,O
3129,representation,O
3129,layer,O
3129,",",O
3129,we,O
3129,use,B
3129,the,O
3129,300,B
3129,-,I
3129,dimensional,I
3129,GloVe,I
3129,word,O
3129,vectors,O
3129,pre-trained,B
3129,from,I
3129,the,O
3129,840B,B
3129,Common,I
3129,Crawl,I
3129,corpus,I
3129,.,O
3130,For,B
3130,the,O
3130,out,B
3130,-,I
3130,of,I
3130,-,O
3130,vocabulary,O
3130,(,O
3130,OOV,O
3130,),O
3130,words,O
3130,",",O
3130,we,O
3130,initialize,B
3130,the,O
3130,word,B
3130,embeddings,I
3130,randomly,B
3130,.,O
3131,We,O
3131,set,B
3131,the,I
3131,hidden,B
3131,size,I
3131,as,B
3131,100,B
3131,for,B
3131,all,B
3131,the,O
3131,LSTM,O
3131,layers,O
3131,",",O
3131,and,O
3131,set,O
3131,the,O
3131,number,B
3131,of,B
3131,perspectives,I
3131,l,I
3131,of,O
3131,our,B
3131,multiperspective,I
3131,matching,I
3131,function,I
3131,(,O
3131,Equation,O
3131,(,O
3131,5,O
3131,),O
3131,),O
3131,as,O
3131,50,B
3131,.,O
3132,We,O
3132,set,O
3132,the,O
3132,learning,B
3132,rate,I
3132,as,B
3132,0.0001,B
3132,.,O
3133,We,O
3133,apply,B
3133,dropout,B
3133,to,B
3133,every,B
3133,layers,I
3133,in,O
3133,",",O
3133,and,O
3133,set,O
3133,the,O
3133,dropout,O
3133,ratio,O
3133,as,B
3133,0.2,B
3133,.,O
3134,To,O
3134,train,O
3134,the,O
3134,model,O
3134,",",O
3134,we,O
3134,minimize,B
3134,the,O
3134,cross,B
3134,entropy,I
3134,of,B
3134,the,O
3134,be,B
3134,-,I
3134,ginning,I
3134,and,I
3134,end,I
3134,points,I
3134,",",O
3134,and,O
3134,use,B
3134,the,O
3134,ADAM,B
3134,optimizer,I
3134,to,O
3134,update,O
3134,parameters,B
3134,.,O
3135,We,O
3135,trained,B
3135,the,O
3135,models,B
3135,on,B
3135,free,B
3135,GPUs,I
3135,available,B
3135,via,I
3135,Google,B
3135,Colaboratory,I
3135,",",O
3135,the,O
3135,training,O
3135,scripts,O
3135,are,O
3135,publicly,O
3135,available,O
3135,.,O
3136,In,O
3136,this,O
3136,work,O
3136,",",O
3136,we,O
3136,focus,O
3136,on,O
3136,the,O
3136,SQuAD,O
3136,dataset,O
3136,and,O
3136,propose,B
3136,an,O
3136,end,O
3136,-,O
3136,to,O
3136,-,O
3136,end,O
3136,deep,O
3136,neural,O
3136,network,O
3136,model,O
3136,for,B
3136,machine,B
3136,comprehension,I
3136,.,O
3137,Based,O
3137,on,O
3137,this,O
3137,assumption,O
3137,",",O
3137,we,O
3137,design,B
3137,a,O
3137,Multi,B
3137,-,I
3137,Perspective,I
3137,Context,B
3137,Matching,I
3137,(,I
3137,MPCM,I
3137,),I
3137,model,I
3137,to,B
3137,identify,I
3137,the,O
3137,answer,B
3137,span,I
3137,by,B
3137,matching,O
3137,the,O
3137,context,O
3137,of,B
3137,each,B
3137,point,I
3137,in,B
3137,the,O
3137,passage,B
3137,with,B
3137,the,O
3137,question,B
3137,from,B
3137,multiple,B
3137,perspectives,I
3137,.,O
3138,Instead,O
3138,of,O
3138,enumerating,O
3138,all,O
3138,the,O
3138,possible,O
3138,spans,O
3138,explicitly,O
3138,and,O
3138,ranking,O
3138,them,O
3138,",",O
3138,our,O
3138,model,O
3138,identifies,B
3138,the,O
3138,answer,B
3138,span,I
3138,by,B
3138,predicting,I
3138,the,O
3138,beginning,B
3138,and,O
3138,ending,O
3138,points,O
3138,individually,B
3138,with,B
3138,globally,B
3138,normalized,I
3138,probability,I
3138,distributions,I
3138,across,B
3138,the,O
3138,whole,B
3138,passage,I
3138,.,O
3139,Multi,O
3139,-,O
3139,Perspective,O
3139,Context,O
3139,Matching,O
3139,for,O
3139,Machine,B
3139,Comprehension,I
3140,Previous,O
3140,machine,B
3140,comprehension,I
3140,(,I
3140,MC,B
3140,),I
3140,datasets,O
3140,are,O
3140,either,O
3140,too,O
3140,small,O
3140,to,O
3140,train,O
3140,endto,O
3140,-,O
3140,end,O
3140,deep,O
3140,learning,O
3140,models,O
3140,",",O
3140,or,O
3140,not,O
3140,difficult,O
3140,enough,O
3140,to,O
3140,evaluate,O
3140,the,O
3140,ability,O
3140,of,O
3140,current,O
3140,MC,O
3140,techniques,O
3140,.,O
3141,We,O
3141,notice,B
3141,that,O
3141,reattention,B
3141,has,O
3141,more,O
3141,influences,O
3141,on,B
3141,EM,B
3141,score,I
3141,while,O
3141,DCRL,B
3141,contributes,B
3141,more,O
3141,to,O
3141,F1,B
3141,metric,I
3141,",",O
3141,and,O
3141,removing,B
3141,both,B
3141,of,O
3141,them,O
3141,results,B
3141,in,I
3141,huge,B
3141,drops,I
3141,on,O
3141,both,O
3141,metrics,O
3141,.,O
3142,Replacing,B
3142,DCRL,B
3142,with,B
3142,SCST,B
3142,also,O
3142,causes,B
3142,a,O
3142,marginal,B
3142,decline,I
3142,of,B
3142,performance,B
3142,on,B
3142,both,B
3142,metrics,I
3142,.,O
3143,Next,O
3143,",",O
3143,we,O
3143,relace,B
3143,the,O
3143,default,B
3143,attention,I
3143,function,I
3143,with,B
3143,the,O
3143,dot,B
3143,product,I
3143,:,I
3143,f,I
3143,(,I
3143,u,I
3143,",",O
3143,v,O
3143,),O
3143,=,O
3143,u,O
3143,v,O
3143,(,O
3143,5,O
3143,),O
3143,",",O
3143,and,O
3143,both,B
3143,metrics,I
3143,suffer,B
3143,from,I
3143,degradations,B
3143,.,O
3144,Removing,B
3144,any,B
3144,of,I
3144,the,I
3144,two,I
3144,heuristics,I
3144,leads,B
3144,to,I
3144,some,B
3144,performance,I
3144,declines,I
3144,",",O
3144,and,O
3144,heuristic,B
3144,subtraction,I
3144,is,B
3144,more,B
3144,effective,I
3144,than,B
3144,multiplication,B
3144,.,O
3145,In,O
3145,both,O
3145,cases,O
3145,the,O
3145,highway,B
3145,-,I
3145,like,I
3145,function,I
3145,has,O
3145,outperformed,B
3145,its,O
3145,simpler,B
3145,variants,I
3145,.,O
3146,NegBERT,O
3146,:,O
3146,A,O
3146,Transfer,O
3146,Learning,O
3146,Approach,O
3146,for,O
3146,Negation,B
3146,Detection,I
3146,and,I
3146,Scope,I
3146,Resolution,I
3147,Interestingly,O
3147,",",O
3147,a,O
3147,very,B
3147,deep,I
3147,alignment,I
3147,with,B
3147,5,B
3147,blocks,I
3147,results,B
3147,in,I
3147,a,O
3147,significant,B
3147,performance,I
3147,decline,I
3147,.,O
3148,We,O
3148,notice,O
3148,that,O
3148,using,B
3148,2,B
3148,blocks,I
3148,causes,B
3148,a,O
3148,slight,B
3148,performance,I
3148,drop,I
3148,",",O
3148,while,O
3148,increasing,B
3148,to,I
3148,4,B
3148,blocks,O
3148,barely,B
3148,affects,I
3148,the,O
3148,SoTA,B
3148,result,I
3148,.,O
3149,We,O
3149,use,B
3149,the,O
3149,Adam,B
3149,optimizer,I
3149,[,O
3149,Kingma,O
3149,and,O
3149,Ba,O
3149,",",O
3149,2014,O
3149,],O
3149,for,B
3149,both,O
3149,ML,B
3149,and,O
3149,DCRL,O
3149,training,O
3149,.,O
3150,The,O
3150,initial,B
3150,learning,I
3150,rates,I
3150,are,O
3150,0.0008,O
3150,and,O
3150,0.0001,O
3150,respectively,O
3150,",",O
3150,and,O
3150,are,O
3150,halved,O
3150,whenever,O
3150,meeting,O
3150,a,O
3150,bad,O
3150,iteration,O
3150,.,O
3151,Word,O
3151,embeddings,O
3151,remain,B
3151,fixed,B
3151,during,B
3151,training,B
3151,.,O
3152,The,O
3152,size,O
3152,of,B
3152,character,B
3152,embedding,I
3152,and,I
3152,corresponding,I
3152,LSTMs,I
3152,is,B
3152,50,B
3152,",",O
3152,the,O
3152,main,B
3152,hidden,I
3152,size,O
3152,is,O
3152,100,B
3152,",",O
3152,and,O
3152,the,O
3152,hyperparameter,B
3152,?,O
3153,is,B
3153,3,B
3153,.,O
3154,The,O
3154,batch,B
3154,size,I
3154,is,B
3154,48,B
3154,and,O
3154,a,O
3154,dropout,B
3154,rate,I
3154,of,B
3154,0.3,B
3154,is,O
3154,used,O
3154,to,B
3154,prevent,I
3154,overfitting,B
3154,.,O
3155,For,B
3155,out,B
3155,of,I
3155,vocabulary,I
3155,words,I
3155,",",O
3155,we,O
3155,set,B
3155,the,O
3155,embeddings,B
3155,from,B
3155,Gaussian,B
3155,distributions,I
3155,and,O
3155,keep,B
3155,them,I
3155,trainable,B
3155,.,O
3156,To,O
3156,address,O
3156,the,O
3156,first,O
3156,problem,O
3156,",",O
3156,we,O
3156,present,B
3156,a,O
3156,reattention,B
3156,mechanism,I
3156,that,B
3156,temporally,B
3156,memorizes,I
3156,past,B
3156,attentions,I
3156,and,O
3156,uses,O
3156,them,O
3156,to,O
3156,refine,O
3156,current,B
3156,attentions,O
3156,in,B
3156,a,O
3156,multi-round,B
3156,alignment,I
3156,architecture,I
3156,.,O
3157,The,O
3157,computation,B
3157,is,O
3157,based,B
3157,on,I
3157,the,O
3157,fact,O
3157,that,O
3157,two,B
3157,words,I
3157,should,O
3157,share,B
3157,similar,I
3157,semantics,I
3157,if,B
3157,their,O
3157,attentions,B
3157,about,B
3157,same,B
3157,texts,I
3157,are,B
3157,highly,B
3157,overlapped,I
3157,",",O
3157,and,O
3157,be,B
3157,less,B
3157,similar,O
3157,vice,O
3157,versa,O
3157,.,O
3158,For,B
3158,cue,B
3158,detection,I
3158,",",O
3158,on,B
3158,the,O
3158,Sherlock,B
3158,dataset,I
3158,test,I
3158,data,I
3158,",",O
3158,we,O
3158,see,B
3158,that,I
3158,we,O
3158,outperform,B
3158,the,O
3158,best,B
3158,system,I
3158,[,O
3158,FBK,O
3158,Chowdhury,O
3158,],O
3158,by,B
3158,0.6,B
3158,F1,I
3158,measure,I
3158,.,O
3159,Therefore,O
3159,",",O
3159,the,O
3159,reattention,B
3159,can,O
3159,be,B
3159,more,I
3159,concentrated,I
3159,if,B
3159,past,B
3159,attentions,I
3159,focus,I
3159,on,I
3159,same,B
3159,parts,I
3159,of,B
3159,the,O
3159,input,B
3159,",",O
3159,or,O
3159,be,O
3159,relatively,B
3159,more,O
3159,distracted,O
3159,so,O
3159,as,O
3159,to,B
3159,focus,O
3159,on,O
3159,new,B
3159,regions,I
3159,if,O
3159,past,O
3159,attentions,O
3159,are,B
3159,not,B
3159,overlapped,I
3159,at,I
3159,all,I
3159,.,O
3160,As,O
3160,for,O
3160,the,O
3160,second,O
3160,problem,O
3160,",",O
3160,we,O
3160,extend,B
3160,the,O
3160,traditional,B
3160,training,I
3160,method,I
3160,with,B
3160,a,O
3160,novel,B
3160,approach,I
3160,called,B
3160,dynamic,B
3160,-,I
3160,critical,I
3160,reinforcement,I
3160,learning,I
3160,.,O
3161,Unlike,O
3161,the,O
3161,traditional,O
3161,reinforcement,O
3161,learning,O
3161,algorithm,O
3161,where,O
3161,the,O
3161,reward,B
3161,and,I
3161,baseline,I
3161,are,O
3161,statically,O
3161,sampled,O
3161,",",O
3161,our,O
3161,approach,O
3161,dynamically,B
3161,decides,I
3161,the,O
3161,reward,O
3161,and,O
3161,the,O
3161,baseline,O
3161,according,B
3161,to,I
3161,two,B
3161,sampling,I
3161,strategies,I
3161,",",O
3161,Context,O
3161,:,O
3161,The,O
3161,American,O
3161,Football,O
3161,Conference,O
3161,(,O
3161,AFC,O
3161,),O
3161,champion,O
3161,Denver,O
3161,Broncos,O
3161,defeated,O
3161,the,O
3161,National,O
3161,Football,O
3161,Conference,O
3161,(,O
3161,NFC,O
3161,),O
3161,champion,O
3161,Carolina,O
3161,Panthers,O
3161,24,O
3161,-,O
3161,10,O
3161,to,O
3161,earn,O
3161,their,O
3161,third,O
3161,Super,O
3161,Bowl,O
3161,title,O
3161,.,O
3162,Reinforced,O
3162,Mnemonic,O
3162,Reader,O
3162,for,O
3162,Machine,B
3162,Reading,I
3162,Comprehension,I
3163,We,O
3163,submitted,O
3163,our,O
3163,model,O
3163,on,B
3163,the,O
3163,hidden,B
3163,test,I
3163,set,I
3163,of,B
3163,SQuAD,B
3163,for,O
3163,evaluation,O
3163,.,O
3164,As,O
3164,shown,O
3164,in,O
3164,",",O
3164,R.M,B
3164,-,I
3164,Reader,I
3164,achieves,B
3164,an,O
3164,EM,B
3164,score,I
3164,of,B
3164,79.5,B
3164,%,I
3164,and,O
3164,F1,B
3164,score,O
3164,of,O
3164,86.6,B
3164,%,O
3164,.,O
3165,As,O
3165,we,O
3165,can,O
3165,see,O
3165,",",O
3165,R.M,O
3165,-,O
3165,Reader,O
3165,comfortably,B
3165,outperforms,I
3165,all,O
3165,previous,B
3165,models,I
3165,by,B
3165,more,B
3165,than,I
3165,6,I
3165,%,I
3165,in,B
3165,both,O
3165,EM,B
3165,and,I
3165,F,I
3165,1,I
3165,scores,I
3165,",",O
3165,indicating,O
3165,that,O
3165,our,O
3165,model,O
3165,is,O
3165,more,O
3165,robust,O
3165,against,O
3165,adversarial,O
3165,attacks,O
3165,.,O
3166,Our,O
3166,ensemble,O
3166,model,O
3166,improves,B
3166,the,O
3166,metrics,B
3166,to,B
3166,82.3,B
3166,%,I
3166,and,I
3166,88.5,I
3166,%,O
3166,respectively,O
3166,2,O
3166,.,O
3167,Experiments,O
3167,3,O
3167,and,O
3167,4,O
3167,show,B
3167,that,O
3167,the,O
3167,two,B
3167,ruminate,I
3167,layers,I
3167,are,B
3167,both,O
3167,important,B
3167,and,O
3167,helpful,O
3167,in,B
3167,contributing,I
3167,performance,B
3167,.,O
3168,It,O
3168,is,O
3168,worth,B
3168,noting,I
3168,that,O
3168,the,O
3168,BiLSTM,B
3168,in,B
3168,the,O
3168,context,B
3168,ruminate,I
3168,layer,I
3168,contributes,B
3168,substantially,B
3168,to,B
3168,model,B
3168,performance,I
3168,.,O
3169,On,B
3169,the,O
3169,BioScope,B
3169,Abstracts,I
3169,",",O
3169,we,O
3169,perform,B
3169,reasonably,B
3169,well,I
3169,.,O
3170,1,O
3170,The,O
3170,latest,O
3170,results,O
3170,are,O
3170,listed,O
3170,at,O
3170,https://rajpurkar.github.io/SQuAD,B
3170,-explorer/,I
3171,In,B
3171,the,O
3171,character,B
3171,encoding,I
3171,layer,I
3171,",",O
3171,we,O
3171,use,B
3171,100,B
3171,filters,I
3171,of,B
3171,width,B
3171,5,I
3171,.,O
3172,In,O
3172,the,O
3172,remainder,O
3172,of,O
3172,the,O
3172,model,O
3172,",",O
3172,we,O
3172,set,B
3172,the,O
3172,hidden,B
3172,layer,I
3172,dimension,I
3172,(,I
3172,d,I
3172,),I
3172,to,B
3172,100,B
3172,.,O
3173,We,O
3173,use,B
3173,pretrained,B
3173,100D,I
3173,Glo,I
3173,Ve,I
3173,vectors,I
3173,(,I
3173,6B,I
3173,-,I
3173,token,I
3173,version,I
3173,),I
3173,as,B
3173,word,B
3173,embeddings,I
3173,.,O
3174,We,O
3174,use,O
3174,the,O
3174,AdaDelta,B
3174,optimizer,I
3174,(,O
3174,Zeiler,O
3174,",",O
3174,2012,O
3174,),O
3174,for,B
3174,optimization,B
3174,.,O
3175,Out,O
3175,-,O
3175,of,O
3175,-,O
3175,vocobulary,O
3175,tokens,O
3175,are,O
3175,represented,B
3175,by,B
3175,an,O
3175,UNK,B
3175,symbol,I
3175,in,B
3175,the,O
3175,word,B
3175,embedding,I
3175,layer,I
3175,",",O
3175,but,O
3175,treated,B
3175,normally,B
3175,by,O
3175,the,O
3175,character,B
3175,embedding,O
3175,layer,O
3175,.,O
3176,Batch,O
3176,size,O
3176,is,B
3176,30,B
3176,.,O
3177,Learning,O
3177,rate,O
3177,starts,B
3177,at,I
3177,0.5,B
3177,",",O
3177,and,O
3177,decreases,B
3177,to,I
3177,0.2,B
3177,once,O
3177,the,O
3177,model,B
3177,stops,B
3177,improving,I
3177,.,O
3178,The,O
3178,L2-regularization,B
3178,weight,I
3178,is,B
3178,1,B
3178,e,I
3178,-,I
3178,4,I
3178,",",O
3178,AQSL,B
3178,weight,O
3178,is,O
3178,1,O
3178,and,O
3178,dropout,B
3178,with,B
3178,a,O
3178,drop,B
3178,rate,I
3178,of,B
3178,0.2,B
3178,is,O
3178,A,O
3178,typical,B
3178,model,I
3178,run,I
3178,converges,B
3178,in,B
3178,about,I
3178,40,B
3178,k,I
3178,steps,I
3178,.,O
3179,We,O
3179,selected,B
3179,hyperparameter,B
3179,values,I
3179,through,B
3179,random,B
3179,search,I
3179,.,O
3180,On,B
3180,the,O
3180,BioScope,B
3180,Full,I
3180,papers,I
3180,",",O
3180,we,O
3180,are,O
3180,able,O
3180,to,O
3180,achieve,B
3180,90.43,B
3180,F1,I
3180,when,B
3180,training,B
3180,on,O
3180,the,O
3180,same,B
3180,data,I
3180,",",O
3180,but,O
3180,we,O
3180,do,O
3180,note,O
3180,that,O
3180,the,O
3180,amount,O
3180,of,O
3180,training,O
3180,data,O
3180,available,O
3180,is,O
3180,significantly,O
3180,lower,O
3180,than,O
3180,for,O
3180,the,O
3180,other,O
3180,datasets,O
3180,",",O
3180,and,O
3180,while,O
3180,general,O
3180,Deep,O
3180,Learning,O
3180,based,O
3180,approaches,O
3180,can,O
3180,not,O
3180,perform,O
3180,well,O
3180,in,O
3180,such,O
3180,situations,O
3180,",",O
3180,we,O
3180,still,O
3180,manage,O
3180,to,O
3180,perform,O
3180,well,O
3180,.,O
3181,This,O
3181,takes,O
3181,two,O
3181,days,O
3181,using,B
3181,Tensorflow,B
3181,and,O
3181,a,O
3181,single,B
3181,NVIDIA,I
3181,K80,I
3181,GPU,I
3181,.,O
3182,We,O
3182,propose,B
3182,an,O
3182,extension,B
3182,of,B
3182,BIDAF,B
3182,",",O
3182,called,B
3182,Ruminating,B
3182,Reader,I
3182,",",O
3182,which,O
3182,uses,B
3182,a,O
3182,second,B
3182,pass,I
3182,of,O
3182,reading,B
3182,and,I
3182,reasoning,I
3182,to,B
3182,allow,O
3182,it,O
3182,to,O
3182,learn,O
3182,to,O
3182,avoid,O
3182,mistakes,B
3182,and,O
3182,to,O
3182,ensure,O
3182,that,O
3182,it,O
3182,is,O
3182,able,O
3182,to,O
3182,effectively,B
3182,use,I
3182,the,O
3182,full,B
3182,context,I
3182,when,B
3182,selecting,I
3182,an,O
3182,answer,B
3182,.,O
3183,In,O
3183,addition,O
3183,to,B
3183,adding,O
3183,a,O
3183,second,O
3183,pass,O
3183,",",O
3183,we,O
3183,also,O
3183,introduce,B
3183,two,B
3183,novel,I
3183,layer,I
3183,types,I
3183,",",O
3183,the,O
3183,ruminate,B
3183,layers,I
3183,",",O
3183,which,O
3183,use,B
3183,gating,B
3183,mechanisms,I
3183,to,O
3183,fuse,O
3183,the,O
3183,obtained,O
3183,from,O
3183,the,O
3183,first,B
3183,and,I
3183,second,O
3183,passes,O
3183,.,O
3184,In,O
3184,addition,O
3184,",",O
3184,we,O
3184,introduce,O
3184,an,O
3184,answer-question,B
3184,similarity,I
3184,loss,I
3184,to,B
3184,penalize,I
3184,overlap,B
3184,between,B
3184,question,B
3184,and,I
3184,predicted,I
3184,answer,I
3184,",",O
3184,a,O
3184,common,O
3184,feature,O
3184,in,O
3184,the,O
3184,errors,O
3184,of,O
3184,our,O
3184,base,O
3184,model,O
3184,.,O
3185,To,O
3185,answer,O
3185,the,O
3185,question,O
3185,in,O
3185,machine,B
3185,comprehension,I
3185,(,I
3185,MC,I
3185,),I
3185,task,O
3185,",",O
3185,the,O
3185,models,O
3185,need,O
3185,to,O
3185,establish,O
3185,the,O
3185,interaction,O
3185,between,O
3185,the,O
3185,question,O
3185,and,O
3185,the,O
3185,context,O
3185,.,O
3186,Machine,O
3186,comprehension,O
3186,(,O
3186,MC,O
3186,),O
3186,-,O
3186,especially,O
3186,in,O
3186,the,O
3186,form,O
3186,of,O
3186,question,B
3186,answering,I
3186,(,O
3186,QA,O
3186,),O
3186,-,O
3186,is,O
3186,therefore,O
3186,attracting,O
3186,a,O
3186,significant,O
3186,amount,O
3186,of,O
3186,attention,O
3186,from,O
3186,the,O
3186,machine,O
3186,learning,O
3186,community,O
3186,.,O
3187,At,O
3187,the,O
3187,time,O
3187,of,O
3187,submission,O
3187,",",O
3187,our,O
3187,model,O
3187,is,B
3187,tied,B
3187,in,B
3187,accuracy,B
3187,on,B
3187,the,O
3187,hidden,B
3187,test,I
3187,set,I
3187,with,B
3187,the,O
3187,bestperforming,B
3187,published,I
3187,single,I
3187,model,O
3187,.,O
3188,We,O
3188,achieve,B
3188,an,O
3188,F,B
3188,1,I
3188,score,I
3188,of,B
3188,79.5,B
3188,and,O
3188,EM,B
3188,score,O
3188,of,O
3188,70.6,B
3188,.,O
3189,In,O
3189,terms,O
3189,of,O
3189,prediction,B
3189,quality,I
3189,",",O
3189,the,O
3189,results,O
3189,show,O
3189,that,O
3189,1,O
3189,),O
3189,the,O
3189,unselected,B
3189,head,B
3189,tokens,I
3189,do,O
3189,contribute,B
3189,to,B
3189,the,O
3189,prediction,O
3189,",",O
3189,bringing,B
3189,0.2,B
3189,%,I
3189,improvement,I
3189,;,O
3189,2,O
3189,),O
3189,using,B
3189,separate,B
3189,RSS,I
3189,modules,I
3189,to,O
3189,select,O
3189,the,O
3189,head,O
3189,and,O
3189,dependent,O
3189,tokens,O
3189,improves,B
3189,accuracy,B
3189,by,B
3189,0.5,B
3189,%,O
3189,;,O
3189,and,O
3189,3,O
3189,),O
3189,hard,B
3189,attention,I
3189,and,O
3189,soft,O
3189,self,O
3189,-,O
3189,attention,O
3189,modules,O
3189,improve,B
3189,the,O
3189,accuracy,O
3189,by,O
3189,0.3,B
3189,%,O
3189,and,O
3189,2.9,O
3189,%,O
3189,respectively,O
3189,.,O
3190,All,O
3190,the,O
3190,experiments,O
3190,codes,O
3190,are,O
3190,released,O
3190,at,O
3190,https://github.com/,B
3190,taoshen58/DiSAN,I
3190,/tree/master/ReSAN,I
3190,.,O
3191,On,O
3191,the,O
3191,SFU,B
3191,Review,I
3191,Corpus,I
3191,",",O
3191,we,O
3191,achieve,B
3191,an,O
3191,F1,B
3191,of,B
3191,87.08,B
3191,.,O
3192,All,O
3192,experiments,B
3192,are,O
3192,conducted,B
3192,in,I
3192,Python,B
3192,with,B
3192,Tensorflow,B
3192,and,O
3192,run,B
3192,on,I
3192,a,O
3192,Nvidia,B
3192,GTX,I
3192,1080,I
3192,Ti,I
3192,.,O
3193,We,O
3193,use,B
3193,Adadelta,B
3193,as,B
3193,optimizer,B
3193,",",O
3193,which,O
3193,performs,B
3193,more,B
3193,stable,I
3193,than,B
3193,Adam,B
3193,on,B
3193,ReSAN,B
3193,.,O
3194,We,O
3194,use,O
3194,300D,B
3194,Glo,I
3194,Ve,I
3194,6B,I
3194,pre-trained,I
3194,vectors,I
3195,Compared,O
3195,to,O
3195,the,O
3195,methods,O
3195,from,O
3195,official,O
3195,leaderboard,O
3195,",",O
3195,ReSAN,B
3195,outperforms,B
3195,all,B
3195,the,O
3195,sentence,O
3195,encoding,O
3195,based,O
3195,methods,O
3195,and,O
3195,achieves,B
3195,the,O
3195,best,B
3195,test,I
3195,accuracy,I
3195,.,O
3196,Furthermore,O
3196,",",O
3196,ReSAN,B
3196,even,O
3196,outperforms,B
3196,the,O
3196,300D,B
3196,SPINN,I
3196,-,I
3196,PI,I
3196,encoders,I
3196,by,B
3196,3.1,O
3196,%.,O
3197,Specifically,O
3197,",",O
3197,compared,B
3197,to,I
3197,the,O
3197,last,B
3197,best,I
3197,models,I
3197,",",O
3197,i.e.,B
3198,",",O
3198,600D,B
3198,Gumbel,I
3198,TreeLSTM,I
3198,encoders,I
3198,and,O
3198,600D,O
3198,Residual,O
3198,stacked,O
3198,encoders,O
3198,",",O
3198,ReSAN,B
3198,uses,B
3198,far,B
3198,fewer,I
3198,parameters,I
3198,with,B
3198,better,B
3198,performance,I
3198,.,O
3199,Compared,O
3199,to,O
3199,the,O
3199,recurrent,B
3199,models,I
3199,(,O
3199,e.g.,B
3200,",",O
3200,Bi,B
3200,-,I
3200,LSTM,I
3200,and,O
3200,Bi,O
3200,-,O
3200,GRU,O
3200,),O
3200,",",O
3200,ReSAN,B
3200,shows,B
3200,better,B
3200,prediction,I
3200,quality,I
3200,and,O
3200,more,B
3200,compelling,I
3200,efficiency,I
3200,due,B
3200,to,I
3200,parallelizable,B
3200,computations,I
3200,.,O
3201,Compared,O
3201,to,O
3201,the,O
3201,convolutional,B
3201,models,I
3201,(,O
3201,i.e.,B
3202,",",O
3202,Multiwindow,B
3202,CNN,I
3202,and,I
3202,Hierarchical,B
3202,CNN,O
3202,),O
3202,",",O
3202,ReSAN,B
3202,significantly,B
3202,outperforms,I
3202,them,O
3202,by,B
3202,3.1,B
3202,%,I
3202,and,O
3202,2.4,O
3202,%,O
3202,respectively,O
3202,due,O
3202,to,O
3202,the,O
3202,weakness,O
3202,of,O
3202,CNNs,O
3202,in,O
3202,modeling,O
3202,long,O
3202,-,O
3202,range,O
3202,dependencies,O
3202,.,O
3203,Compared,O
3203,to,O
3203,the,O
3203,attention,O
3203,-,O
3203,based,O
3203,models,O
3203,",",O
3203,multi-head,B
3203,attention,O
3203,and,O
3203,DiSAN,B
3203,",",O
3203,ReSAN,B
3203,uses,B
3203,a,O
3203,similar,B
3203,number,I
3203,of,I
3203,parameters,I
3203,with,B
3203,better,B
3203,test,I
3203,performance,I
3203,and,O
3203,less,B
3203,time,I
3203,cost,I
3203,.,O
3204,Overall,O
3204,",",O
3204,we,O
3204,find,O
3204,that,O
3204,RESIDE,B
3204,gives,B
3204,competitive,B
3204,performance,I
3204,even,O
3204,when,B
3204,very,B
3204,limited,I
3204,amount,I
3204,of,I
3204,relation,I
3204,alias,I
3204,information,I
3204,is,B
3204,available,B
3204,.,O
3205,Our,O
3205,proposed,O
3205,model,O
3205,also,B
3205,beats,I
3205,a,O
3205,multitask,B
3205,model,O
3205,which,B
3205,uses,I
3205,signals,B
3205,from,B
3205,additional,B
3205,tasks,I
3205,by,B
3205,more,I
3205,than,I
3205,1.5,B
3205,F,I
3205,1,I
3205,points,I
3205,.,O
3206,For,O
3206,scope,B
3206,resolution,I
3206,:,O
3207,In,B
3207,this,O
3207,paper,O
3207,",",O
3207,we,O
3207,first,O
3207,propose,B
3207,a,O
3207,novel,B
3207,hard,I
3207,attention,I
3207,mechanism,I
3207,called,B
3207,"""",O
3207,reinforced,B
3207,sequence,I
3207,sampling,I
3207,(,I
3207,RSS,I
3207,),I
3207,"""",O
3207,",",O
3207,which,O
3207,selects,B
3207,tokens,B
3207,from,B
3207,an,O
3207,input,B
3207,sequence,O
3207,in,O
3207,parallel,B
3207,",",O
3207,and,O
3207,differs,O
3207,from,O
3207,existing,O
3207,ones,O
3207,in,O
3207,that,O
3207,it,O
3207,is,B
3207,highly,B
3207,parallelizable,I
3207,without,B
3207,any,B
3207,recurrent,I
3207,structure,I
3207,.,O
3208,We,O
3208,then,O
3208,develop,B
3208,a,O
3208,model,O
3208,",",O
3208,"""",O
3208,reinforced,B
3208,self,I
3208,-,I
3208,attention,I
3208,(,I
3208,ReSA,I
3208,),I
3208,"""",O
3208,",",O
3208,which,O
3208,naturally,O
3208,combines,B
3208,the,O
3208,RSS,B
3208,with,B
3208,a,O
3208,soft,B
3208,self,O
3208,-,O
3208,attention,O
3208,.,O
3209,In,B
3209,ReSA,B
3209,",",O
3209,two,B
3209,parameter,I
3209,-,I
3209,untied,I
3209,RSS,I
3209,are,O
3209,respectively,O
3209,applied,B
3209,to,I
3209,two,O
3209,copies,O
3209,of,B
3209,the,O
3209,input,B
3209,sequence,I
3209,",",O
3209,where,O
3209,the,O
3209,tokens,O
3209,from,O
3209,one,O
3209,and,O
3209,another,O
3209,are,O
3209,called,O
3209,dependent,O
3209,and,O
3209,head,O
3209,tokens,O
3209,",",O
3209,respectively,O
3209,.,O
3210,Re,O
3210,SA,O
3210,only,O
3210,models,B
3210,the,O
3210,sparse,B
3210,dependencies,I
3210,between,B
3210,the,O
3210,head,B
3210,and,I
3210,dependent,I
3210,tokens,I
3210,selected,B
3210,by,I
3210,the,O
3210,two,B
3210,RSS,I
3210,modules,I
3210,.,O
3211,Finally,O
3211,",",O
3211,we,O
3211,build,B
3211,an,O
3211,sentence,B
3211,-,I
3211,encoding,I
3211,model,I
3211,",",O
3211,"""",O
3211,reinforced,B
3211,self,I
3211,-,O
3211,attention,O
3211,network,O
3211,(,O
3211,ReSAN,O
3211,),O
3211,"""",O
3211,",",O
3211,based,B
3211,on,I
3211,ReSA,B
3211,without,B
3211,any,B
3211,CNN,I
3211,/,I
3211,RNN,I
3211,structure,I
3211,.,O
3212,Equipping,O
3212,deep,O
3212,neural,O
3212,networks,O
3212,(,O
3212,DNN,O
3212,),O
3212,with,O
3212,attention,B
3212,mechanisms,I
3212,provides,O
3212,an,O
3212,effective,O
3212,and,O
3212,parallelizable,O
3212,approach,O
3212,for,O
3212,context,O
3212,fusion,O
3212,and,O
3212,sequence,O
3212,compression,O
3212,.,O
3213,There,O
3213,is,O
3213,a,O
3213,slight,B
3213,increment,I
3213,from,B
3213,RAGF,B
3213,to,B
3213,RAGFD,B
3213,",",O
3213,which,O
3213,demonstrates,B
3213,the,O
3213,effectiveness,B
3213,of,B
3213,discriminator,B
3213,.,O
3214,From,O
3214,",",O
3214,we,O
3214,find,B
3214,that,I
3214,RAGFWD,B
3214,achieves,B
3214,a,O
3214,4.3,B
3214,%,I
3214,improvement,I
3214,over,B
3214,RAGFD,B
3214,in,B
3214,terms,I
3214,of,I
3214,BLEU,B
3214,",",O
3214,and,O
3214,PAAG,B
3214,outperforms,B
3214,RAGFWD,O
3214,4.1,B
3214,%,O
3214,in,O
3214,terms,O
3214,of,O
3214,BLEU,O
3214,.,O
3215,Accordingly,O
3215,",",O
3215,we,O
3215,conclude,B
3215,that,I
3215,the,O
3215,performance,B
3215,of,B
3215,PAAG,B
3215,benefits,B
3215,from,I
3215,using,B
3215,Wasserstein,B
3215,distance,I
3215,based,I
3215,adversarial,I
3215,learning,I
3215,with,B
3215,gradient,B
3215,penalty,I
3215,.,O
3216,This,O
3216,approach,O
3216,can,B
3216,help,I
3216,our,B
3216,model,B
3216,to,B
3216,achieve,I
3216,a,O
3216,better,B
3216,performance,I
3216,than,B
3216,the,O
3216,model,O
3216,using,O
3216,the,O
3216,vanilla,B
3216,GAN,I
3216,architecture,I
3216,.,O
3217,On,B
3217,the,I
3217,Sherlock,B
3217,dataset,I
3217,",",O
3217,we,O
3217,achieve,B
3217,an,O
3217,F1,O
3217,of,O
3217,92.36,B
3217,",",O
3217,outperforming,B
3217,the,O
3217,previous,B
3217,State,I
3217,of,O
3217,the,O
3217,Art,O
3217,by,B
3217,a,O
3217,significant,B
3217,margin,I
3217,(,I
3217,almost,I
3217,3.0,I
3217,F1,O
3217,),O
3217,.,O
3218,(,O
3218,1,O
3218,),O
3218,S2SA,B
3218,:,O
3218,Sequence,O
3218,-,O
3218,to,O
3218,-,O
3218,sequence,O
3218,framework,O
3218,has,O
3218,been,O
3218,proposed,B
3218,for,I
3218,language,B
3218,generation,I
3218,task,I
3218,.,O
3219,(,O
3219,2,O
3219,),O
3219,S2SAR,B
3219,:,O
3219,We,O
3219,implement,B
3219,a,O
3219,simple,B
3219,method,I
3219,which,O
3219,can,O
3219,incorporate,B
3219,the,O
3219,review,B
3219,information,I
3219,when,B
3219,generating,I
3219,the,O
3219,answer,B
3219,.,O
3220,(,O
3220,3,O
3220,),O
3220,SNet,B
3220,:,O
3220,S-,O
3220,Net,O
3220,is,B
3220,a,O
3220,two,B
3220,-,I
3220,stage,I
3220,state,I
3220,-,O
3220,of,O
3220,-,O
3220,the,O
3220,-,O
3220,art,O
3220,model,O
3220,which,B
3220,extracts,I
3220,some,B
3220,text,I
3220,spans,B
3220,from,B
3220,multiple,B
3220,documents,I
3220,context,I
3220,and,O
3220,synthesis,B
3220,the,O
3220,answer,B
3220,from,O
3220,those,O
3220,spans,O
3220,.,O
3221,(,O
3221,4,O
3221,),O
3221,QS,B
3221,:,O
3221,We,O
3221,implement,B
3221,the,O
3221,query,B
3221,-,I
3221,based,I
3221,summarization,I
3221,model,I
3221,proposed,O
3221,by,O
3221,Hasselqvist,O
3221,et,O
3221,al,O
3221,..,O
3222,(,O
3222,5,O
3222,),O
3222,BM25,B
3222,:,O
3222,BM25,O
3222,is,B
3222,a,O
3222,bag,B
3222,-,I
3222,of,I
3222,-,O
3222,words,O
3222,retrieval,O
3222,function,O
3222,that,O
3222,ranks,B
3222,a,O
3222,set,B
3222,of,O
3222,reviews,O
3222,based,B
3222,on,I
3222,the,O
3222,question,B
3222,terms,I
3222,appearing,B
3222,in,I
3222,each,B
3222,review,I
3222,.,O
3223,(,O
3223,6,O
3223,),O
3223,TF,B
3223,-,I
3223,IDF,I
3223,:,O
3223,Term,B
3223,Frequency,I
3223,-,O
3223,Inverse,O
3223,Document,O
3223,Frequency,O
3223,is,B
3223,a,O
3223,numerical,B
3223,statistic,I
3223,that,O
3223,is,O
3223,intended,O
3223,to,B
3223,reflect,I
3223,how,B
3223,important,I
3223,a,O
3223,question,B
3223,word,I
3223,is,O
3223,to,O
3223,a,O
3223,review,B
3223,.,O
3224,Without,O
3224,using,O
3224,pre-trained,B
3224,embeddings,I
3224,",",O
3224,we,O
3224,randomly,B
3224,initialize,I
3224,the,O
3224,network,B
3224,parameters,I
3224,at,B
3224,the,O
3224,beginning,B
3224,of,B
3224,our,O
3224,experiments,B
3224,.,O
3225,All,O
3225,the,O
3225,RNN,O
3225,networks,O
3225,have,B
3225,512,B
3225,hidden,I
3225,units,I
3225,and,O
3225,the,O
3225,dimension,B
3225,of,B
3225,word,B
3225,embedding,I
3225,is,B
3225,256,B
3225,.,O
3226,Adagrad,B
3226,with,B
3226,learning,B
3226,rate,I
3226,0.1,B
3226,is,B
3226,used,O
3226,to,B
3226,optimize,I
3226,the,O
3226,parameters,B
3226,and,O
3226,batch,B
3226,size,I
3226,is,O
3226,64,B
3226,.,O
3227,To,O
3227,produce,O
3227,better,B
3227,answers,I
3227,",",O
3227,we,O
3227,use,B
3227,beam,B
3227,search,I
3227,with,B
3227,beam,O
3227,size,O
3228,On,O
3228,the,O
3228,BioScope,B
3228,Abstracts,I
3228,",",O
3228,we,O
3228,achieve,B
3228,an,O
3228,F1,O
3228,of,B
3228,95.68,B
3228,",",O
3228,outperforming,B
3228,the,O
3228,best,B
3228,architecture,I
3228,by,B
3228,3.57,B
3228,F1,O
3228,.,O
3229,4,B
3229,.,O
3230,We,O
3230,implement,B
3230,our,B
3230,model,I
3230,using,B
3230,TensorFlow,B
3230,framework,I
3230,and,I
3230,train,B
3230,our,O
3230,model,O
3230,and,O
3230,all,O
3230,baseline,O
3230,models,O
3230,on,B
3230,NVIDIA,B
3230,Tesla,I
3230,P40,I
3230,GPU,I
3230,.,O
3231,In,O
3231,this,O
3231,paper,O
3231,",",O
3231,we,O
3231,propose,B
3231,the,O
3231,product,B
3231,-,I
3231,aware,I
3231,answer,I
3231,generator,I
3231,(,I
3231,PAAG,I
3231,),I
3231,",",O
3231,a,O
3231,product,O
3231,related,O
3231,question,O
3231,answering,O
3231,model,O
3231,which,O
3231,incorporates,B
3231,customer,B
3231,reviews,I
3231,with,B
3231,product,O
3231,attributes,O
3231,.,O
3232,Eventually,O
3232,",",O
3232,we,O
3232,propose,O
3232,a,O
3232,recurrent,B
3232,neural,I
3232,network,I
3232,(,I
3232,RNN,I
3232,),I
3232,based,I
3232,decoder,I
3232,",",O
3232,which,O
3232,combines,B
3232,product,B
3232,-,I
3232,aware,I
3232,review,I
3232,representation,I
3232,and,I
3232,attributes,I
3232,to,B
3232,generate,I
3232,the,O
3232,answer,B
3232,.,O
3233,Specifically,O
3233,",",O
3233,at,O
3233,the,O
3233,beginning,O
3233,we,O
3233,employ,B
3233,an,O
3233,attention,B
3233,mechanism,I
3233,to,B
3233,model,I
3233,interactions,B
3233,between,B
3233,a,O
3233,question,B
3233,and,I
3233,reviews,I
3233,.,O
3234,Simultaneously,O
3234,",",O
3234,we,O
3234,employ,O
3234,a,O
3234,key,B
3234,-,I
3234,value,I
3234,memory,I
3234,network,I
3234,to,I
3234,store,I
3234,the,O
3234,product,B
3234,attributes,I
3234,and,O
3234,extract,B
3234,the,O
3234,relevance,B
3234,values,I
3234,according,B
3234,to,O
3234,the,O
3234,question,B
3234,.,O
3235,More,O
3235,importantly,O
3235,",",O
3235,to,B
3235,tackle,I
3235,the,O
3235,problem,O
3235,of,O
3235,meaningless,B
3235,answers,I
3235,",",O
3235,we,O
3235,propose,B
3235,an,O
3235,adversarial,B
3235,learning,I
3235,mechanism,I
3235,in,B
3235,the,O
3235,loss,B
3235,calculation,I
3235,for,B
3235,optimizing,I
3235,parameters,B
3235,.,O
3236,In,O
3236,recent,O
3236,years,O
3236,",",O
3236,the,O
3236,explosive,O
3236,popularity,O
3236,of,O
3236,question,B
3236,-,I
3236,answering,I
3236,(,I
3236,QA,I
3236,),I
3236,is,O
3236,revitalizing,O
3236,the,O
3236,task,O
3236,of,O
3236,reading,B
3236,comprehension,I
3236,with,O
3236,promising,O
3236,results,O
3236,.,O
3237,In,O
3237,these,O
3237,experimental,O
3237,results,O
3237,",",O
3237,we,O
3237,see,B
3237,that,I
3237,PAAG,B
3237,achieves,B
3237,a,O
3237,111,B
3237,%,I
3237,",",O
3237,8,B
3237,%,O
3237,and,O
3237,62.73,B
3237,%,O
3237,increment,O
3237,over,B
3237,the,I
3237,stateof,B
3237,-,I
3237,the,O
3237,-,O
3237,art,O
3237,baseline,O
3237,SNet,O
3237,in,O
3237,terms,O
3237,of,O
3237,BLEU,B
3237,",",O
3237,embedding,B
3237,greedy,I
3237,and,O
3237,consistency,B
3237,score,I
3237,",",O
3237,respectively,O
3237,.,O
3238,On,O
3238,the,O
3238,Bioscope,B
3238,Full,I
3238,Papers,I
3238,",",O
3238,we,O
3238,outperform,B
3238,the,O
3238,best,B
3238,architecture,I
3238,by,B
3238,2.64,B
3238,F1,I
3238,when,O
3238,training,O
3238,on,O
3238,the,O
3238,same,B
3238,dataset,I
3239,In,B
3239,",",O
3239,we,O
3239,see,O
3239,that,O
3239,our,O
3239,PAAG,O
3239,outperforms,B
3239,all,B
3239,the,I
3239,baseline,I
3239,significantly,B
3239,in,O
3239,semantic,B
3239,distance,I
3239,with,B
3239,respect,I
3239,to,I
3239,the,O
3239,ground,B
3239,truth,I
3239,.,O
3240,In,B
3240,",",O
3240,we,O
3240,can,O
3240,see,O
3240,that,O
3240,PAAG,O
3240,outperforms,O
3240,other,B
3240,baseline,I
3240,models,I
3240,in,O
3240,both,B
3240,sentence,I
3240,fluency,I
3240,and,I
3240,consistency,I
3240,with,B
3240,the,O
3240,facts,B
3240,.,O
3241,Although,O
3241,there,O
3241,is,O
3241,a,O
3241,small,B
3241,increment,I
3241,of,B
3241,S2,B
3241,SAR,I
3241,with,B
3241,respect,I
3241,to,I
3241,S2SA,B
3241,in,B
3241,all,B
3241,metrics,I
3241,",",O
3241,we,O
3241,still,O
3241,find,B
3241,a,O
3241,noticeable,B
3241,gap,I
3241,between,B
3241,S2SAR,B
3241,and,I
3241,PAAG,I
3241,.,O
3242,Although,O
3242,the,O
3242,number,O
3242,of,O
3242,parameters,O
3242,in,O
3242,the,O
3242,DRCN,O
3242,significantly,O
3242,decreased,O
3242,as,O
3242,shown,O
3242,in,O
3242,",",O
3242,we,O
3242,could,B
3242,see,I
3242,that,O
3242,the,O
3242,performance,B
3242,was,B
3242,rather,B
3242,higher,I
3242,because,B
3242,of,O
3242,the,O
3242,regularization,B
3242,effect,I
3242,.,O
3243,The,O
3243,result,B
3243,shows,B
3243,that,O
3243,the,O
3243,dense,B
3243,connections,I
3243,over,B
3243,attentive,B
3243,features,I
3243,are,B
3243,more,B
3243,effective,I
3243,.,O
3244,The,O
3244,models,B
3244,(,O
3244,5,O
3244,-,O
3244,9,O
3244,),O
3244,which,B
3244,have,I
3244,connections,B
3244,between,B
3244,layers,B
3244,",",O
3244,are,B
3244,more,B
3244,robust,I
3244,to,I
3244,the,O
3244,increased,B
3244,depth,I
3244,of,I
3244,network,I
3244,",",O
3244,however,O
3244,",",O
3244,the,O
3244,performances,B
3244,of,O
3244,(,O
3244,10,O
3244,-,O
3244,11,O
3244,),O
3244,tend,B
3244,to,O
3244,degrade,B
3244,as,B
3244,layers,O
3244,get,B
3244,deeper,B
3244,.,O
3245,In,O
3245,addition,O
3245,",",O
3245,the,O
3245,models,O
3245,with,B
3245,dense,B
3245,connections,I
3245,rather,B
3245,than,I
3245,residual,B
3245,connections,O
3245,",",O
3245,have,B
3245,higher,B
3245,performance,I
3245,in,O
3245,general,O
3245,.,O
3246,In,O
3246,",",O
3246,we,O
3246,removed,B
3246,dense,B
3246,connections,I
3246,over,B
3246,both,B
3246,co-attentive,I
3246,and,I
3246,recurrent,I
3246,features,I
3246,",",O
3246,and,O
3246,the,O
3246,performance,B
3246,degraded,B
3246,to,B
3246,88.5,B
3246,%,I
3246,.,O
3247,The,O
3247,results,O
3247,of,O
3247,(,O
3247,8,O
3247,-,O
3247,9,O
3247,),O
3247,demonstrate,B
3247,that,O
3247,the,O
3247,dense,B
3247,connection,I
3247,using,B
3247,concatenation,B
3247,operation,I
3247,over,B
3247,deeper,B
3247,layers,I
3247,",",O
3247,has,O
3247,more,B
3247,powerful,I
3247,capability,I
3247,retaining,B
3247,collective,B
3247,knowledge,I
3247,to,B
3247,learn,I
3247,textual,B
3247,semantics,I
3247,.,O
3248,The,O
3248,result,O
3248,of,O
3248,(,O
3248,10,O
3248,),O
3248,shows,B
3248,that,O
3248,the,O
3248,connections,B
3248,among,B
3248,the,O
3248,layers,B
3248,are,O
3248,important,B
3248,to,I
3248,help,I
3248,gradient,B
3248,flow,I
3248,.,O
3249,On,O
3249,the,O
3249,SFU,B
3249,Review,I
3249,Corpus,I
3249,",",O
3249,we,O
3249,outperform,B
3249,the,O
3249,best,B
3249,system,I
3249,to,O
3249,date,O
3249,by,B
3249,1.02,B
3249,F1,I
3249,.,O
3250,And,O
3250,",",O
3250,the,O
3250,result,O
3250,of,O
3250,(,O
3250,11,O
3250,),O
3250,shows,O
3250,that,O
3250,the,O
3250,attentive,B
3250,information,I
3250,functioning,B
3250,as,I
3250,a,O
3250,soft,B
3250,-,I
3250,alignment,I
3250,is,B
3250,significantly,B
3250,effective,I
3250,in,B
3250,semantic,B
3250,sentence,I
3250,matching,I
3250,.,O
3251,shows,O
3251,that,O
3251,the,O
3251,connection,O
3251,between,B
3251,layers,B
3251,is,B
3251,essential,B
3251,",",O
3251,especially,O
3251,in,O
3251,deep,O
3251,models,O
3251,",",O
3251,endowing,B
3251,more,B
3251,representational,I
3251,power,I
3251,",",O
3251,and,O
3251,the,O
3251,dense,B
3251,connection,O
3251,is,O
3251,more,O
3251,effective,O
3251,than,B
3251,the,O
3251,residual,B
3251,connection,O
3251,.,O
3252,We,O
3252,initialized,B
3252,word,B
3252,embedding,I
3252,with,B
3252,300d,B
3252,Glo,I
3252,Ve,I
3252,vectors,I
3252,pre-trained,O
3252,from,O
3252,the,O
3252,840B,O
3252,Common,O
3252,Crawl,O
3252,corpus,O
3252,(,O
3252,Pennington,O
3252,",",O
3252,Socher,O
3252,",",O
3252,and,O
3252,Manning,O
3252,2014,O
3252,),O
3252,",",O
3252,while,O
3252,the,O
3252,word,O
3252,embeddings,O
3252,for,B
3252,the,O
3252,out,B
3252,-,I
3252,of,I
3252,-,O
3252,vocabulary,O
3252,words,O
3252,were,O
3252,initialized,O
3252,randomly,B
3252,.,O
3253,The,O
3253,dropout,B
3253,was,O
3253,applied,B
3253,after,I
3253,the,O
3253,word,B
3253,and,I
3253,character,I
3253,embedding,I
3253,layers,I
3253,with,B
3253,a,O
3253,keep,B
3253,rate,I
3253,of,B
3253,0.5,B
3253,.,O
3254,It,O
3254,was,O
3254,also,O
3254,applied,B
3254,before,I
3254,the,O
3254,fully,B
3254,-,I
3254,connected,I
3254,layers,I
3254,with,B
3254,a,O
3254,keep,B
3254,rate,I
3254,of,B
3254,0.8,B
3254,.,O
3255,The,O
3255,batch,B
3255,normalization,I
3255,was,O
3255,applied,B
3255,on,I
3255,the,O
3255,fully,B
3255,-,I
3255,connected,I
3255,layers,I
3255,",",O
3255,only,O
3255,for,B
3255,the,O
3255,one,B
3255,-,O
3255,way,O
3255,type,O
3255,datasets,O
3255,.,O
3256,The,O
3256,RMSProp,B
3256,optimizer,I
3256,with,B
3256,an,O
3256,initial,B
3256,learning,I
3256,rate,I
3256,of,B
3256,0.001,B
3256,was,O
3256,applied,O
3256,.,O
3257,The,O
3257,learning,B
3257,rate,I
3257,was,O
3257,decreased,B
3257,by,I
3257,a,O
3257,factor,B
3257,of,B
3257,0.85,B
3257,when,B
3257,the,O
3257,dev,B
3257,accuracy,I
3257,does,B
3257,not,I
3257,improve,I
3257,.,O
3258,All,O
3258,weights,B
3258,except,B
3258,embedding,B
3258,matrices,I
3258,are,O
3258,constrained,B
3258,by,I
3258,L2,B
3258,regularization,I
3258,with,B
3258,a,O
3258,regularization,O
3258,constant,O
3258,?,O
3259,The,O
3259,sequence,B
3259,lengths,I
3259,of,B
3259,the,O
3259,sentence,B
3259,are,B
3259,all,B
3259,different,I
3259,for,B
3259,each,B
3259,dataset,I
3259,:,O
3259,35,B
3259,for,O
3259,SNLI,B
3259,",",O
3259,55,B
3259,for,O
3259,MultiNLI,B
3259,",",O
3259,25,B
3259,for,O
3259,Quora,B
3259,question,I
3259,pair,I
3259,and,O
3259,50,B
3259,for,O
3259,TrecQA,B
3259,.,O
3260,For,O
3260,negation,B
3260,cue,I
3260,detection,I
3260,",",I
3260,we,O
3260,observe,B
3260,a,O
3260,significant,B
3260,gap,I
3260,between,B
3260,our,B
3260,model,I
3260,",",O
3260,NegBERT,O
3260,",",O
3260,and,O
3260,the,O
3260,current,O
3260,state,O
3260,-,O
3260,of,O
3260,the,O
3260,-,O
3260,art,O
3260,systems,O
3260,",",O
3260,while,O
3260,we,O
3260,outperform,B
3260,the,O
3260,baseline,B
3260,systems,O
3260,.,O
3261,We,O
3261,also,O
3261,randomly,B
3261,initialized,I
3261,character,I
3261,embedding,I
3261,with,B
3261,a,O
3261,16d,B
3261,vector,I
3261,and,O
3261,extracted,B
3261,32d,B
3261,character,O
3261,representation,O
3261,with,O
3261,a,O
3261,convolutional,B
3261,network,I
3261,.,O
3262,For,B
3262,the,O
3262,densely,B
3262,-,I
3262,connected,I
3262,recurrent,I
3262,layers,I
3262,",",O
3262,we,O
3262,stacked,B
3262,5,B
3262,layers,O
3262,each,B
3262,of,I
3262,which,I
3262,have,I
3262,100,B
3262,hidden,I
3262,units,I
3262,.,O
3263,For,O
3263,the,O
3263,bottleneck,B
3263,component,I
3263,",",O
3263,we,O
3263,set,B
3263,200,B
3263,hidden,I
3263,units,I
3263,as,B
3263,encoded,B
3263,features,I
3263,of,B
3263,the,O
3263,autoencoder,B
3263,with,B
3263,a,O
3263,dropout,B
3263,rate,I
3263,of,O
3263,0.2,B
3263,.,O
3264,We,O
3264,set,B
3264,1000,B
3264,hidden,I
3264,units,I
3264,with,B
3264,respect,I
3264,to,I
3264,the,O
3264,fullyconnected,B
3264,layers,I
3264,.,O
3265,Inspired,O
3265,by,O
3265,Densenet,O
3265,),O
3265,",",O
3265,we,O
3265,propose,B
3265,a,O
3265,densely,B
3265,-,I
3265,connected,I
3265,recurrent,B
3265,network,I
3265,where,B
3265,the,O
3265,recurrent,O
3265,hidden,O
3265,features,O
3265,are,O
3265,retained,B
3265,to,I
3265,the,O
3265,uppermost,B
3265,layer,I
3265,.,O
3266,In,O
3266,addition,O
3266,",",O
3266,instead,B
3266,of,I
3266,the,O
3266,conventional,B
3266,summation,I
3266,operation,I
3266,",",O
3266,the,O
3266,concatenation,B
3266,operation,O
3266,is,O
3266,used,B
3266,in,O
3266,combination,O
3266,with,O
3266,the,O
3266,attention,B
3266,mechanism,I
3266,to,B
3266,preserve,I
3266,co-attentive,B
3266,information,I
3266,better,B
3266,.,O
3267,The,O
3267,proposed,O
3267,architecture,O
3267,shown,O
3267,in,O
3267,is,O
3267,called,B
3267,DRCN,B
3267,which,O
3267,is,O
3267,an,O
3267,abbreviation,B
3267,for,I
3267,Densely,B
3267,-,I
3267,connected,I
3267,Recurrent,I
3267,and,I
3267,Co,I
3267,-attentive,I
3267,neural,I
3267,Network,I
3267,.,O
3268,The,O
3268,proposed,B
3268,DRCN,B
3268,can,O
3268,utilize,B
3268,the,O
3268,increased,B
3268,representational,I
3268,power,I
3268,of,B
3268,deeper,B
3268,recurrent,I
3268,networks,I
3268,and,O
3268,attentive,B
3268,information,I
3268,.,O
3269,Furthermore,O
3269,",",O
3269,to,B
3269,alleviate,O
3269,the,O
3269,problem,O
3269,of,O
3269,an,O
3269,ever-,O
3269,increasing,O
3269,feature,O
3269,vector,O
3269,size,O
3269,due,O
3269,to,O
3269,concatenation,O
3269,operations,O
3269,",",O
3269,we,O
3269,adopted,B
3269,an,O
3269,autoencoder,B
3269,and,O
3269,forwarded,B
3269,a,O
3269,fixed,B
3269,length,I
3269,vector,O
3269,to,O
3269,the,O
3269,higher,B
3269,layer,I
3269,recurrent,I
3269,module,I
3269,as,O
3269,shown,O
3269,in,O
3269,the,O
3269,figure,O
3269,.,O
3270,When,O
3270,we,O
3270,trained,B
3270,on,I
3270,BioScope,B
3270,Abstracts,I
3270,and,O
3270,tested,B
3270,on,O
3270,the,O
3270,BioScope,O
3270,Full,O
3270,Papers,O
3270,",",O
3270,we,O
3270,surprisingly,O
3270,observed,B
3270,a,O
3270,stateof,B
3270,-,I
3270,the,O
3270,-,O
3270,art,O
3270,result,O
3270,of,B
3270,91.24,B
3270,(,O
3270,a,O
3270,gain,O
3270,of,O
3270,3.89,O
3270,F1,O
3270,points,O
3270,over,O
3270,training,O
3270,on,O
3270,BioScope,O
3270,Full,O
3270,Papers,O
3270,),O
3270,",",O
3270,which,O
3270,is,O
3270,far,O
3270,beyond,O
3270,the,O
3270,achievable,O
3270,results,O
3270,on,O
3270,training,O
3270,and,O
3270,evaluating,O
3270,on,O
3270,the,O
3270,Bio-Medical,O
3270,sub,O
3270,corpora,O
3270,.,O
3271,The,O
3271,proposed,B
3271,DRCN,I
3271,obtains,B
3271,an,O
3271,accuracy,B
3271,of,B
3271,88.9,B
3271,%,I
3271,which,O
3271,is,B
3271,a,O
3271,competitive,B
3271,score,I
3271,although,O
3271,we,O
3271,do,O
3271,not,O
3271,use,O
3271,any,O
3271,external,O
3271,knowledge,O
3271,like,O
3271,ESIM,O
3271,+,O
3271,ELMo,O
3271,and,O
3271,LM,O
3271,-,O
3271,Transformer,O
3271,.,O
3272,The,O
3272,ensemble,B
3272,model,I
3272,achieves,B
3272,an,O
3272,accuracy,B
3272,of,I
3272,90.1,B
3272,%,I
3272,",",O
3272,which,O
3272,sets,B
3272,the,O
3272,new,B
3272,state,I
3272,-,I
3272,of,O
3272,the,O
3272,-,O
3272,art,O
3272,performance,O
3272,.,O
3273,Our,O
3273,ensemble,O
3273,model,O
3273,with,B
3273,53,B
3273,m,I
3273,parameters,I
3273,(,I
3273,6.7,I
3273,m,O
3273,8,O
3273,),O
3273,outperforms,B
3273,the,O
3273,LM,B
3273,-,I
3273,Transformer,I
3273,whose,B
3273,the,O
3273,number,B
3273,of,I
3273,parameters,O
3273,is,B
3273,85,B
3273,m,O
3273,.,O
3274,Furthermore,O
3274,",",O
3274,in,B
3274,case,I
3274,of,B
3274,the,O
3274,encoding,B
3274,-,I
3274,based,I
3274,method,I
3274,",",O
3274,we,O
3274,obtain,B
3274,the,O
3274,best,B
3274,performance,I
3274,of,O
3274,86.5,B
3274,%,I
3274,without,B
3274,the,O
3274,co-attention,B
3274,and,I
3274,exact,I
3274,match,I
3274,flag,I
3274,.,O
3275,shows,O
3275,the,O
3275,results,O
3275,on,O
3275,MATCHED,O
3275,and,O
3275,MISMATCHED,O
3275,problems,O
3275,of,B
3275,MultiNLI,B
3275,dataset,I
3275,.,O
3276,Our,O
3276,plain,O
3276,DRCN,O
3276,has,O
3276,a,O
3276,competitive,B
3276,performance,I
3276,without,B
3276,any,O
3276,contextualized,B
3276,knowledge,I
3276,.,O
3277,And,O
3277,",",O
3277,by,B
3277,combining,I
3277,DRCN,B
3277,with,B
3277,the,O
3277,ELMo,B
3277,",",O
3277,one,O
3277,of,B
3277,the,O
3277,contextualized,O
3277,embeddings,O
3277,from,O
3277,language,O
3277,models,O
3277,",",O
3277,our,B
3277,model,I
3277,outperforms,B
3277,the,O
3277,LM,B
3277,-,I
3277,Transformer,I
3277,which,B
3277,has,I
3277,85,B
3277,m,I
3277,parameters,I
3277,with,O
3277,fewer,B
3277,parameters,O
3277,of,O
3277,61,B
3277,m,O
3277,.,O
3278,Pair,O
3278,shows,O
3278,our,O
3278,results,O
3278,on,B
3278,the,O
3278,Quora,B
3278,question,I
3278,pair,O
3278,dataset,O
3278,.,O
3279,We,O
3279,obtained,B
3279,accuracies,B
3279,of,B
3279,90.15,B
3279,%,I
3279,and,I
3279,91.30,I
3279,%,O
3279,in,B
3279,single,B
3279,and,O
3279,ensemble,O
3279,methods,O
3279,",",O
3279,respectively,O
3279,",",O
3279,surpassing,B
3279,the,I
3279,previous,B
3279,state,I
3279,-,I
3279,of,O
3279,-,O
3279,the,O
3279,-,O
3279,art,O
3279,model,O
3279,of,O
3279,DIIN,B
3279,.,O
3280,We,O
3280,observe,B
3280,that,O
3280,+,O
3280,Message,O
3280,passing,O
3280,-,O
3280,a,O
3280,and,O
3280,+,O
3280,Message,O
3280,passing,O
3280,-,O
3280,d,O
3280,contribute,B
3280,to,I
3280,the,O
3280,performance,B
3280,gains,I
3280,the,O
3280,most,O
3280,",",O
3280,which,O
3280,demonstrates,B
3280,the,O
3280,effectiveness,B
3280,of,B
3280,the,O
3280,proposed,B
3280,message,O
3280,passing,O
3280,mechanism,O
3280,.,O
3281,However,O
3281,",",O
3281,the,O
3281,proposed,B
3281,DRCN,I
3281,using,B
3281,collective,B
3281,attentions,I
3281,over,B
3281,multiple,B
3281,layers,I
3281,",",O
3281,achieves,B
3281,the,O
3281,new,B
3281,state,I
3281,-,I
3281,of,I
3281,the,O
3281,-,O
3281,art,O
3281,performance,O
3281,",",O
3281,exceeding,B
3281,the,O
3281,current,B
3281,state,O
3281,-,O
3281,of,O
3281,-,O
3281,the,O
3281,-,O
3281,art,O
3281,performance,O
3281,significantly,B
3281,on,O
3281,both,O
3281,datasets,O
3281,.,O
3282,We,O
3282,pre-train,B
3282,a,O
3282,large,B
3282,model,I
3282,with,B
3282,12,B
3282,layers,I
3282,in,B
3282,each,O
3282,of,B
3282,the,O
3282,encoder,B
3282,and,I
3282,decoder,I
3282,",",O
3282,and,O
3282,a,O
3282,hidden,B
3282,size,I
3282,of,O
3282,1024,B
3282,.,O
3283,Following,B
3283,RoBERTa,B
3283,",",O
3283,we,O
3283,use,B
3283,a,O
3283,batch,B
3283,size,I
3283,of,B
3283,8000,B
3283,",",O
3283,and,O
3283,train,B
3283,the,O
3283,model,B
3283,for,B
3283,500000,B
3283,steps,I
3283,.,O
3284,Documents,B
3284,are,O
3284,tokenized,B
3284,with,I
3284,the,O
3284,same,B
3284,byte,I
3284,-,I
3284,pair,I
3284,encoding,I
3284,as,B
3284,GPT,B
3284,-,O
3284,2,O
3284,.,O
3285,Based,O
3285,on,O
3285,the,O
3285,results,O
3285,in,O
3285,Section,O
3285,4,O
3285,",",O
3285,we,O
3285,use,B
3285,a,O
3285,combination,B
3285,of,B
3285,text,B
3285,infilling,I
3285,and,O
3285,sentence,B
3285,permutation,I
3285,.,O
3286,We,O
3286,mask,B
3286,30,B
3286,%,I
3286,of,B
3286,tokens,B
3286,in,B
3286,each,B
3286,document,I
3286,",",O
3286,and,O
3286,permute,B
3286,all,B
3286,sentences,I
3286,.,O
3287,To,O
3287,help,O
3287,the,O
3287,model,B
3287,better,B
3287,fit,I
3287,the,O
3287,data,B
3287,",",O
3287,we,O
3287,dis,B
3287,abled,I
3287,dropout,B
3287,for,B
3287,the,O
3287,final,B
3287,10,I
3287,%,I
3287,of,B
3287,training,B
3287,steps,I
3287,.,O
3288,The,O
3288,most,O
3288,directly,O
3288,comparable,O
3288,baseline,O
3288,is,O
3288,RoBERTa,B
3288,",",O
3288,which,O
3288,was,O
3288,pre-trained,B
3288,with,I
3288,the,O
3288,same,B
3288,resources,I
3288,",",O
3288,but,O
3288,a,O
3288,different,B
3288,objective,I
3288,.,O
3289,We,O
3289,also,O
3289,experiment,B
3289,with,I
3289,several,B
3289,text,I
3289,generation,I
3289,tasks,I
3289,.,O
3290,We,O
3290,also,O
3290,observe,O
3290,that,O
3290,simply,O
3290,adding,B
3290,documentlevel,I
3290,tasks,I
3290,(,I
3290,+,I
3290,DS,I
3290,/,I
3290,DD,I
3290,),I
3290,with,B
3290,parameter,B
3290,sharing,I
3290,only,O
3290,marginally,B
3290,improves,I
3290,the,O
3290,performance,B
3290,of,B
3290,IMN,B
3290,?d,I
3290,.,O
3291,To,O
3291,provide,O
3291,a,O
3291,comparison,O
3291,with,O
3291,the,O
3291,state,O
3291,-,O
3291,of,O
3291,-,O
3291,the,O
3291,-,O
3291,art,O
3291,in,O
3291,summarization,O
3291,",",O
3291,we,O
3291,present,B
3291,results,B
3291,on,B
3291,two,B
3291,summarization,O
3291,datasets,O
3291,",",O
3291,CNN,B
3291,/,I
3291,DailyMail,I
3291,and,O
3291,XSum,B
3291,",",O
3291,which,O
3291,have,O
3291,distinct,O
3291,properties,O
3291,.,O
3292,Nevertheless,O
3292,",",O
3292,BART,B
3292,outperforms,B
3292,all,O
3292,existing,O
3292,work,O
3292,.,O
3293,BART,O
3293,outperforms,O
3293,the,O
3293,best,B
3293,previous,I
3293,work,I
3293,",",O
3293,which,O
3293,leverages,B
3293,BERT,B
3293,",",O
3293,by,B
3293,roughly,B
3293,6.0,I
3293,points,I
3293,on,B
3293,all,B
3293,ROUGE,I
3293,metrics,I
3293,-,O
3293,representing,B
3293,a,O
3293,significant,B
3293,advance,I
3293,in,B
3293,performance,B
3293,on,O
3293,this,O
3293,problem,O
3293,.,O
3294,We,O
3294,evaluate,B
3294,dialogue,B
3294,response,I
3294,generation,I
3294,on,B
3294,CONVAI2,B
3294,",",O
3294,in,O
3294,which,O
3294,agents,O
3294,must,O
3294,generate,O
3294,responses,O
3294,conditioned,O
3294,on,O
3294,both,O
3294,the,O
3294,previous,O
3294,context,O
3294,and,O
3294,a,O
3294,textually,O
3294,-,O
3294,specified,O
3294,persona,O
3294,.,O
3295,BART,B
3295,outperforms,B
3295,previous,B
3295,work,I
3295,on,B
3295,two,B
3295,automated,I
3295,metrics,I
3295,.,O
3296,We,O
3296,use,B
3296,the,O
3296,recently,B
3296,proposed,I
3296,ELI5,I
3296,dataset,I
3296,to,O
3296,test,O
3296,the,O
3296,model,O
3296,'s,O
3296,ability,O
3296,to,O
3296,generate,O
3296,long,O
3296,freeform,O
3296,answers,O
3296,.,O
3297,We,O
3297,find,B
3297,BART,B
3297,outperforms,B
3297,the,O
3297,best,B
3297,previous,I
3297,work,I
3297,by,B
3297,1.2,B
3297,ROUGE,I
3297,-,I
3297,L,I
3297,",",O
3297,but,O
3297,the,O
3297,dataset,O
3297,remains,O
3297,a,O
3297,challenging,O
3297,",",O
3297,because,O
3297,answers,O
3297,are,O
3297,only,O
3297,weakly,O
3297,specified,O
3297,by,O
3297,the,O
3297,question,O
3297,.,O
3298,For,O
3298,each,O
3298,row,O
3298,we,O
3298,experiment,B
3298,on,I
3298,the,O
3298,original,B
3298,WMT16,I
3298,Romanian,I
3298,-,I
3298,English,I
3298,augmented,B
3298,with,I
3298,back,B
3298,-,O
3298,translation,O
3298,data,O
3298,.,O
3299,Preliminary,O
3299,results,O
3299,suggested,B
3299,that,O
3299,our,B
3299,approach,I
3299,was,B
3299,less,B
3299,effective,I
3299,without,B
3299,back,B
3299,-,I
3299,translation,I
3299,data,I
3299,",",O
3299,and,O
3299,prone,B
3299,to,I
3299,overfitting,B
3299,-,O
3299,future,O
3299,work,O
3299,should,O
3299,explore,O
3299,additional,O
3299,regularization,O
3299,techniques,O
3299,.,O
3300,In,O
3300,this,O
3300,paper,O
3300,",",O
3300,we,O
3300,present,B
3300,BART,B
3300,",",O
3300,which,O
3300,pre-trains,B
3300,a,O
3300,model,B
3300,combining,B
3300,Bidirectional,B
3300,and,I
3300,Auto,I
3300,-,I
3300,Regressive,I
3300,Transformers,I
3300,.,O
3301,However,O
3301,",",O
3301,+,O
3301,Message,B
3301,passing,I
3301,-d,I
3301,is,O
3301,still,B
3301,helpful,I
3301,with,I
3301,considerable,B
3301,performance,I
3301,gains,I
3301,",",O
3301,showing,O
3301,that,O
3301,aspect,O
3301,-,O
3301,level,O
3301,tasks,O
3301,can,O
3301,benefit,O
3301,from,O
3301,knowing,O
3301,predictions,O
3301,of,O
3301,the,O
3301,relevant,O
3301,document,O
3301,-,O
3301,level,O
3301,tasks,O
3301,.,O
3302,BART,B
3302,is,B
3302,a,O
3302,denoising,B
3302,autoencoder,I
3302,built,B
3302,with,I
3302,a,O
3302,sequence,O
3302,-,O
3302,to,O
3302,-,O
3302,sequence,O
3302,model,O
3302,that,O
3302,is,O
3302,applicable,B
3302,to,O
3302,a,O
3302,very,B
3302,wide,I
3302,range,I
3302,of,I
3302,end,I
3302,tasks,I
3302,.,O
3303,BART,O
3303,uses,B
3303,a,O
3303,standard,B
3303,Tranformer,I
3303,-,I
3303,based,I
3303,neural,I
3303,machine,I
3303,translation,I
3303,architecture,I
3303,which,O
3303,",",O
3303,despite,O
3303,its,O
3303,simplicity,O
3303,",",O
3303,can,O
3303,be,O
3303,seen,B
3303,as,I
3303,generalizing,B
3303,BERT,B
3303,(,O
3303,due,B
3303,to,I
3303,the,O
3303,bidirectional,B
3303,encoder,I
3303,),O
3303,",",O
3303,GPT,B
3303,(,O
3303,with,B
3303,the,O
3303,left,B
3303,-,O
3303,to,O
3303,-,O
3303,right,O
3303,decoder,O
3303,),O
3303,",",O
3303,and,O
3303,many,O
3303,other,O
3303,more,O
3303,recent,O
3303,pretraining,O
3303,schemes,O
3303,(,O
3303,see,O
3303,.,O
3304,Pretraining,B
3304,has,O
3304,two,B
3304,stages,I
3304,(,O
3304,1,O
3304,),O
3304,text,O
3304,is,B
3304,corrupted,B
3304,with,I
3304,an,O
3304,arbitrary,B
3304,noising,I
3304,function,I
3304,",",O
3304,and,O
3304,(,O
3304,2,O
3304,),O
3304,a,O
3304,sequence,O
3304,-,O
3304,to,B
3304,-,O
3304,sequence,O
3304,model,O
3304,is,O
3304,learned,B
3304,to,O
3304,reconstruct,O
3304,the,O
3304,original,B
3304,text,O
3304,.,O
3305,We,O
3305,present,O
3305,BART,O
3305,",",O
3305,a,O
3305,denoising,O
3305,autoencoder,O
3305,for,O
3305,pretraining,B
3305,sequence,I
3305,-,I
3305,to,I
3305,-,O
3305,sequence,O
3305,models,O
3305,.,O
3306,We,O
3306,examine,B
3306,a,O
3306,simple,B
3306,model,I
3306,family,I
3306,",",O
3306,the,O
3306,decomposable,B
3306,attention,I
3306,model,O
3306,of,O
3306,",",O
3306,that,O
3306,has,O
3306,shown,B
3306,promise,I
3306,in,I
3306,modeling,I
3306,natural,B
3306,language,I
3306,inference,I
3306,and,O
3306,has,O
3306,inspired,O
3306,recent,O
3306,work,O
3306,on,O
3306,similar,O
3306,tasks,O
3306,.,O
3307,First,O
3307,",",O
3307,to,B
3307,mitigate,I
3307,data,B
3307,sparsity,I
3307,",",O
3307,we,O
3307,modify,B
3307,the,O
3307,input,B
3307,representation,I
3307,of,I
3307,the,O
3307,decomposable,B
3307,attention,I
3307,model,I
3307,to,O
3307,use,O
3307,sums,B
3307,of,O
3307,character,B
3307,n-gram,I
3307,embeddings,I
3307,instead,B
3307,of,O
3307,word,B
3307,embeddings,O
3307,.,O
3308,Second,O
3308,",",O
3308,to,O
3308,significantly,O
3308,improve,O
3308,our,O
3308,model,O
3308,performance,O
3308,",",O
3308,we,O
3308,pretrain,B
3308,all,B
3308,our,O
3308,model,O
3308,parameters,B
3308,on,B
3308,the,O
3308,noisy,B
3308,",",O
3308,automatically,O
3308,collected,O
3308,question,O
3308,-,O
3308,paraphrase,O
3308,corpus,O
3308,Paralex,B
3308,",",O
3308,followed,B
3308,by,I
3308,fine,B
3308,-,O
3308,tuning,O
3308,the,O
3308,parameters,O
3308,on,O
3308,the,O
3308,Quora,B
3308,dataset,I
3308,.,O
3309,We,O
3309,tuned,O
3309,the,O
3309,following,O
3309,hyperparameters,O
3309,by,B
3309,grid,B
3309,search,I
3309,on,B
3309,the,O
3309,development,B
3309,set,I
3309,(,O
3309,settings,O
3309,for,B
3309,our,O
3309,best,O
3309,model,O
3309,are,O
3309,in,O
3309,parenthesis,O
3309,),O
3309,:,O
3309,embedding,B
3309,dimension,I
3309,(,O
3309,300,B
3309,),O
3309,",",O
3309,shape,B
3309,of,I
3309,all,I
3309,feedforward,I
3309,networks,I
3309,(,O
3309,two,B
3309,layers,I
3309,with,B
3309,400,B
3309,and,I
3309,200,I
3309,width,I
3309,),O
3309,",",O
3309,character,B
3309,n,I
3309,-gram,I
3309,sizes,I
3309,(,O
3309,5,B
3309,),O
3309,",",O
3309,context,B
3309,size,I
3309,(,O
3309,1,B
3309,),O
3309,",",O
3309,learning,B
3309,rate,I
3309,(,O
3309,0.1,B
3309,for,O
3309,both,O
3309,pretraining,B
3309,and,O
3309,tuning,B
3309,),O
3309,",",O
3309,batch,B
3309,size,O
3309,(,O
3309,256,B
3309,for,O
3309,pretraining,O
3309,and,O
3309,64,B
3309,for,O
3309,tuning,O
3309,),O
3309,",",O
3309,dropout,B
3309,ratio,I
3309,(,O
3309,0.1,O
3309,for,O
3309,tuning,O
3309,),O
3309,and,O
3309,prediction,B
3309,threshold,I
3309,(,O
3309,positive,B
3309,paraphrase,I
3309,for,O
3309,a,O
3309,score,O
3309,?,O
3310,The,O
3310,Recall,B
3310,gains,I
3310,for,I
3310,RE,B
3310,(,O
3310,4.3,B
3310,absolute,I
3310,points,I
3310,),O
3310,are,O
3310,much,B
3310,higher,I
3310,than,I
3310,for,O
3310,EMD,B
3310,(,O
3310,0.6,B
3310,absolute,O
3310,points,O
3310,),O
3310,.,O
3311,We,O
3311,adopt,B
3311,the,O
3311,multi,B
3311,-,I
3311,layer,I
3311,-,O
3311,CNN,B
3311,structure,I
3311,from,B
3311,as,O
3311,the,O
3311,CNN,O
3311,-,O
3311,based,O
3311,encoders,O
3311,in,O
3311,our,O
3311,proposed,O
3311,network,O
3311,.,O
3312,We,O
3312,present,O
3312,a,O
3312,solution,O
3312,to,O
3312,the,O
3312,problem,O
3312,of,O
3312,paraphrase,B
3312,identification,I
3312,of,O
3312,questions,O
3312,.,O
3313,We,O
3313,observe,B
3313,that,O
3313,the,O
3313,simple,B
3313,FFNN,I
3313,baselines,I
3313,work,B
3313,better,I
3313,than,B
3313,more,B
3313,complex,I
3313,Siamese,I
3313,and,I
3313,Multi,I
3313,-,I
3313,Perspective,I
3313,CNN,I
3313,or,I
3313,LSTM,I
3313,models,I
3313,",",O
3313,more,O
3313,so,O
3313,if,O
3313,character,O
3313,n-gram,O
3313,based,O
3313,embeddings,O
3313,are,O
3313,used,O
3313,.,O
3314,Our,O
3314,basic,O
3314,decomposable,O
3314,attention,O
3314,model,O
3314,DECATT,O
3314,word,O
3314,without,B
3314,pre-trained,B
3314,embeddings,I
3314,is,B
3314,better,B
3314,than,B
3314,most,B
3314,of,I
3314,the,I
3314,models,I
3314,",",O
3314,all,O
3314,of,O
3314,which,O
3314,used,B
3314,GloVe,B
3314,embeddings,O
3314,.,O
3315,An,O
3315,interesting,O
3315,observation,O
3315,is,O
3315,that,B
3315,DECATT,B
3315,char,I
3315,model,I
3315,without,B
3315,any,B
3315,pretrained,I
3315,embeddings,I
3315,outperforms,B
3315,DE,B
3315,-,I
3315,CATT,I
3315,glove,I
3315,that,O
3315,uses,O
3315,task,B
3315,-,O
3315,agnostic,O
3315,GloVe,O
3315,embeddings,O
3315,.,O
3316,Furthermore,O
3316,",",O
3316,when,B
3316,character,B
3316,n-gram,I
3316,embeddings,I
3316,are,B
3316,pre-trained,B
3316,in,B
3316,a,O
3316,task,B
3316,-,I
3316,specific,I
3316,manner,I
3316,in,O
3316,DECATT,O
3316,paralex,O
3316,?,O
3317,char,O
3317,model,O
3317,",",O
3317,we,O
3317,observe,B
3317,a,O
3317,significant,B
3317,boost,I
3317,in,B
3317,performance,B
3317,.,O
3318,Finally,O
3318,",",O
3318,we,O
3318,note,B
3318,that,O
3318,our,B
3318,best,I
3318,performing,I
3318,model,I
3318,is,B
3318,pt,B
3318,-,I
3318,DECATT,I
3318,char,I
3318,",",O
3318,which,O
3318,leverages,B
3318,the,O
3318,full,B
3318,power,I
3318,of,B
3318,character,B
3318,embeddings,I
3318,and,O
3318,pretraining,O
3318,the,O
3318,model,O
3318,on,O
3318,Paralex,O
3318,.,O
3319,First,O
3319,",",O
3319,replacing,B
3319,the,O
3319,word,O
3319,-,O
3319,by,B
3319,-,O
3319,word,O
3319,attention,O
3319,with,B
3319,Attentive,B
3319,Reader,I
3319,style,B
3319,attention,O
3319,decreases,B
3319,the,O
3319,EM,B
3319,score,I
3319,by,O
3319,about,O
3319,4.5,B
3319,%,I
3319,",",O
3319,showing,O
3319,the,O
3319,strength,O
3319,of,O
3319,our,O
3319,proposed,O
3319,attention,O
3319,mechanism,O
3319,.,O
3320,The,O
3320,result,O
3320,shows,B
3320,that,O
3320,POS,B
3320,feature,I
3320,(,I
3320,1,I
3320,),I
3320,and,I
3320,question,I
3320,-,I
3320,word,I
3320,feature,O
3320,(,O
3320,3,O
3320,),O
3320,are,B
3320,the,O
3320,two,B
3320,most,I
3320,important,I
3320,features,I
3320,.,O
3321,Finally,O
3321,",",O
3321,combining,B
3321,the,O
3321,DCR,B
3321,model,I
3321,with,B
3321,the,O
3321,proposed,B
3321,POS,I
3321,-,I
3321,trie,I
3321,constraints,I
3321,yields,B
3321,a,O
3321,score,B
3321,similar,B
3321,to,I
3321,the,O
3321,one,O
3321,obtained,O
3321,using,O
3321,the,O
3321,DCR,O
3321,model,O
3321,with,O
3321,all,B
3321,possible,I
3321,n-gram,I
3321,chunks,I
3321,.,O
3322,We,O
3322,adopt,O
3322,their,O
3322,released,B
3322,domainspecific,I
3322,embeddings,I
3322,for,B
3322,restaurant,B
3322,and,I
3322,laptop,I
3322,domains,I
3322,with,B
3322,100,B
3322,dimensions,I
3322,",",O
3322,which,O
3322,are,O
3322,trained,B
3322,on,I
3322,a,O
3322,large,B
3322,domain,I
3322,-,I
3322,specific,I
3322,corpus,I
3322,using,B
3322,fast,B
3322,Text,I
3322,.,O
3323,We,O
3323,pre-processed,B
3323,the,O
3323,SQuAD,B
3323,dataset,I
3323,using,B
3323,Stanford,B
3323,CoreNLP,I
3323,tool,I
3323,5,O
3323,with,B
3323,its,O
3323,default,B
3323,setting,I
3323,to,B
3323,tokenize,I
3323,the,O
3323,text,B
3323,and,I
3323,obtain,B
3323,the,O
3323,POS,B
3323,and,O
3323,NE,O
3323,annotations,O
3323,.,O
3324,To,O
3324,train,O
3324,our,O
3324,model,O
3324,",",O
3324,we,O
3324,used,B
3324,stochastic,B
3324,gradient,I
3324,descent,I
3324,with,B
3324,the,O
3324,ADAM,B
3324,optimizer,I
3324,",",O
3324,with,O
3324,an,O
3324,initial,B
3324,learning,I
3324,rate,I
3324,of,B
3324,0.001,B
3324,.,O
3325,All,O
3325,GRU,O
3325,weights,O
3325,were,O
3325,initialized,B
3325,from,I
3325,a,O
3325,uniform,B
3325,distribution,I
3325,between,B
3325,(,B
3325,-,I
3325,0.01,I
3325,",",I
3325,0.01,O
3325,),O
3325,.,O
3326,The,O
3326,hidden,B
3326,state,I
3326,size,I
3326,",",O
3326,d,B
3326,",",O
3326,was,O
3326,set,B
3326,to,I
3326,300,B
3326,for,B
3326,all,B
3326,GRUs,I
3326,.,O
3327,We,O
3327,trained,B
3327,in,B
3327,mini-batch,B
3327,style,I
3327,(,O
3327,mini,B
3327,-,I
3327,batch,I
3327,size,I
3327,is,B
3327,180,B
3327,),O
3327,and,O
3327,applied,B
3327,zero,B
3327,-,O
3327,padding,O
3327,to,B
3327,the,O
3327,passage,B
3327,and,O
3327,question,O
3327,inputs,O
3327,in,O
3327,each,B
3327,batch,O
3327,.,O
3328,We,O
3328,also,O
3328,applied,O
3328,dropout,B
3328,of,B
3328,rate,I
3328,0.2,B
3328,to,B
3328,the,O
3328,embedding,B
3328,layer,I
3328,of,O
3328,input,B
3328,bi,I
3328,-,I
3328,GRU,I
3328,encoder,I
3328,",",O
3328,and,O
3328,gradient,B
3328,clipping,I
3328,when,B
3328,the,O
3328,norm,B
3328,of,O
3328,gradients,B
3328,exceeded,B
3328,10,B
3328,.,O
3329,We,O
3329,also,O
3329,set,O
3329,the,O
3329,maximum,B
3329,passage,I
3329,length,I
3329,to,B
3329,be,I
3329,300,B
3329,tokens,I
3329,",",O
3329,and,O
3329,pruned,B
3329,all,B
3329,the,O
3329,tokens,O
3329,after,B
3329,the,O
3329,300,O
3329,-,O
3329,th,O
3329,token,O
3329,in,B
3329,the,O
3329,training,B
3329,set,O
3329,to,O
3329,save,O
3329,memory,O
3329,and,O
3329,speedup,O
3329,the,O
3329,training,O
3329,process,O
3329,.,O
3330,We,O
3330,trained,B
3330,the,O
3330,model,B
3330,for,B
3330,at,B
3330,most,I
3330,30,I
3330,epochs,I
3330,",",O
3330,and,O
3330,in,O
3330,case,O
3330,the,O
3330,accuracy,O
3330,did,O
3330,not,O
3330,improve,O
3330,for,O
3330,10,O
3330,epochs,O
3330,",",O
3330,we,O
3330,stopped,O
3330,training,O
3330,.,O
3331,For,B
3331,the,O
3331,feature,B
3331,ranking,I
3331,-,I
3331,based,I
3331,system,I
3331,",",O
3331,we,O
3331,used,B
3331,jforest,B
3331,ranker,I
3331,(,O
3331,Ganjis,O
3331,affar,O
3331,",",O
3331,Caruana,O
3331,",",O
3331,and,O
3331,Lopes,O
3331,2011,O
3331,),O
3331,with,B
3331,Lambda,B
3331,MART,I
3331,-,O
3331,Regression,O
3331,Tree,O
3331,algorithm,O
3331,and,O
3331,the,O
3331,ranking,O
3331,metric,O
3331,was,O
3331,NDCG,O
3331,@,O
3331,10,O
3331,.,O
3332,Our,O
3332,proposed,O
3332,model,O
3332,",",O
3332,called,B
3332,dynamic,B
3332,chunk,I
3332,reader,I
3332,(,I
3332,DCR,I
3332,),I
3332,",",O
3332,not,O
3332,only,O
3332,significantly,O
3332,differs,O
3332,from,O
3332,both,O
3332,the,O
3332,above,O
3332,systems,O
3332,in,O
3332,the,O
3332,way,O
3332,that,O
3332,answer,O
3332,candidates,O
3332,are,O
3332,generated,O
3332,and,O
3332,ranked,O
3332,",",O
3332,but,O
3332,also,O
3332,shares,O
3332,merits,O
3332,with,O
3332,both,O
3332,works,O
3332,.,O
3333,For,B
3333,word,B
3333,embedding,I
3333,initialization,I
3333,",",O
3333,we,O
3333,concatenate,B
3333,a,O
3333,general,B
3333,-,I
3333,purpose,I
3333,embedding,O
3333,matrix,O
3333,and,O
3333,a,O
3333,domain,B
3333,-,O
3333,specific,O
3333,embedding,O
3333,matrix,O
3333,7,O
3333,following,O
3333,.,O
3334,First,O
3334,",",O
3334,our,O
3334,model,O
3334,uses,B
3334,deep,B
3334,networks,I
3334,to,B
3334,learn,I
3334,better,B
3334,representations,I
3334,for,B
3334,candidate,B
3334,answer,I
3334,chunks,I
3334,",",O
3334,instead,B
3334,of,I
3334,using,O
3334,fixed,B
3334,feature,I
3334,representations,O
3334,as,O
3334,in,O
3334,.,O
3335,Second,O
3335,",",O
3335,it,O
3335,represents,B
3335,answer,B
3335,candidates,B
3335,as,B
3335,chunks,B
3335,",",O
3335,as,O
3335,in,O
3335,(,O
3335,Rajpurkar,O
3335,et,O
3335,al.,O
3335,),O
3336,",",O
3336,instead,B
3336,of,I
3336,word,B
3336,-,I
3336,level,I
3336,representations,I
3336,",",O
3336,to,B
3336,make,I
3336,the,O
3336,model,B
3336,aware,B
3336,of,O
3336,the,O
3336,subtle,B
3336,differences,I
3336,among,B
3336,candidates,B
3336,(,O
3336,importantly,O
3336,",",O
3336,overlapping,O
3336,candidates,O
3336,),O
3336,.,O
3337,End,O
3337,-,O
3337,to,O
3337,-,O
3337,End,O
3337,Answer,O
3337,Chunk,O
3337,Extraction,O
3337,and,O
3337,Ranking,O
3337,for,O
3337,Reading,B
3337,Comprehension,I
3338,This,O
3338,paper,O
3338,proposes,O
3338,dynamic,O
3338,chunk,O
3338,reader,O
3338,(,O
3338,DCR,O
3338,),O
3338,",",O
3338,an,O
3338,end,O
3338,-,O
3338,toend,O
3338,neural,B
3338,reading,I
3338,comprehension,I
3338,(,O
3338,RC,O
3338,),O
3338,model,O
3338,that,O
3338,is,O
3338,able,O
3338,to,O
3338,extract,O
3338,and,O
3338,rank,O
3338,a,O
3338,set,O
3338,of,O
3338,answer,O
3338,candidates,O
3338,from,O
3338,a,O
3338,given,O
3338,document,O
3338,to,O
3338,answer,O
3338,questions,O
3338,.,O
3339,Different,O
3339,from,O
3339,the,O
3339,above,O
3339,two,O
3339,assumptions,O
3339,for,O
3339,RCQA,B
3339,",",O
3339,in,O
3339,the,O
3339,real,O
3339,-,O
3339,world,O
3339,QA,O
3339,scenario,O
3339,",",O
3339,people,O
3339,may,O
3339,ask,O
3339,questions,O
3339,about,O
3339,both,O
3339,entities,O
3339,(,O
3339,factoid,O
3339,),O
3339,and,O
3339,non-entities,O
3339,such,O
3339,as,O
3339,explanations,O
3339,and,O
3339,reasons,O
3339,(,O
3339,non,O
3339,-factoid,O
3339,),O
3339,(,O
3339,see,O
3339,for,O
3339,examples,O
3339,),O
3339,.,O
3340,Results,O
3340,shows,O
3340,our,O
3340,main,O
3340,results,O
3340,on,B
3340,the,O
3340,SQuAD,B
3340,dataset,I
3340,.,O
3341,Compared,O
3341,to,O
3341,the,O
3341,scores,O
3341,reported,O
3341,in,O
3341,",",O
3341,our,B
3341,exact,I
3341,match,I
3341,(,I
3341,EM,I
3341,),I
3341,and,I
3341,F1,B
3341,on,B
3341,the,O
3341,development,B
3341,set,I
3341,and,O
3341,EM,O
3341,score,O
3341,on,O
3341,the,O
3341,test,B
3341,set,O
3341,are,B
3341,better,B
3341,",",O
3341,and,O
3341,F1,O
3341,on,O
3341,the,O
3341,test,O
3341,set,O
3341,is,O
3341,comparable,B
3341,.,O
3342,As,O
3342,the,O
3342,first,O
3342,row,O
3342,of,O
3342,shows,O
3342,",",O
3342,our,B
3342,baseline,I
3342,system,I
3342,improves,B
3342,10,B
3342,%,I
3342,(,I
3342,EM,I
3342,),I
3342,over,B
3342,",",O
3342,row,O
3342,1,O
3342,),O
3342,",",O
3342,the,O
3342,feature,B
3342,-,I
3342,based,I
3342,ranking,I
3342,system,O
3342,.,O
3343,However,O
3343,when,O
3343,compared,B
3343,to,I
3343,our,B
3343,DCR,I
3343,model,I
3343,",",O
3343,row,O
3343,2,O
3343,),O
3343,",",O
3343,the,O
3343,baseline,B
3343,(,I
3343,row,O
3343,1,O
3343,),O
3343,is,B
3343,more,B
3343,than,I
3343,12,I
3343,%,I
3343,(,O
3343,EM,O
3343,),O
3343,behind,B
3343,even,O
3343,though,O
3343,it,O
3343,is,O
3343,based,O
3343,on,O
3343,the,O
3343,state,O
3343,-,O
3343,of,O
3343,-,O
3343,the,O
3343,-,O
3343,art,O
3343,model,O
3343,for,O
3343,cloze,O
3343,-,O
3343,style,O
3343,RC,O
3343,tasks,O
3343,.,O
3344,The,O
3344,general,B
3344,-,I
3344,purpose,I
3344,embeddings,I
3344,are,B
3344,pre-trained,B
3344,Glove,I
3344,vectors,I
3344,with,B
3344,300,B
3344,dimensions,I
3344,.,O
3345,The,O
3345,first,B
3345,ablation,I
3345,baseline,I
3345,shows,B
3345,that,O
3345,without,B
3345,richer,I
3345,features,I
3345,as,B
3345,the,O
3345,alignment,B
3345,input,I
3345,",",O
3345,the,O
3345,performance,B
3345,on,B
3345,all,B
3345,datasets,I
3345,degrades,B
3345,significantly,I
3345,.,O
3346,The,O
3346,results,O
3346,of,O
3346,the,O
3346,second,B
3346,baseline,I
3346,show,B
3346,that,O
3346,vanilla,B
3346,residual,I
3346,connections,I
3346,without,B
3346,direct,I
3346,access,I
3346,to,B
3346,the,O
3346,original,B
3346,pointwise,I
3346,features,I
3346,are,B
3346,not,B
3346,enough,I
3346,to,O
3346,model,O
3346,the,O
3346,relations,B
3346,in,B
3346,many,B
3346,text,I
3346,matching,I
3346,tasks,I
3346,.,O
3347,The,O
3347,simpler,B
3347,implementation,I
3347,of,B
3347,the,O
3347,fusion,B
3347,layer,I
3347,leads,B
3347,to,I
3347,evidently,B
3347,worse,I
3347,performance,I
3347,",",O
3347,indicating,O
3347,that,O
3347,the,O
3347,fu-,O
3347,sion,O
3347,layer,O
3347,can,O
3347,not,O
3347,be,O
3347,further,O
3347,simplified,O
3347,.,O
3348,In,O
3348,the,O
3348,last,O
3348,ablation,O
3348,study,O
3348,",",O
3348,we,O
3348,can,O
3348,see,B
3348,that,I
3348,parallel,B
3348,blocks,I
3348,perform,B
3348,worse,B
3348,than,B
3348,stacked,B
3348,blocks,O
3348,",",O
3348,which,O
3348,supports,B
3348,the,O
3348,preference,B
3348,for,B
3348,deeper,B
3348,models,I
3348,over,B
3348,wider,B
3348,ones,I
3348,.,O
3349,We,O
3349,implement,B
3349,our,O
3349,model,B
3349,with,B
3349,TensorFlow,B
3349,and,O
3349,train,B
3349,on,I
3349,Nvidia,B
3349,P100,I
3349,GPUs,I
3349,.,O
3350,We,O
3350,tokenize,B
3350,sentences,B
3350,with,B
3350,the,O
3350,NLTK,B
3350,toolkit,I
3350,",",O
3350,convert,B
3350,them,O
3350,to,O
3350,lower,B
3350,cases,I
3350,and,O
3350,remove,B
3350,all,B
3350,punctuations,I
3350,.,O
3351,Word,O
3351,embeddings,O
3351,are,O
3351,initialized,B
3351,with,I
3351,840B,B
3351,-,I
3351,300d,I
3352,Glo,O
3352,Ve,O
3352,word,O
3352,vectors,O
3352,and,O
3352,fixed,B
3352,during,I
3352,training,B
3352,.,O
3353,Embeddings,B
3353,of,B
3353,out,B
3353,-,I
3353,ofvocabulary,I
3353,words,I
3353,are,O
3353,initialized,B
3353,to,I
3353,zeros,B
3353,and,O
3353,fixed,O
3353,as,O
3353,well,O
3353,.,O
3354,All,O
3354,other,O
3354,parameters,O
3354,are,B
3354,initialized,B
3354,with,B
3354,He,B
3354,initialization,I
3354,and,O
3354,normalized,B
3354,by,B
3354,weight,B
3354,normalization,I
3354,.,O
3355,Learning,O
3355,rate,O
3355,and,O
3355,batch,O
3355,size,O
3355,are,O
3355,set,B
3355,to,I
3355,conventional,B
3355,values,I
3355,without,B
3355,specific,I
3355,tuning,I
3355,for,I
3355,our,B
3355,task,I
3355,.,O
3356,Dropout,B
3356,with,B
3356,a,O
3356,keep,B
3356,probability,I
3356,of,B
3356,0.8,B
3356,is,O
3356,applied,B
3356,before,I
3356,every,O
3356,fully,B
3356,-,I
3356,connected,I
3356,or,O
3356,convolutional,B
3356,layer,I
3356,.,O
3357,The,O
3357,kernel,B
3357,size,I
3357,of,B
3357,the,O
3357,convolutional,B
3357,encoder,I
3357,is,O
3357,set,B
3357,to,I
3357,3,B
3357,.,O
3358,The,O
3358,prediction,B
3358,layer,I
3358,is,B
3358,a,O
3358,two,B
3358,-,I
3358,layer,O
3358,feed,O
3358,-,O
3358,forward,O
3358,network,O
3358,.,O
3359,The,O
3359,hidden,B
3359,size,I
3359,is,O
3359,set,B
3359,to,I
3359,150,B
3359,in,O
3359,all,O
3359,experiments,O
3359,.,O
3360,Activations,B
3360,in,B
3360,all,B
3360,feed,I
3360,-,I
3360,forward,I
3360,networks,I
3360,are,B
3360,GeLU,O
3360,activations,O
3360,",",O
3360,and,O
3360,we,O
3360,use,O
3360,?,O
3361,The,O
3361,number,B
3361,of,I
3361,blocks,I
3361,is,O
3361,tuned,B
3361,in,I
3361,a,O
3361,range,B
3361,from,B
3361,1,B
3361,to,I
3361,3,I
3361,.,O
3362,The,O
3362,number,B
3362,of,B
3362,layers,I
3362,of,O
3362,the,O
3362,convolutional,B
3362,encoder,I
3362,is,O
3362,tuned,B
3362,from,I
3362,1,B
3362,to,B
3362,3,B
3362,.,O
3363,The,O
3363,initial,B
3363,learning,I
3363,rate,I
3363,is,O
3363,tuned,B
3363,from,I
3363,0.0001,B
3363,to,I
3363,0.003,I
3363,.,O
3364,The,O
3364,batch,B
3364,size,I
3364,is,O
3364,tuned,B
3364,from,I
3364,64,B
3364,to,I
3364,512,I
3364,.,O
3365,The,O
3365,threshold,B
3365,for,B
3365,gradient,B
3365,clipping,I
3365,is,O
3365,set,B
3365,to,I
3365,5,B
3365,.,O
3366,We,O
3366,tune,B
3366,the,O
3366,maximum,B
3366,number,I
3366,of,I
3366,iterations,I
3366,T,I
3366,in,B
3366,the,O
3366,message,B
3366,passing,I
3366,mechanism,I
3366,by,B
3366,training,I
3366,IMN,B
3366,?d,I
3366,via,B
3366,cross,B
3366,validation,I
3366,on,O
3366,D1,O
3366,.,O
3367,We,O
3367,scale,B
3367,the,O
3367,summation,B
3367,in,B
3367,augmented,B
3367,residual,I
3367,connections,I
3367,by,B
3367,1,O
3367,/,O
3367,?,O
3368,2,O
3368,when,B
3368,n,O
3368,?,O
3369,3,O
3369,to,B
3369,preserve,I
3369,the,O
3369,variance,O
3369,under,B
3369,the,O
3369,assumption,B
3369,that,B
3369,the,O
3369,two,B
3369,addends,I
3369,have,B
3369,the,O
3369,same,B
3369,variance,O
3369,.,O
3370,This,O
3370,paper,O
3370,presents,B
3370,RE2,B
3370,",",O
3370,a,O
3370,fast,B
3370,and,I
3370,strong,I
3370,neural,I
3370,architecture,I
3370,with,B
3370,multiple,B
3370,alignment,I
3370,processes,I
3370,for,B
3370,general,B
3370,purpose,I
3370,text,I
3370,matching,I
3370,.,O
3371,These,O
3371,components,B
3371,",",O
3371,which,O
3371,the,O
3371,name,O
3371,RE2,O
3371,stands,O
3371,for,O
3371,",",O
3371,are,O
3371,previous,B
3371,aligned,I
3371,features,I
3371,(,O
3371,Residual,B
3371,vectors,I
3371,),O
3371,",",O
3371,original,B
3371,point,I
3371,-,I
3371,wise,I
3371,features,O
3371,(,O
3371,Embedding,B
3371,vectors,O
3371,),O
3371,",",O
3371,and,O
3371,contextual,B
3371,features,O
3371,(,O
3371,Encoded,B
3371,vectors,O
3371,),O
3371,.,O
3372,An,O
3372,embedding,B
3372,layer,I
3372,first,O
3372,embeds,B
3372,discrete,B
3372,tokens,I
3372,.,O
3373,Several,O
3373,same,B
3373,-,I
3373,structured,I
3373,blocks,I
3373,consisting,B
3373,of,I
3373,encoding,B
3373,",",O
3373,alignment,B
3373,and,O
3373,fusion,B
3373,layers,I
3373,then,O
3373,process,B
3373,the,O
3373,sequences,B
3373,consecutively,B
3373,.,O
3374,These,O
3374,blocks,O
3374,are,O
3374,connected,B
3374,by,I
3374,an,O
3374,augmented,B
3374,version,I
3374,of,I
3374,residual,I
3374,connections,I
3374,(,O
3374,see,O
3374,section,O
3374,2.1,O
3374,),O
3374,.,O
3375,A,O
3375,pooling,B
3375,layer,I
3375,aggregates,B
3375,sequential,B
3375,representations,I
3375,into,B
3375,vectors,B
3375,which,O
3375,are,O
3375,finally,O
3375,processed,B
3375,by,I
3375,a,O
3375,prediction,O
3375,layer,O
3375,to,B
3375,give,I
3375,the,O
3375,final,B
3375,prediction,O
3375,.,O
3376,The,O
3376,implementation,B
3376,of,B
3376,each,B
3376,layer,I
3376,is,O
3376,kept,B
3376,as,I
3376,simple,I
3376,as,O
3376,possible,O
3376,",",O
3376,and,O
3376,the,O
3376,whole,O
3376,model,O
3376,",",O
3376,as,O
3376,a,O
3376,well,O
3376,-,O
3376,organized,O
3376,combination,O
3376,",",O
3376,is,O
3376,quite,O
3376,powerful,O
3376,and,O
3376,lightweight,O
3376,at,O
3376,the,O
3376,same,O
3376,time,O
3376,.,O
3377,Simple,O
3377,and,O
3377,Effective,O
3377,Text,B
3377,Matching,I
3377,with,O
3377,Richer,O
3377,Alignment,O
3377,Features,O
3378,Results,O
3378,on,B
3378,WikiQA,B
3378,dataset,I
3378,are,O
3378,listed,O
3378,in,O
3378,.,O
3379,It,O
3379,is,O
3379,set,B
3379,to,I
3379,2,B
3379,.,O
3380,We,O
3380,obtain,B
3380,a,O
3380,result,B
3380,on,B
3380,par,I
3380,with,I
3380,the,I
3380,state,B
3380,-,I
3380,of,I
3380,-,O
3380,the,O
3380,-,O
3380,art,O
3380,reported,O
3380,on,O
3380,this,O
3380,dataset,O
3380,.,O
3381,Our,O
3381,method,B
3381,can,O
3381,perform,B
3381,well,B
3381,in,B
3381,the,O
3381,answer,B
3381,selection,I
3381,task,I
3381,without,B
3381,any,B
3381,taskspecific,I
3381,modifications,I
3381,.,O
3382,From,O
3382,the,O
3382,results,O
3382,",",O
3382,we,O
3382,observe,B
3382,that,I
3382,the,O
3382,concatenation,B
3382,would,O
3382,yield,B
3382,an,O
3382,improvement,B
3382,",",O
3382,verifying,B
3382,that,O
3382,integrating,B
3382,contextual,B
3382,semantics,I
3382,would,O
3382,be,B
3382,quite,B
3382,useful,I
3382,for,B
3382,language,B
3382,understanding,I
3382,.,O
3383,However,O
3383,",",O
3383,SemBERT,B
3383,still,O
3383,outperforms,B
3383,the,O
3383,simple,B
3383,BERT,I
3383,+,I
3383,SRL,I
3383,model,I
3383,just,O
3383,like,O
3383,the,O
3383,latter,O
3383,outperforms,O
3383,the,O
3383,original,O
3383,BERT,O
3383,by,O
3383,a,O
3383,large,O
3383,performance,O
3383,margin,O
3383,",",O
3383,which,O
3383,shows,B
3383,that,I
3383,SemBERT,O
3383,works,B
3383,more,B
3383,effectively,I
3383,for,B
3383,integrating,B
3383,both,B
3383,plain,B
3383,contextual,B
3383,representation,I
3383,and,O
3383,contextual,O
3383,semantics,O
3383,at,O
3383,the,O
3383,same,O
3383,time,O
3383,.,O
3384,Our,O
3384,implementation,O
3384,is,O
3384,based,B
3384,on,I
3384,the,O
3384,PyTorch,B
3384,implementation,O
3384,of,B
3384,BERT,B
3384,6,O
3384,.,O
3385,The,O
3385,batch,B
3385,size,I
3385,is,O
3385,selected,B
3385,in,I
3385,{,B
3385,16,I
3385,",",I
3385,24,I
3385,",",O
3385,32,O
3385,},O
3385,.,O
3386,The,O
3386,maximum,B
3386,number,I
3386,of,I
3386,epochs,I
3386,is,O
3386,set,B
3386,in,I
3386,[,B
3386,2,I
3386,",",I
3386,5,I
3386,],I
3386,depending,B
3386,on,I
3386,tasks,B
3386,.,O
3387,Texts,B
3387,are,O
3387,tokenized,B
3387,using,I
3387,wordpieces,B
3387,",",O
3387,with,B
3387,maximum,B
3387,length,I
3387,of,B
3387,384,B
3387,for,B
3387,SQuAD,B
3387,and,O
3387,128,B
3387,or,I
3387,200,I
3387,for,O
3387,other,B
3387,tasks,I
3387,.,O
3388,The,O
3388,dimension,B
3388,of,B
3388,SRL,B
3388,embedding,I
3388,is,O
3388,set,B
3388,to,I
3388,10,B
3388,.,O
3389,The,O
3389,default,B
3389,maximum,I
3389,number,I
3389,of,B
3389,predicateargument,B
3389,structures,I
3389,m,I
3389,is,O
3389,set,B
3389,to,I
3389,3,B
3389,.,O
3390,We,O
3390,use,B
3390,Adam,B
3390,optimizer,I
3390,with,B
3390,learning,B
3390,rate,I
3390,set,B
3390,to,B
3390,10,O
3390,?,O
3391,4,O
3391,",",O
3391,and,O
3391,we,O
3391,set,B
3391,batch,B
3391,size,I
3391,to,B
3391,32,B
3391,.,O
3392,We,O
3392,use,B
3392,the,I
3392,pre-trained,B
3392,weights,I
3392,of,B
3392,BERT,B
3392,and,O
3392,follow,B
3392,the,O
3392,same,B
3392,fine,I
3392,-,I
3392,tuning,I
3392,procedure,I
3392,as,B
3392,BERT,O
3392,without,O
3392,any,O
3392,modification,O
3392,",",O
3392,and,O
3392,all,B
3392,the,O
3392,layers,O
3392,are,O
3392,tuned,B
3392,with,I
3392,moderate,B
3392,model,I
3392,size,I
3392,increasing,B
3392,",",O
3392,as,O
3392,the,O
3392,extra,B
3392,SRL,I
3392,embedding,I
3392,volume,I
3392,is,B
3392,less,B
3392,than,I
3392,15,I
3392,%,I
3392,of,O
3392,the,O
3392,original,B
3392,encoder,I
3392,size,O
3392,.,O
3393,We,O
3393,set,B
3393,the,O
3393,initial,B
3393,learning,I
3393,rate,I
3393,in,B
3393,{,B
3393,8e,I
3393,-6,I
3393,",",I
3393,1,I
3393,e,I
3393,-,I
3393,5,I
3393,",",O
3393,2,O
3393,e,O
3393,-,O
3393,5,O
3393,",",O
3393,3,O
3393,e,O
3393,-,O
3393,5,O
3393,},O
3393,with,B
3393,warm,B
3393,-,O
3393,up,O
3393,rate,O
3393,of,B
3393,0.1,B
3393,and,O
3393,L2,B
3393,weight,I
3393,decay,I
3393,of,O
3393,0.01,B
3393,.,O
3394,Thus,O
3394,we,O
3394,are,O
3394,motivated,O
3394,to,O
3394,enrich,B
3394,the,O
3394,sentence,B
3394,contextual,I
3394,semantics,I
3394,in,B
3394,multiple,B
3394,predicate,I
3394,-,I
3394,specific,I
3394,argument,I
3394,sequences,I
3394,by,B
3394,presenting,I
3394,SemBERT,B
3394,:,I
3394,Semantics,O
3394,-,O
3394,aware,O
3394,BERT,O
3394,",",O
3394,which,O
3394,is,B
3394,a,O
3394,fine,B
3394,-,O
3394,tuned,O
3394,BERT,O
3394,with,B
3394,explicit,B
3394,contextual,O
3394,semantic,O
3394,clues,O
3394,.,O
3395,The,O
3395,proposed,B
3395,SemBERT,I
3395,learns,B
3395,the,O
3395,representation,O
3395,in,B
3395,a,O
3395,fine,B
3395,-,I
3395,grained,I
3395,manner,I
3395,and,O
3395,takes,B
3395,both,O
3395,strengths,B
3395,of,B
3395,BERT,B
3395,on,B
3395,plain,B
3395,context,I
3395,representation,O
3395,and,O
3395,explicit,B
3395,semantics,I
3395,for,B
3395,deeper,B
3395,meaning,I
3395,representation,O
3395,.,O
3396,Our,O
3396,model,O
3396,consists,B
3396,of,I
3396,three,B
3396,components,I
3396,:,O
3397,1,O
3397,),O
3397,an,B
3397,out,I
3397,-,I
3397,ofshelf,I
3397,semantic,I
3397,role,I
3397,labeler,I
3397,to,B
3397,annotate,I
3397,the,O
3397,input,O
3397,sentences,O
3397,with,B
3397,a,O
3397,variety,B
3397,of,I
3397,semantic,O
3397,role,O
3397,labels,O
3397,;,O
3397,2,O
3397,),O
3397,an,O
3397,sequence,B
3397,encoder,I
3397,where,B
3397,a,O
3397,pre-trained,B
3397,language,I
3397,model,I
3397,is,O
3397,used,B
3397,to,O
3397,build,O
3397,representation,O
3397,for,B
3397,input,O
3397,raw,B
3397,texts,I
3397,and,O
3397,the,O
3397,semantic,O
3397,role,O
3397,labels,O
3397,are,O
3397,mapped,B
3397,to,O
3397,embedding,O
3397,in,B
3397,parallel,B
3397,;,O
3397,3,O
3397,),O
3397,a,O
3397,semantic,O
3397,integration,O
3397,component,O
3397,to,O
3397,integrate,O
3397,the,O
3397,text,B
3397,representation,O
3397,with,O
3397,the,O
3397,contextual,B
3397,explicit,I
3397,semantic,O
3397,embedding,O
3397,to,O
3397,obtain,O
3397,the,O
3397,joint,B
3397,representation,O
3397,for,O
3397,downstream,B
3397,tasks,I
3397,.,O
3398,The,O
3398,latest,O
3398,work,O
3398,on,O
3398,language,B
3398,representations,I
3398,carefully,O
3398,integrates,O
3398,contextualized,O
3398,features,O
3398,into,O
3398,language,O
3398,model,O
3398,training,O
3398,",",O
3398,which,O
3398,enables,O
3398,a,O
3398,series,O
3398,of,O
3398,success,O
3398,especially,O
3398,in,O
3398,various,O
3398,machine,O
3398,reading,O
3398,comprehension,O
3398,and,O
3398,natural,O
3398,language,O
3398,inference,O
3398,tasks,O
3398,.,O
3399,Recently,O
3399,",",O
3399,deep,O
3399,contextual,O
3399,language,O
3399,model,O
3399,(,O
3399,LM,O
3399,),O
3399,has,O
3399,been,O
3399,shown,O
3399,effective,O
3399,for,O
3399,learning,B
3399,universal,I
3399,language,O
3399,representations,O
3399,",",O
3399,achieving,O
3399,state,O
3399,-,O
3399,of,O
3399,-,O
3399,the,O
3399,-,O
3399,art,O
3399,results,O
3399,in,O
3399,a,O
3399,series,O
3399,of,O
3399,flagship,O
3399,natural,O
3399,language,O
3399,understanding,O
3399,(,O
3399,NLU,O
3399,),O
3399,tasks,O
3399,.,O
3400,The,O
3400,ablation,O
3400,results,O
3400,of,B
3400,QA,I
3400,performances,I
3400,in,B
3400,the,O
3400,development,B
3400,set,I
3400,of,O
3400,Hotpot,B
3400,QA,O
3400,are,O
3400,shown,O
3400,in,O
3400,.,O
3401,From,O
3401,the,O
3401,table,O
3401,we,O
3401,can,O
3401,see,B
3401,that,I
3401,each,B
3401,of,I
3401,our,I
3401,model,I
3401,components,I
3401,can,O
3401,provide,B
3401,from,O
3401,1,O
3401,%,O
3401,to,O
3401,2,O
3401,%,O
3401,relative,B
3401,gain,I
3401,over,B
3401,the,O
3401,QA,B
3401,performance,I
3401,.,O
3402,At,B
3402,training,B
3402,phase,I
3402,",",O
3402,we,O
3402,randomly,B
3402,sample,I
3402,20,B
3402,%,I
3402,of,B
3402,the,O
3402,training,O
3402,data,O
3402,from,B
3402,the,O
3402,aspect,B
3402,-,I
3402,level,I
3402,dataset,I
3402,as,B
3402,the,O
3402,development,B
3402,set,I
3402,and,O
3402,only,O
3402,use,B
3402,the,O
3402,remaining,B
3402,80,I
3402,%,O
3402,for,B
3402,training,O
3402,.,O
3403,Particularly,O
3403,",",O
3403,using,B
3403,a,O
3403,1,B
3403,-,I
3403,layer,I
3403,fusion,I
3403,block,I
3403,leads,B
3403,to,I
3403,an,O
3403,obvious,B
3403,performance,I
3403,loss,I
3403,",",O
3403,which,O
3403,implies,B
3403,the,O
3403,significance,B
3403,of,B
3403,performing,B
3403,multi-hop,B
3403,reasoning,I
3403,in,B
3403,Hotpot,B
3403,QA,I
3403,.,O
3404,Besides,O
3404,",",O
3404,the,O
3404,dataset,B
3404,abla-tion,I
3404,results,I
3404,show,B
3404,that,O
3404,our,B
3404,model,I
3404,is,O
3404,not,B
3404,very,I
3404,sensitive,I
3404,to,B
3404,the,O
3404,noisy,B
3404,paragraphs,I
3404,comparing,B
3404,with,I
3404,the,O
3404,baseline,B
3404,model,O
3404,which,O
3404,can,B
3404,achieve,I
3404,a,O
3404,more,B
3404,than,I
3404,5,I
3404,%,I
3404,performance,I
3404,gain,I
3404,in,B
3404,the,O
3404,"""",O
3404,gold,B
3404,paragraphs,O
3404,only,O
3404,"""",O
3404,and,O
3404,"""",O
3404,supporting,B
3404,facts,I
3404,only,O
3404,"""",O
3404,settings,O
3404,.,O
3405,In,B
3405,paragraph,B
3405,selection,I
3405,stage,I
3405,",",O
3405,we,O
3405,use,B
3405,the,O
3405,uncased,B
3405,version,I
3405,of,I
3405,BERT,I
3405,Tokenizer,I
3405,to,B
3405,tokenize,I
3405,all,B
3405,passages,I
3405,and,I
3405,questions,I
3405,.,O
3406,In,O
3406,graph,B
3406,construction,I
3406,stage,I
3406,",",O
3406,we,O
3406,use,B
3406,a,O
3406,pretrained,B
3406,NER,I
3406,model,I
3406,from,B
3406,Stanford,B
3406,CoreNLP,I
3406,Toolkits,I
3406,1,O
3406,to,B
3406,extract,I
3406,named,B
3406,entities,I
3406,.,O
3407,In,O
3407,the,O
3407,encoding,B
3407,stage,I
3407,",",O
3407,we,O
3407,also,O
3407,use,B
3407,a,O
3407,pre-trained,B
3407,BERT,I
3407,model,I
3407,as,B
3407,the,O
3407,encoder,B
3407,",",O
3407,thus,O
3407,d,B
3407,1,I
3407,is,B
3407,768,B
3407,.,O
3408,The,O
3408,encoding,B
3408,vectors,I
3408,of,B
3408,sentence,B
3408,pairs,I
3408,are,O
3408,generated,B
3408,from,I
3408,a,O
3408,pre-trained,B
3408,BERT,I
3408,model,I
3408,.,O
3409,The,O
3409,maximum,B
3409,number,I
3409,of,I
3409,entities,I
3409,in,B
3409,a,O
3409,graph,B
3409,is,O
3409,set,B
3409,to,I
3409,be,O
3409,40,B
3409,.,O
3410,Each,O
3410,entity,B
3410,node,O
3410,in,B
3410,the,O
3410,entity,O
3410,graphs,O
3410,has,O
3410,an,O
3410,average,B
3410,degree,I
3410,of,B
3410,3.52,B
3410,.,O
3411,All,O
3411,the,O
3411,hidden,B
3411,state,I
3411,dimensions,I
3411,d,I
3411,2,I
3411,are,O
3411,set,B
3411,to,I
3411,300,B
3411,.,O
3412,We,O
3412,set,B
3412,a,O
3412,relatively,B
3412,low,I
3412,threshold,I
3412,during,B
3412,selection,B
3412,to,B
3412,keep,I
3412,a,O
3412,high,B
3412,recall,I
3412,(,I
3412,97,I
3412,%,I
3412,),I
3412,and,O
3412,a,O
3412,reasonable,B
3412,precision,I
3412,(,O
3412,69,O
3412,%,O
3412,),O
3412,on,B
3412,supporting,B
3412,facts,I
3412,.,O
3413,In,O
3413,this,O
3413,work,O
3413,",",O
3413,we,O
3413,propose,B
3413,an,O
3413,interactive,B
3413,multitask,I
3413,learning,I
3413,network,I
3413,(,I
3413,IMN,I
3413,),I
3413,",",O
3413,which,O
3413,solves,O
3413,both,O
3413,tasks,O
3413,simultaneously,O
3413,",",O
3413,enabling,O
3413,the,O
3413,interactions,O
3413,between,O
3413,both,O
3413,tasks,O
3413,to,O
3413,be,O
3413,better,O
3413,exploited,O
3413,.,O
3414,We,O
3414,set,O
3414,the,O
3414,dropout,B
3414,rate,I
3414,for,B
3414,all,B
3414,hidden,I
3414,units,I
3414,of,B
3414,LSTM,B
3414,and,I
3414,dynamic,I
3414,graph,I
3414,attention,I
3414,to,B
3414,0.3,B
3414,and,O
3414,0.5,O
3414,respectively,O
3414,.,O
3415,For,B
3415,optimization,B
3415,",",O
3415,we,O
3415,use,B
3415,Adam,B
3415,Optimizer,I
3415,with,B
3415,an,O
3415,initial,B
3415,learning,I
3415,rate,I
3415,of,B
3415,1,B
3415,e,I
3415,?4,I
3415,.,O
3416,In,O
3416,this,O
3416,paper,O
3416,",",O
3416,we,O
3416,propose,B
3416,Dynamically,B
3416,Fused,I
3416,Graph,I
3416,Network,I
3416,(,I
3416,DFGN,I
3416,),I
3416,",",O
3416,a,O
3416,novel,B
3416,method,I
3416,to,O
3416,address,O
3416,the,O
3416,aforementioned,O
3416,concerns,O
3416,for,O
3416,multi-hop,O
3416,text,O
3416,-,O
3416,based,O
3416,QA,O
3416,.,O
3417,To,O
3417,solve,O
3417,the,O
3417,second,O
3417,challenge,O
3417,",",O
3417,we,O
3417,propose,O
3417,a,O
3417,fusion,B
3417,process,I
3417,in,B
3417,DFGN,B
3417,to,O
3417,solve,O
3417,the,O
3417,unrestricted,B
3417,QA,I
3417,challenge,O
3417,.,O
3418,For,O
3418,the,O
3418,first,O
3418,challenge,O
3418,",",O
3418,DFGN,B
3418,constructs,B
3418,a,O
3418,dynamic,B
3418,entity,B
3418,graph,I
3418,based,B
3418,on,I
3418,entity,O
3418,mentions,O
3418,in,B
3418,the,O
3418,query,B
3418,and,I
3418,documents,I
3418,.,O
3419,This,O
3419,process,B
3419,iterates,B
3419,in,I
3419,multiple,B
3419,rounds,I
3419,to,B
3419,achieve,I
3419,multihop,B
3419,reasoning,I
3419,.,O
3420,The,O
3420,fusion,B
3420,process,I
3420,is,B
3420,iteratively,B
3420,performed,I
3420,at,B
3420,each,B
3420,hop,I
3420,through,B
3420,the,O
3420,document,B
3420,tokens,I
3420,and,I
3420,entities,I
3420,",",O
3420,and,O
3420,the,O
3420,final,B
3420,resulting,I
3420,answer,I
3420,is,O
3420,then,O
3420,obtained,B
3420,from,I
3420,document,O
3420,tokens,O
3420,.,O
3421,The,O
3421,fusion,O
3421,process,O
3421,of,B
3421,doc2,B
3421,graph,I
3421,and,I
3421,graph2doc,I
3421,along,B
3421,with,I
3421,the,O
3421,dynamic,B
3421,entity,I
3421,graph,O
3421,jointly,B
3421,improve,I
3421,the,O
3421,interaction,B
3421,between,B
3421,the,O
3421,information,B
3421,of,O
3421,documents,B
3421,and,O
3421,the,O
3421,entity,O
3421,graph,O
3421,",",O
3421,leading,B
3421,to,I
3421,a,O
3421,less,B
3421,noisy,I
3421,entity,O
3421,graph,O
3421,and,O
3421,thus,O
3421,more,B
3421,accurate,I
3421,answers,I
3421,.,O
3422,In,B
3422,each,B
3422,round,I
3422,",",O
3422,DFGN,B
3422,generates,B
3422,and,I
3422,reasons,I
3422,on,B
3422,a,O
3422,dynamic,B
3422,graph,I
3422,",",O
3422,where,O
3422,irrelevant,B
3422,entities,I
3422,are,B
3422,masked,B
3422,out,I
3422,while,B
3422,only,O
3422,reasoning,B
3422,sources,I
3422,are,O
3422,preserved,B
3422,",",O
3422,via,B
3422,a,O
3422,mask,B
3422,prediction,I
3422,module,I
3422,.,O
3423,We,O
3423,not,O
3423,only,O
3423,aggregate,B
3423,information,B
3423,from,B
3423,documents,B
3423,to,I
3423,the,O
3423,entity,B
3423,graph,I
3423,(,O
3423,doc2,B
3423,graph,O
3423,),O
3423,",",O
3423,but,O
3423,also,O
3423,propagate,B
3423,the,O
3423,information,O
3423,of,B
3423,the,O
3423,entity,O
3423,graph,O
3423,back,B
3423,to,O
3423,document,B
3423,representations,I
3423,(,O
3423,graph2doc,O
3423,),O
3423,.,O
3424,Thus,O
3424,",",O
3424,our,B
3424,large,I
3424,gains,I
3424,in,B
3424,RE,B
3424,Recall,I
3424,(,I
3424,and,I
3424,F,I
3424,1,I
3424,),I
3424,showcase,B
3424,the,O
3424,effectiveness,B
3424,of,I
3424,our,O
3424,simple,O
3424,modeling,O
3424,of,O
3424,ordered,O
3424,span,O
3424,pairs,O
3424,for,B
3424,relation,B
3424,extraction,I
3424,(,O
3424,Section,O
3424,3.3,O
3424,),O
3424,.,O
3425,Furthermore,O
3425,",",O
3425,IMN,B
3425,allows,B
3425,AE,B
3425,and,I
3425,AS,I
3425,to,B
3425,be,I
3425,trained,I
3425,together,I
3425,with,I
3425,related,B
3425,document,I
3425,-,I
3425,level,I
3425,tasks,I
3425,",",O
3425,exploiting,B
3425,the,O
3425,knowledge,B
3425,from,B
3425,larger,B
3425,document,O
3425,-,O
3425,level,O
3425,corpora,O
3425,.,O
3426,Dynamically,O
3426,Fused,O
3426,Graph,O
3426,Network,O
3426,for,O
3426,Multi-hop,B
3426,Reasoning,I
3427,QA,B
3427,provides,O
3427,a,O
3427,quantifiable,O
3427,way,O
3427,to,O
3427,evaluate,O
3427,an,O
3427,NLP,O
3427,system,O
3427,'s,O
3427,capability,O
3427,on,O
3427,language,O
3427,understanding,O
3427,and,O
3427,reasoning,O
3427,.,O
3428,shows,O
3428,the,O
3428,performance,O
3428,of,B
3428,different,O
3428,models,O
3428,in,B
3428,the,O
3428,private,B
3428,test,I
3428,set,I
3428,of,O
3428,Hotpot,B
3428,QA,I
3428,.,O
3429,From,O
3429,the,O
3429,table,O
3429,we,O
3429,can,O
3429,see,B
3429,that,I
3429,our,B
3429,model,I
3429,achieves,B
3429,the,O
3429,second,B
3429,best,I
3429,result,I
3429,on,B
3429,the,O
3429,leaderboard,B
3429,now,O
3429,3,O
3429,(,O
3429,on,O
3429,March,B
3429,1st,I
3429,),O
3429,.,O
3430,Besides,O
3430,",",O
3430,the,O
3430,answer,O
3430,performance,O
3430,and,O
3430,the,O
3430,joint,B
3430,performance,O
3430,of,O
3430,our,B
3430,model,I
3430,are,B
3430,competitive,B
3430,against,B
3430,state,B
3430,-,I
3430,of,O
3430,-,O
3430,the,O
3430,-,O
3430,art,O
3430,unpublished,O
3430,models,O
3430,.,O
3431,The,O
3431,results,O
3431,show,B
3431,that,O
3431,our,B
3431,model,I
3431,achieves,B
3431,a,O
3431,1.5,B
3431,%,I
3431,gain,I
3431,in,B
3431,the,O
3431,joint,B
3431,F1,I
3431,-,I
3431,score,I
3431,with,B
3431,the,O
3431,entity,O
3431,graph,O
3431,built,B
3431,from,I
3431,a,O
3431,better,B
3431,entity,O
3431,recognizer,O
3431,.,O
3432,Results,O
3432,shows,O
3432,results,O
3432,in,O
3432,the,O
3432,task,O
3432,of,O
3432,sentence,O
3432,selection,O
3432,on,O
3432,SQuAD,B
3432,and,I
3432,New,I
3432,s,I
3432,QA,I
3432,.,O
3433,First,O
3433,",",O
3433,our,O
3433,selector,B
3433,outperforms,B
3433,TF,B
3433,-,I
3433,IDF,I
3433,method,I
3433,and,I
3433,the,I
3433,previous,I
3433,state,I
3433,-,O
3433,of,O
3433,-,O
3433,the,O
3433,-,O
3433,art,O
3433,by,B
3433,large,B
3433,margin,I
3433,(,O
3433,up,B
3433,to,I
3433,2.9,B
3433,%,I
3433,MAP,I
3433,),O
3433,.,O
3434,Second,O
3434,",",O
3434,our,O
3434,three,B
3434,training,I
3434,techniques,I
3434,-,O
3434,weight,B
3434,transfer,I
3434,",",O
3434,data,B
3434,modification,I
3434,and,O
3434,score,B
3434,normalization,I
3434,-,O
3434,improve,B
3434,performance,B
3434,by,B
3434,up,B
3434,to,I
3434,5.6,I
3434,%,I
3434,MAP,I
3434,.,O
3435,In,O
3435,addition,O
3435,",",O
3435,IMN,O
3435,allows,O
3435,fined,B
3435,-,I
3435,grained,I
3435,tokenlevel,I
3435,classification,I
3435,tasks,I
3435,to,B
3435,be,I
3435,trained,I
3435,together,I
3435,with,I
3435,document,B
3435,-,O
3435,level,O
3435,classification,O
3435,tasks,O
3435,.,O
3436,Finally,O
3436,",",O
3436,our,O
3436,Dyn,B
3436,method,I
3436,achieves,B
3436,higher,B
3436,accuracy,I
3436,with,B
3436,less,B
3436,sentences,I
3436,than,B
3436,the,O
3436,Top,B
3436,k,I
3436,method,O
3436,.,O
3437,On,B
3437,News,B
3437,QA,I
3437,",",O
3437,Top,B
3437,4,I
3437,achieves,B
3437,92.5,B
3437,accuracy,I
3437,",",O
3437,whereas,O
3437,Dyn,B
3437,achieves,O
3437,94.6,B
3437,accuracy,O
3437,with,B
3437,3.9,B
3437,sentences,I
3437,per,I
3437,example,I
3437,.,O
3438,On,B
3438,SQuAD,B
3438,",",O
3438,S,B
3438,-,I
3438,Reader,I
3438,achieves,B
3438,6.7,B
3438,training,I
3438,and,O
3438,3.6,B
3438,inference,I
3438,speedup,B
3438,on,O
3438,SQuAD,O
3438,",",O
3438,and,O
3438,15.0,B
3438,training,O
3438,and,O
3438,6.9,B
3438,inference,O
3438,speedup,O
3438,on,O
3438,News,B
3438,QA,I
3438,.,O
3439,We,O
3439,compare,B
3439,with,I
3439,the,O
3439,results,O
3439,from,O
3439,the,O
3439,sentences,O
3439,selected,O
3439,by,O
3439,TF,B
3439,-,I
3439,IDF,I
3439,method,I
3439,and,O
3439,our,B
3439,selector,I
3439,(,I
3439,Dyn,I
3439,),I
3439,.,O
3440,We,O
3440,also,O
3440,compare,O
3440,with,O
3440,published,B
3440,Rank1,I
3440,-,I
3440,3,I
3440,models,I
3440,.,O
3441,First,O
3441,",",O
3441,MINI,B
3441,-,I
3441,MAL,I
3441,obtains,B
3441,higher,B
3441,F1,I
3441,and,I
3441,EM,I
3441,over,B
3441,FULL,B
3441,",",O
3441,with,O
3441,the,O
3441,inference,O
3441,speedup,O
3441,of,O
3441,up,O
3441,to,O
3441,13.8,O
3441,.,O
3442,Second,O
3442,",",O
3442,the,O
3442,model,B
3442,with,B
3442,our,B
3442,sentence,I
3442,selector,I
3442,with,O
3442,Dyn,B
3442,achieves,B
3442,higher,B
3442,F1,I
3442,and,I
3442,EM,I
3442,over,B
3442,the,O
3442,model,O
3442,with,O
3442,TF,B
3442,-,I
3442,IDF,I
3442,selector,O
3442,.,O
3443,Third,O
3443,",",O
3443,we,O
3443,outperforms,B
3443,the,I
3443,published,O
3443,state,B
3443,-,I
3443,of,I
3443,-,O
3443,the,O
3443,-,O
3443,art,O
3443,on,B
3443,both,B
3443,dataset,I
3443,.,O
3444,In,O
3444,contrast,O
3444,to,B
3444,most,O
3444,multi-task,O
3444,learning,O
3444,schemes,O
3444,which,O
3444,share,O
3444,information,O
3444,through,B
3444,learning,O
3444,a,O
3444,common,O
3444,feature,O
3444,representation,O
3444,",",O
3444,IMN,O
3444,not,O
3444,only,O
3444,allows,O
3444,shared,O
3444,features,O
3444,",",O
3444,but,O
3444,also,O
3444,explicitly,B
3444,models,I
3444,the,O
3444,interactions,B
3444,between,B
3444,tasks,I
3444,through,O
3444,the,O
3444,message,B
3444,passing,I
3444,mechanism,I
3444,",",O
3444,allowing,B
3444,different,B
3444,tasks,O
3444,to,O
3444,better,O
3444,influence,O
3444,each,B
3444,other,I
3444,.,O
3445,Results,O
3445,shows,B
3445,that,O
3445,MINIMAL,B
3445,outperforms,B
3445,FULL,B
3445,",",O
3445,achieving,B
3445,the,I
3445,new,B
3445,state,I
3445,-,I
3445,of,I
3445,-,O
3445,the,O
3445,-,O
3445,art,O
3445,by,B
3445,large,B
3445,margin,I
3445,(,O
3445,+,O
3445,11.1,O
3445,and,O
3445,+,O
3445,11.5,O
3445,F1,O
3445,on,B
3445,AddSent,B
3445,and,O
3445,Add,O
3445,OneSent,O
3445,",",O
3445,respectively,O
3445,),O
3445,.,O
3446,In,O
3446,this,O
3446,paper,O
3446,",",O
3446,we,O
3446,aim,O
3446,to,O
3446,develop,B
3446,a,O
3446,QA,B
3446,system,I
3446,that,O
3446,is,O
3446,scalable,B
3446,to,O
3446,large,B
3446,documents,I
3446,as,O
3446,well,O
3446,as,O
3446,robust,B
3446,to,O
3446,adversarial,B
3446,inputs,I
3446,.,O
3447,First,O
3447,",",O
3447,we,O
3447,study,B
3447,the,I
3447,context,B
3447,required,B
3447,to,I
3447,answer,B
3447,the,O
3447,question,O
3447,by,B
3447,sampling,I
3447,examples,B
3447,in,B
3447,the,O
3447,dataset,B
3447,and,O
3447,carefully,O
3447,analyzing,O
3447,them,O
3447,.,O
3448,Second,O
3448,",",O
3448,inspired,O
3448,by,O
3448,this,O
3448,observation,O
3448,",",O
3448,we,O
3448,propose,B
3448,a,O
3448,sentence,B
3448,selector,I
3448,to,B
3448,select,I
3448,the,O
3448,minimal,B
3448,set,I
3448,of,I
3448,sentences,I
3448,to,O
3448,give,O
3448,to,O
3448,the,O
3448,QA,B
3448,model,I
3448,in,O
3448,order,O
3448,to,O
3448,answer,O
3448,the,O
3448,question,B
3448,.,O
3449,Since,O
3449,the,O
3449,minimum,O
3449,number,O
3449,of,O
3449,sentences,O
3449,depends,O
3449,on,O
3449,the,O
3449,question,O
3449,",",O
3449,our,O
3449,sentence,O
3449,selector,O
3449,chooses,B
3449,a,O
3449,different,B
3449,number,O
3449,of,O
3449,sentences,O
3449,for,B
3449,each,B
3449,question,O
3449,",",O
3449,in,O
3449,contrast,O
3449,with,O
3449,previous,O
3449,models,O
3449,that,O
3449,select,O
3449,a,O
3449,fixed,O
3449,number,O
3449,of,O
3449,sentences,O
3449,.,O
3450,Our,O
3450,sentence,O
3450,selector,O
3450,leverages,B
3450,three,B
3450,simple,I
3450,techniques,I
3450,-,O
3450,weight,B
3450,transfer,I
3450,",",O
3450,data,B
3450,modification,I
3450,and,O
3450,score,B
3450,normalization,I
3450,",",O
3450,which,O
3450,we,O
3450,show,O
3450,to,O
3450,be,O
3450,highly,O
3450,effective,O
3450,on,O
3450,the,O
3450,task,O
3450,of,O
3450,sentence,O
3450,selection,O
3450,.,O
3451,Efficient,O
3451,and,O
3451,Robust,O
3451,Question,B
3451,Answering,I
3451,from,O
3451,Minimal,O
3451,Context,O
3451,over,O
3451,Documents,O
3452,Neural,O
3452,models,O
3452,for,O
3452,question,B
3452,answering,I
3452,(,I
3452,QA,I
3452,),I
3452,over,O
3452,documents,O
3452,have,O
3452,achieved,O
3452,significant,O
3452,performance,O
3452,improvements,O
3452,.,O
3453,Inspired,O
3453,by,O
3453,this,O
3453,observation,O
3453,",",O
3453,we,O
3453,propose,O
3453,a,O
3453,simple,O
3453,sentence,O
3453,selector,O
3453,to,O
3453,select,O
3453,the,O
3453,minimal,O
3453,set,O
3453,of,O
3453,sentences,O
3453,to,O
3453,feed,O
3453,into,O
3453,the,O
3453,QA,B
3453,model,O
3453,.,O
3454,The,O
3454,information,B
3454,is,O
3454,then,O
3454,combined,B
3454,with,I
3454,the,O
3454,shared,B
3454,latent,I
3454,representation,I
3454,and,O
3454,made,B
3454,available,I
3454,to,I
3454,all,B
3454,tasks,I
3454,for,B
3454,further,B
3454,processing,I
3454,.,O
3455,The,O
3455,good,O
3455,results,O
3455,on,O
3455,the,O
3455,10,O
3455,fold,O
3455,cross,O
3455,validations,O
3455,are,O
3455,confirmed,O
3455,on,O
3455,the,O
3455,official,O
3455,test,O
3455,set,O
3455,:,O
3455,the,O
3455,model,O
3455,is,O
3455,very,O
3455,accurate,O
3455,and,O
3455,achieved,B
3455,the,O
3455,first,B
3455,position,I
3455,among,B
3455,12,B
3455,systems,I
3455,",",O
3455,with,B
3455,the,O
3455,best,B
3455,MAP,I
3455,.,O
3456,On,O
3456,the,O
3456,official,O
3456,test,O
3456,set,O
3456,",",O
3456,our,B
3456,primary,I
3456,submission,I
3456,achieved,B
3456,the,O
3456,third,B
3456,position,I
3456,w.r.t.,B
3457,MAP,B
3457,among,B
3457,11,B
3457,systems,I
3457,.,O
3458,The,O
3458,primary,B
3458,system,I
3458,achieves,B
3458,the,O
3458,highest,B
3458,F,I
3458,1,I
3458,and,I
3458,accuracy,I
3458,on,B
3458,both,B
3458,tuning,I
3458,and,O
3458,test,O
3458,stages,O
3458,.,O
3459,Our,O
3459,primary,B
3459,submission,I
3459,achieved,B
3459,the,O
3459,second,B
3459,highest,I
3459,MAP,I
3459,",",O
3459,while,O
3459,our,O
3459,Contrastive,O
3459,2,O
3459,is,O
3459,the,O
3459,best,O
3459,result,O
3459,.,O
3460,It,O
3460,should,O
3460,be,O
3460,also,O
3460,noted,B
3460,that,I
3460,the,O
3460,F,B
3460,1,I
3460,our,I
3460,system,I
3460,is,B
3460,the,O
3460,best,B
3460,among,B
3460,10,B
3460,primary,I
3460,submissions,I
3460,.,O
3461,All,O
3461,the,O
3461,above,O
3461,subtasks,O
3461,have,O
3461,been,O
3461,modeled,B
3461,as,I
3461,binary,B
3461,classification,B
3461,problems,I
3461,:,O
3461,kernel,B
3461,-,I
3461,based,I
3461,classifiers,I
3461,are,B
3461,trained,B
3461,and,O
3461,the,O
3461,classification,O
3461,score,O
3461,is,O
3461,used,O
3461,to,B
3461,sort,I
3461,the,O
3461,instances,B
3461,and,O
3461,produce,B
3461,the,O
3461,final,B
3461,ranking,I
3461,.,O
3462,All,O
3462,classifiers,B
3462,and,I
3462,kernels,I
3462,have,O
3462,been,O
3462,implemented,B
3462,within,I
3462,the,O
3462,Kernel,B
3462,-,I
3462,based,I
3462,Learning,I
3462,Platform,I
3462,2,I
3462,(,I
3462,KeLP,I
3462,),I
3462,",",O
3462,thus,O
3462,determining,O
3462,the,O
3462,team,O
3462,'s,O
3462,name,O
3462,.,O
3463,The,O
3463,proposed,O
3463,solution,O
3463,provides,O
3463,three,O
3463,main,O
3463,contributions,O
3463,:,O
3463,(,O
3463,i,O
3463,),O
3463,we,O
3463,employ,O
3463,the,O
3463,approach,O
3463,proposed,O
3463,in,O
3463,",",O
3463,which,O
3463,applies,B
3463,tree,B
3463,kernels,I
3463,directly,B
3463,to,I
3463,question,B
3463,and,I
3463,answer,I
3463,texts,I
3463,modeled,B
3463,as,I
3463,pairs,B
3463,of,B
3463,linked,B
3463,syntactic,I
3463,trees,I
3463,.,O
3464,IMN,O
3464,introduces,B
3464,a,O
3464,novel,B
3464,message,I
3464,passing,I
3464,mechanism,I
3464,that,O
3464,allows,B
3464,informative,B
3464,interactions,I
3464,between,B
3464,tasks,B
3464,.,O
3465,(,O
3465,iii,O
3465,),O
3465,we,O
3465,propose,B
3465,a,O
3465,stacking,B
3465,schema,I
3465,so,O
3465,that,O
3465,classifiers,B
3465,for,B
3465,Subtask,B
3465,B,I
3465,and,I
3465,C,I
3465,exploit,B
3465,the,O
3465,inferences,B
3465,obtained,B
3465,in,I
3465,the,O
3465,previous,B
3465,subtasks,I
3465,.,O
3466,This,O
3466,paper,O
3466,describes,O
3466,the,O
3466,KeLP,O
3466,system,O
3466,participating,O
3466,in,O
3466,the,O
3466,SemEval,O
3466,-,O
3466,2016,O
3466,Community,B
3466,Question,I
3466,Answering,I
3466,(,I
3466,c,I
3466,QA,I
3466,),I
3466,task,O
3466,.,O
3467,In,O
3467,this,O
3467,task,O
3467,",",O
3467,participants,O
3467,are,O
3467,asked,O
3467,to,O
3467,automatically,O
3467,provide,O
3467,good,O
3467,answers,O
3467,in,O
3467,a,O
3467,c,B
3467,QA,I
3467,setting,O
3467,.,O
3468,RACE,B
3468,-,O
3468,the,O
3468,key,B
3468,competitors,I
3468,are,B
3468,the,O
3468,Stanford,O
3468,Attention,O
3468,Reader,O
3468,(,O
3468,Stanford,O
3468,AR,O
3468,),O
3468,",",O
3468,Gated,B
3468,Attention,O
3468,Reader,O
3468,(,O
3468,GA,O
3468,),O
3468,",",O
3468,and,O
3468,Dynamic,B
3468,Fusion,I
3468,Networks,I
3468,(,O
3468,DFN,O
3468,),O
3468,.,O
3469,Search,O
3469,QA,O
3469,-,O
3469,the,O
3469,main,B
3469,competitor,I
3469,baseline,I
3469,is,B
3469,the,O
3469,AMANDA,B
3469,model,I
3469,proposed,O
3469,by,O
3469,.,O
3470,NarrativeQA,B
3471,We,O
3471,compete,O
3471,on,O
3471,the,O
3471,summaries,O
3471,setting,O
3471,",",O
3471,in,O
3471,which,O
3471,the,O
3471,baselines,B
3471,are,B
3471,a,O
3471,context,B
3471,-,I
3471,less,I
3471,sequence,I
3471,to,I
3471,sequence,O
3471,(,O
3471,seq2seq,O
3471,),O
3471,model,O
3471,",",O
3471,ASR,B
3471,and,O
3471,BiDAF,B
3471,.,O
3472,We,O
3472,implement,B
3472,all,B
3472,models,I
3472,in,B
3472,TensorFlow,B
3472,.,O
3473,Word,O
3473,embeddings,O
3473,are,O
3473,initialized,B
3473,with,I
3473,300d,B
3473,Glo,I
3473,Ve,I
3473,vectors,I
3473,and,O
3473,are,O
3473,not,B
3473,fine,I
3473,-,I
3473,tuned,I
3473,during,I
3473,training,B
3473,.,O
3474,Dropout,O
3474,rate,O
3474,is,O
3474,tuned,B
3474,amongst,I
3474,{,B
3474,0.1,I
3474,",",I
3474,0.2,I
3474,",",O
3474,0.3,O
3474,},O
3474,on,B
3474,all,B
3474,layers,I
3474,including,B
3474,the,O
3474,embedding,B
3474,layer,I
3474,.,O
3475,Specifically,O
3475,",",O
3475,it,O
3475,sends,B
3475,useful,B
3475,information,I
3475,from,B
3475,different,B
3475,tasks,I
3475,back,B
3475,to,I
3475,a,O
3475,shared,B
3475,latent,I
3475,representation,I
3475,.,O
3476,The,O
3476,batch,B
3476,size,I
3476,is,O
3476,set,B
3476,to,I
3476,64/256/32,B
3476,accordingly,O
3476,.,O
3477,The,O
3477,maximum,B
3477,sequence,I
3477,lengths,I
3477,are,B
3477,500/200/1100,B
3477,respectively,O
3477,.,O
3478,We,O
3478,adopt,B
3478,the,O
3478,Adam,B
3478,optimizer,I
3478,with,B
3478,a,O
3478,learning,B
3478,rate,I
3478,of,B
3478,0.0003/,B
3478,0.001/0.001,I
3478,for,B
3478,RACE,B
3478,/,I
3478,SearchQA,I
3478,/,O
3478,NarrativeQA,O
3478,respectively,O
3478,.,O
3479,All,O
3479,models,O
3479,are,O
3479,trained,B
3479,and,O
3479,all,O
3479,runtime,O
3479,benchmarks,O
3479,are,O
3479,based,B
3479,on,I
3479,a,O
3479,TitanXP,B
3479,GPU,I
3479,.,O
3480,To,O
3480,this,O
3480,end,O
3480,",",O
3480,we,O
3480,propose,B
3480,a,O
3480,new,B
3480,compositional,I
3480,encoder,I
3480,that,O
3480,can,O
3480,either,O
3480,be,O
3480,used,B
3480,in,I
3480,-,I
3480,place,I
3480,of,I
3480,standard,B
3480,RNN,I
3480,encoders,I
3480,or,O
3480,serve,B
3480,as,I
3480,a,O
3480,new,O
3480,module,O
3480,that,O
3480,is,O
3480,complementary,O
3480,to,O
3480,existing,B
3480,neural,I
3480,architectures,I
3480,.,O
3481,Our,O
3481,proposed,O
3481,MRU,O
3481,encoders,O
3481,learns,B
3481,gating,B
3481,vectors,I
3481,via,B
3481,multiple,B
3481,contract,I
3481,-,I
3481,and,I
3481,-,O
3481,expand,O
3481,layers,O
3481,at,B
3481,multiple,O
3481,dilated,O
3481,resolutions,O
3481,.,O
3482,The,O
3482,k,B
3482,document,I
3482,representations,I
3482,(,O
3482,at,B
3482,multiple,B
3482,ranges,I
3482,and,I
3482,n-gram,I
3482,blocks,I
3482,),O
3482,are,O
3482,then,O
3482,combined,B
3482,and,O
3482,modeled,O
3482,with,O
3482,fully,B
3482,connected,I
3482,layers,I
3482,to,B
3482,form,I
3482,the,O
3482,final,B
3482,compositional,I
3482,gate,I
3482,which,O
3482,are,O
3482,applied,B
3482,onto,I
3482,the,O
3482,original,B
3482,input,I
3482,document,O
3482,.,O
3483,Specifically,O
3483,",",O
3483,we,O
3483,compress,B
3483,the,O
3483,input,B
3483,document,I
3483,an,O
3483,arbitrary,O
3483,k,O
3483,times,O
3483,at,O
3483,multi-ranges,O
3483,(,O
3483,e.g.,O
3484,",",O
3484,1,O
3484,",",O
3484,2,O
3484,",",O
3484,4,O
3484,",",O
3484,10,O
3484,",",O
3484,25,O
3484,),O
3484,into,B
3484,a,O
3484,neural,B
3484,bag,I
3484,-,I
3484,of,I
3484,-,O
3484,words,O
3484,(,O
3484,summed,O
3484,),O
3484,representation,O
3484,.,O
3485,The,O
3485,compact,O
3485,sequence,O
3485,is,O
3485,then,O
3485,passed,B
3485,through,I
3485,affine,B
3485,transformation,I
3485,layers,I
3485,and,O
3485,then,O
3485,re-expanded,B
3485,to,I
3485,the,O
3485,original,B
3485,sequence,O
3485,length,O
3485,.,O
3486,Multi-range,O
3486,Reasoning,O
3486,for,O
3486,Machine,B
3486,Comprehension,I
3487,We,O
3487,incorporated,B
3487,two,B
3487,document,B
3487,-,I
3487,level,I
3487,classification,I
3487,tasks,I
3487,-,O
3487,sentiment,B
3487,classification,O
3487,(,O
3487,DS,O
3487,),O
3487,and,O
3487,domain,B
3487,classification,O
3487,(,O
3487,DD,O
3487,),O
3487,-,O
3487,to,B
3487,be,I
3487,jointly,I
3487,trained,I
3487,with,I
3487,AE,B
3487,and,O
3487,AS,O
3487,",",O
3487,allowing,B
3487,the,O
3487,aspect,B
3487,-,O
3487,level,O
3487,tasks,O
3487,to,O
3487,benefit,O
3487,from,O
3487,document,O
3487,-,O
3487,level,O
3487,information,O
3487,.,O
3488,We,O
3488,propose,O
3488,MRU,O
3488,(,O
3488,Multi,O
3488,-,O
3488,Range,O
3488,Reasoning,O
3488,Units,O
3488,),O
3488,",",O
3488,a,O
3488,new,O
3488,fast,O
3488,compositional,O
3488,encoder,O
3488,for,O
3488,machine,B
3488,comprehension,I
3488,(,O
3488,MC,O
3488,),O
3488,.,O
3489,While,O
3489,the,O
3489,usage,O
3489,of,O
3489,recurrent,O
3489,encoder,O
3489,is,O
3489,often,O
3489,regarded,O
3489,as,O
3489,indispensable,O
3489,in,O
3489,highly,O
3489,complex,O
3489,MC,B
3489,tasks,O
3489,",",O
3489,there,O
3489,are,O
3489,still,O
3489,several,O
3489,challenges,O
3489,and,O
3489,problems,O
3489,pertaining,O
3489,to,O
3489,it,O
3489,'s,O
3489,usage,O
3489,in,O
3489,modern,O
3489,MC,O
3489,tasks,O
3489,.,O
3490,Experimental,O
3490,Results,O
3490,on,B
3490,RACE,B
3491,Overall,O
3491,",",O
3491,there,O
3491,is,O
3491,a,O
3491,6,B
3491,%,I
3491,improvement,I
3491,on,B
3491,the,O
3491,RACE,B
3491,-,I
3491,H,I
3491,dataset,I
3491,and,O
3491,1.8,B
3491,%,O
3491,improvement,O
3491,on,O
3491,the,O
3491,RACE,O
3491,-,O
3491,M,O
3491,dataset,O
3491,.,O
3492,MRU,O
3492,and,O
3492,MRU,O
3492,can,O
3492,achieve,B
3492,comparable,B
3492,performance,I
3492,to,B
3492,each,B
3492,other,I
3492,",",O
3492,(,O
3492,2,O
3492,),O
3492,GRU,B
3492,and,O
3492,LSTM,O
3492,models,O
3492,do,B
3492,not,I
3492,have,I
3492,a,O
3492,competitive,B
3492,edge,I
3492,and,O
3492,(,O
3492,3,O
3492,),O
3492,Using,O
3492,no,B
3492,encoder,I
3492,already,O
3492,achieves,B
3492,comparable,O
3492,1,O
3492,performance,O
3492,to,O
3492,DFN,B
3492,.,O
3493,Finally,O
3493,",",O
3493,an,O
3493,ensemble,O
3493,of,B
3493,Sim,O
3493,.,O
3494,MRU,O
3494,models,O
3494,achieve,B
3494,state,B
3494,-,I
3494,of,B
3494,-,O
3494,the,O
3494,-,O
3494,art,O
3494,performance,O
3494,on,B
3494,the,O
3494,RACE,B
3494,dataset,I
3494,",",O
3494,achieving,B
3494,and,O
3494,over,B
3494,all,I
3494,score,I
3494,of,O
3494,53.3,B
3494,%,I
3494,.,O
3495,reports,O
3495,our,O
3495,results,O
3495,on,O
3495,the,O
3495,Narrative,B
3495,QA,I
3495,benchmark,I
3495,.,O
3496,First,O
3496,",",O
3496,we,O
3496,observe,B
3496,that,I
3496,300d,B
3496,MRU,I
3496,can,B
3496,achieve,I
3496,comparable,B
3496,performance,I
3496,with,B
3496,BiDAF,B
3496,.,O
3497,When,O
3497,compared,B
3497,with,B
3497,a,O
3497,BiLSTM,B
3497,of,B
3497,equal,B
3497,output,I
3497,dimensions,I
3497,(,I
3497,150,I
3497,d,I
3497,),I
3497,",",O
3497,we,O
3497,find,B
3497,that,I
3497,our,O
3497,MRU,B
3497,model,I
3497,performs,B
3497,competitively,B
3497,",",O
3497,with,O
3497,less,B
3497,than,I
3497,1,I
3497,%,I
3497,deprovement,I
3497,across,B
3497,all,B
3497,metrics,I
3497,.,O
3498,The,O
3498,performance,B
3498,of,I
3498,our,B
3498,model,I
3498,is,B
3498,significantly,B
3498,better,I
3498,than,B
3498,300d,B
3498,LSTM,I
3498,model,O
3498,while,O
3498,also,B
3498,being,I
3498,significantly,O
3498,faster,O
3498,.,O
3499,An,O
3499,Interactive,O
3499,Multi,O
3499,-,O
3499,Task,O
3499,Learning,O
3499,Network,O
3499,for,O
3499,End,O
3499,-,O
3499,to,O
3499,-,O
3499,End,O
3499,Aspect,B
3499,-,O
3499,Based,O
3499,Sentiment,O
3499,Analysis,O
3500,Finally,O
3500,",",O
3500,the,O
3500,MRU,B
3500,-,I
3500,LSTM,I
3500,significantly,B
3500,outperforms,I
3500,all,B
3500,models,I
3500,",",O
3500,including,B
3500,BiDAF,B
3500,on,O
3500,this,O
3500,dataset,O
3500,.,O
3501,Performance,O
3501,improvement,O
3501,over,B
3501,the,O
3501,vanilla,B
3501,BiLSTM,I
3501,model,I
3501,ranges,B
3501,from,I
3501,1,O
3501,%,O
3501,?,O
3502,3,O
3502,%,O
3502,across,B
3502,all,B
3502,metrics,I
3502,",",O
3502,suggesting,O
3502,that,O
3502,MRU,O
3502,encoders,O
3502,are,O
3502,also,O
3502,effective,O
3502,as,O
3502,a,O
3502,complementary,O
3502,neural,O
3502,building,O
3502,block,O
3502,.,O
3503,As,O
3503,shown,O
3503,in,B
3503,",",O
3503,we,O
3503,conduct,B
3503,an,B
3503,ablation,I
3503,experiment,I
3503,on,B
3503,SNLI,B
3503,development,I
3503,dataset,I
3503,to,O
3503,evaluate,O
3503,the,O
3503,individual,O
3503,contribution,O
3503,of,O
3503,each,O
3503,component,O
3503,of,O
3503,our,O
3503,model,O
3503,.,O
3504,The,O
3504,result,B
3504,is,B
3504,obviously,O
3504,not,B
3504,satisfactory,I
3504,",",O
3504,which,O
3504,indicates,O
3504,that,O
3504,only,B
3504,using,I
3504,sentence,B
3504,embedding,I
3504,from,B
3504,discourse,B
3504,markers,I
3504,to,B
3504,predict,I
3504,the,O
3504,answer,B
3504,is,O
3504,not,O
3504,ideal,O
3504,in,O
3504,large,B
3504,-,I
3504,scale,I
3504,datasets,I
3504,.,O
3505,we,O
3505,remove,B
3505,the,O
3505,character,B
3505,-,I
3505,level,I
3505,embedding,I
3505,and,I
3505,the,O
3505,POS,B
3505,and,O
3505,NER,O
3505,features,O
3505,",",O
3505,the,O
3505,performance,B
3505,drops,B
3505,a,I
3505,lot,I
3505,.,O
3506,The,O
3506,exact,B
3506,match,I
3506,feature,I
3506,also,O
3506,demonstrates,B
3506,its,O
3506,effectiveness,B
3506,in,B
3506,the,O
3506,ablation,B
3506,result,I
3506,.,O
3507,We,O
3507,then,O
3507,remove,B
3507,the,O
3507,sentence,B
3507,encoder,I
3507,model,I
3507,",",O
3507,which,O
3507,means,O
3507,we,O
3507,do,O
3507,n't,O
3507,use,O
3507,the,O
3507,knowledge,O
3507,transferred,O
3507,from,O
3507,the,O
3507,DMP,O
3507,task,O
3507,and,O
3507,thus,O
3507,the,O
3507,representations,O
3507,r,O
3507,p,O
3507,and,O
3507,r,O
3507,hare,O
3507,set,O
3507,to,B
3507,be,O
3507,zero,O
3507,vectors,O
3507,in,O
3507,the,O
3507,equation,O
3507,(,O
3507,6,O
3507,),O
3507,and,O
3507,the,O
3507,equation,O
3507,.,O
3508,We,O
3508,observe,B
3508,that,I
3508,the,O
3508,performance,B
3508,drops,B
3508,significantly,I
3508,to,O
3508,87,O
3508,.,O
3509,Finally,O
3509,",",O
3509,we,O
3509,ablate,B
3509,the,O
3509,reinforcement,B
3509,learning,I
3509,part,I
3509,",",O
3509,in,O
3509,other,O
3509,words,O
3509,",",O
3509,we,O
3509,only,O
3509,use,O
3509,the,O
3509,original,O
3509,loss,O
3509,function,O
3509,to,O
3509,optimize,O
3509,the,O
3509,model,O
3509,(,O
3509,set,O
3509,?,O
3510,The,O
3510,result,B
3510,drops,B
3510,about,I
3510,0.5,I
3510,%,I
3510,",",O
3510,which,O
3510,proves,O
3510,that,O
3510,it,O
3510,is,O
3510,helpful,O
3510,to,O
3510,utilize,O
3510,all,O
3510,the,O
3510,information,O
3510,from,O
3510,the,O
3510,annotators,O
3510,.,O
3511,We,O
3511,use,B
3511,the,O
3511,Stanford,B
3511,CoreNLP,I
3511,toolkit,I
3511,to,B
3511,tokenize,I
3511,the,O
3511,words,B
3511,and,I
3511,generate,B
3511,POS,B
3511,and,O
3511,NER,O
3511,tags,O
3511,.,O
3512,We,O
3512,use,O
3512,the,O
3512,AdaDelta,B
3512,for,B
3512,optimization,B
3512,as,O
3512,described,O
3512,in,O
3512,with,B
3512,?,O
3513,The,O
3513,word,B
3513,embeddings,I
3513,are,B
3513,initialized,B
3513,by,I
3513,300d,B
3513,Glove,I
3513,",",O
3513,the,O
3513,dimensions,B
3513,of,B
3513,POS,B
3513,and,I
3513,NER,I
3513,embeddings,O
3513,are,O
3513,30,B
3513,and,O
3513,10,O
3513,.,O
3514,We,O
3514,set,B
3514,our,B
3514,batch,I
3514,size,I
3514,as,B
3514,36,B
3514,and,O
3514,the,O
3514,initial,B
3514,learning,I
3514,rate,I
3514,as,O
3514,0.6,B
3514,.,O
3515,We,O
3515,set,O
3515,the,O
3515,hidden,B
3515,size,I
3515,as,B
3515,300,B
3515,for,B
3515,all,B
3515,the,O
3515,LSTM,O
3515,layers,B
3515,and,O
3515,apply,B
3515,dropout,B
3515,between,B
3515,layers,O
3515,with,B
3515,an,O
3515,initial,B
3515,ratio,I
3515,of,B
3515,0.9,B
3515,",",O
3515,the,O
3515,decay,B
3515,rate,I
3515,as,O
3515,0.97,B
3515,for,O
3515,every,B
3515,5000,I
3515,step,I
3515,.,O
3516,We,O
3516,apply,O
3516,Tensorflow,B
3516,r,I
3516,1.3,I
3516,as,B
3516,our,B
3516,neural,I
3516,network,I
3516,framework,I
3516,.,O
3517,The,O
3517,number,B
3517,of,I
3517,epochs,I
3517,is,B
3517,set,B
3517,to,I
3517,be,O
3517,10,B
3517,",",O
3517,and,O
3517,the,O
3517,feedforward,B
3517,dropout,I
3517,rate,I
3517,is,O
3517,0.2,B
3517,.,O
3518,For,B
3518,DMP,B
3518,task,I
3518,",",O
3518,we,O
3518,use,B
3518,stochastic,B
3518,gradient,I
3518,descent,I
3518,with,B
3518,initial,B
3518,learning,I
3518,rate,I
3518,as,B
3518,0.1,B
3518,",",O
3518,and,O
3518,we,O
3518,anneal,B
3518,by,B
3518,half,B
3518,each,B
3518,time,I
3518,the,O
3518,validation,B
3518,accuracy,I
3518,is,B
3518,lower,B
3518,than,B
3518,the,O
3518,previous,B
3518,epoch,I
3518,.,O
3519,In,O
3519,this,O
3519,paper,O
3519,",",O
3519,we,O
3519,propose,B
3519,a,O
3519,Discourse,B
3519,Marker,I
3519,Augmented,I
3519,Network,I
3519,for,B
3519,natural,B
3519,language,I
3519,inference,I
3519,",",O
3519,where,B
3519,we,O
3519,transfer,B
3519,the,O
3519,knowledge,B
3519,from,B
3519,the,O
3519,existing,B
3519,supervised,I
3519,task,I
3519,:,O
3519,Discourse,O
3519,Marker,O
3519,Prediction,O
3519,(,O
3519,DMP,O
3519,),O
3519,",",O
3519,to,B
3519,an,O
3519,integrated,B
3519,NLI,I
3519,model,I
3519,.,O
3520,We,O
3520,first,O
3520,propose,O
3520,a,O
3520,sentence,B
3520,encoder,B
3520,model,I
3520,that,B
3520,learns,I
3520,the,O
3520,representations,B
3520,of,B
3520,the,O
3520,sentences,B
3520,from,B
3520,the,O
3520,DMP,B
3520,task,I
3520,and,O
3520,then,O
3520,inject,B
3520,the,O
3520,encoder,O
3520,to,B
3520,the,O
3520,NLI,B
3520,network,I
3520,.,O
3521,This,O
3521,is,O
3521,done,O
3521,by,O
3521,extracting,O
3521,explicit,O
3521,aspect,B
3521,mentions,O
3521,",",O
3521,referred,O
3521,to,O
3521,as,O
3521,aspect,O
3521,term,O
3521,extraction,O
3521,(,O
3521,AE,O
3521,),O
3521,",",O
3521,and,O
3521,detecting,O
3521,the,O
3521,sentiment,O
3521,orientation,O
3521,towards,O
3521,each,O
3521,extracted,O
3521,aspect,O
3521,term,O
3521,",",O
3521,referred,O
3521,to,O
3521,as,O
3521,aspect,O
3521,-,O
3521,level,O
3521,sentiment,O
3521,classification,O
3521,(,O
3521,AS,O
3521,),O
3521,.,O
3522,In,O
3522,consideration,O
3522,of,B
3522,that,O
3522,different,O
3522,confidence,O
3522,level,O
3522,of,O
3522,the,O
3522,final,O
3522,labels,O
3522,should,O
3522,be,O
3522,discriminated,O
3522,",",O
3522,we,O
3522,employ,B
3522,reinforcement,B
3522,learning,I
3522,with,B
3522,a,O
3522,reward,B
3522,defined,B
3522,by,I
3522,the,O
3522,uniformity,B
3522,extent,I
3522,of,O
3522,the,O
3522,original,B
3522,labels,O
3522,to,B
3522,train,I
3522,the,O
3522,model,B
3522,.,O
3523,Discourse,O
3523,Marker,O
3523,Augmented,O
3523,Network,O
3523,with,O
3523,Reinforcement,O
3523,Learning,O
3523,for,O
3523,Natural,B
3523,Language,I
3523,Inference,I
3524,Natural,O
3524,Language,O
3524,Inference,O
3524,(,O
3524,NLI,O
3524,),O
3524,",",O
3524,also,O
3524,known,O
3524,as,O
3524,Recognizing,B
3524,Textual,I
3524,Entailment,I
3524,(,O
3524,RTE,O
3524,),O
3524,",",O
3524,is,O
3524,one,O
3524,of,O
3524,the,O
3524,most,O
3524,important,O
3524,problems,O
3524,in,O
3524,natural,O
3524,language,O
3524,processing,O
3524,.,O
3525,While,O
3525,current,O
3525,approaches,O
3525,mostly,O
3525,focus,O
3525,on,O
3525,the,O
3525,interaction,O
3525,architectures,O
3525,of,O
3525,the,O
3525,sentences,O
3525,",",O
3525,in,O
3525,this,O
3525,paper,O
3525,",",O
3525,we,O
3525,propose,O
3525,to,O
3525,transfer,O
3525,knowledge,O
3525,from,O
3525,some,O
3525,important,O
3525,discourse,O
3525,markers,O
3525,to,O
3525,augment,O
3525,the,O
3525,quality,O
3525,of,O
3525,the,O
3525,NLI,B
3525,model,O
3525,.,O
3526,Obviously,O
3526,",",O
3526,the,O
3526,performance,B
3526,of,I
3526,most,B
3526,of,O
3526,the,O
3526,integrated,O
3526,methods,O
3526,are,B
3526,better,B
3526,than,B
3526,the,O
3526,sentence,B
3526,encoding,I
3526,based,I
3526,models,I
3526,above,O
3526,.,O
3527,The,O
3527,performance,O
3527,of,O
3527,our,B
3527,model,I
3527,achieves,B
3527,89.6,B
3527,%,I
3527,on,B
3527,SNLI,B
3527,",",O
3527,80.3,B
3527,%,O
3527,on,O
3527,matched,B
3527,MultiNLI,I
3527,and,O
3527,79.4,B
3527,%,O
3527,on,O
3527,mismatched,B
3527,MultiNLI,O
3527,",",O
3527,which,O
3527,are,O
3527,all,B
3527,state,I
3527,-,I
3527,of,O
3527,-,O
3527,the,O
3527,-,O
3527,art,O
3527,results,O
3527,.,O
3528,The,O
3528,BoW,O
3528,model,O
3528,is,O
3528,trained,B
3528,on,I
3528,spans,B
3528,up,B
3528,to,I
3528,length,I
3528,10,B
3528,to,O
3528,keep,O
3528,the,O
3528,computation,O
3528,tractable,O
3528,.,O
3529,As,B
3529,pre-processing,B
3529,steps,I
3529,we,O
3529,lowercase,B
3529,all,B
3529,inputs,I
3529,and,O
3529,tokenize,B
3529,it,O
3529,using,B
3529,spacy,B
3529,4,O
3529,.,O
3530,The,O
3530,binary,B
3530,word,I
3530,in,B
3530,question,B
3530,feature,I
3530,is,O
3530,computed,B
3530,on,I
3530,lemmas,B
3530,provided,B
3530,by,I
3530,spacy,B
3530,and,O
3530,restricted,B
3530,to,I
3530,alphanumeric,B
3530,words,I
3530,that,O
3530,are,B
3530,not,I
3530,stopwords,B
3530,.,O
3531,For,B
3531,both,B
3531,tasks,I
3531,",",O
3531,our,B
3531,model,I
3531,'s,I
3531,Precision,I
3531,is,O
3531,close,B
3531,to,I
3531,and,O
3531,Recall,B
3531,is,O
3531,significantly,B
3531,higher,I
3531,than,B
3531,previous,B
3531,works,I
3531,.,O
3532,From,O
3532,",",O
3532,we,O
3532,observe,B
3532,that,I
3532,IMN,B
3532,?d,I
3532,is,O
3532,able,B
3532,to,I
3532,significantly,B
3532,outperform,I
3532,other,B
3532,baselines,B
3532,on,B
3532,F1,B
3532,-,O
3532,I,O
3532,.,O
3533,Throughout,O
3533,all,B
3533,experiments,O
3533,we,O
3533,use,B
3533,a,O
3533,hidden,B
3533,dimensionality,I
3533,of,B
3533,n,B
3533,=,B
3533,150,B
3533,",",O
3533,dropout,B
3533,at,B
3533,the,O
3533,input,B
3533,embeddings,I
3533,with,B
3533,the,O
3533,same,B
3533,mask,I
3533,for,B
3533,all,O
3533,words,O
3533,and,O
3533,a,O
3533,rate,B
3533,of,O
3533,0.2,B
3533,and,O
3533,300,B
3533,-,I
3533,dimensional,I
3533,fixed,B
3533,word,I
3533,-,O
3533,embeddings,O
3533,from,B
3533,Glove,B
3533,.,O
3534,We,O
3534,employed,B
3534,ADAM,B
3534,for,B
3534,optimization,B
3534,with,B
3534,an,O
3534,initial,B
3534,learning,I
3534,-,I
3534,rate,I
3534,of,B
3534,10,B
3534,?3,I
3534,which,O
3534,was,O
3534,halved,O
3534,whenever,O
3534,the,O
3534,F,O
3534,1,O
3534,measure,O
3534,on,O
3534,the,O
3534,development,O
3534,set,O
3534,dropped,O
3534,between,O
3534,epochs,O
3534,.,O
3535,We,O
3535,used,B
3535,mini-batches,B
3535,of,B
3535,size,B
3535,32,B
3535,.,O
3536,FastQA,B
3537,We,O
3537,tokenize,B
3537,the,O
3537,input,B
3537,on,B
3537,whitespaces,B
3537,(,O
3537,exclusive,O
3537,),O
3537,and,O
3537,non-alphanumeric,B
3537,characters,I
3537,(,O
3537,inclusive,O
3537,),O
3537,.,O
3538,The,O
3538,binary,B
3538,word,I
3538,in,I
3538,question,B
3538,feature,I
3538,is,O
3538,computed,B
3538,on,I
3538,the,O
3538,words,B
3538,as,O
3538,they,O
3538,appear,B
3538,in,O
3538,context,B
3538,.,O
3539,Throughout,O
3539,all,B
3539,experiments,O
3539,we,O
3539,use,B
3539,a,O
3539,hidden,B
3539,dimensionality,I
3539,of,B
3539,n,B
3539,=,B
3539,300,B
3539,",",O
3539,variational,B
3539,dropout,I
3539,at,B
3539,the,O
3539,input,B
3539,embeddings,I
3539,with,B
3539,the,O
3539,same,B
3539,mask,I
3539,for,B
3539,all,O
3539,words,O
3539,and,O
3539,a,O
3539,rate,B
3539,of,O
3539,0.5,B
3539,and,O
3539,300,O
3539,dimensional,O
3539,fixed,B
3539,word,I
3539,-,I
3539,embeddings,O
3539,from,B
3539,Glove,B
3539,.,O
3540,We,O
3540,employed,B
3540,ADAM,B
3540,for,B
3540,optimization,B
3540,with,B
3540,an,O
3540,initial,B
3540,learning,I
3540,-,I
3540,rate,I
3540,of,B
3540,10,B
3540,?3,I
3540,which,O
3540,was,O
3540,halved,O
3540,whenever,O
3540,the,O
3540,F,O
3540,1,O
3540,measure,O
3540,on,O
3540,the,O
3540,development,O
3540,set,O
3540,dropped,O
3540,between,O
3540,checkpoints,O
3540,.,O
3541,In,O
3541,particular,O
3541,",",O
3541,we,O
3541,develop,B
3541,a,O
3541,simple,O
3541,neural,O
3541,",",O
3541,bag,O
3541,-,O
3541,of,O
3541,-,O
3541,words,O
3541,(,O
3541,BoW,O
3541,),O
3541,-,O
3541,and,O
3541,a,O
3541,recurrent,B
3541,neural,O
3541,network,O
3541,(,O
3541,RNN,O
3541,),O
3541,baseline,O
3541,",",O
3541,namely,B
3541,FastQA,B
3541,.,O
3542,Crucially,O
3542,",",O
3542,both,O
3542,models,O
3542,do,O
3542,not,O
3542,make,O
3542,use,O
3542,of,O
3542,a,O
3542,complex,O
3542,interaction,B
3542,layer,O
3542,but,O
3542,model,B
3542,interaction,O
3542,between,B
3542,question,B
3542,and,I
3542,context,I
3542,only,O
3542,through,B
3542,computable,B
3542,features,I
3542,on,B
3542,the,O
3542,word,B
3542,level,I
3542,.,O
3543,IMN,B
3543,further,O
3543,boosts,B
3543,the,O
3543,performance,B
3543,and,I
3543,outperforms,B
3543,the,O
3543,best,B
3543,F1,I
3543,-,O
3543,I,O
3543,results,O
3543,from,B
3543,the,O
3543,baselines,B
3543,by,B
3543,2.29,B
3543,%,I
3543,",",I
3543,1.77,I
3543,%,O
3543,",",O
3543,and,O
3543,2.61,O
3543,%,O
3543,on,B
3543,D1,B
3543,",",O
3543,D2,O
3543,",",O
3543,and,O
3543,D3,O
3543,.,O
3544,Making,O
3544,Neural,B
3544,QA,I
3544,as,O
3544,Simple,O
3544,as,O
3544,Possible,O
3544,but,O
3544,not,O
3544,Simpler,O
3545,Recent,O
3545,development,O
3545,of,O
3545,large,O
3545,-,O
3545,scale,O
3545,question,B
3545,answering,I
3545,(,I
3545,QA,B
3545,),I
3545,datasets,O
3545,triggered,O
3545,a,O
3545,substantial,O
3545,amount,O
3545,of,O
3545,research,O
3545,into,O
3545,end,O
3545,-,O
3545,toend,O
3545,neural,O
3545,architectures,O
3545,for,O
3545,QA,O
3545,.,O
3546,Our,O
3546,neural,B
3546,BoW,I
3546,baseline,I
3546,achieves,B
3546,good,B
3546,results,I
3546,on,O
3546,both,O
3546,datasets,O
3546,(,O
3546,Tables,O
3546,3,O
3546,and,O
3546,1,O
3546,),O
3546,5,O
3546,.,O
3547,For,O
3547,instance,O
3547,",",O
3547,it,O
3547,outperforms,B
3547,a,O
3547,feature,B
3547,rich,I
3547,logistic,I
3547,-,I
3547,regression,I
3547,baseline,I
3547,on,B
3547,the,O
3547,SQuAD,B
3547,development,I
3547,set,I
3547,and,O
3547,nearly,B
3547,reaches,I
3547,the,O
3547,BiLSTM,B
3547,baseline,O
3547,system,O
3547,(,O
3547,i.e.,O
3548,It,O
3548,is,O
3548,very,B
3548,competitive,I
3548,to,B
3548,previously,B
3548,established,I
3548,stateof,I
3548,-,I
3548,the,I
3548,-,O
3548,art,O
3548,results,O
3548,on,O
3548,the,O
3548,two,O
3548,datasets,O
3548,and,O
3548,even,O
3548,improves,B
3548,those,O
3548,for,B
3548,News,B
3548,QA,I
3548,.,O
3549,In,O
3549,this,O
3549,work,O
3549,we,O
3549,propose,B
3549,the,O
3549,Key,B
3549,-,I
3549,Value,I
3549,Memory,I
3549,Network,I
3549,(,I
3549,KV,I
3549,-,O
3549,MemNN,O
3549,),O
3549,",",O
3549,a,O
3549,new,B
3549,neural,I
3549,network,O
3549,architecture,O
3549,that,O
3549,generalizes,B
3549,the,O
3549,original,B
3549,Memory,O
3549,Network,O
3549,and,O
3549,can,O
3549,work,O
3549,with,O
3549,either,O
3549,knowledge,O
3549,source,O
3549,.,O
3550,The,O
3550,KV,B
3550,-,I
3550,MemNN,I
3550,performs,B
3550,QA,B
3550,by,O
3550,first,O
3550,storing,B
3550,facts,B
3550,in,B
3550,a,O
3550,key,O
3550,-,O
3550,value,B
3550,structured,I
3550,memory,I
3550,before,O
3550,reasoning,O
3550,on,O
3550,them,O
3550,in,O
3550,order,O
3550,to,O
3550,predict,O
3550,an,O
3550,answer,O
3550,.,O
3551,The,O
3551,memory,B
3551,is,B
3551,designed,B
3551,so,O
3551,that,O
3551,the,O
3551,model,O
3551,learns,O
3551,to,O
3551,use,O
3551,keys,B
3551,to,O
3551,address,O
3551,relevant,B
3551,memories,I
3551,with,B
3551,respect,I
3551,to,O
3551,the,O
3551,question,B
3551,",",O
3551,whose,O
3551,corresponding,O
3551,values,O
3551,are,O
3551,subsequently,O
3551,returned,O
3551,.,O
3552,This,O
3552,structure,O
3552,allows,O
3552,the,O
3552,model,O
3552,to,B
3552,encode,B
3552,prior,B
3552,knowledge,I
3552,for,O
3552,the,O
3552,considered,O
3552,task,O
3552,and,O
3552,to,O
3552,leverage,O
3552,possibly,O
3552,complex,B
3552,transforms,I
3552,between,B
3552,keys,B
3552,and,O
3552,values,O
3552,",",O
3552,while,O
3552,still,O
3552,being,O
3552,trained,O
3552,using,O
3552,standard,O
3552,backpropagation,O
3552,via,O
3552,stochastic,O
3552,gradient,O
3552,descent,O
3552,.,O
3553,IMN,B
3553,wo,O
3553,DE,O
3553,performs,B
3553,only,B
3553,marginally,I
3553,below,B
3553,IMN,O
3553,.,O
3554,To,O
3554,avoid,O
3554,its,O
3554,inherent,O
3554,difficulty,O
3554,",",O
3554,question,B
3554,answering,I
3554,(,I
3554,QA,I
3554,),I
3554,has,O
3554,been,O
3554,directed,O
3554,towards,O
3554,using,O
3554,Knowledge,O
3554,Bases,O
3554,(,O
3554,KBs,O
3554,),O
3554,instead,O
3554,",",O
3554,which,O
3554,has,O
3554,proven,O
3554,effective,O
3554,.,O
3555,To,O
3555,compare,O
3555,using,O
3555,KBs,O
3555,",",O
3555,information,O
3555,extraction,O
3555,or,O
3555,Wikipedia,O
3555,documents,O
3555,directly,O
3555,in,O
3555,a,O
3555,single,O
3555,framework,O
3555,we,O
3555,construct,O
3555,an,O
3555,analysis,O
3555,tool,O
3555,",",O
3555,WIKIMOVIES,O
3555,",",O
3555,a,O
3555,QA,B
3555,dataset,O
3555,that,O
3555,contains,O
3555,raw,O
3555,text,O
3555,alongside,O
3555,a,O
3555,preprocessed,O
3555,KB,O
3555,",",O
3555,in,O
3555,the,O
3555,domain,O
3555,of,O
3555,movies,O
3555,.,O
3556,WikiMovies,B
3557,However,O
3557,",",O
3557,Key,B
3557,-,I
3557,Value,I
3557,Memory,I
3557,Networks,I
3557,outperform,B
3557,all,B
3557,other,I
3557,methods,I
3557,on,O
3557,all,O
3557,three,O
3557,data,O
3557,source,O
3557,types,O
3557,.,O
3558,Reading,B
3558,from,B
3558,Wikipedia,B
3558,documents,I
3558,directly,O
3558,(,O
3558,Doc,O
3558,),O
3558,outperforms,B
3558,an,O
3558,IE,O
3558,-,O
3558,based,O
3558,KB,O
3558,(,O
3558,IE,O
3558,),O
3558,",",O
3558,which,O
3558,is,O
3558,an,O
3558,encouraging,O
3558,result,O
3558,towards,O
3558,automated,O
3558,machine,O
3558,reading,O
3558,though,O
3558,a,O
3558,gap,O
3558,to,O
3558,a,O
3558,humanannotated,O
3558,KB,O
3558,still,O
3558,remains,O
3558,(,O
3558,93.9,O
3558,vs.,O
3558,76.2,O
3558,),O
3558,.,O
3559,WikiQA,B
3560,Key,O
3560,-,O
3560,Value,O
3560,Memory,O
3560,Networks,O
3560,outperform,B
3560,a,O
3560,large,B
3560,set,I
3560,of,I
3560,other,I
3560,methods,I
3560,",",O
3560,although,O
3560,the,O
3560,results,O
3560,of,O
3560,the,O
3560,L.D.C.,O
3561,The,O
3561,full,O
3561,dataset,O
3561,is,O
3561,available,O
3561,at,O
3561,https://github.com/Websail-NU,B
3561,/CODAH,I
3561,.,O
3562,In,O
3562,this,O
3562,work,O
3562,",",O
3562,we,O
3562,introduce,B
3562,the,O
3562,COmmonsense,B
3562,Dataset,I
3562,Adversarially,I
3562,-,I
3562,authored,I
3562,by,I
3562,Humans,I
3562,(,I
3562,CODAH,I
3562,),I
3562,for,B
3562,commonsense,O
3562,question,O
3562,answering,O
3562,in,O
3562,the,O
3562,style,O
3562,of,O
3562,SWAG,B
3562,multiple,I
3562,choice,I
3562,sentence,I
3562,completion,I
3562,.,O
3563,IMN,O
3563,?d,O
3563,is,O
3563,more,B
3563,affected,I
3563,without,I
3563,domain,B
3563,-,I
3563,specific,I
3563,embeddings,I
3563,",",O
3563,while,O
3563,it,O
3563,still,O
3563,outperforms,B
3563,all,B
3563,other,I
3563,baselines,I
3563,except,B
3563,DECNN,B
3563,-,O
3563,d,O
3563,Trans,O
3563,.,O
3564,Also,O
3564,",",O
3564,when,B
3564,training,I
3564,the,O
3564,initial,B
3564,SWAG,I
3564,model,I
3564,we,O
3564,use,B
3564,the,O
3564,hyperparameters,B
3564,recommended,B
3564,in,I
3564,the,O
3564,BERT,B
3564,paper,I
3564,",",O
3564,namely,B
3564,a,O
3564,batch,B
3564,size,I
3564,of,B
3564,16,B
3564,",",O
3564,learning,B
3564,rate,I
3564,of,O
3564,2,B
3564,e,I
3564,-,I
3564,5,I
3564,",",O
3564,and,O
3564,3,B
3564,epochs,B
3564,.,O
3565,In,B
3565,our,O
3565,initial,O
3565,experiments,O
3565,",",O
3565,we,O
3565,found,O
3565,that,O
3565,a,O
3565,lower,O
3565,learning,O
3565,rate,O
3565,and,O
3565,more,O
3565,training,O
3565,epochs,O
3565,produced,O
3565,higher,O
3565,accuracy,O
3565,on,O
3565,CODAH,O
3565,",",O
3565,so,O
3565,we,O
3565,replaced,B
3565,the,O
3565,5e,B
3565,-,I
3565,5,I
3565,learning,O
3565,rate,O
3565,in,O
3565,the,O
3565,original,B
3565,grid,I
3565,search,I
3565,with,B
3565,1,B
3565,e,I
3565,-,O
3565,5,O
3565,",",O
3565,and,O
3565,we,O
3565,added,B
3565,a,O
3565,6,B
3565,-,O
3565,epoch,O
3565,setting,O
3565,.,O
3566,The,O
3566,final,B
3566,hyperparameter,I
3566,grid,I
3566,is,O
3566,as,O
3566,follows,O
3566,:,O
3567,Batch,O
3567,size,O
3567,:,O
3567,16,B
3567,",",I
3567,32,I
3567,Learning,B
3567,rate,I
3567,:,O
3567,1,B
3567,e,I
3567,-,I
3567,5,I
3567,",",O
3567,2,O
3567,e,O
3567,-,O
3567,5,O
3567,",",O
3567,3,B
3567,e,O
3567,-,O
3567,5,O
3567,Number,B
3567,of,I
3567,epochs,I
3567,:,O
3567,3,O
3567,",",O
3567,4,O
3567,",",O
3567,6,O
3567,In,O
3567,addition,O
3567,",",O
3567,we,O
3567,observed,O
3567,that,O
3567,in,O
3567,rare,O
3567,cases,O
3567,BERT,O
3567,fails,O
3567,to,O
3567,train,O
3567,;,O
3567,that,O
3567,is,O
3567,",",O
3567,after,O
3567,several,O
3567,training,O
3567,epochs,O
3567,it,O
3567,has,O
3567,accuracy,O
3567,approximately,O
3567,equal,O
3567,to,O
3567,that,O
3567,of,O
3567,random,O
3567,guessing,O
3567,.,O
3568,We,O
3568,propose,B
3568,a,O
3568,novel,B
3568,method,I
3568,for,B
3568,question,I
3568,generation,I
3568,",",O
3568,in,B
3568,which,I
3568,human,B
3568,annotators,I
3568,are,O
3568,educated,B
3568,on,I
3568,the,I
3568,workings,B
3568,of,I
3568,a,O
3568,state,B
3568,-,I
3568,of,O
3568,-,O
3568,the,O
3568,-,O
3568,art,O
3568,question,O
3568,answering,O
3568,model,O
3568,",",O
3568,and,O
3568,are,O
3568,asked,B
3568,to,I
3568,submit,B
3568,questions,B
3568,that,O
3568,adversarially,B
3568,target,I
3568,the,O
3568,weaknesses,B
3568,.,O
3569,Annotators,B
3569,are,O
3569,rewarded,B
3569,for,I
3569,submissions,B
3569,in,B
3569,which,I
3569,the,I
3569,model,B
3569,fails,B
3569,to,B
3569,identify,I
3569,the,O
3569,correct,B
3569,sentence,I
3569,completion,I
3569,both,O
3569,before,B
3569,and,I
3569,after,I
3569,fine,B
3569,-,I
3569,tuning,I
3569,on,B
3569,a,O
3569,sample,B
3569,of,I
3569,the,O
3569,submitted,O
3569,questions,O
3569,",",O
3569,encouraging,O
3569,the,O
3569,creation,O
3569,of,O
3569,questions,O
3569,that,O
3569,are,O
3569,not,O
3569,easily,O
3569,learnable,O
3569,.,O
3570,CODAH,O
3570,:,O
3570,An,O
3570,Adversarially,O
3570,-,O
3570,Authored,O
3570,Question,B
3570,Answering,I
3570,Dataset,O
3570,for,O
3570,Common,O
3570,Sense,O
3571,The,O
3571,rise,O
3571,of,O
3571,datadriven,O
3571,methods,O
3571,has,O
3571,led,O
3571,to,O
3571,interest,O
3571,in,O
3571,developing,O
3571,large,O
3571,datasets,O
3571,for,O
3571,commonsense,B
3571,reasoning,I
3571,over,I
3571,text,I
3571,.,O
3572,In,O
3572,this,O
3572,work,O
3572,",",O
3572,we,O
3572,introduce,O
3572,the,O
3572,COmmonsense,B
3572,Dataset,O
3572,Adversarially,O
3572,-,O
3572,authored,O
3572,by,O
3572,Humans,O
3572,(,O
3572,CODAH,O
3572,),O
3572,for,O
3572,commonsense,O
3572,question,O
3572,answering,O
3572,in,O
3572,the,O
3572,style,O
3572,of,O
3572,SWAG,O
3572,multiple,O
3572,choice,O
3572,sentence,O
3572,completion,O
3572,.,O
3573,DECNN,O
3573,-,O
3573,dTrans,O
3573,is,B
3573,a,O
3573,very,B
3573,strong,I
3573,baseline,I
3573,as,O
3573,it,O
3573,exploits,B
3573,additional,B
3573,knowledge,I
3573,from,B
3573,larger,B
3573,corpora,I
3573,for,B
3573,both,B
3573,tasks,I
3573,.,O
3574,As,B
3574,a,O
3574,baseline,B
3574,",",O
3574,we,O
3574,evaluate,B
3574,both,B
3574,models,I
3574,on,B
3574,the,O
3574,full,B
3574,SWAG,I
3574,training,I
3574,and,I
3574,validation,I
3574,sets,I
3574,",",O
3574,providing,B
3574,an,O
3574,accuracy,B
3574,of,B
3574,84.2,B
3574,%,I
3574,on,O
3574,BERT,B
3574,and,O
3574,80.2,B
3574,%,O
3574,on,O
3574,GPT,B
3574,.,O
3575,To,O
3575,adjust,O
3575,for,O
3575,the,O
3575,difference,O
3575,in,O
3575,size,O
3575,between,O
3575,our,O
3575,dataset,O
3575,and,O
3575,SWAG,O
3575,",",O
3575,we,O
3575,also,O
3575,train,B
3575,the,O
3575,models,B
3575,on,B
3575,a,O
3575,sample,B
3575,of,B
3575,"2,241",B
3575,SWAG,O
3575,questions,O
3575,(,O
3575,the,O
3575,size,O
3575,of,O
3575,the,O
3575,training,O
3575,set,O
3575,in,O
3575,each,O
3575,of,O
3575,CODAH,O
3575,'s,O
3575,crossvalidation,O
3575,folds,O
3575,),O
3575,and,O
3575,evaluate,B
3575,them,O
3575,on,O
3575,the,O
3575,full,B
3575,SWAG,O
3575,validation,O
3575,set,O
3575,.,O
3576,This,O
3576,produces,B
3576,an,O
3576,accuracy,B
3576,of,B
3576,75.2,B
3576,%,I
3576,for,B
3576,BERT,B
3576,(,O
3576,using,O
3576,the,O
3576,cross-validation,O
3576,grid,O
3576,search,O
3576,),O
3576,and,O
3576,63.6,B
3576,%,O
3576,for,O
3576,GPT,B
3576,.,O
3577,We,O
3577,tokenize,B
3577,the,O
3577,corpora,B
3577,with,B
3577,NLTK,B
3577,2,O
3577,.,O
3578,We,O
3578,use,B
3578,the,O
3578,300,B
3578,dimension,I
3578,pre-trained,B
3578,word,I
3578,vectors,I
3578,from,B
3578,GloVe,B
3578,(,O
3578,Pennington,O
3578,",",O
3578,Socher,O
3578,",",O
3578,and,O
3578,Manning,O
3578,2014,O
3578,),O
3578,and,O
3578,we,O
3578,do,O
3578,not,O
3578,update,O
3578,them,O
3578,during,O
3578,training,O
3578,.,O
3579,We,O
3579,use,O
3579,50,B
3579,-,I
3579,dimension,I
3579,character,B
3579,-,O
3579,level,O
3579,embedding,O
3579,vectors,O
3579,.,O
3580,We,O
3580,use,O
3580,dropout,B
3580,),O
3580,with,B
3580,probability,B
3580,0.3,I
3580,for,B
3580,every,B
3580,learnable,I
3580,layer,I
3580,.,O
3581,We,O
3581,use,O
3581,the,O
3581,Adam,B
3581,optimizer,I
3581,with,B
3581,learning,B
3581,rate,I
3581,of,B
3581,0.001,B
3581,and,O
3581,clipnorm,B
3581,of,O
3581,5,B
3581,.,O
3582,The,O
3582,out,B
3582,-,I
3582,of,I
3582,-,O
3582,vocabulary,O
3582,words,O
3582,are,O
3582,initialized,B
3582,with,I
3582,zero,B
3582,vectors,I
3582,.,O
3583,The,O
3583,number,B
3583,of,I
3583,hidden,I
3583,units,I
3583,in,B
3583,all,B
3583,the,O
3583,LSTMs,O
3583,is,B
3583,150,B
3583,.,O
3584,IMN,O
3584,?d,O
3584,wo,O
3584,DE,O
3584,is,O
3584,competitive,B
3584,with,I
3584,DECNN,B
3584,-,I
3584,dTrans,I
3584,even,O
3584,without,O
3584,utilizing,O
3584,additional,O
3584,knowledge,O
3584,",",O
3584,which,O
3584,suggests,O
3584,the,O
3584,effectiveness,O
3584,of,O
3584,the,O
3584,proposed,O
3584,network,O
3584,structure,O
3584,.,O
3585,For,B
3585,multi-factor,B
3585,attentive,I
3585,encoding,I
3585,",",O
3585,we,O
3585,choose,B
3585,4,B
3585,factors,I
3585,(,O
3585,m,O
3585,),O
3585,based,O
3585,on,O
3585,our,O
3585,experimental,O
3585,findings,O
3585,(,O
3585,refer,O
3585,to,O
3585,),O
3585,.,O
3586,During,B
3586,training,B
3586,",",O
3586,the,O
3586,minibatch,B
3586,size,I
3586,is,O
3586,fixed,B
3586,at,I
3586,60,B
3586,.,O
3587,In,O
3587,this,O
3587,work,O
3587,",",O
3587,we,O
3587,propose,B
3587,an,O
3587,end,O
3587,-,O
3587,to,B
3587,-,O
3587,end,O
3587,question,O
3587,-,O
3587,focused,O
3587,multi-factor,O
3587,attention,O
3587,network,O
3587,for,B
3587,document,B
3587,-,O
3587,based,O
3587,question,O
3587,answering,O
3587,(,O
3587,AMANDA,B
3587,),O
3587,",",O
3587,which,O
3587,learns,B
3587,to,O
3587,aggregate,B
3587,evidence,B
3587,distributed,B
3587,across,I
3587,multiple,B
3587,sentences,I
3587,and,O
3587,identifies,B
3587,the,O
3587,important,B
3587,question,O
3587,words,O
3587,to,O
3587,help,O
3587,extract,B
3587,the,O
3587,answer,B
3587,.,O
3588,Intuitively,O
3588,",",O
3588,AMANDA,B
3588,extracts,B
3588,the,O
3588,answer,O
3588,not,O
3588,only,O
3588,by,B
3588,synthesizing,I
3588,relevant,B
3588,facts,I
3588,from,B
3588,the,O
3588,passage,B
3588,but,O
3588,also,O
3588,by,O
3588,implicitly,O
3588,determining,O
3588,the,O
3588,suitable,B
3588,answer,O
3588,type,O
3588,during,B
3588,prediction,B
3588,.,O
3589,A,O
3589,Question,B
3589,-,O
3589,Focused,O
3589,Multi-,O
3589,Factor,O
3589,Attention,O
3589,Network,O
3589,for,O
3589,Question,O
3589,Answering,O
3590,Neural,O
3590,network,O
3590,models,O
3590,recently,O
3590,proposed,O
3590,for,O
3590,question,B
3590,answering,I
3590,(,I
3590,QA,I
3590,),I
3590,primarily,O
3590,focus,O
3590,on,O
3590,capturing,O
3590,the,O
3590,passagequestion,O
3590,relation,O
3590,.,O
3591,They,O
3591,also,O
3591,do,O
3591,not,O
3591,explicitly,O
3591,focus,O
3591,on,O
3591,the,O
3591,question,O
3591,and,O
3591,answer,O
3591,type,O
3591,which,O
3591,often,O
3591,plays,O
3591,a,O
3591,critical,O
3591,role,O
3591,in,O
3591,QA,B
3591,.,O
3592,In,O
3592,machine,B
3592,comprehension,I
3592,-,I
3592,based,I
3592,(,I
3592,MC,I
3592,),I
3592,question,I
3592,answering,I
3592,(,O
3592,QA,O
3592,),O
3592,",",O
3592,a,O
3592,machine,O
3592,is,O
3592,expected,O
3592,to,O
3592,provide,O
3592,an,O
3592,answer,O
3592,for,O
3592,a,O
3592,given,O
3592,question,O
3592,by,O
3592,understanding,O
3592,texts,O
3592,.,O
3593,shows,O
3593,that,O
3593,AMANDA,B
3593,outperforms,B
3593,all,B
3593,the,I
3593,stateof,I
3593,-,I
3593,the,O
3593,-,O
3593,art,O
3593,models,O
3593,by,B
3593,a,O
3593,significant,B
3593,margin,I
3593,on,B
3593,the,O
3593,New,B
3593,s,I
3593,QA,I
3593,dataset,I
3593,.,O
3594,shows,B
3594,the,O
3594,results,B
3594,on,B
3594,the,O
3594,TriviaQA,B
3594,dataset,I
3594,.,O
3595,Specifically,O
3595,",",O
3595,for,B
3595,AE,B
3595,(,I
3595,F1,I
3595,-,I
3595,a,I
3595,and,I
3595,F1,O
3595,-,O
3595,o,O
3595,),O
3595,",",O
3595,IMN,B
3595,?d,I
3595,performs,B
3595,the,O
3595,best,B
3595,in,B
3595,most,B
3595,cases,I
3595,.,O
3596,shows,B
3596,that,O
3596,AMANDA,B
3596,achieves,B
3596,state,B
3596,-,I
3596,of,I
3596,the,I
3596,-,O
3596,art,O
3596,results,O
3596,in,B
3596,both,O
3596,Wikipedia,B
3596,and,I
3596,Web,I
3596,domain,I
3596,on,B
3596,distantly,B
3596,supervised,I
3596,and,O
3596,verified,O
3596,data,O
3596,.,O
3597,Results,O
3597,on,B
3597,the,O
3597,Search,B
3597,QA,I
3597,dataset,I
3597,are,O
3597,shown,O
3597,in,O
3597,.,O
3598,AMANDA,B
3598,outperforms,B
3598,both,B
3598,systems,I
3598,",",O
3598,especially,B
3598,for,I
3598,multi-word,B
3598,-,I
3598,answer,I
3598,questions,I
3598,by,B
3598,a,O
3598,huge,B
3598,margin,I
3598,.,O
3599,shows,O
3599,that,O
3599,AMANDA,O
3599,performs,B
3599,better,B
3599,than,B
3599,any,B
3599,of,B
3599,the,I
3599,ablated,I
3599,models,I
3599,which,O
3599,include,B
3599,the,O
3599,ablation,B
3599,of,O
3599,multifactor,B
3599,attentive,I
3599,encoding,I
3599,",",O
3599,max,B
3599,-,I
3599,attentional,I
3599,question,B
3599,aggregation,I
3599,(,I
3599,q,I
3599,ma,I
3599,),I
3599,",",O
3599,and,O
3599,question,O
3599,type,O
3599,representation,O
3599,(,O
3599,q,O
3599,f,O
3599,),O
3599,.,O
3600,We,O
3600,use,B
3600,pre-trained,B
3600,GloVe,I
3600,embeddings,I
3600,of,B
3600,dimension,I
3600,d,I
3600,w,B
3600,=,I
3600,300,I
3600,and,O
3600,produce,B
3600,character,B
3600,-,I
3600,based,I
3600,word,I
3600,representations,I
3600,via,B
3600,dc,B
3600,=,O
3600,100,O
3600,convolutional,B
3600,filters,I
3600,over,B
3600,character,O
3600,embeddings,O
3600,as,O
3600,in,O
3600,.,O
3601,To,O
3601,illustrate,O
3601,this,O
3601,idea,O
3601,",",O
3601,we,O
3601,take,B
3601,a,O
3601,model,B
3601,that,B
3601,carries,B
3601,out,I
3601,only,B
3601,basic,I
3601,question,I
3601,-,I
3601,document,I
3601,interaction,I
3601,and,I
3601,prepend,O
3601,to,O
3601,it,O
3601,a,O
3601,module,B
3601,that,O
3601,produces,O
3601,token,B
3601,embeddings,I
3601,by,B
3601,explicitly,B
3601,gating,I
3601,between,B
3601,contextual,B
3601,and,O
3601,non-contextual,O
3601,representations,O
3601,(,O
3601,for,O
3601,both,O
3601,the,O
3601,document,O
3601,and,O
3601,question,O
3601,),O
3601,.,O
3602,Motivated,O
3602,by,O
3602,these,O
3602,findings,O
3602,",",O
3602,we,O
3602,turn,B
3602,to,I
3602,a,O
3602,semisupervised,B
3602,setting,I
3602,in,O
3602,which,O
3602,we,O
3602,leverage,B
3602,a,O
3602,language,B
3602,model,I
3602,",",O
3602,pre-trained,B
3602,on,I
3602,large,B
3602,amounts,I
3602,of,I
3602,data,I
3602,",",O
3602,as,B
3602,a,O
3602,sequence,B
3602,encoder,I
3602,which,O
3602,forcibly,B
3602,facilitates,I
3602,context,B
3602,utilization,I
3602,.,O
3603,Contextualized,O
3603,Word,O
3603,Representations,O
3603,for,O
3603,Reading,B
3603,Comprehension,I
3604,RC,B
3604,has,O
3604,attracted,O
3604,substantial,O
3604,attention,O
3604,over,O
3604,the,O
3604,last,O
3604,few,O
3604,years,O
3604,with,O
3604,the,O
3604,advent,O
3604,of,O
3604,large,O
3604,annotated,O
3604,datasets,O
3604,",",O
3604,computing,O
3604,resources,O
3604,",",O
3604,and,O
3604,neural,O
3604,network,O
3604,models,O
3604,and,O
3604,optimization,O
3604,procedures,O
3604,.,O
3605,For,B
3605,AS,B
3605,(,I
3605,acc,I
3605,-,I
3605,s,I
3605,and,I
3605,F1,I
3605,-,O
3605,s,O
3605,),O
3605,",",O
3605,IMN,B
3605,outperforms,B
3605,other,B
3605,methods,I
3605,by,B
3605,large,B
3605,margins,I
3605,.,O
3606,In,O
3606,we,O
3606,compare,O
3606,these,O
3606,two,O
3606,variants,O
3606,over,O
3606,the,O
3606,development,O
3606,set,O
3606,and,O
3606,observe,B
3606,superior,B
3606,performance,I
3606,by,B
3606,the,O
3606,contextual,B
3606,one,I
3606,",",O
3606,illustrating,B
3606,the,O
3606,benefit,B
3606,of,B
3606,contextualization,B
3606,and,O
3606,specifically,O
3606,per-sequence,O
3606,contextualization,O
3606,which,O
3606,is,O
3606,done,O
3606,separately,O
3606,for,O
3606,the,O
3606,question,O
3606,and,O
3606,for,O
3606,the,O
3606,passage,O
3606,.,O
3607,On,O
3607,average,O
3607,",",O
3607,the,O
3607,less,B
3607,frequent,I
3607,a,O
3607,word,B
3607,-,I
3607,type,I
3607,is,B
3607,",",O
3607,the,O
3607,smaller,B
3607,are,B
3607,its,O
3607,gate,B
3607,activations,I
3607,",",O
3607,i.e.,O
3608,Besides,O
3608,a,O
3608,crosscutting,O
3608,boost,O
3608,in,O
3608,results,O
3608,",",O
3608,we,O
3608,note,O
3608,that,O
3608,the,O
3608,performance,B
3608,due,B
3608,to,I
3608,utilizing,B
3608,the,O
3608,LM,B
3608,hidden,I
3608,states,I
3608,of,B
3608,the,O
3608,first,B
3608,LSTM,I
3608,layer,I
3608,significantly,B
3608,surpasses,I
3608,the,O
3608,other,B
3608,two,I
3608,variants,I
3608,.,O
3609,Supplementing,B
3609,the,O
3609,calculation,B
3609,of,B
3609,token,B
3609,reembeddings,I
3609,with,B
3609,the,O
3609,hidden,B
3609,states,I
3609,of,O
3609,a,O
3609,strong,B
3609,language,I
3609,model,I
3609,proves,B
3609,to,I
3609,be,I
3609,highly,B
3609,effective,I
3609,.,O
3610,Overall,O
3610,",",O
3610,we,O
3610,observe,B
3610,a,O
3610,significant,B
3610,improvement,I
3610,with,B
3610,all,O
3610,three,O
3610,configurations,O
3610,",",O
3610,effectively,O
3610,showing,B
3610,the,O
3610,benefit,B
3610,of,B
3610,training,B
3610,a,O
3610,QA,B
3610,model,I
3610,in,B
3610,a,O
3610,semisupervised,B
3610,fashion,I
3610,with,O
3610,a,O
3610,large,B
3610,language,I
3610,model,O
3610,.,O
3611,We,O
3611,use,B
3611,the,O
3611,Adam,B
3611,method,I
3611,for,B
3611,optimization,B
3611,.,O
3612,We,O
3612,use,O
3612,pre-trained,B
3612,300,I
3612,-,I
3612,D,I
3612,Glove,I
3612,840B,I
3612,vectors,I
3612,to,B
3612,initialize,I
3612,word,B
3612,embeddings,I
3612,.,O
3613,e,O
3613,initial,B
3613,learning,I
3613,rate,I
3613,is,B
3613,set,B
3613,to,I
3613,0.0005,B
3613,",",O
3613,and,O
3613,the,O
3613,batch,B
3613,size,I
3613,is,O
3613,128,B
3613,.,O
3614,e,O
3614,dimensions,B
3614,of,B
3614,all,O
3614,hidden,B
3614,states,I
3614,of,O
3614,Bi,B
3614,-,I
3614,aLSTM,I
3614,and,I
3614,word,I
3614,embedding,I
3614,are,B
3614,300,B
3614,.,O
3615,Dropout,O
3615,rate,O
3615,is,O
3615,set,B
3615,to,I
3615,0.2,B
3615,during,B
3615,training,B
3615,.,O
3616,In,B
3616,our,B
3616,d-TBCNN,I
3616,model,I
3616,",",O
3616,the,O
3616,number,B
3616,of,I
3616,units,I
3616,is,B
3616,300,B
3616,for,B
3616,convolution,B
3616,and,O
3616,200,B
3616,for,O
3616,the,O
3616,last,B
3616,hidden,I
3616,layer,I
3616,.,O
3617,Out,O
3617,-,O
3617,of,O
3617,-,O
3617,vocabulary,O
3617,(,O
3617,OOV,O
3617,),O
3617,words,O
3617,are,B
3617,initialized,B
3617,randomly,I
3617,with,B
3617,Gaussian,B
3617,samples,I
3617,.,O
3618,We,O
3618,employ,B
3618,non-linearity,B
3618,function,I
3618,f,I
3618,=,I
3618,selu,I
3618,replacing,B
3618,recti,O
3618,ed,O
3618,linear,B
3618,unit,I
3618,ReLU,I
3618,on,B
3618,account,I
3618,of,I
3618,its,O
3618,faster,B
3618,convergence,I
3618,rate,I
3618,.,O
3619,erefore,O
3619,",",O
3619,in,O
3619,this,O
3619,study,O
3619,",",O
3619,using,B
3619,ESIM,B
3619,model,I
3619,as,B
3619,the,O
3619,baseline,B
3619,",",O
3619,we,O
3619,add,B
3619,an,O
3619,a,B
3619,ention,I
3619,layer,I
3619,behind,B
3619,each,B
3619,Bi,I
3619,-,I
3619,LSTM,I
3619,layer,O
3619,",",O
3619,then,O
3619,use,B
3619,an,O
3619,adaptive,B
3619,orientation,I
3619,embedding,I
3619,layer,O
3619,to,B
3619,jointly,I
3619,represent,I
3619,the,O
3619,forward,B
3619,and,I
3619,backward,I
3619,vectors,I
3619,.,O
3620,We,O
3620,name,O
3620,this,O
3620,a,O
3620,ention,O
3620,boosted,O
3620,Bi,B
3620,-,I
3620,LSTM,I
3620,as,B
3620,Bi,O
3620,-,O
3620,a,O
3620,LSTM,O
3620,",",O
3620,and,O
3620,denote,B
3620,the,O
3620,modi,B
3620,ed,I
3620,ESIM,I
3620,as,O
3620,aESIM,B
3620,.,O
3621,is,O
3621,paper,O
3621,proposes,O
3621,an,O
3621,a,O
3621,ention,O
3621,boosted,O
3621,natural,B
3621,language,I
3621,inference,I
3621,model,O
3621,named,O
3621,a,O
3621,ESIM,O
3621,by,O
3621,adding,O
3621,word,O
3621,a,O
3621,ention,O
3621,and,O
3621,adaptive,O
3621,direction,O
3621,-,O
3621,oriented,O
3621,a,O
3621,ention,O
3621,mechanisms,O
3621,to,O
3621,the,O
3621,traditional,O
3621,Bi,O
3621,-,O
3621,LSTM,O
3621,layer,O
3621,of,O
3621,natural,O
3621,language,O
3621,inference,O
3621,models,O
3621,",",O
3621,e.g.,O
3622,In,O
3622,the,O
3622,literature,O
3622,",",O
3622,the,O
3622,task,O
3622,of,O
3622,NLI,B
3622,is,O
3622,usually,O
3622,viewed,O
3622,as,O
3622,a,O
3622,relation,O
3622,classi,O
3622,cation,O
3622,.,O
3623,According,O
3623,to,O
3623,the,O
3623,results,O
3623,in,O
3623,",",O
3623,a,O
3623,ESIM,B
3623,model,I
3623,achieved,B
3623,88.1,B
3623,%,I
3623,on,B
3623,SNLI,B
3623,corpus,I
3623,",",O
3623,elevating,B
3623,0.8,I
3623,percent,I
3623,higher,B
3623,than,I
3623,ESIM,O
3623,model,O
3623,.,O
3624,It,O
3624,promoted,B
3624,almost,B
3624,0.5,I
3624,percent,I
3624,accuracy,I
3624,and,O
3624,outperformed,B
3624,the,O
3624,baselines,B
3624,on,B
3624,MultiNLI,B
3624,.,O
3625,After,O
3625,removing,O
3625,the,O
3625,exact,B
3625,match,I
3625,binary,I
3625,feature,I
3625,",",O
3625,we,O
3625,find,B
3625,the,O
3625,performance,B
3625,degrade,B
3625,to,B
3625,78.2,B
3625,on,B
3625,matched,B
3625,score,I
3625,on,O
3625,development,B
3625,set,I
3625,and,O
3625,78.0,B
3625,on,O
3625,mismatched,B
3625,score,O
3625,.,O
3626,Dropout,B
3626,is,O
3626,further,O
3626,applied,B
3626,to,I
3626,both,B
3626,weights,I
3626,and,I
3626,embeddings,I
3626,.,O
3627,We,O
3627,obtain,B
3627,73.2,B
3627,for,B
3627,matched,B
3627,score,I
3627,and,O
3627,73.6,B
3627,on,B
3627,mismatched,B
3627,data,I
3627,.,O
3628,If,O
3628,we,O
3628,remove,B
3628,encoding,B
3628,layer,I
3628,completely,I
3628,",",O
3628,then,O
3628,we,O
3628,'ll,O
3628,obtain,B
3628,a,O
3628,73.5,B
3628,for,B
3628,matched,B
3628,score,I
3628,and,O
3628,73.2,B
3628,for,O
3628,mismatched,B
3628,score,O
3628,.,O
3629,The,O
3629,result,O
3629,demonstrate,B
3629,the,O
3629,feature,O
3629,extraction,O
3629,layer,O
3629,have,B
3629,powerful,B
3629,capability,I
3629,to,B
3629,capture,I
3629,the,O
3629,semantic,B
3629,feature,O
3629,.,O
3630,In,O
3630,experiment,O
3630,5,O
3630,",",O
3630,we,O
3630,remove,O
3630,both,B
3630,self,I
3630,-,I
3630,attention,I
3630,and,I
3630,fuse,I
3630,gate,I
3630,",",O
3630,thus,O
3630,retaining,B
3630,only,I
3630,highway,B
3630,network,I
3630,.,O
3631,The,O
3631,result,B
3631,improves,B
3631,to,B
3631,77.7,B
3631,and,I
3631,77.3,I
3631,respectively,O
3631,on,B
3631,matched,B
3631,and,O
3631,mismatched,O
3631,development,O
3631,set,O
3631,.,O
3632,However,O
3632,",",O
3632,in,O
3632,experiment,O
3632,6,O
3632,",",O
3632,when,O
3632,we,O
3632,only,O
3632,remove,O
3632,fuse,B
3632,gate,I
3632,",",O
3632,to,B
3632,our,O
3632,surprise,O
3632,",",O
3632,the,O
3632,performance,B
3632,degrade,B
3632,to,O
3632,73.5,B
3632,for,B
3632,matched,B
3632,score,I
3632,and,O
3632,73.8,B
3632,for,O
3632,mismatched,B
3632,.,O
3633,On,O
3633,the,O
3633,other,O
3633,hand,O
3633,",",O
3633,if,O
3633,we,O
3633,use,B
3633,the,O
3633,addition,B
3633,of,B
3633,the,O
3633,representation,B
3633,after,B
3633,highway,B
3633,network,I
3633,and,I
3633,the,O
3633,representation,O
3633,after,O
3633,self,B
3633,-,I
3633,attention,I
3633,as,B
3633,skip,B
3633,connection,I
3633,as,O
3633,in,O
3633,experiment,O
3633,7,O
3633,",",O
3633,the,O
3633,performance,B
3633,increase,I
3633,to,B
3633,77.3,B
3633,and,O
3633,76.3,O
3633,.,O
3634,We,O
3634,implement,B
3634,our,B
3634,algorithm,I
3634,with,B
3634,Tensorflow,B
3634,framework,I
3634,.,O
3635,An,O
3635,Adadelta,B
3635,optimizer,I
3635,(,O
3635,Zeiler,O
3635,",",O
3635,2012,O
3635,),O
3635,with,B
3635,?,O
3636,8,O
3636,is,O
3636,used,B
3636,to,I
3636,optimize,B
3636,all,B
3636,the,I
3636,trainable,I
3636,weights,I
3636,.,O
3637,The,O
3637,initial,B
3637,learning,I
3637,rate,I
3637,is,O
3637,set,B
3637,to,B
3637,0.5,B
3637,and,O
3637,batch,B
3637,size,I
3637,to,O
3637,70,B
3637,.,O
3638,To,O
3638,better,O
3638,quantify,O
3638,the,O
3638,contribution,O
3638,of,O
3638,the,O
3638,different,O
3638,components,O
3638,of,O
3638,our,O
3638,model,B
3638,",",O
3638,we,O
3638,also,O
3638,conduct,O
3638,an,O
3638,ablation,O
3638,study,O
3638,evaluating,B
3638,several,B
3638,simplified,I
3638,models,I
3638,.,O
3639,All,O
3639,hidden,O
3639,layers,O
3639,are,O
3639,dropped,B
3639,out,I
3639,by,I
3639,50,B
3639,%,I
3639,",",O
3639,and,O
3639,embeddings,B
3639,40,B
3639,%,O
3639,.,O
3640,When,O
3640,the,O
3640,model,B
3640,does,O
3640,not,B
3640,improve,I
3640,best,B
3640,in,I
3640,domain,I
3640,performance,I
3640,for,B
3640,"30,000",B
3640,steps,I
3640,",",O
3640,an,O
3640,SGD,B
3640,optimizer,I
3640,with,B
3640,learning,B
3640,rate,I
3640,of,B
3640,3e,O
3640,?,O
3641,4,O
3641,is,O
3641,used,O
3641,to,B
3641,help,I
3641,model,B
3641,to,O
3641,find,B
3641,a,O
3641,better,B
3641,local,I
3641,optimum,I
3641,.,O
3642,Dropout,O
3642,layers,O
3642,are,O
3642,applied,B
3642,before,I
3642,all,B
3642,linear,I
3642,layers,O
3642,and,O
3642,after,B
3642,word,B
3642,-,I
3642,embedding,I
3642,layer,I
3642,.,O
3643,We,O
3643,initialize,B
3643,our,O
3643,word,O
3643,embeddings,O
3643,with,B
3643,pre-trained,B
3643,300D,I
3643,Glo,I
3643,Ve,I
3643,840B,I
3643,vectors,I
3643,while,O
3643,the,O
3643,out,B
3643,-,I
3643,of,I
3643,-,O
3643,vocabulary,O
3643,word,O
3643,are,B
3643,randomly,B
3643,initialized,I
3643,with,O
3643,uniform,B
3643,distribution,I
3643,.,O
3644,The,O
3644,character,B
3644,embeddings,I
3644,are,B
3644,randomly,B
3644,initialized,I
3644,with,B
3644,100D,B
3644,.,O
3645,We,O
3645,crop,B
3645,or,I
3645,pad,I
3645,each,B
3645,token,B
3645,to,B
3645,have,I
3645,16,B
3645,characters,I
3645,.,O
3646,The,O
3646,1D,B
3646,convolution,I
3646,kernel,I
3646,size,I
3646,for,B
3646,character,B
3646,embedding,I
3646,is,B
3646,5,B
3646,.,O
3647,All,O
3647,weights,O
3647,are,O
3647,constraint,B
3647,by,I
3647,L2,B
3647,regularization,I
3647,",",O
3647,and,O
3647,the,O
3647,L2,O
3647,regularization,O
3647,at,O
3647,step,O
3647,t,O
3647,is,O
3647,calculated,O
3647,as,O
3647,follows,O
3647,:,O
3648,The,O
3648,first,B
3648,scale,I
3648,down,I
3648,ratio,I
3648,?,O
3649,in,B
3649,feature,B
3649,extraction,I
3649,layer,I
3649,is,O
3649,set,B
3649,to,I
3649,0.3,B
3649,and,O
3649,transitional,B
3649,scale,I
3649,down,I
3649,ratio,I
3649,?,O
3650,is,O
3650,set,B
3650,to,I
3650,0.5,B
3650,.,O
3651,Word,O
3651,embeddings,O
3651,are,B
3651,300,B
3651,dimensional,I
3651,",",O
3651,pretrained,B
3651,ourselves,I
3651,using,I
3651,word2vec,B
3651,To,B
3651,train,I
3651,our,B
3651,model,I
3651,",",O
3651,we,O
3651,compute,B
3651,gradient,I
3651,by,B
3651,back,B
3651,-,I
3651,propagation,I
3651,and,O
3651,apply,B
3651,stochastic,B
3651,gradient,O
3651,descent,O
3651,with,B
3651,mini-batch,B
3651,200,I
3651,.,O
3652,The,O
3652,sequence,B
3652,length,I
3652,is,O
3652,set,B
3652,as,I
3652,a,O
3652,hard,B
3652,cutoff,I
3652,on,B
3652,all,B
3652,experiments,I
3652,:,O
3652,48,B
3652,for,B
3652,MultiNLI,B
3652,",",O
3652,32,B
3652,for,O
3652,SNLI,B
3652,and,O
3652,24,B
3652,for,O
3652,Quora,B
3652,Question,I
3652,Pair,I
3652,Dataset,I
3652,.,O
3653,We,O
3653,use,B
3653,an,O
3653,exponential,B
3653,decayed,I
3653,keep,I
3653,rate,I
3653,during,B
3653,training,B
3653,",",O
3653,where,B
3653,the,O
3653,initial,B
3653,keep,O
3653,rate,O
3653,is,B
3653,1.0,B
3653,and,O
3653,the,O
3653,decay,B
3653,rate,O
3653,is,O
3653,0.977,B
3653,for,B
3653,every,B
3653,"10,000",I
3653,step,I
3653,.,O
3654,In,O
3654,this,O
3654,work,O
3654,",",O
3654,we,O
3654,push,B
3654,the,O
3654,multi-head,B
3654,attention,I
3654,to,B
3654,a,O
3654,extreme,B
3654,by,I
3654,building,I
3654,a,O
3654,word,O
3654,-,O
3654,by,O
3654,-,O
3654,word,O
3654,dimension,O
3654,-,O
3654,wise,O
3654,alignment,O
3654,tensor,O
3654,which,O
3654,we,O
3654,call,B
3654,interaction,B
3654,tensor,O
3654,.,O
3655,The,O
3655,interaction,B
3655,tensor,I
3655,encodes,B
3655,the,O
3655,high,B
3655,-,I
3655,order,I
3655,alignment,I
3655,relationship,I
3655,between,B
3655,sentences,B
3655,pair,I
3655,.,O
3656,We,O
3656,dub,B
3656,the,O
3656,general,B
3656,framework,I
3656,as,B
3656,Interactive,B
3656,Inference,I
3656,Network,I
3656,(,I
3656,IIN,I
3656,),I
3656,.,O
3657,Published,O
3657,as,O
3657,a,O
3657,conference,O
3657,paper,O
3657,at,O
3657,ICLR,O
3657,2018,O
3657,NATURAL,B
3657,LANGUAGE,I
3657,INFERENCE,I
3657,OVER,O
3657,INTERACTION,O
3657,SPACE,O
3658,Natural,O
3658,Language,O
3658,Inference,O
3658,(,O
3658,NLI,B
3658,also,O
3658,known,O
3658,as,O
3658,recognizing,B
3658,textual,I
3658,entiailment,I
3658,",",O
3658,or,O
3658,RTE,B
3658,),O
3658,task,O
3658,requires,O
3658,one,O
3658,to,O
3658,determine,O
3658,whether,O
3658,the,O
3658,logical,O
3658,relationship,O
3658,between,O
3658,two,O
3658,sentences,O
3658,is,O
3658,among,O
3658,entailment,O
3658,(,O
3658,if,O
3658,the,O
3658,premise,O
3658,is,O
3658,true,O
3658,",",O
3658,then,O
3658,the,O
3658,hypothesis,O
3658,must,O
3658,be,O
3658,true,O
3658,),O
3658,",",O
3658,contradiction,O
3658,(,O
3658,if,O
3658,the,O
3658,premise,O
3658,is,O
3658,true,O
3658,",",O
3658,then,O
3658,the,O
3658,hypothesis,O
3658,must,O
3658,be,O
3658,false,O
3658,),O
3658,and,O
3658,neutral,O
3658,(,O
3658,neither,O
3658,entailment,O
3658,nor,O
3658,contradiction,O
3658,),O
3658,.,O
3659,EXPERIMENT,O
3659,ON,O
3659,MULTINLI,B
3660,Our,O
3660,approach,O
3660,",",O
3660,without,B
3660,using,I
3660,any,O
3660,recurrent,B
3660,structure,I
3660,",",O
3660,achieves,B
3660,the,I
3660,new,B
3660,state,I
3660,-,I
3660,of,I
3660,-,O
3660,the,O
3660,-,O
3660,art,O
3660,performance,O
3660,of,O
3660,80.0,B
3660,%,I
3660,",",O
3660,exceeding,B
3660,current,B
3660,state,O
3660,-,O
3660,of,O
3660,-,O
3660,the,O
3660,-,O
3660,art,O
3660,performance,O
3660,by,B
3660,more,B
3660,than,I
3660,5,I
3660,%,O
3660,.,O
3661,Unlike,O
3661,the,O
3661,observation,O
3661,from,O
3661,",",O
3661,we,O
3661,find,B
3661,the,O
3661,out,B
3661,-,I
3661,of,I
3661,-,O
3661,domain,O
3661,test,O
3661,performance,O
3661,is,B
3661,consistently,B
3661,lower,I
3661,than,B
3661,in,B
3661,-,O
3661,domain,O
3661,test,O
3661,performance,O
3661,.,O
3662,We,O
3662,use,B
3662,ReLU,B
3662,as,B
3662,the,O
3662,activation,B
3662,function,I
3662,.,O
3663,EXPERIMENT,O
3663,ON,O
3663,SNLI,B
3664,We,O
3664,show,B
3664,our,B
3664,model,I
3664,",",I
3664,DIIN,I
3664,",",O
3664,achieves,B
3664,state,B
3664,-,I
3664,of,I
3664,-,O
3664,the,O
3664,-,O
3664,art,O
3664,performance,O
3664,on,B
3664,the,O
3664,competitive,B
3664,leaderboard,I
3664,.,O
3665,EXPERIMENT,O
3665,ON,O
3665,QUORA,B
3665,QUESTION,I
3665,PAIR,I
3665,DATASET,I
3666,BIMPM,B
3666,models,B
3666,different,B
3666,perspective,I
3666,of,I
3666,matching,B
3666,between,B
3666,sentence,B
3666,pair,I
3666,on,B
3666,both,B
3666,direction,I
3666,",",O
3666,then,O
3666,aggregates,B
3666,matching,O
3666,vector,O
3666,with,B
3666,LSTM,B
3666,.,O
3667,DECATT,O
3667,word,O
3667,and,O
3667,DECATT,O
3667,char,O
3667,uses,B
3667,automatically,B
3667,collected,I
3667,in,I
3667,-,I
3667,domain,I
3667,paraphrase,I
3667,data,I
3667,to,B
3667,noisy,I
3667,pretrain,I
3667,n-gram,B
3667,word,O
3667,embedding,O
3667,and,O
3667,ngram,O
3667,subword,O
3667,embedding,O
3667,correspondingly,O
3667,on,B
3667,decomposable,B
3667,attention,I
3667,model,I
3667,proposed,O
3667,by,O
3667,.,O
3668,We,O
3668,adopt,B
3668,the,O
3668,Whole,B
3668,Word,I
3668,Masking,I
3668,BERT,I
3668,as,O
3668,the,O
3668,baseline,O
3668,6,O
3668,.,O
3669,The,O
3669,initial,B
3669,learning,I
3669,rate,I
3669,is,O
3669,set,B
3669,in,I
3669,{,B
3669,8e,I
3669,-6,I
3669,",",I
3669,1,I
3669,e,I
3669,-,I
3669,5,I
3669,",",O
3669,2,O
3669,e,O
3669,-,O
3669,5,O
3669,",",O
3669,3,O
3669,e,O
3669,-,O
3669,5,O
3669,},O
3669,with,B
3669,warm,B
3669,-,O
3669,up,O
3669,rate,O
3669,of,B
3669,0.1,B
3669,and,O
3669,L2,B
3669,weight,I
3669,decay,I
3669,of,O
3669,0.01,B
3669,.,O
3670,The,O
3670,batch,B
3670,size,I
3670,is,O
3670,selected,B
3670,in,I
3670,{,B
3670,16,I
3670,",",I
3670,20,I
3670,",",O
3670,32,O
3670,},O
3670,.,O
3671,The,O
3671,maximum,B
3671,number,I
3671,of,I
3671,epochs,I
3671,is,O
3671,set,B
3671,to,I
3671,3,B
3671,or,I
3671,10,I
3671,depending,O
3671,on,O
3671,tasks,O
3671,.,O
3672,The,O
3672,weight,B
3672,?,O
3673,For,B
3673,regularization,B
3673,",",O
3673,we,O
3673,add,B
3673,2,B
3673,penalty,I
3673,for,O
3673,weights,B
3673,with,B
3673,a,O
3673,coefficient,B
3673,of,B
3673,10,B
3673,?5,I
3673,.,O
3674,in,B
3674,the,O
3674,dual,B
3674,context,I
3674,aggregation,I
3674,is,B
3674,0.5,B
3674,.,O
3675,All,O
3675,the,O
3675,texts,B
3675,are,B
3675,tokenized,B
3675,using,B
3675,wordpieces,B
3675,",",O
3675,and,O
3675,the,O
3675,maximum,B
3675,input,I
3675,length,I
3675,is,O
3675,set,B
3675,to,I
3675,384,B
3675,for,B
3675,both,O
3675,of,O
3675,SQuAD,B
3675,and,O
3675,RACE,O
3675,.,O
3676,In,O
3676,this,O
3676,paper,O
3676,",",O
3676,we,O
3676,extend,B
3676,the,O
3676,self,B
3676,-,I
3676,attention,I
3676,mechanism,I
3676,with,B
3676,syntax,B
3676,-,O
3676,guided,O
3676,constraint,O
3676,",",O
3676,to,B
3676,capture,I
3676,syntax,O
3676,related,O
3676,parts,O
3676,with,O
3676,each,B
3676,concerned,I
3676,word,I
3676,.,O
3677,Specifically,O
3677,",",O
3677,we,O
3677,adopt,B
3677,pre-trained,B
3677,dependency,I
3677,syntactic,B
3677,parse,I
3677,tree,I
3677,structure,I
3677,to,B
3677,produce,I
3677,the,O
3677,related,B
3677,nodes,I
3677,for,B
3677,each,B
3677,word,I
3677,in,B
3677,a,O
3677,sentence,B
3677,",",O
3677,namely,B
3677,syntactic,O
3677,dependency,O
3677,of,O
3677,interest,O
3677,(,O
3677,SDOI,O
3677,),O
3677,",",O
3677,by,O
3677,regarding,B
3677,each,O
3677,word,O
3677,as,B
3677,a,O
3677,child,B
3677,node,I
3677,and,O
3677,the,O
3677,SDOI,O
3677,consists,O
3677,all,O
3677,its,O
3677,ancestor,O
3677,nodes,O
3677,and,O
3677,itself,O
3677,in,O
3677,the,O
3677,dependency,O
3677,parsing,O
3677,tree,O
3677,.,O
3678,To,O
3678,effectively,O
3678,accommodate,B
3678,such,O
3678,SDOI,O
3678,information,O
3678,",",O
3678,we,O
3678,propose,B
3678,a,O
3678,novel,B
3678,syntax,I
3678,-,I
3678,guided,I
3678,network,I
3678,(,I
3678,SG,I
3678,-,O
3678,Net,O
3678,),O
3678,",",O
3678,which,O
3678,fuses,B
3678,the,O
3678,original,B
3678,SAN,I
3678,and,I
3678,SDOI,O
3678,-,O
3678,SAN,O
3678,",",O
3678,to,O
3678,provide,O
3678,more,B
3678,linguistically,I
3678,inspired,I
3678,representation,I
3678,for,B
3678,challenging,O
3678,reading,B
3678,comprehension,I
3678,tasks,I
3678,1,O
3678,.,O
3679,SG,O
3679,-,O
3679,Net,O
3679,:,O
3679,Syntax,O
3679,-,O
3679,Guided,O
3679,Machine,B
3679,Reading,I
3679,Comprehension,I
3680,Understanding,O
3680,the,O
3680,meaning,O
3680,of,O
3680,a,O
3680,sentence,O
3680,is,O
3680,a,O
3680,prerequisite,O
3680,to,O
3680,solve,O
3680,many,O
3680,natural,O
3680,language,O
3680,understanding,O
3680,(,O
3680,NLU,O
3680,),O
3680,problems,O
3680,",",O
3680,such,O
3680,as,O
3680,machine,B
3680,reading,I
3680,comprehension,I
3680,(,O
3680,MRC,O
3680,),O
3680,based,O
3680,question,O
3680,answering,O
3680,.,O
3681,We,O
3681,observe,O
3681,that,O
3681,the,O
3681,accuracy,O
3681,of,O
3681,MRC,B
3681,models,O
3681,decreases,O
3681,when,O
3681,answering,O
3681,long,O
3681,questions,O
3681,(,O
3681,shown,O
3681,in,O
3681,Section,O
3681,5.1,O
3681,),O
3681,.,O
3682,It,O
3682,also,O
3682,outperforms,B
3682,all,B
3682,the,I
3682,published,I
3682,works,I
3682,and,O
3682,achieves,B
3682,the,O
3682,2nd,B
3682,place,I
3682,on,B
3682,the,O
3682,leaderboard,B
3682,when,B
3682,submitting,I
3682,SG,B
3682,-,I
3682,NET,I
3682,.,O
3683,We,O
3683,also,O
3683,find,O
3683,that,O
3683,adding,B
3683,an,O
3683,extra,B
3683,answer,I
3683,verifier,I
3683,module,I
3683,could,O
3683,yield,B
3683,better,B
3683,result,I
3683,",",O
3683,which,O
3683,is,O
3683,pre-trained,O
3683,only,O
3683,to,O
3683,determine,O
3683,whether,O
3683,question,O
3683,is,O
3683,answerable,O
3683,or,O
3683,not,O
3683,with,O
3683,the,O
3683,same,O
3683,training,O
3683,data,O
3683,as,O
3683,SG,O
3683,-,O
3683,Net,O
3683,.,O
3684,In,O
3684,this,O
3684,paper,O
3684,",",O
3684,we,O
3684,propose,B
3684,a,O
3684,novel,B
3684,neural,I
3684,architecture,I
3684,for,B
3684,discriminative,B
3684,sentence,I
3684,modeling,I
3684,",",O
3684,called,B
3684,the,O
3684,Tree,B
3684,-,I
3684,Based,I
3684,Convolutional,I
3684,Neural,O
3684,Network,O
3684,(,O
3684,TBCNN,O
3684,),O
3684,.,O
3685,We,O
3685,used,B
3685,word,B
3685,embeddings,I
3685,(,I
3685,d,I
3685,=,I
3685,50,I
3685,),I
3685,that,O
3685,were,O
3685,computed,B
3685,using,I
3685,Collobert,B
3685,and,I
3685,Weston,I
3685,'s,I
3685,neural,I
3685,language,I
3685,model,I
3685,and,O
3685,provided,O
3685,by,O
3685,Turian,O
3685,et,O
3685,al,O
3685,..,O
3686,The,O
3686,other,B
3686,model,I
3686,weights,I
3686,were,O
3686,randomly,B
3686,intitialised,I
3686,using,B
3686,a,O
3686,Gaussian,O
3686,distribution,O
3686,(,O
3686,=,O
3686,0,O
3686,",",O
3686,?,O
3687,All,O
3687,hyperparameters,O
3687,were,O
3687,optimised,B
3687,via,I
3687,grid,B
3687,search,I
3687,on,I
3687,the,I
3687,MAP,B
3687,score,I
3687,on,O
3687,the,O
3687,development,O
3687,data,O
3687,.,O
3688,L,O
3688,-,O
3688,BFGS,O
3688,was,O
3688,used,O
3688,to,B
3688,train,I
3688,the,O
3688,logistic,B
3688,regression,I
3688,classifier,I
3688,",",O
3688,with,B
3688,L2,B
3688,regulariser,I
3688,of,B
3688,0.01,B
3688,.,O
3689,We,O
3689,use,B
3689,the,O
3689,AdaGrad,B
3689,algorithm,I
3689,for,B
3689,training,B
3689,.,O
3690,In,O
3690,this,O
3690,paper,O
3690,",",O
3690,we,O
3690,show,B
3690,that,O
3690,a,O
3690,neural,B
3690,network,I
3690,-,I
3690,based,I
3690,sentence,I
3690,model,I
3690,can,B
3690,be,I
3690,applied,I
3690,to,I
3690,the,O
3690,task,B
3690,of,I
3690,answer,I
3690,sentence,O
3690,selection,O
3690,.,O
3691,We,O
3691,construct,B
3691,two,B
3691,distributional,I
3691,sentence,I
3691,models,I
3691,;,O
3691,first,B
3691,a,O
3691,bag,B
3691,-,I
3691,of,I
3691,-,O
3691,words,O
3691,model,O
3691,",",O
3691,and,O
3691,second,B
3691,",",O
3691,a,O
3691,bigram,B
3691,model,O
3691,based,B
3691,on,I
3691,a,O
3691,convolutional,B
3691,neural,I
3691,network,I
3691,.,O
3692,Assuming,O
3692,a,O
3692,set,O
3692,of,O
3692,pre-trained,B
3692,semantic,I
3692,word,I
3692,embeddings,I
3692,",",O
3692,we,O
3692,train,B
3692,a,O
3692,supervised,B
3692,model,I
3692,to,B
3692,learn,I
3692,a,O
3692,semantic,O
3692,matching,O
3692,between,B
3692,question,B
3692,and,I
3692,answer,I
3692,pairs,I
3692,.,O
3693,We,O
3693,also,O
3693,present,B
3693,an,O
3693,enhanced,B
3693,version,I
3693,of,B
3693,this,O
3693,model,O
3693,",",O
3693,which,O
3693,combines,B
3693,the,O
3693,signal,B
3693,of,O
3693,the,O
3693,distributed,B
3693,matching,I
3693,algorithm,I
3693,with,B
3693,two,B
3693,simple,I
3693,word,I
3693,matching,O
3693,features,O
3693,.,O
3694,Deep,O
3694,Learning,O
3694,for,O
3694,Answer,B
3694,Sentence,I
3694,Selection,I
3695,Our,O
3695,models,O
3695,can,O
3695,leverage,B
3695,different,B
3695,sentence,I
3695,parsing,I
3695,trees,I
3695,",",O
3695,e.g.,O
3696,As,O
3696,can,O
3696,be,O
3696,seen,O
3696,",",O
3696,the,O
3696,bigram,B
3696,model,I
3696,performs,B
3696,better,B
3696,than,B
3696,the,O
3696,unigram,B
3696,model,O
3696,and,O
3696,the,O
3696,addition,B
3696,of,I
3696,the,O
3696,IDF,B
3696,-,I
3696,weighted,I
3696,word,I
3696,count,I
3696,features,I
3696,significantly,B
3696,improve,I
3696,performance,B
3696,for,B
3696,both,B
3696,models,I
3696,by,B
3696,10,B
3696,%,I
3696,-,O
3696,15,O
3696,%,O
3696,.,O
3697,As,O
3697,can,O
3697,be,O
3697,seen,O
3697,in,O
3697,",",O
3697,our,O
3697,best,B
3697,models,I
3697,(,I
3697,bigram,I
3697,+,I
3697,count,I
3697,),I
3697,outperform,B
3697,all,B
3697,baselines,I
3697,and,O
3697,prior,O
3697,work,O
3697,on,O
3697,MAP,O
3697,and,O
3697,are,O
3697,very,O
3697,close,O
3697,to,O
3697,the,O
3697,best,O
3697,model,O
3697,proposed,O
3697,by,O
3697,Yih,O
3697,et,O
3697,al.,O
3698,Our,O
3698,code,O
3698,is,O
3698,available,O
3698,at,O
3698,https://github.com/cheng6076/,B
3699,We,O
3699,used,B
3699,stochastic,B
3699,gradient,I
3699,descent,I
3699,for,B
3699,optimization,B
3699,with,B
3699,an,O
3699,initial,B
3699,learning,I
3699,rate,I
3699,of,B
3699,0.65,B
3699,",",O
3699,which,O
3699,decays,B
3699,by,B
3699,a,O
3699,factor,B
3699,of,O
3699,0.85,B
3699,per,B
3699,epoch,B
3699,if,O
3699,no,O
3699,significant,O
3699,improvement,O
3699,has,O
3699,been,O
3699,observed,O
3699,on,O
3699,the,O
3699,validation,O
3699,set,O
3699,.,O
3700,We,O
3700,renormalize,B
3700,the,O
3700,gradient,B
3700,if,B
3700,its,O
3700,norm,B
3700,is,O
3700,greater,B
3700,than,I
3700,5,B
3700,.,O
3701,The,O
3701,mini,B
3701,-,I
3701,batch,I
3701,size,I
3701,was,O
3701,set,B
3701,to,I
3701,40,B
3701,.,O
3702,The,O
3702,dimensions,B
3702,of,B
3702,the,O
3702,word,B
3702,embeddings,I
3702,were,O
3702,set,B
3702,to,I
3702,150,B
3702,for,B
3702,all,B
3702,models,I
3702,.,O
3703,The,O
3703,first,O
3703,one,O
3703,is,O
3703,a,O
3703,Kneser,B
3703,-,I
3703,Ney,I
3703,5,I
3703,-,O
3703,gram,O
3703,language,B
3703,model,I
3703,(,I
3703,KN5,I
3703,),I
3703,which,O
3703,generally,O
3703,serves,B
3703,as,I
3703,a,O
3703,non-neural,B
3703,baseline,I
3703,for,B
3703,the,O
3703,language,O
3703,modeling,O
3703,task,O
3703,.,O
3704,The,O
3704,gated,B
3704,-,I
3704,feedback,B
3704,LSTM,I
3704,has,O
3704,feedback,O
3704,gates,O
3704,connecting,B
3704,the,O
3704,hidden,B
3704,states,I
3704,across,B
3704,multiple,B
3704,time,I
3704,steps,I
3704,as,B
3704,an,O
3704,adaptive,B
3704,control,I
3704,of,B
3704,the,O
3704,information,B
3704,flow,I
3704,.,O
3705,The,O
3705,model,O
3705,variants,B
3705,are,O
3705,denoted,B
3705,as,I
3705,c-,B
3705,TBCNN,I
3705,and,O
3705,d,B
3705,-,I
3705,TBCNN,O
3705,",",O
3705,respectively,O
3705,.,O
3706,The,O
3706,depth,B
3706,-,I
3706,gated,I
3706,LSTM,I
3706,uses,B
3706,a,O
3706,depth,O
3706,gate,O
3706,to,B
3706,connect,I
3706,memory,B
3706,cells,I
3706,of,B
3706,vertically,B
3706,adjacent,I
3706,layers,I
3706,.,O
3707,Amongst,B
3707,all,B
3707,deep,I
3707,architectures,I
3707,",",O
3707,the,O
3707,three,B
3707,-,I
3707,layer,I
3707,LSTMN,I
3707,also,O
3707,performs,B
3707,best,B
3707,.,O
3708,Most,O
3708,of,O
3708,these,O
3708,models,O
3708,(,O
3708,including,O
3708,ours,O
3708,),O
3708,are,B
3708,LSTM,B
3708,variants,I
3708,(,O
3708,third,O
3708,block,O
3708,in,O
3708,",",O
3708,recursive,O
3708,neural,O
3708,networks,O
3708,(,O
3708,first,O
3708,block,O
3708,),O
3708,",",O
3708,or,O
3708,convolutional,O
3708,neural,O
3708,networks,O
3708,(,O
3708,CNNs,O
3708,;,O
3708,second,O
3708,block,O
3708,),O
3708,.,O
3709,For,O
3709,comparison,O
3709,",",O
3709,we,O
3709,also,O
3709,report,B
3709,the,O
3709,performance,B
3709,of,B
3709,the,O
3709,paragraph,B
3709,vector,I
3709,model,I
3709,(,O
3709,PV,O
3709,;,O
3709,;,O
3709,see,O
3709,",",O
3709,second,O
3709,block,O
3709,),O
3709,which,O
3709,neither,O
3709,operates,O
3709,on,O
3709,trees,O
3709,nor,O
3709,sequences,O
3709,but,O
3709,learns,O
3709,distributed,O
3709,document,O
3709,representations,O
3709,parameterized,O
3709,directly,O
3709,.,O
3710,We,O
3710,used,B
3710,pretrained,B
3710,300,I
3710,-,I
3710,D,I
3710,Glove,I
3710,840B,I
3710,vectors,I
3710,to,B
3710,initialize,I
3710,the,O
3710,word,B
3710,embeddings,I
3710,.,O
3711,We,O
3711,used,O
3711,Adam,B
3711,(,I
3711,Kingma,I
3711,and,I
3711,Ba,I
3711,",",I
3711,2015,I
3711,),I
3711,for,B
3711,optimization,B
3711,with,B
3711,the,O
3711,two,B
3711,momentum,I
3711,parameters,I
3711,set,B
3711,to,I
3711,0.9,B
3711,and,O
3711,0.999,O
3711,respectively,O
3711,.,O
3712,The,O
3712,gradient,B
3712,for,B
3712,words,B
3712,with,B
3712,Glove,B
3712,embeddings,I
3712,",",O
3712,was,O
3712,scaled,B
3712,by,I
3712,0.35,B
3712,in,B
3712,the,O
3712,first,B
3712,epoch,I
3712,after,B
3712,which,O
3712,all,B
3712,word,I
3712,embeddings,O
3712,were,O
3712,updated,B
3712,normally,B
3712,.,O
3713,The,O
3713,initial,B
3713,learning,I
3713,rate,I
3713,was,O
3713,set,B
3713,to,I
3713,2E,B
3713,-,I
3713,3,I
3713,.,O
3714,The,O
3714,regularization,B
3714,constant,I
3714,was,B
3714,1E,B
3714,-,I
3714,4,I
3714,and,O
3714,the,O
3714,mini-batch,B
3714,size,I
3714,was,O
3714,5,B
3714,.,O
3715,The,O
3715,idea,O
3715,of,B
3715,tree,I
3715,-,I
3715,based,I
3715,convolution,I
3715,is,O
3715,to,O
3715,apply,B
3715,a,O
3715,set,B
3715,of,O
3715,subtree,O
3715,feature,O
3715,detectors,O
3715,",",O
3715,sliding,B
3715,over,I
3715,the,O
3715,entire,B
3715,parsing,I
3715,tree,O
3715,of,O
3715,a,O
3715,sentence,B
3715,;,O
3715,then,O
3715,pooling,B
3715,aggregates,B
3715,these,I
3715,extracted,I
3715,feature,O
3715,vectors,O
3715,by,O
3715,taking,B
3715,the,O
3715,maximum,B
3715,value,I
3715,in,B
3715,each,B
3715,dimension,I
3715,.,O
3716,A,O
3716,dropout,B
3716,rate,I
3716,of,B
3716,0.5,B
3716,was,O
3716,applied,B
3716,to,I
3716,the,O
3716,neural,B
3716,network,I
3716,classifier,I
3716,.,O
3717,The,O
3717,results,O
3717,in,O
3717,show,B
3717,that,I
3717,both,B
3717,1,I
3717,-,I
3717,and,I
3717,2,I
3717,-,O
3717,layer,O
3717,LSTMNs,O
3717,outperform,B
3717,the,O
3717,LSTM,B
3717,baselines,I
3717,while,O
3717,achieving,O
3717,numbers,O
3717,comparable,O
3717,to,O
3717,state,O
3717,of,O
3717,the,O
3717,art,O
3717,.,O
3718,On,B
3718,the,O
3718,fine,B
3718,-,I
3718,grained,I
3718,and,I
3718,binary,I
3718,classification,I
3718,tasks,I
3718,our,B
3718,2,I
3718,-,O
3718,layer,O
3718,LSTMN,O
3718,performs,B
3718,close,B
3718,to,B
3718,the,O
3718,best,B
3718,system,I
3718,T,O
3718,-.,O
3719,We,O
3719,used,B
3719,pre-trained,B
3719,300,I
3719,-,I
3719,D,I
3719,Glove,I
3719,840B,I
3719,vectors,I
3719,to,B
3719,initialize,I
3719,the,O
3719,word,B
3719,embeddings,I
3719,.,O
3720,Out,O
3720,-,O
3720,of,O
3720,-,O
3720,vocabulary,O
3720,(,O
3720,OOV,O
3720,),O
3720,words,O
3720,were,O
3720,initialized,B
3720,randomly,B
3720,with,B
3720,Gaussian,B
3720,samples,I
3720,(,O
3720,=,O
3720,0,O
3720,",",O
3720,?=,O
3720,1,O
3720,),O
3720,.,O
3721,We,O
3721,used,O
3721,Adam,B
3721,(,I
3721,Kingma,I
3721,and,I
3721,Ba,I
3721,",",I
3721,2015,I
3721,),I
3721,for,B
3721,optimization,B
3721,with,B
3721,the,O
3721,two,B
3721,momentum,I
3721,parameters,I
3721,set,B
3721,to,I
3721,0.9,B
3721,and,O
3721,0.999,O
3721,respectively,O
3721,",",O
3721,and,O
3721,the,O
3721,initial,B
3721,learning,I
3721,rate,I
3721,set,O
3721,to,O
3721,1E,B
3721,-,I
3721,3,I
3721,.,O
3722,The,O
3722,mini-,B
3722,batch,I
3722,size,I
3722,was,O
3722,set,B
3722,to,I
3722,16,B
3722,or,I
3722,32,I
3722,.,O
3723,We,O
3723,only,O
3723,updated,B
3723,OOV,B
3723,vectors,I
3723,in,B
3723,the,O
3723,first,B
3723,epoch,I
3723,",",O
3723,after,B
3723,which,O
3723,all,B
3723,word,I
3723,embeddings,I
3723,were,O
3723,updated,O
3723,normally,B
3723,.,O
3724,The,O
3724,dropout,B
3724,rate,I
3724,was,O
3724,selected,B
3724,from,I
3724,[,B
3724,0.1,I
3724,",",I
3724,0.2,I
3724,",",O
3724,0.3,O
3724,",",O
3724,0.4,O
3724,],O
3724,.,O
3725,",",O
3725,2016,O
3725,),O
3725,",",O
3725,a,O
3725,word,O
3725,-,O
3725,by,O
3725,-,O
3725,word,O
3725,attention,O
3725,model,O
3725,",",O
3725,and,O
3725,a,O
3725,matching,B
3725,LSTM,I
3725,(,I
3725,m,I
3725,LSTM,O
3725,;,O
3725,),O
3725,.,O
3726,We,O
3726,also,O
3726,compared,B
3726,our,O
3726,models,O
3726,with,O
3726,a,O
3726,bag,B
3726,-,I
3726,of,I
3726,-,O
3726,words,O
3726,baseline,O
3726,which,O
3726,averages,O
3726,the,O
3726,pre-trained,O
3726,embeddings,O
3726,for,O
3726,the,O
3726,words,O
3726,in,O
3726,each,O
3726,sentence,O
3726,and,O
3726,concatenates,O
3726,them,O
3726,to,O
3726,create,O
3726,features,O
3726,for,O
3726,a,O
3726,logistic,O
3726,regression,O
3726,classifier,O
3726,(,O
3726,first,O
3726,block,O
3726,in,O
3726,),O
3726,.,O
3727,LSTMNs,B
3727,achieve,B
3727,better,B
3727,performance,I
3727,compared,O
3727,Models,O
3728,We,O
3728,also,O
3728,observe,B
3728,that,O
3728,fusion,O
3728,is,B
3728,generally,B
3728,beneficial,I
3728,",",O
3728,and,O
3728,that,O
3728,deep,B
3728,fusion,O
3728,slightly,B
3728,improves,I
3728,over,B
3728,shallow,B
3728,fusion,O
3728,.,O
3729,With,B
3729,standard,B
3729,training,I
3729,",",O
3729,our,O
3729,deep,B
3729,fusion,I
3729,yields,B
3729,the,I
3729,state,B
3729,-,I
3729,of,I
3729,-,O
3729,the,O
3729,-,O
3729,art,O
3729,performance,O
3729,in,O
3729,this,O
3729,task,O
3729,.,O
3730,The,O
3730,idea,O
3730,is,O
3730,to,B
3730,use,B
3730,multiple,B
3730,memory,I
3730,slots,I
3730,outside,B
3730,the,O
3730,recurrence,B
3730,to,O
3730,piece,B
3730,-,I
3730,wise,I
3730,store,I
3730,representations,I
3730,of,B
3730,the,O
3730,input,B
3730,;,O
3730,read,B
3730,and,I
3730,write,I
3730,operations,I
3730,for,B
3730,each,B
3730,slot,I
3730,can,O
3730,be,O
3730,modeled,B
3730,as,I
3730,an,O
3730,attention,B
3730,mechanism,I
3730,with,B
3730,a,O
3730,recurrent,B
3730,controller,I
3730,.,O
3731,We,O
3731,also,O
3731,leverage,B
3731,memory,B
3731,and,I
3731,attention,I
3731,to,B
3731,empower,I
3731,a,O
3731,recurrent,B
3731,network,I
3731,with,B
3731,stronger,B
3731,memorization,I
3731,capability,I
3731,and,O
3731,more,O
3731,importantly,O
3731,the,O
3731,ability,B
3731,to,O
3731,discover,O
3731,relations,B
3731,among,B
3731,tokens,B
3731,.,O
3732,This,O
3732,is,O
3732,realized,B
3732,by,I
3732,inserting,B
3732,a,O
3732,memory,B
3732,network,I
3732,module,I
3732,in,B
3732,the,O
3732,update,B
3732,of,B
3732,a,O
3732,recurrent,B
3732,network,O
3732,together,B
3732,with,I
3732,attention,B
3732,for,B
3732,memory,O
3732,addressing,O
3732,.,O
3733,The,O
3733,resulting,O
3733,model,O
3733,",",O
3733,which,O
3733,we,O
3733,term,O
3733,Long,B
3733,Short,I
3733,-,I
3733,Term,O
3733,Memory,O
3733,-,O
3733,Network,O
3733,(,O
3733,LSTMN,O
3733,),O
3733,",",O
3733,is,B
3733,a,O
3733,reading,B
3733,simulator,I
3733,that,O
3733,can,O
3733,be,O
3733,used,B
3733,for,I
3733,sequence,B
3733,processing,I
3733,tasks,I
3733,.,O
3734,The,O
3734,model,O
3734,processes,B
3734,text,B
3734,incrementally,B
3734,while,B
3734,learning,B
3734,which,O
3734,past,B
3734,tokens,I
3734,in,B
3734,the,O
3734,memory,O
3734,and,O
3734,to,O
3734,what,O
3734,extent,O
3734,they,O
3734,relate,B
3734,to,O
3734,the,O
3734,current,B
3734,token,I
3734,being,B
3734,processed,B
3734,.,O
3735,Nonetheless,O
3735,",",O
3735,our,O
3735,d-TBCNN,B
3735,model,I
3735,achieves,B
3736,As,O
3736,a,O
3736,result,O
3736,",",O
3736,the,O
3736,model,O
3736,induces,B
3736,undirected,B
3736,relations,I
3736,among,B
3736,tokens,B
3736,as,O
3736,an,O
3736,intermediate,B
3736,step,I
3736,of,B
3736,learning,I
3736,representations,B
3736,.,O
3737,Long,O
3737,Short,O
3737,-,O
3737,Term,O
3737,Memory,O
3737,-,O
3737,Networks,O
3737,for,O
3737,Machine,B
3737,Reading,I
3738,Experiment,O
3738,1,O
3738,and,O
3738,5,O
3738,are,O
3738,our,O
3738,models,O
3738,presented,O
3738,in,O
3738,were,O
3738,also,O
3738,important,O
3738,for,O
3738,the,O
3738,model,O
3738,'s,O
3738,performance,B
3738,and,O
3738,that,O
3738,self,B
3738,-,I
3738,attention,I
3738,is,O
3738,able,B
3738,to,B
3738,contribute,I
3738,significantly,B
3738,to,O
3738,performance,O
3738,on,B
3738,top,I
3738,of,I
3738,other,B
3738,components,I
3738,of,O
3738,the,O
3738,model,O
3738,.,O
3739,Finally,O
3739,",",O
3739,we,O
3739,see,B
3739,that,I
3739,effectively,B
3739,introducing,I
3739,external,B
3739,knowledge,I
3739,via,B
3739,our,B
3739,commonsense,I
3739,selection,I
3739,algorithm,I
3739,and,O
3739,NOIC,B
3739,can,O
3739,improve,B
3739,performance,B
3739,even,O
3739,further,O
3739,on,B
3739,top,I
3739,of,I
3739,our,O
3739,strong,O
3739,baseline,O
3739,.,O
3740,The,O
3740,results,O
3740,of,O
3740,these,O
3740,are,O
3740,shown,O
3740,in,O
3740,",",O
3740,where,O
3740,we,O
3740,see,O
3740,that,O
3740,neither,O
3740,NumberBatch,O
3740,nor,O
3740,random,O
3740,-,O
3740,relationships,O
3740,nor,O
3740,single,O
3740,-,O
3740,hop,O
3740,common,O
3740,-,O
3740,sense,O
3740,offer,O
3740,statistically,O
3740,significant,O
3740,improvements,O
3740,7,O
3740,",",O
3740,whereas,O
3740,our,B
3740,commonsense,I
3740,selection,I
3740,and,I
3740,incorporation,I
3740,mechanism,I
3740,improves,B
3740,performance,B
3740,significantly,I
3740,across,B
3740,all,B
3740,metrics,I
3740,.,O
3741,https://github.com/yicheng-w/CommonSenseMultiHopQA,B
3741,task,O
3741,tests,O
3741,a,O
3741,model,O
3741,'s,O
3741,natural,O
3741,language,O
3741,understanding,O
3741,capabilities,O
3741,by,O
3741,asking,O
3741,it,O
3741,to,O
3741,answer,O
3741,a,O
3741,question,O
3741,based,O
3741,on,O
3741,a,O
3741,passage,O
3741,of,O
3741,relevant,O
3741,content,O
3741,.,O
3742,In,O
3742,this,O
3742,paper,O
3742,",",O
3742,we,O
3742,first,B
3742,propose,I
3742,the,O
3742,Multi,B
3742,-,I
3742,Hop,I
3742,Pointer,B
3742,-,O
3742,Generator,O
3742,Model,O
3742,(,O
3742,MHPGM,O
3742,),O
3742,",",O
3742,a,O
3742,strong,B
3742,baseline,I
3742,model,O
3742,that,O
3742,uses,B
3742,multiple,B
3742,hops,I
3742,of,B
3742,bidirectional,B
3742,attention,I
3742,",",O
3742,self,B
3742,-,O
3742,attention,O
3742,",",O
3742,and,O
3742,a,O
3742,pointer,O
3742,-,O
3742,generator,O
3742,decoder,O
3742,to,B
3742,effectively,I
3742,read,B
3742,and,O
3742,reason,O
3742,within,B
3742,along,B
3742,passage,I
3742,and,O
3742,synthesize,B
3742,a,O
3742,coherent,B
3742,response,I
3742,.,O
3743,Next,O
3743,",",O
3743,to,O
3743,address,O
3743,the,O
3743,issue,O
3743,that,O
3743,understanding,O
3743,human,O
3743,-,O
3743,generated,O
3743,text,O
3743,and,O
3743,performing,O
3743,longdistance,O
3743,reasoning,O
3743,on,O
3743,it,O
3743,often,O
3743,involves,O
3743,intermittent,O
3743,access,O
3743,to,O
3743,missing,O
3743,hops,O
3743,of,O
3743,external,O
3743,commonsense,O
3743,(,O
3743,background,O
3743,),O
3743,knowledge,O
3743,",",O
3743,we,O
3743,present,B
3743,an,O
3743,algorithm,B
3743,for,B
3743,selecting,I
3743,useful,B
3743,",",O
3743,grounded,O
3743,multi-hop,O
3743,relational,O
3743,knowledge,O
3743,paths,O
3743,from,B
3743,ConceptNet,B
3743,),O
3743,via,B
3743,a,O
3743,pointwise,B
3743,mutual,I
3743,information,I
3743,(,O
3743,PMI,O
3743,),O
3743,and,O
3743,term,B
3743,-,O
3743,frequency,O
3743,-,O
3743,based,O
3743,scoring,O
3743,function,O
3743,.,O
3744,We,O
3744,then,O
3744,present,O
3744,a,O
3744,novel,B
3744,method,I
3744,of,I
3744,inserting,B
3744,these,O
3744,selected,B
3744,commonsense,B
3744,paths,I
3744,between,B
3744,the,O
3744,hops,B
3744,of,O
3744,document,B
3744,-,I
3744,context,I
3744,reasoning,I
3744,within,B
3744,our,B
3744,model,I
3744,",",O
3744,via,B
3744,the,O
3744,Necessary,B
3744,and,I
3744,Optional,I
3744,Information,I
3744,Cell,I
3744,(,I
3744,NOIC,I
3744,),I
3744,",",O
3744,which,O
3744,employs,B
3744,a,O
3744,selectivelygated,B
3744,attention,I
3744,mechanism,I
3744,that,B
3744,utilizes,I
3744,commonsense,O
3744,information,O
3744,to,B
3744,effectively,I
3744,fill,I
3744,in,I
3744,gaps,B
3744,of,O
3744,inference,O
3744,.,O
3745,Commonsense,O
3745,for,O
3745,Generative,B
3745,Multi,I
3745,-,I
3745,Hop,I
3745,Question,I
3745,Answering,I
3745,Tasks,O
3746,The,O
3746,first,B
3746,simplification,I
3746,is,O
3746,to,B
3746,use,I
3746,our,O
3746,model,O
3746,without,B
3746,the,O
3746,input,B
3746,attention,I
3746,mechanism,I
3746,but,O
3746,with,B
3746,the,O
3746,pooling,B
3746,attention,O
3746,layer,O
3746,.,O
3747,In,O
3747,this,O
3747,paper,O
3747,",",O
3747,we,O
3747,explore,O
3747,the,O
3747,task,O
3747,of,O
3747,machine,B
3747,reading,I
3747,comprehension,I
3747,(,I
3747,MRC,I
3747,),I
3747,based,I
3747,QA,I
3747,.,O
3748,Much,O
3748,progress,O
3748,has,O
3748,been,O
3748,made,O
3748,in,O
3748,reasoning,B
3748,-,I
3748,based,I
3748,MRC,I
3748,-,O
3748,QA,O
3748,on,O
3748,the,O
3748,bAbI,O
3748,dataset,O
3748,",",O
3748,which,O
3748,contains,O
3748,questions,O
3748,that,O
3748,require,O
3748,the,O
3748,combination,O
3748,of,O
3748,multiple,O
3748,disjoint,O
3748,pieces,O
3748,of,O
3748,evidence,O
3748,in,O
3748,the,O
3748,context,O
3748,.,O
3749,We,O
3749,see,B
3749,empirically,I
3749,that,I
3749,our,B
3749,model,I
3749,outperforms,B
3749,all,B
3749,generative,I
3749,models,I
3749,on,B
3749,NarrativeQA,B
3749,",",O
3749,and,O
3749,is,O
3749,competitive,B
3749,with,B
3749,the,O
3749,top,B
3749,span,I
3749,prediction,I
3749,models,O
3749,.,O
3750,Furthermore,O
3750,",",O
3750,with,B
3750,the,I
3750,NOIC,B
3750,commonsense,I
3750,integration,I
3750,",",O
3750,we,O
3750,were,O
3750,able,B
3750,to,I
3750,further,B
3750,improve,I
3750,performance,B
3750,(,O
3750,p,O
3750,<,O
3750,0.001,O
3750,on,O
3750,all,O
3750,metrics,O
3750,5,O
3750,),O
3750,",",O
3750,establishing,B
3750,a,O
3750,new,B
3750,state,I
3750,-,I
3750,of,I
3750,-,O
3750,the,O
3750,-,O
3750,art,O
3750,for,B
3750,the,O
3750,task,B
3750,.,O
3751,We,O
3751,also,O
3751,see,B
3751,that,I
3751,our,B
3751,model,I
3751,performs,B
3751,reasonably,B
3751,well,I
3751,on,B
3751,WikiHop,B
3751,",",O
3751,and,O
3751,further,O
3751,achieves,B
3751,promising,B
3751,initial,I
3751,improvements,I
3751,via,B
3751,the,O
3751,addition,B
3751,of,B
3751,commonsense,B
3751,",",O
3751,hinting,B
3751,at,I
3751,the,O
3751,generalizability,B
3751,of,O
3751,our,O
3751,approaches,O
3751,.,O
3752,We,O
3752,speculate,B
3752,that,O
3752,the,O
3752,improvement,B
3752,is,O
3752,smaller,B
3752,on,B
3752,Wikihop,B
3752,because,O
3752,only,O
3752,approximately,O
3752,11,O
3752,%,O
3752,of,O
3752,WikiHop,O
3752,data,O
3752,points,O
3752,require,O
3752,commonsense,O
3752,and,O
3752,because,O
3752,WikiHop,O
3752,data,O
3752,requires,O
3752,more,O
3752,fact,O
3752,-,O
3752,based,O
3752,commonsense,O
3752,(,O
3752,e.g.,O
3753,Removing,B
3753,the,O
3753,independent,B
3753,span,I
3753,loss,I
3753,(,I
3753,indep,I
3753,-,I
3753,I,I
3753,),I
3753,results,B
3753,in,I
3753,a,O
3753,performance,B
3753,drop,I
3753,for,B
3753,all,B
3753,answerable,I
3753,questions,I
3753,(,O
3753,HasAns,O
3753,),O
3753,",",O
3753,indicating,O
3753,that,O
3753,this,O
3753,loss,O
3753,helps,O
3753,the,O
3753,model,O
3753,in,O
3753,better,O
3753,identifying,O
3753,the,O
3753,answer,O
3753,boundary,O
3753,.,O
3754,Ablating,B
3754,independent,B
3754,no,B
3754,-,I
3754,answer,I
3754,loss,I
3754,(,I
3754,indep,I
3754,-,O
3754,II,O
3754,),O
3754,",",O
3754,on,B
3754,the,O
3754,other,O
3754,hand,O
3754,",",O
3754,causes,B
3754,little,B
3754,influence,I
3754,on,O
3754,HasAns,B
3754,",",O
3754,but,O
3754,leads,B
3754,to,I
3754,a,O
3754,severe,B
3754,decline,I
3754,on,O
3754,no,O
3754,-,O
3754,answer,O
3754,accuracy,O
3754,(,O
3754,NoAns,O
3754,ACC,O
3754,),O
3754,.,O
3755,Ablating,O
3755,two,B
3755,auxiliary,I
3755,losses,I
3755,",",O
3755,however,O
3755,",",O
3755,leads,B
3755,to,I
3755,an,O
3755,over,B
3755,all,I
3755,degradation,I
3755,on,B
3755,the,O
3755,curve,B
3755,",",O
3755,but,O
3755,it,O
3755,still,O
3755,outperforms,B
3755,the,O
3755,baseline,B
3755,by,B
3755,a,O
3755,large,B
3755,margin,I
3755,.,O
3756,In,B
3756,a,O
3756,more,O
3756,controlled,O
3756,comparison,O
3756,-,O
3756,with,B
3756,shallow,B
3756,architectures,I
3756,and,I
3756,the,O
3756,basic,B
3756,interaction,I
3756,(,I
3756,linearly,I
3756,transformed,I
3756,and,O
3756,non-linearly,O
3756,squashed,O
3756,),O
3756,-,O
3756,TBCNNs,B
3756,",",O
3756,of,O
3756,both,O
3756,variants,O
3756,",",O
3756,consistently,B
3756,outperform,I
3756,RNNs,B
3756,to,B
3756,a,O
3756,large,B
3756,extent,I
3756,(,O
3756,50.4,O
3756,-,O
3756,51.4,O
3756,%,O
3756,versus,O
3756,43.2,O
3756,%,O
3756,),O
3756,;,O
3756,they,O
3756,also,O
3756,consistently,O
3756,outperform,O
3756,"""",O
3756,flat,O
3756,"""",O
3756,CNNs,O
3756,by,B
3756,more,O
3756,than,O
3756,10,B
3756,%,O
3756,.,O
3757,Finally,O
3757,",",O
3757,deleting,B
3757,both,B
3757,of,I
3757,two,I
3757,losses,I
3757,causes,B
3757,a,O
3757,degradation,B
3757,of,O
3757,more,B
3757,than,I
3757,1.5,I
3757,points,I
3757,on,B
3757,the,O
3757,over,B
3757,all,I
3757,performance,I
3757,in,B
3757,terms,I
3757,of,O
3757,F1,B
3757,",",O
3757,with,B
3757,or,I
3757,without,I
3757,ELMo,B
3757,embeddings,I
3757,.,O
3758,Adding,B
3758,ELMo,B
3758,embeddings,I
3758,",",O
3758,however,O
3758,",",O
3758,does,B
3758,not,I
3758,boost,B
3758,the,O
3758,performance,B
3758,.,O
3759,We,O
3759,find,B
3759,that,I
3759,the,O
3759,improvement,B
3759,on,B
3759,noanswer,B
3759,accuracy,I
3759,is,B
3759,significant,B
3759,.,O
3760,We,O
3760,observe,B
3760,that,O
3760,RMR,B
3760,+,I
3760,ELMo,I
3760,+,O
3760,Verifier,O
3760,achieves,B
3760,the,O
3760,best,B
3760,precision,I
3760,when,B
3760,the,O
3760,recall,B
3760,is,B
3760,less,B
3760,than,I
3760,80,I
3760,.,O
3761,We,O
3761,run,B
3761,a,O
3761,grid,B
3761,search,I
3761,on,O
3761,?,O
3762,among,B
3762,[,B
3762,0.1,I
3762,",",I
3762,0.3,I
3762,",",O
3762,0.5,O
3762,",",O
3762,0.7,O
3762,",",O
3762,1,O
3762,",",O
3762,2,O
3762,],O
3762,.,O
3763,For,B
3763,Model,B
3763,-,I
3763,II,I
3763,",",O
3763,the,O
3763,Adam,B
3763,optimizer,I
3763,(,I
3763,Kingma,I
3763,and,I
3763,Ba,I
3763,2014,I
3763,),I
3763,with,B
3763,a,O
3763,learning,B
3763,rate,I
3763,of,B
3763,0.0008,B
3763,is,O
3763,used,O
3763,",",O
3763,the,O
3763,hidden,B
3763,size,I
3763,is,O
3763,set,B
3763,as,I
3763,300,B
3763,",",O
3763,and,O
3763,a,O
3763,dropout,B
3763,),O
3763,of,O
3763,0.3,B
3763,is,O
3763,applied,O
3763,for,O
3763,preventing,B
3763,overfitting,I
3763,.,O
3764,The,O
3764,batch,B
3764,size,I
3764,is,B
3764,48,B
3764,for,B
3764,the,O
3764,reader,B
3764,",",O
3764,64,B
3764,for,O
3764,Model,B
3764,-,I
3764,II,I
3764,",",O
3764,and,O
3764,32,B
3764,for,O
3764,Model,O
3764,-,O
3764,I,O
3764,as,O
3764,well,O
3764,as,O
3764,Model,O
3764,-,O
3764,III,O
3764,.,O
3765,We,O
3765,use,B
3765,the,O
3765,Glo,B
3765,Ve,I
3765,100D,I
3765,embeddings,I
3765,for,B
3765,the,O
3765,reader,B
3765,",",O
3765,and,O
3765,300D,B
3765,embeddings,O
3765,for,O
3765,Model,B
3765,-,I
3765,II,I
3765,and,O
3765,Model,O
3765,-,O
3765,III,O
3765,.,O
3766,We,O
3766,utilize,B
3766,the,O
3766,nltk,B
3766,tokenizer,I
3766,3,O
3766,to,B
3766,preprocess,I
3766,passages,B
3766,and,I
3766,questions,I
3766,",",O
3766,as,O
3766,well,O
3766,as,O
3766,split,B
3766,sentences,B
3766,.,O
3767,To,B
3767,address,O
3767,the,O
3767,above,O
3767,issue,O
3767,",",O
3767,we,O
3767,propose,B
3767,a,O
3767,read,B
3767,-,I
3767,then,I
3767,-,O
3767,verify,O
3767,system,O
3767,that,O
3767,aims,B
3767,to,O
3767,be,O
3767,robust,B
3767,to,O
3767,unanswerable,B
3767,questions,I
3767,in,O
3767,this,O
3767,paper,O
3767,.,O
3768,We,O
3768,also,O
3768,observe,B
3768,d-,B
3768,TBCNN,I
3768,achieves,B
3768,higher,B
3768,performance,I
3768,than,B
3768,c,B
3768,-,I
3768,TBCNN,O
3768,.,O
3769,As,O
3769,shown,O
3769,in,O
3769,",",O
3769,our,B
3769,system,I
3769,consists,B
3769,of,I
3769,two,B
3769,components,I
3769,:,O
3769,(,O
3769,1,O
3769,),O
3769,a,O
3769,no-answer,B
3769,reader,I
3769,for,B
3769,extracting,I
3769,candidate,I
3769,answers,I
3769,and,O
3769,detecting,B
3769,unanswerable,B
3769,questions,I
3769,",",O
3769,and,O
3769,(,O
3769,2,O
3769,),O
3769,an,O
3769,answer,B
3769,verifier,I
3769,for,O
3769,deciding,O
3769,whether,O
3769,or,O
3769,not,O
3769,the,O
3769,extracted,B
3769,candidate,O
3769,is,B
3769,legitimate,B
3769,.,O
3770,First,O
3770,",",O
3770,we,O
3770,augment,B
3770,existing,B
3770,readers,I
3770,with,B
3770,two,B
3770,auxiliary,I
3770,losses,I
3770,",",O
3770,to,O
3770,better,O
3770,handle,O
3770,answer,O
3770,extraction,O
3770,and,O
3770,no,O
3770,-,O
3770,answer,O
3770,detection,O
3770,respectively,O
3770,.,O
3771,We,O
3771,solve,O
3771,this,O
3771,problem,O
3771,by,O
3771,introducing,B
3771,an,O
3771,independent,B
3771,span,I
3771,loss,I
3771,that,O
3771,aims,B
3771,to,I
3771,concentrate,B
3771,on,B
3771,the,O
3771,answer,B
3771,extraction,I
3771,task,I
3771,regardless,O
3771,of,O
3771,the,O
3771,answerability,O
3771,of,O
3771,the,O
3771,question,O
3771,.,O
3772,In,O
3772,order,O
3772,to,B
3772,not,O
3772,conflict,O
3772,with,B
3772,no,B
3772,-,O
3772,answer,O
3772,detection,O
3772,",",O
3772,we,O
3772,leverage,B
3772,a,O
3772,multi-head,B
3772,pointer,I
3772,network,I
3772,to,O
3772,generate,O
3772,two,B
3772,pairs,I
3772,of,I
3772,span,I
3772,scores,I
3772,",",O
3772,where,B
3772,one,B
3772,pair,I
3772,is,B
3772,normalized,B
3772,with,O
3772,the,O
3772,no,O
3772,-answer,O
3772,score,O
3772,and,O
3772,the,O
3772,other,B
3772,is,O
3772,used,B
3772,for,I
3772,our,O
3772,auxiliary,B
3772,loss,I
3772,.,O
3773,Besides,O
3773,",",O
3773,we,O
3773,present,B
3773,another,B
3773,independent,I
3773,noanswer,I
3773,loss,I
3773,to,B
3773,further,I
3773,alleviate,I
3773,the,O
3773,confliction,B
3773,",",O
3773,by,O
3773,focusing,B
3773,on,I
3773,the,O
3773,no-answer,B
3773,detection,I
3773,task,I
3773,without,B
3773,considering,O
3773,the,O
3773,shared,B
3773,normalization,I
3773,of,B
3773,answer,B
3773,extraction,I
3773,.,O
3774,Second,O
3774,",",O
3774,in,O
3774,addition,O
3774,to,O
3774,the,O
3774,standard,O
3774,reading,O
3774,phase,O
3774,",",O
3774,we,O
3774,introduce,B
3774,an,O
3774,additional,B
3774,answer,B
3774,verifying,I
3774,phase,O
3774,",",O
3774,which,O
3774,aims,B
3774,at,I
3774,finding,B
3774,local,B
3774,entailment,I
3774,that,O
3774,supports,B
3774,the,O
3774,answer,O
3774,by,O
3774,comparing,O
3774,the,O
3774,answer,O
3774,sentence,O
3774,with,O
3774,the,O
3774,question,O
3774,.,O
3775,Inspired,O
3775,by,O
3775,recent,O
3775,advances,O
3775,in,O
3775,natural,O
3775,language,O
3775,inference,O
3775,(,O
3775,NLI,O
3775,),O
3775,",",O
3775,we,O
3775,investigate,B
3775,three,B
3775,different,I
3775,architectures,I
3775,for,B
3775,the,O
3775,answer,B
3775,verifying,I
3775,task,I
3775,.,O
3776,The,O
3776,first,B
3776,one,I
3776,is,B
3776,a,O
3776,sequential,B
3776,model,I
3776,that,O
3776,takes,B
3776,two,B
3776,sentences,I
3776,as,B
3776,along,B
3776,sequence,I
3776,",",O
3776,while,O
3776,the,O
3776,second,B
3776,one,O
3776,attempts,O
3776,to,O
3776,capture,B
3776,interactions,B
3776,between,B
3776,two,O
3776,sentences,O
3776,.,O
3777,The,O
3777,last,B
3777,one,I
3777,is,B
3777,a,O
3777,hybrid,B
3777,model,I
3777,that,B
3777,combines,I
3777,the,O
3777,above,B
3777,two,I
3777,models,I
3777,to,O
3777,test,O
3777,if,O
3777,the,O
3777,performance,O
3777,can,O
3777,be,O
3777,further,O
3777,improved,O
3777,.,O
3778,Read,O
3778,+,O
3778,Verify,O
3778,:,O
3778,Machine,B
3778,Reading,I
3778,Comprehension,I
3778,with,O
3778,Unanswerable,O
3778,Questions,O
3779,After,O
3779,removing,B
3779,the,O
3779,deep,B
3779,transformation,I
3779,(,O
3779,i.e.,O
3780,",",O
3780,the,O
3780,techniques,O
3780,introduced,O
3780,in,B
3780,Section,O
3780,2.2,O
3780,),O
3780,",",O
3780,both,O
3780,TNet,B
3780,-,I
3780,LF,I
3780,and,I
3780,TNet,O
3780,-,O
3780,AS,O
3780,are,O
3780,reduced,B
3780,to,I
3780,TNet,O
3780,w/o,O
3780,transformation,O
3780,(,O
3780,where,O
3780,position,O
3780,relevance,O
3780,is,O
3780,kept,O
3780,),O
3780,",",O
3780,and,O
3780,their,O
3780,results,B
3780,in,O
3780,both,O
3780,accuracy,B
3780,and,O
3780,F,O
3780,1,O
3780,measure,O
3780,are,O
3780,incomparable,B
3780,with,I
3780,those,O
3780,of,O
3780,TNet,O
3780,.,O
3781,As,O
3781,we,O
3781,can,O
3781,see,O
3781,",",O
3781,our,B
3781,system,I
3781,obtains,B
3781,state,B
3781,-,I
3781,of,B
3781,the,I
3781,-,O
3781,art,O
3781,results,O
3781,by,B
3781,achieving,I
3781,an,O
3781,EM,B
3781,score,I
3781,of,O
3781,71.7,B
3781,and,O
3781,a,O
3781,F,B
3781,1,I
3781,score,O
3781,of,O
3781,74.2,B
3781,on,B
3781,the,O
3781,test,B
3781,set,I
3781,.,O
3782,Notice,O
3782,that,O
3782,SLQA,B
3782,+,I
3782,has,O
3782,reached,B
3782,a,O
3782,comparable,B
3782,result,I
3782,compared,B
3782,to,I
3782,our,B
3782,approach,I
3782,.,O
3783,Our,O
3783,optimized,O
3783,C,O
3783,++/,O
3783,CUDA,O
3783,models,O
3783,and,O
3783,the,O
3783,Theano,B
3783,source,I
3783,code,I
3783,for,O
3783,the,O
3783,full,B
3783,SPINN,I
3783,are,O
3783,available,O
3783,at,O
3783,https://github.com,B
3783,/,I
3783,stanfordnlp/spinn.,I
3784,We,O
3784,fix,B
3784,the,O
3784,model,B
3784,dimension,I
3784,D,I
3784,and,O
3784,the,O
3784,word,B
3784,embedding,I
3784,dimension,O
3784,at,B
3784,300,B
3784,.,O
3785,We,O
3785,run,O
3785,the,O
3785,CPU,B
3785,performance,I
3785,test,I
3785,on,B
3785,a,O
3785,2.20,B
3785,GHz,I
3785,16,I
3785,core,I
3785,Intel,I
3785,Xeon,I
3785,E5-2660,I
3785,processor,I
3785,with,B
3785,hyperthreading,B
3785,enabled,O
3785,.,O
3786,We,O
3786,test,B
3786,our,O
3786,thin,B
3786,-,I
3786,stack,I
3786,implementation,I
3786,and,O
3786,the,O
3786,RNN,B
3786,model,I
3786,on,B
3786,an,O
3786,NVIDIA,B
3786,Titan,I
3786,X,I
3786,GPU,I
3786,.,O
3787,This,O
3787,paper,O
3787,introduces,B
3787,a,O
3787,new,O
3787,model,O
3787,to,O
3787,address,O
3787,both,O
3787,these,O
3787,issues,O
3787,:,O
3787,the,O
3787,Stack,B
3787,-,I
3787,augmented,I
3787,Parser,I
3787,-,O
3787,Interpreter,O
3787,Neural,O
3787,Network,O
3787,",",O
3787,or,O
3787,SPINN,B
3787,",",O
3787,shown,O
3787,in,O
3787,.,O
3788,SPINN,B
3788,executes,B
3788,the,O
3788,computations,B
3788,of,B
3788,a,O
3788,tree,B
3788,-,I
3788,structured,I
3788,model,I
3788,in,B
3788,a,O
3788,linearized,B
3788,sequence,I
3788,",",O
3788,and,O
3788,can,O
3788,incorporate,B
3788,a,O
3788,neural,B
3788,network,I
3788,parser,I
3788,that,B
3788,produces,I
3788,the,O
3788,required,B
3788,parse,I
3788,structure,I
3788,on,O
3788,the,O
3788,fly,O
3788,.,O
3789,This,O
3789,design,O
3789,improves,B
3789,upon,I
3789,the,O
3789,TreeRNN,B
3789,architecture,I
3789,in,O
3789,three,O
3789,ways,O
3789,:,O
3790,At,B
3790,test,B
3790,time,I
3790,",",O
3790,it,O
3790,can,B
3790,simultaneously,I
3790,parse,B
3790,and,O
3790,interpret,B
3790,unparsed,B
3790,sentences,I
3790,",",O
3790,removing,B
3790,the,O
3790,dependence,B
3790,on,B
3790,an,O
3790,external,B
3790,parser,I
3790,at,O
3790,nearly,O
3790,no,O
3790,additional,O
3790,computational,O
3790,cost,O
3790,.,O
3791,It,O
3791,shows,B
3791,that,I
3791,the,O
3791,integration,B
3791,of,B
3791,target,B
3791,information,I
3791,into,B
3791,the,O
3791,word,B
3791,-,I
3791,level,I
3791,representations,I
3791,is,O
3791,crucial,B
3791,for,I
3791,good,B
3791,performance,I
3791,.,O
3792,Secondly,O
3792,",",O
3792,it,O
3792,supports,B
3792,batched,B
3792,computation,I
3792,for,B
3792,both,O
3792,parsed,B
3792,and,I
3792,unparsed,I
3792,sentences,I
3792,",",O
3792,yielding,B
3792,dramatic,B
3792,speedups,I
3792,over,B
3792,standard,B
3792,TreeRNNs,I
3792,.,O
3793,Finally,O
3793,",",O
3793,it,O
3793,supports,O
3793,a,O
3793,novel,B
3793,tree,I
3793,-,I
3793,sequence,I
3793,hybrid,I
3793,architecture,I
3793,for,B
3793,handling,I
3793,local,B
3793,linear,I
3793,context,I
3793,in,B
3793,sentence,B
3793,interpretation,I
3793,.,O
3794,A,O
3794,Fast,O
3794,Unified,O
3794,Model,O
3794,for,O
3794,Parsing,B
3794,and,O
3794,Sentence,B
3794,Understanding,I
3795,We,O
3795,find,B
3795,that,I
3795,the,O
3795,bare,B
3795,SPINN,B
3795,-,I
3795,PI,I
3795,-,O
3795,NT,O
3795,model,O
3795,performs,B
3795,little,B
3795,better,I
3795,than,B
3795,the,O
3795,RNN,B
3795,baseline,I
3795,",",O
3795,but,O
3795,that,O
3795,SPINN,O
3795,-,O
3795,PI,O
3795,with,B
3795,the,O
3795,added,B
3795,tracking,I
3795,LSTM,I
3795,performs,O
3795,well,B
3795,.,O
3796,The,O
3796,full,B
3796,SPINN,I
3796,model,I
3796,with,B
3796,its,O
3796,relatively,B
3796,weak,I
3796,internal,I
3796,parser,I
3796,performs,B
3796,slightly,B
3796,less,I
3796,well,I
3796,",",O
3796,but,O
3796,nonetheless,O
3796,robustly,B
3796,exceeds,I
3796,the,O
3796,performance,B
3796,of,B
3796,the,O
3796,RNN,B
3796,baseline,I
3796,.,O
3797,Both,O
3797,SPINN,O
3797,-,O
3797,PI,O
3797,and,O
3797,the,O
3797,full,O
3797,SPINN,O
3797,significantly,B
3797,outperform,I
3797,all,O
3797,previous,B
3797,sentence,I
3797,-,O
3797,encoding,O
3797,models,O
3797,.,O
3798,Most,O
3798,notably,O
3798,",",O
3798,these,O
3798,models,O
3798,outperform,B
3798,the,O
3798,tree,B
3798,-,I
3798,based,I
3798,CNN,I
3798,of,O
3798,",",O
3798,which,O
3798,also,O
3798,uses,B
3798,tree,O
3798,-,O
3798,structured,O
3798,composition,O
3798,for,B
3798,local,B
3798,feature,I
3798,extraction,I
3798,",",O
3798,but,O
3798,uses,O
3798,simpler,B
3798,pooling,I
3798,techniques,I
3798,to,B
3798,build,I
3798,sentence,B
3798,features,I
3798,in,O
3798,the,O
3798,interest,O
3798,of,O
3798,efficiency,O
3798,.,O
3799,The,O
3799,full,B
3799,SPINN,I
3799,performed,B
3799,moderately,B
3799,well,I
3799,at,B
3799,reproducing,I
3799,the,O
3799,Stanford,B
3799,Parser,I
3799,'s,I
3799,parses,I
3799,of,B
3799,the,O
3799,SNLI,B
3799,data,I
3799,at,O
3799,a,O
3799,transition,O
3799,-,O
3799,by,O
3799,-,O
3799,transition,O
3799,level,O
3799,",",O
3799,with,B
3799,92.4,B
3799,%,I
3799,accuracy,I
3799,at,O
3799,test,B
3799,time,I
3799,.,O
3800,Our,O
3800,results,O
3800,show,B
3800,that,B
3800,a,O
3800,model,B
3800,that,O
3800,uses,O
3800,tree,O
3800,-,O
3800,structured,O
3800,composition,O
3800,fully,O
3800,(,O
3800,SPINN,O
3800,),O
3800,outper,B
3800,-,O
3800,forms,O
3800,one,B
3800,which,B
3800,uses,O
3800,it,O
3800,only,B
3800,partially,I
3800,(,O
3800,tree,O
3800,-,O
3800,based,O
3800,CNN,O
3800,),O
3800,",",O
3800,which,O
3800,in,O
3800,turn,O
3800,outperforms,B
3800,one,O
3800,which,O
3800,does,O
3800,not,B
3800,use,I
3800,it,O
3800,at,O
3800,all,O
3800,(,O
3800,RNN,O
3800,),O
3800,.,O
3801,Comparing,B
3801,the,O
3801,results,B
3801,of,B
3801,TNet,B
3801,and,I
3801,TNet,O
3801,w/o,O
3801,context,O
3801,(,O
3801,where,O
3801,TST,O
3801,and,O
3801,position,O
3801,relevance,O
3801,are,O
3801,kept,O
3801,),O
3801,",",O
3801,we,O
3801,observe,B
3801,that,O
3801,the,O
3801,performance,B
3801,of,O
3801,TNet,O
3801,w/o,O
3801,context,O
3801,drops,B
3801,significantly,B
3801,on,B
3801,LAPTOP,B
3801,and,O
3801,REST,O
3801,7,O
3801,",",O
3801,while,O
3801,on,O
3801,TWITTER,B
3801,",",O
3801,TNet,O
3801,w/o,O
3801,context,O
3801,performs,B
3801,very,B
3801,competitive,I
3801,(,O
3801,p-,O
3801,values,O
3801,with,O
3801,TNet,O
3801,-,O
3801,LF,O
3801,and,O
3801,TNet,O
3801,-,O
3801,AS,O
3801,are,O
3801,0.066,O
3801,and,O
3801,0.053,O
3801,respectively,O
3801,for,O
3801,Accuracy,O
3801,),O
3801,.,O
3802,Each,O
3802,sequence,O
3802,as,O
3802,the,O
3802,sum,B
3802,of,B
3802,the,O
3802,embeddings,B
3802,of,O
3802,the,O
3802,words,B
3802,it,I
3802,contains,I
3802,",",O
3802,then,O
3802,they,O
3802,are,O
3802,concatenated,B
3802,and,I
3802,fed,I
3802,to,B
3802,a,O
3802,MLP,B
3802,.,O
3803,Single,O
3803,LSTM,O
3803,:,O
3803,A,O
3803,single,O
3803,LSTM,O
3803,to,O
3803,encode,B
3803,the,O
3803,two,B
3803,sequences,I
3803,",",O
3803,which,O
3803,is,O
3803,used,O
3803,in,O
3803,.,O
3804,Parallel,O
3804,LSTMs,O
3804,:,O
3804,Two,B
3804,sequences,I
3804,are,B
3804,encoded,B
3804,by,I
3804,two,O
3804,LSTMs,O
3804,separately,O
3804,",",O
3804,then,O
3804,they,O
3804,are,O
3804,concatenated,B
3804,and,I
3804,fed,I
3804,to,B
3804,a,O
3804,MLP,B
3804,.,O
3805,Attention,O
3805,LSTMs,O
3805,:,O
3805,An,O
3805,attentive,B
3805,LSTM,I
3805,to,B
3805,encode,I
3805,two,B
3805,sentences,I
3805,into,B
3805,a,O
3805,semantic,B
3805,space,I
3805,",",O
3805,which,O
3805,used,O
3805,in,O
3805,.,O
3806,The,O
3806,word,B
3806,embeddings,I
3806,for,B
3806,all,B
3806,of,I
3806,the,O
3806,models,O
3806,are,O
3806,initialized,B
3806,with,I
3806,the,O
3806,100d,B
3806,GloVe,I
3806,vectors,I
3806,(,O
3806,840B,O
3806,token,O
3806,version,O
3806,",",O
3806,),O
3806,and,O
3806,fine,B
3806,-,I
3806,tuned,I
3806,during,I
3806,training,B
3806,to,B
3806,improve,I
3806,the,O
3806,performance,B
3806,.,O
3807,The,O
3807,other,B
3807,parameters,I
3807,are,O
3807,initialized,B
3807,by,I
3807,randomly,B
3807,sampling,I
3807,from,B
3807,uniform,B
3807,distribution,I
3807,in,B
3807,[,O
3807,?,O
3808,For,B
3808,each,B
3808,task,I
3808,",",I
3808,we,O
3808,take,B
3808,the,O
3808,hyperparameters,B
3808,which,O
3808,achieve,B
3808,the,O
3808,best,B
3808,performance,I
3808,on,B
3808,the,O
3808,development,B
3808,set,I
3808,via,B
3808,an,O
3808,small,B
3808,grid,I
3808,search,I
3808,over,B
3808,combinations,B
3808,of,B
3808,the,O
3808,initial,B
3808,learning,I
3808,rate,I
3808,[,I
3808,0.05,I
3808,",",O
3808,0.0005,O
3808,",",O
3808,0.0001,O
3808,],O
3808,",",O
3808,l,O
3808,2,O
3808,regularization,O
3808,[,O
3808,0.0,O
3808,",",O
3808,5,O
3808,E?,O
3809,6,O
3809,],O
3809,and,O
3809,the,O
3809,threshold,B
3809,value,I
3810,In,O
3810,this,O
3810,paper,O
3810,",",O
3810,we,O
3810,propose,B
3810,a,O
3810,new,B
3810,deep,I
3810,neural,I
3810,network,I
3810,architecture,I
3810,to,B
3810,model,I
3810,the,O
3810,strong,B
3810,interactions,I
3810,of,B
3810,two,B
3810,sentences,I
3810,.,O
3811,Specifically,O
3811,",",O
3811,we,O
3811,propose,O
3811,two,B
3811,interdependent,I
3811,ways,I
3811,for,B
3811,the,O
3811,coupled,O
3811,-,O
3811,LSTMs,O
3811,:,O
3811,loosely,B
3811,coupled,O
3811,model,O
3811,(,O
3811,LC,O
3811,-,O
3811,LSTMs,O
3811,),O
3811,and,O
3811,tightly,B
3811,coupled,O
3811,model,O
3811,(,O
3811,TC,O
3811,-,O
3811,LSTMs,O
3811,),O
3811,.,O
3812,Different,O
3812,with,O
3812,modelling,O
3812,two,B
3812,sentences,O
3812,with,O
3812,separated,O
3812,LSTMs,O
3812,",",O
3812,we,O
3812,utilize,B
3812,two,O
3812,interdependent,O
3812,LSTMs,O
3812,",",O
3812,called,B
3812,coupled,B
3812,-,I
3812,LSTMs,O
3812,",",O
3812,to,B
3812,fully,I
3812,affect,I
3812,each,B
3812,other,I
3812,at,B
3812,different,O
3812,time,O
3812,steps,O
3812,.,O
3813,TNet,O
3813,w/o,O
3813,context,O
3813,performs,B
3813,consistently,B
3813,better,I
3813,than,B
3813,TNet,O
3813,w/o,O
3813,transformation,O
3813,",",O
3813,which,O
3813,verifies,O
3813,the,O
3813,efficacy,O
3813,of,O
3813,the,O
3813,target,O
3813,specific,O
3813,transformation,O
3813,(,O
3813,TST,O
3813,),O
3813,",",O
3813,before,O
3813,applying,O
3813,context,O
3813,-,O
3813,preserving,O
3813,.,O
3814,To,O
3814,utilize,O
3814,all,B
3814,the,I
3814,information,I
3814,of,B
3814,four,B
3814,directions,I
3814,of,O
3814,coupled,B
3814,-,I
3814,LSTMs,I
3814,",",O
3814,we,O
3814,aggregate,B
3814,them,O
3814,and,O
3814,adopt,B
3814,a,O
3814,dynamic,B
3814,pooling,I
3814,strategy,I
3814,to,O
3814,automatically,O
3814,select,O
3814,the,O
3814,most,B
3814,informative,I
3814,interaction,I
3814,signals,I
3814,.,O
3815,Finally,O
3815,",",O
3815,we,O
3815,feed,B
3815,them,I
3815,into,I
3815,a,O
3815,fully,B
3815,connected,I
3815,layer,I
3815,",",O
3815,followed,B
3815,by,I
3815,an,O
3815,output,B
3815,layer,O
3815,to,B
3815,compute,I
3815,the,O
3815,matching,B
3815,score,I
3815,.,O
3816,The,O
3816,output,B
3816,of,B
3816,coupled,B
3816,-,I
3816,LSTMs,I
3816,at,B
3816,each,B
3816,step,I
3816,depends,B
3816,on,I
3816,both,B
3816,sentences,I
3816,.,O
3817,Recently,O
3817,",",O
3817,there,O
3817,is,O
3817,rising,O
3817,interest,O
3817,in,O
3817,modelling,B
3817,the,I
3817,interactions,I
3817,of,I
3817,two,I
3817,sentences,I
3817,with,O
3817,deep,O
3817,neural,O
3817,networks,O
3817,.,O
3818,Among,O
3818,these,O
3818,tasks,O
3818,",",O
3818,a,O
3818,common,O
3818,problem,O
3818,is,O
3818,modelling,B
3818,the,I
3818,relevance,I
3818,/,I
3818,similarity,I
3818,of,I
3818,the,O
3818,sentence,O
3818,pair,O
3818,",",O
3818,which,O
3818,is,O
3818,also,O
3818,called,O
3818,text,B
3818,semantic,I
3818,matching,I
3818,.,O
3819,Our,O
3819,proposed,B
3819,two,I
3819,C,I
3819,-,I
3819,LSTMs,I
3819,models,I
3819,with,I
3819,four,I
3819,stacked,I
3819,blocks,I
3819,outperform,B
3819,all,B
3819,the,I
3819,competitor,I
3819,models,O
3819,",",O
3819,which,O
3819,indicates,B
3819,that,I
3819,our,O
3819,thinner,O
3819,and,O
3819,deeper,O
3819,network,O
3819,does,B
3819,work,I
3819,effectively,I
3819,.,O
3820,Compared,O
3820,with,O
3820,attention,B
3820,LSTMs,I
3820,",",O
3820,our,B
3820,two,I
3820,models,I
3820,achieve,B
3820,comparable,B
3820,results,I
3820,to,O
3820,them,O
3820,using,B
3820,much,B
3820,fewer,I
3820,parameters,I
3820,(,I
3820,nearly,I
3820,1,I
3820,/,I
3820,5,I
3820,),I
3820,.,O
3821,By,O
3821,stacking,O
3821,C,B
3821,-,I
3821,LSTMs,I
3821,",",O
3821,the,O
3821,performance,B
3821,of,O
3821,them,O
3821,are,O
3821,improved,B
3821,significantly,B
3821,",",O
3821,and,O
3821,the,O
3821,four,O
3821,stacked,O
3821,TC,O
3821,-,O
3821,LSTMs,O
3821,achieve,O
3821,85.1,O
3821,%,O
3821,accuracy,O
3821,on,O
3821,this,O
3821,dataset,O
3821,.,O
3822,All,O
3822,of,O
3822,the,O
3822,produced,B
3822,p-values,I
3822,are,B
3822,less,I
3822,than,I
3822,0.05,B
3822,",",O
3822,suggesting,B
3822,that,I
3822,the,O
3822,improvements,B
3822,brought,B
3822,in,I
3822,by,I
3822,position,B
3822,information,I
3822,are,O
3822,significant,B
3822,.,O
3823,We,O
3823,run,O
3823,the,O
3823,task,O
3823,with,B
3823,three,B
3823,additional,I
3823,baselines,I
3823,:,O
3823,NUTM,B
3823,using,B
3823,direct,B
3823,attention,I
3823,(,I
3823,DA,I
3823,),I
3823,",",I
3823,NUTM,O
3823,using,O
3823,key,B
3823,-,I
3823,value,I
3823,without,I
3823,regularization,I
3823,(,O
3823,KV,O
3823,),O
3823,",",O
3823,NUTM,O
3823,using,O
3823,fixed,B
3823,",",O
3823,uniform,O
3823,program,O
3823,distribution,O
3823,(,O
3823,UP,O
3823,),O
3823,and,O
3823,a,O
3823,vanilla,B
3823,NTM,I
3823,with,O
3823,2,O
3823,memory,O
3823,heads,O
3823,(,O
3823,h,O
3823,=,O
3823,2,O
3823,),O
3823,.,O
3824,The,O
3824,results,O
3824,demonstrate,B
3824,that,O
3824,DA,B
3824,exhibits,B
3824,fast,B
3824,yet,I
3824,shallow,I
3824,convergence,I
3824,.,O
3825,It,O
3825,tends,O
3825,to,B
3825,fall,B
3825,into,I
3825,local,B
3825,minima,I
3825,",",O
3825,which,O
3825,finally,O
3825,fails,B
3825,to,O
3825,reach,O
3825,zero,B
3825,loss,I
3825,.,O
3826,Key-,O
3826,value,O
3826,attention,O
3826,helps,B
3826,NUTM,B
3826,converge,I
3826,completely,O
3826,with,B
3826,fewer,B
3826,iterations,I
3826,.,O
3827,The,O
3827,performance,B
3827,is,B
3827,further,B
3827,improved,I
3827,with,B
3827,the,O
3827,proposed,B
3827,regularization,I
3827,loss,I
3827,.,O
3828,UP,B
3828,underperforms,B
3828,NUTM,B
3828,as,B
3828,it,O
3828,lacks,B
3828,dynamic,B
3828,programs,I
3828,.,O
3829,The,O
3829,NTM,B
3829,with,B
3829,2,I
3829,heads,I
3829,shows,B
3829,slightly,B
3829,better,I
3829,convergence,I
3829,compared,B
3829,to,I
3829,the,O
3829,NTM,O
3829,",",O
3829,yet,O
3829,obviously,O
3829,underperforms,B
3829,NUTM,B
3829,(,I
3829,p,I
3829,=,I
3829,2,O
3829,),O
3829,with,O
3829,1,B
3829,head,I
3829,and,I
3829,fewer,I
3829,parameters,I
3829,.,O
3830,Our,O
3830,goal,O
3830,is,O
3830,to,O
3830,advance,O
3830,a,O
3830,step,B
3830,further,I
3830,towards,I
3830,UTM,B
3830,by,B
3830,coupling,I
3830,a,O
3830,MANN,B
3830,with,B
3830,an,O
3830,external,B
3830,program,I
3830,memory,I
3830,.,O
3831,The,O
3831,program,B
3831,memory,I
3831,co-exists,B
3831,with,I
3831,the,O
3831,data,B
3831,memory,O
3831,in,B
3831,the,O
3831,MANN,B
3831,",",O
3831,providing,B
3831,more,O
3831,flexibility,O
3831,",",O
3831,reuseability,O
3831,and,O
3831,modularity,O
3831,in,O
3831,learning,B
3831,complicated,B
3831,tasks,I
3831,.,O
3832,The,O
3832,program,O
3832,memory,O
3832,stores,B
3832,the,O
3832,weights,B
3832,of,B
3832,the,O
3832,MANN,B
3832,'s,I
3832,controller,I
3832,network,I
3832,",",O
3832,which,O
3832,are,O
3832,retrieved,B
3832,quickly,B
3832,via,B
3832,a,O
3832,key,B
3832,-,I
3832,value,I
3832,attention,I
3832,mechanism,I
3832,across,B
3832,timesteps,B
3832,yet,O
3832,updated,B
3832,slowly,B
3832,via,O
3832,backpropagation,B
3832,.,O
3833,SVM,B
3833,:,O
3833,It,O
3833,is,B
3833,a,O
3833,traditional,B
3833,support,I
3833,vector,I
3833,machine,I
3833,based,I
3833,model,I
3833,with,B
3833,extensive,B
3833,feature,I
3833,engineering,I
3833,;,O
3834,By,O
3834,introducing,O
3834,a,O
3834,meta,O
3834,network,O
3834,to,O
3834,moderate,O
3834,the,O
3834,operations,O
3834,of,B
3834,the,O
3834,program,O
3834,memory,O
3834,",",O
3834,our,O
3834,model,O
3834,",",O
3834,henceforth,O
3834,referred,B
3834,to,O
3834,as,O
3834,Neural,B
3834,Stored,I
3834,-,I
3834,program,O
3834,Memory,O
3834,(,O
3834,NSM,O
3834,),O
3834,",",O
3834,can,O
3834,learn,B
3834,to,O
3834,switch,B
3834,the,O
3834,programs,B
3834,/,I
3834,weights,I
3834,in,B
3834,the,O
3834,controller,B
3834,network,O
3834,appropriately,B
3834,",",O
3834,adapting,B
3834,to,O
3834,different,B
3834,functionalities,I
3834,aligning,B
3834,with,I
3834,different,O
3834,parts,O
3834,of,O
3834,a,O
3834,sequential,B
3834,task,I
3834,",",O
3834,or,O
3834,different,O
3834,tasks,O
3834,in,O
3834,continual,B
3834,and,I
3834,few,I
3834,-,O
3834,shot,O
3834,learning,O
3834,.,O
3835,In,O
3835,this,O
3835,paper,O
3835,",",O
3835,we,O
3835,introduce,O
3835,a,O
3835,new,O
3835,memory,O
3835,to,O
3835,store,O
3835,weights,O
3835,for,O
3835,the,O
3835,controller,O
3835,",",O
3835,analogous,O
3835,to,O
3835,the,O
3835,stored,B
3835,-,I
3835,program,I
3835,memory,O
3835,in,O
3835,modern,O
3835,computer,O
3835,architectures,O
3835,.,O
3836,Except,O
3836,for,O
3836,the,O
3836,Copy,O
3836,task,O
3836,",",O
3836,which,O
3836,is,O
3836,too,O
3836,simple,O
3836,",",O
3836,other,B
3836,tasks,I
3836,observe,B
3836,convergence,B
3836,speed,I
3836,improvement,I
3836,of,B
3836,NUTM,B
3836,over,B
3836,that,O
3836,of,O
3836,NTM,B
3836,",",O
3836,thereby,O
3836,validating,B
3836,the,O
3836,benefit,B
3836,of,O
3836,using,O
3836,two,B
3836,programs,I
3836,across,B
3836,timesteps,B
3836,even,B
3836,for,O
3836,the,O
3836,single,B
3836,task,O
3836,setting,O
3836,.,O
3837,NUTM,B
3837,requires,B
3837,fewer,B
3837,training,B
3837,samples,I
3837,to,B
3837,converge,B
3837,and,O
3837,it,O
3837,generalizes,B
3837,better,B
3837,to,O
3837,unseen,B
3837,sequences,I
3837,that,B
3837,are,I
3837,longer,B
3837,than,B
3837,training,O
3837,sequences,O
3837,.,O
3838,Instead,O
3838,",",O
3838,we,O
3838,utilize,B
3838,the,O
3838,order,B
3838,inherent,I
3838,in,B
3838,the,O
3838,the,O
3838,unaugmented,B
3838,sequence,I
3838,to,B
3838,decompose,I
3838,the,O
3838,graph,B
3838,into,B
3838,two,B
3838,Directed,I
3838,Acyclic,I
3838,Graphs,I
3838,(,I
3838,DAGs,I
3838,),I
3838,with,B
3838,a,O
3838,topological,B
3838,ordering,I
3838,.,O
3839,We,O
3839,introduce,B
3839,the,O
3839,Memory,B
3839,as,I
3839,Acyclic,I
3839,Graph,I
3839,Encoding,I
3839,RNN,I
3839,(,I
3839,MAGE,B
3839,-,I
3839,RNN,O
3839,),O
3839,framework,O
3839,to,B
3839,compute,I
3839,the,O
3839,representation,B
3839,of,B
3839,such,O
3839,graphs,B
3839,while,B
3839,touching,B
3839,every,B
3839,node,B
3839,only,B
3839,once,I
3839,",",O
3839,and,O
3839,implement,B
3839,a,O
3839,GRU,O
3839,version,O
3839,of,O
3839,it,O
3839,called,B
3839,MAGE,O
3839,-,O
3839,GRU,O
3839,.,O
3840,MAGE,O
3840,-,O
3840,RNN,O
3840,learns,B
3840,separate,B
3840,representations,I
3840,for,B
3840,propagation,B
3840,along,B
3840,each,B
3840,edge,I
3840,type,I
3840,",",O
3840,which,O
3840,leads,B
3840,to,I
3840,superior,B
3840,performance,I
3840,empirically,I
3840,.,O
3841,We,O
3841,use,B
3841,MAGE,B
3841,-,I
3841,RNN,I
3841,to,I
3841,model,I
3841,coreference,B
3841,relations,I
3841,for,B
3841,text,B
3841,comprehension,I
3841,tasks,I
3841,",",O
3841,where,B
3841,answers,B
3841,to,O
3841,a,O
3841,query,O
3841,have,B
3841,to,O
3841,be,O
3841,extracted,O
3841,from,O
3841,a,O
3841,context,B
3841,document,I
3841,.,O
3842,Tokens,B
3842,in,B
3842,a,O
3842,document,B
3842,are,O
3842,connected,B
3842,by,I
3842,a,O
3842,coreference,B
3842,relation,I
3842,if,B
3842,they,O
3842,refer,B
3842,to,B
3842,the,O
3842,same,B
3842,underlying,I
3842,entity,I
3842,.,O
3843,AdaRNN,B
3843,:,O
3843,It,O
3843,learns,B
3843,the,O
3843,sentence,B
3843,representation,I
3843,toward,B
3843,target,B
3843,for,B
3843,sentiment,B
3843,prediction,I
3843,via,B
3843,semantic,B
3843,composition,I
3843,over,B
3843,dependency,B
3843,tree,I
3843,;,O
3844,Linguistic,O
3844,Knowledge,O
3844,as,O
3844,Memory,O
3844,for,O
3844,Recurrent,B
3844,Neural,I
3844,Networks,I
3845,Our,O
3845,model,O
3845,achieves,B
3845,new,B
3845,state,I
3845,-,I
3845,of,I
3845,-,O
3845,the,O
3845,-,O
3845,art,O
3845,results,O
3845,",",O
3845,outperforming,B
3845,strong,B
3845,baselines,I
3845,such,B
3845,as,I
3845,QRNs,B
3845,.,O
3846,Both,O
3846,variants,O
3846,of,O
3846,MAGE,O
3846,substantially,B
3846,outperform,I
3846,QRNs,B
3846,",",O
3846,which,O
3846,are,B
3846,the,I
3846,current,B
3846,state,I
3846,-,I
3846,of,O
3846,-,O
3846,the,O
3846,-,O
3846,art,O
3846,models,O
3846,on,B
3846,the,O
3846,bAbi,B
3846,dataset,I
3846,.,O
3847,Moreover,O
3847,",",O
3847,we,O
3847,observe,B
3847,that,O
3847,the,O
3847,proposed,B
3847,MAGE,I
3847,architecture,I
3847,can,O
3847,substantially,B
3847,improve,I
3847,the,O
3847,performance,B
3847,for,B
3847,both,B
3847,bi,I
3847,-,I
3847,GRUs,I
3847,and,I
3847,GAs,I
3847,.,O
3848,Adding,B
3848,the,O
3848,same,B
3848,information,I
3848,as,B
3848,one,B
3848,-,I
3848,hot,I
3848,features,I
3848,fails,B
3848,to,I
3848,improve,B
3848,the,O
3848,performance,B
3848,",",O
3848,which,O
3848,indicates,O
3848,that,O
3848,the,O
3848,inductive,O
3848,bias,O
3848,we,O
3848,employ,O
3848,on,O
3848,MAGE,O
3848,is,O
3848,useful,O
3848,.,O
3849,The,O
3849,DAG,B
3849,-,I
3849,RNN,I
3849,baseline,I
3849,from,O
3849,and,O
3849,the,O
3849,shared,B
3849,version,I
3849,of,I
3849,MAGE,I
3849,(,O
3849,where,O
3849,edge,O
3849,representations,O
3849,are,O
3849,tied,O
3849,),O
3849,also,O
3849,perform,B
3849,worse,B
3849,",",O
3849,showing,B
3849,that,O
3849,our,B
3849,proposed,I
3849,architecture,I
3849,is,B
3849,superior,B
3849,.,O
3850,For,O
3850,our,O
3850,second,O
3850,benchmark,O
3850,we,O
3850,pick,B
3850,the,O
3850,LAMBADA,B
3850,dataset,I
3850,from,O
3850,",",O
3850,where,O
3850,the,O
3850,task,O
3850,is,O
3850,to,O
3850,predict,O
3850,the,O
3850,last,O
3850,word,O
3850,in,O
3850,a,O
3850,given,O
3850,passage,O
3850,.,O
3851,The,O
3851,second,B
3851,removes,B
3851,both,B
3851,attention,I
3851,mechanisms,I
3851,.,O
3852,AE,O
3852,-,O
3852,LSTM,O
3852,",",O
3852,and,O
3852,ATAE,B
3852,-,O
3852,LSTM,O
3852,:,O
3852,AE,O
3852,-,O
3852,LSTM,O
3852,is,B
3852,a,O
3852,simple,B
3852,LSTM,O
3852,model,O
3852,incorporating,B
3852,the,O
3852,target,B
3852,embedding,I
3852,as,B
3852,input,B
3852,",",O
3852,while,O
3852,ATAE,O
3852,-,O
3852,LSTM,O
3852,extends,B
3852,AE,O
3852,-,O
3852,LSTM,O
3852,with,B
3852,attention,B
3852,;,O
3853,Our,O
3853,implementation,O
3853,of,O
3853,GA,O
3853,gave,B
3853,higher,B
3853,performance,I
3853,than,O
3853,that,O
3853,reported,O
3853,by,O
3853,",",O
3853,without,O
3853,the,O
3853,use,O
3853,of,O
3853,linguistic,O
3853,features,O
3853,.,O
3854,On,B
3854,the,O
3854,simple,B
3854,bi,I
3854,-,I
3854,GRU,I
3854,architecture,I
3854,we,O
3854,see,B
3854,an,O
3854,improvement,B
3854,of,B
3854,1.7,B
3854,%,I
3854,by,B
3854,incorporating,I
3854,coreference,B
3854,edges,I
3854,in,B
3854,the,O
3854,graph,B
3854,",",O
3854,whereas,O
3854,the,O
3854,one,O
3854,-,O
3854,hot,O
3854,baseline,O
3854,does,O
3854,not,O
3854,lead,O
3854,to,O
3854,any,O
3854,improvement,O
3854,.,O
3855,On,O
3855,the,O
3855,multi,B
3855,-,I
3855,layer,I
3855,GA,I
3855,architecture,I
3855,",",O
3855,the,O
3855,coreference,B
3855,edges,I
3855,again,O
3855,lead,B
3855,to,I
3855,an,O
3855,improvement,B
3855,of,I
3855,2,B
3855,%,I
3855,",",O
3855,setting,B
3855,a,O
3855,new,B
3855,state,I
3855,-,O
3855,of,O
3855,-,O
3855,theart,O
3855,on,O
3855,this,O
3855,dataset,O
3855,.,O
3856,Cloze,O
3856,-,O
3856,style,O
3856,QA,O
3856,:,O
3856,Lastly,O
3856,",",O
3856,we,O
3856,test,O
3856,our,O
3856,models,O
3856,on,B
3856,the,O
3856,CNN,B
3856,dataset,I
3856,from,O
3856,",",O
3856,which,O
3856,consists,O
3856,of,B
3856,pairs,O
3856,of,O
3856,news,O
3856,articles,O
3856,and,O
3856,a,O
3856,cloze,O
3856,-,O
3856,style,O
3856,question,O
3856,over,O
3856,the,O
3856,contents,O
3856,.,O
3857,Augmenting,B
3857,the,O
3857,bi,B
3857,-,I
3857,GRU,I
3857,model,I
3857,with,B
3857,MAGE,B
3857,leads,B
3857,to,I
3857,an,O
3857,improvement,B
3857,of,O
3857,2.5,B
3857,%,I
3857,on,B
3857,the,O
3857,test,B
3857,set,I
3857,.,O
3858,The,O
3858,previous,B
3858,best,I
3858,results,I
3858,for,O
3858,this,O
3858,dataset,O
3858,were,O
3858,achieved,B
3858,by,I
3858,the,O
3858,GA,B
3858,Reader,I
3858,",",O
3858,and,O
3858,we,O
3858,see,O
3858,that,O
3858,adding,B
3858,MAGE,B
3858,to,I
3858,it,O
3858,leads,B
3858,to,O
3858,a,O
3858,further,B
3858,improvement,I
3858,of,I
3858,0.7,B
3858,%,I
3858,",",O
3858,setting,B
3858,a,O
3858,new,B
3858,state,I
3858,of,O
3858,the,O
3858,art,O
3858,.,O
3859,We,O
3859,use,B
3859,cross-entropy,B
3859,loss,I
3859,plus,B
3859,L2,B
3859,regularization,I
3859,penalty,I
3859,as,B
3859,optimization,B
3859,objective,I
3859,.,O
3860,We,O
3860,minimize,B
3860,it,O
3860,by,B
3860,Adadelta,B
3860,),O
3860,(,O
3860,an,O
3860,optimizer,O
3860,of,B
3860,mini,O
3860,-,O
3860,batch,B
3860,SGD,O
3860,),O
3860,with,B
3860,batch,O
3860,size,O
3860,of,O
3860,64,B
3860,.,O
3861,Initial,O
3861,learning,O
3861,rate,O
3861,is,O
3861,set,B
3861,to,I
3861,0.5,B
3861,.,O
3862,All,O
3862,weight,B
3862,matrices,I
3862,are,O
3862,initialized,B
3862,by,I
3862,Glorot,B
3862,Initialization,I
3862,",",O
3862,and,O
3862,the,O
3862,biases,B
3862,are,O
3862,initialized,O
3862,with,O
3862,0,B
3862,.,O
3863,IAN,B
3863,:,O
3863,IAN,O
3863,employs,B
3863,two,B
3863,LSTMs,I
3863,to,B
3863,learn,I
3863,the,I
3863,representations,B
3863,of,B
3863,the,O
3863,context,B
3863,and,I
3863,the,O
3863,target,O
3863,phrase,O
3863,interactively,O
3863,;,O
3864,The,O
3864,Out,B
3864,-,I
3864,of,I
3864,-,O
3864,Vocabulary,O
3864,words,O
3864,in,B
3864,training,B
3864,set,I
3864,are,O
3864,randomly,B
3864,initialized,I
3864,by,B
3864,uniform,B
3864,distribution,I
3864,between,B
3864,(,O
3864,?,O
3865,The,O
3865,L2,B
3865,regularization,I
3865,decay,I
3865,factors,I
3865,?,O
3866,are,B
3866,5,O
3866,10,O
3866,?5,O
3866,and,O
3866,10,O
3866,?,O
3867,4,O
3867,for,B
3867,language,B
3867,inference,I
3867,and,I
3867,sentiment,I
3867,analysis,I
3867,",",O
3867,respectively,O
3867,.,O
3868,Hidden,O
3868,units,O
3868,number,O
3868,d,B
3868,h,I
3868,is,O
3868,set,B
3868,to,I
3868,300,B
3868,.,O
3869,(,O
3869,),O
3869,are,B
3869,ELU,B
3869,(,O
3869,exponential,O
3869,linear,O
3869,unit,O
3869,),O
3869,(,O
3869,Clevert,O
3869,",",O
3869,Unterthiner,O
3869,",",O
3869,and,O
3869,Hochreiter,O
3869,2016,O
3869,),O
3869,if,O
3869,not,O
3869,specified,O
3869,.,O
3870,We,O
3870,initialize,B
3870,the,O
3870,word,B
3870,embedding,I
3870,in,B
3870,x,B
3870,by,B
3870,300D,B
3870,Glo,I
3870,Ve,I
3870,6B,I
3870,pre-trained,I
3870,vectors,I
3870,.,O
3871,We,O
3871,use,B
3871,Dropout,B
3871,),O
3871,with,B
3871,keep,B
3871,probability,I
3871,0.75,B
3871,for,B
3871,language,B
3871,inference,I
3871,and,O
3871,0.8,B
3871,for,O
3871,sentiment,B
3871,analysis,I
3871,.,O
3872,All,O
3872,models,O
3872,are,O
3872,implemented,B
3872,with,I
3872,TensorFlow,B
3872,2,I
3872,and,O
3872,run,B
3872,on,I
3872,sin,O
3872,-,O
3872,3.0,O
3872,m,O
3872,83.9,O
3872,80.6,O
3872,1024D,O
3872,GRU,O
3872,encoders,O
3872,15,O
3872,m,O
3872,98.8,O
3872,81.4,O
3872,300D,O
3872,Tree,O
3872,-,O
3872,based,O
3872,CNN,O
3872,encoders,O
3872,3.5,O
3872,m,O
3872,83.3,O
3872,82.1,O
3872,300D,O
3872,SPINN,O
3872,-,O
3872,PI,O
3872,encoders,O
3872,3.7,O
3872,m,O
3872,89.2,O
3872,83.2,O
3872,600D,O
3872,Bi-,O
3872,LSTM,O
3872,encoders,O
3872,2.0,O
3872,m,O
3872,86.4,O
3872,83.3,O
3872,300D,O
3872,NTI,O
3872,-,O
3872,SLSTM,O
3872,-,O
3872,LSTM,O
3872,encoders,O
3872,4.0,O
3872,m,O
3872,82.5,O
3872,83.4,O
3872,600D,O
3872,Bi-LSTM,O
3872,encoders+intra-attention,O
3872,2.8,O
3872,m,O
3872,84.5,O
3872,84.2,O
3872,300D,O
3872,NSE,O
3872,encoders,O
3872,3,O
3872,gle,O
3872,Nvidia,B
3872,GTX,I
3872,1080,I
3872,Ti,I
3872,graphic,I
3872,card,I
3872,.,O
3873,We,O
3873,propose,B
3873,a,O
3873,novel,B
3873,attention,I
3873,mechanism,I
3873,that,O
3873,differs,B
3873,from,I
3873,previous,B
3873,ones,I
3873,in,B
3873,that,O
3873,it,O
3873,is,O
3873,1,O
3873,),O
3873,multi-dimensional,B
3873,:,O
3873,the,O
3873,attention,O
3873,w.r.t.,O
3874,each,O
3874,pair,O
3874,of,O
3874,elements,O
3874,from,O
3874,the,O
3874,source,O
3874,(,O
3874,s,O
3874,),O
3874,is,O
3874,a,O
3874,vector,O
3874,",",O
3874,where,O
3874,each,O
3874,entry,O
3874,is,O
3874,the,O
3874,attention,O
3874,computed,O
3874,on,O
3874,each,O
3874,feature,O
3874,;,O
3874,and,O
3874,2,O
3874,),O
3874,directional,B
3874,:,O
3874,it,O
3874,uses,O
3874,one,O
3874,or,O
3874,multiple,O
3874,positional,O
3874,masks,O
3874,to,O
3874,model,O
3874,the,O
3874,asymmetric,O
3874,attention,O
3874,between,O
3874,two,O
3874,elements,O
3874,.,O
3875,We,O
3875,compute,B
3875,feature,B
3875,-,I
3875,wise,I
3875,attention,I
3875,since,B
3875,each,B
3875,element,I
3875,in,B
3875,a,O
3875,sequence,B
3875,is,O
3875,usually,O
3875,represented,B
3875,by,I
3875,a,O
3875,vector,B
3875,",",O
3875,e.g.,O
3876,We,O
3876,apply,B
3876,positional,B
3876,masks,I
3876,to,B
3876,attention,B
3876,distribution,I
3876,since,O
3876,they,O
3876,can,O
3876,easily,B
3876,encode,I
3876,prior,B
3876,structure,I
3876,knowledge,I
3876,such,B
3876,as,I
3876,temporal,B
3876,order,I
3876,and,O
3876,dependency,B
3876,parsing,I
3876,.,O
3877,We,O
3877,then,O
3877,build,B
3877,a,O
3877,light,B
3877,-,I
3877,weight,I
3877,and,I
3877,RNN,I
3877,/,I
3877,CNN,I
3877,-,O
3877,free,O
3877,neural,O
3877,network,O
3877,",",O
3877,"""",O
3877,Directional,B
3877,Self,I
3877,-,O
3877,Attention,O
3877,Network,O
3877,(,O
3877,DiSAN,O
3877,),O
3877,"""",O
3877,",",O
3877,for,B
3877,sentence,B
3877,encoding,I
3877,.,O
3878,In,B
3878,DiSAN,B
3878,",",O
3878,the,O
3878,input,B
3878,sequence,I
3878,is,O
3878,processed,B
3878,by,I
3878,directional,B
3878,(,I
3878,forward,I
3878,and,I
3878,backward,I
3878,),I
3878,self,I
3878,-,I
3878,attentions,I
3878,to,B
3878,model,I
3878,context,B
3878,dependency,I
3878,and,O
3878,produce,B
3878,context,O
3878,-,O
3878,aware,O
3878,representations,O
3878,for,B
3878,all,B
3878,tokens,I
3878,.,O
3879,Then,O
3879,",",O
3879,a,O
3879,multi-dimensional,B
3879,attention,I
3879,computes,B
3879,a,O
3879,vector,B
3879,representation,I
3879,of,B
3879,the,O
3879,entire,B
3879,sequence,I
3879,",",O
3879,which,O
3879,can,O
3879,be,O
3879,passed,B
3879,into,I
3879,a,O
3879,classification,B
3879,/,I
3879,regression,I
3879,module,I
3879,to,B
3879,compute,I
3879,the,O
3879,final,B
3879,prediction,I
3879,for,I
3879,a,O
3879,particular,O
3879,task,O
3879,.,O
3880,DiSAN,O
3880,:,O
3880,Directional,O
3880,Self,O
3880,-,O
3880,Attention,O
3880,Network,O
3880,for,O
3880,RNN,B
3880,/,I
3880,CNN,I
3880,-,O
3880,Free,O
3880,Language,O
3880,Understanding,O
3881,Compared,O
3881,to,O
3881,the,O
3881,results,B
3881,from,B
3881,the,O
3881,official,B
3881,leaderboard,I
3881,of,B
3881,SNLI,I
3881,in,O
3881,",",O
3881,DiSAN,B
3881,outperforms,B
3881,previous,B
3881,works,I
3881,and,O
3881,improves,B
3881,the,O
3881,best,B
3881,latest,I
3881,test,I
3881,accuracy,I
3881,(,O
3881,achieved,B
3881,by,B
3881,a,O
3881,memory,B
3881,-,I
3881,based,I
3881,NSE,I
3881,encoder,I
3881,network,I
3881,),O
3881,by,O
3881,a,O
3881,remarkable,B
3881,margin,I
3881,of,O
3881,1.02,B
3881,%,I
3881,.,O
3882,DiSAN,B
3882,surpasses,B
3882,the,O
3882,RNN,B
3882,/,I
3882,CNN,I
3882,based,I
3882,models,I
3882,with,B
3882,more,B
3882,complicated,I
3882,architecture,I
3882,and,O
3882,more,O
3882,parameters,O
3882,by,B
3882,large,B
3882,margins,I
3882,",",O
3882,e.g.,O
3883,",",O
3883,+,O
3883,2.32,O
3883,%,O
3883,to,O
3883,Bi,O
3883,-,O
3883,LSTM,O
3883,",",O
3883,+,O
3883,1.42,O
3883,%,O
3883,to,O
3883,Bi,O
3883,-,O
3883,LSTM,O
3883,with,B
3883,additive,O
3883,attention,O
3883,.,O
3884,It,O
3884,even,O
3884,outperforms,B
3884,models,B
3884,with,B
3884,the,O
3884,assistance,B
3884,of,B
3884,a,O
3884,semantic,B
3884,parsing,I
3884,tree,I
3884,",",O
3884,e.g.,O
3885,Also,O
3885,",",O
3885,a,O
3885,comparison,B
3885,between,B
3885,the,O
3885,third,B
3885,baseline,I
3885,and,I
3885,DiSAN,B
3885,shows,B
3885,that,O
3885,DiSAN,O
3885,can,O
3885,substantially,B
3885,outperform,I
3885,multi-head,B
3885,attention,I
3885,by,B
3885,1.45,B
3885,%,I
3885,.,O
3886,Moreover,O
3886,",",O
3886,a,O
3886,comparison,O
3886,between,O
3886,the,O
3886,forth,B
3886,baseline,I
3886,and,I
3886,DiSAN,I
3886,shows,B
3886,that,O
3886,the,O
3886,DiSA,B
3886,block,I
3886,can,O
3886,even,O
3886,outperform,B
3886,Bi,B
3886,-,I
3886,LSTM,I
3886,layer,I
3886,in,B
3886,context,B
3886,encoding,I
3886,",",O
3886,improving,B
3886,test,B
3886,accuracy,I
3886,by,B
3886,0.64,B
3886,%,I
3886,.,O
3887,It,O
3887,is,B
3887,a,O
3887,CNN,B
3887,-,I
3887,based,I
3887,model,I
3887,implemented,O
3887,by,O
3887,us,O
3887,which,B
3887,directly,I
3887,concatenates,I
3887,target,B
3887,representation,I
3887,to,B
3887,each,B
3887,word,I
3887,embedding,I
3887,;,O
3888,A,O
3888,comparison,O
3888,between,O
3888,the,O
3888,fifth,B
3888,baseline,I
3888,and,I
3888,DiSAN,I
3888,shows,B
3888,that,O
3888,directional,B
3888,self,I
3888,-,I
3888,attention,I
3888,with,I
3888,forward,B
3888,and,O
3888,backward,O
3888,masks,O
3888,(,O
3888,with,O
3888,temporal,O
3888,order,O
3888,encoded,O
3888,),O
3888,can,O
3888,bring,B
3888,0.96,B
3888,%,I
3888,improvement,I
3888,.,O
3889,First,O
3889,",",O
3889,a,O
3889,comparison,O
3889,between,O
3889,the,O
3889,first,O
3889,two,O
3889,models,O
3889,shows,B
3889,that,O
3889,changing,B
3889,token,B
3889,-,I
3889,wise,I
3889,attention,I
3889,to,I
3889,multi-dimensional,B
3889,/,I
3889,feature,I
3889,-,O
3889,wise,O
3889,attention,O
3889,leads,B
3889,to,O
3889,3.31,B
3889,%,I
3889,improvement,I
3889,on,B
3889,a,O
3889,word,B
3889,embedding,I
3889,based,I
3889,model,I
3889,.,O
3890,To,O
3890,the,O
3890,best,O
3890,of,O
3890,our,O
3890,knowledge,O
3890,",",O
3890,DiSAN,B
3890,improves,B
3890,the,O
3890,last,B
3890,best,O
3890,accuracy,O
3890,(,O
3890,given,B
3890,by,B
3890,CNN,B
3890,-,I
3890,Tensor,I
3890,),O
3890,by,O
3890,0.52,B
3890,%,I
3890,.,O
3891,Additionally,O
3891,",",O
3891,DiSAN,O
3891,achieves,B
3891,better,B
3891,performance,I
3891,than,B
3891,CNN,B
3891,-,I
3891,based,I
3891,models,I
3891,.,O
3892,Nonetheless,O
3892,",",O
3892,DiSAN,O
3892,still,O
3892,outperforms,B
3892,these,O
3892,fancy,O
3892,models,O
3892,",",O
3892,such,B
3892,as,I
3892,NCSL,B
3892,(,O
3892,+,B
3892,0.62,I
3892,%,I
3892,),O
3892,and,O
3892,LR-,B
3892,Bi-,I
3892,LSTM,I
3892,(,O
3892,+,O
3892,1.12,O
3892,%,O
3892,),O
3892,.,O
3893,Compared,O
3893,to,O
3893,tree,B
3893,-,I
3893,based,I
3893,models,I
3893,with,B
3893,heavy,B
3893,use,I
3893,of,B
3893,the,O
3893,prior,B
3893,structure,I
3893,",",O
3893,e.g.,B
3894,",",O
3894,MV,B
3894,-,I
3894,RNN,I
3894,",",O
3894,RNTN,B
3894,and,I
3894,Tree,B
3894,-,O
3894,LSTM,O
3894,",",O
3894,DiSAN,B
3894,outperforms,B
3894,them,O
3894,by,B
3894,7.32,B
3894,%,I
3894,",",O
3894,6.02,O
3894,%,O
3894,and,O
3894,0.72,O
3894,%,O
3894,",",O
3894,respectively,O
3894,.,O
3895,1,O
3895,https://github.com/shuohangwang/,B
3896,We,O
3896,use,B
3896,the,O
3896,Adam,B
3896,method,I
3896,(,O
3896,Kingma,O
3896,and,O
3896,Ba,O
3896,",",O
3896,2014,O
3896,),O
3896,with,B
3896,hyperparameters,B
3896,?,O
3897,1,O
3897,set,B
3897,to,I
3897,0.9,B
3897,and,O
3897,?,O
3898,2,O
3898,set,O
3898,to,O
3898,0.999,B
3898,for,B
3898,optimization,B
3898,.,O
3899,The,O
3899,initial,B
3899,learning,I
3899,rate,I
3899,is,O
3899,set,B
3899,to,I
3899,be,O
3899,0.001,B
3899,with,O
3899,a,O
3899,decay,B
3899,ratio,I
3899,of,B
3899,0.95,B
3899,for,B
3899,each,B
3899,iteration,I
3899,.,O
3900,The,O
3900,batch,B
3900,size,I
3900,is,O
3900,set,B
3900,to,I
3900,be,O
3900,30,B
3900,.,O
3901,We,O
3901,experiment,B
3901,with,I
3901,d,I
3901,=,I
3901,150,I
3901,and,I
3901,d,O
3901,=,O
3901,300,O
3901,where,O
3901,d,O
3901,is,O
3901,the,O
3901,dimension,O
3901,of,O
3901,all,O
3901,the,O
3901,hidden,O
3901,states,O
3901,.,O
3902,In,O
3902,this,O
3902,paper,O
3902,",",O
3902,we,O
3902,propose,B
3902,a,O
3902,new,B
3902,LSTM,I
3902,-,I
3902,based,I
3902,architecture,I
3902,for,B
3902,learning,I
3902,natural,B
3902,language,I
3902,inference,I
3902,.,O
3903,Instead,O
3903,",",O
3903,we,O
3903,use,B
3903,an,O
3903,LSTM,B
3903,to,B
3903,perform,I
3903,word,I
3903,-,I
3903,by,I
3903,-,O
3903,word,O
3903,matching,O
3903,of,B
3903,the,O
3903,hypothesis,B
3903,with,B
3903,the,O
3903,premise,B
3903,.,O
3904,Our,O
3904,LSTM,O
3904,sequentially,B
3904,processes,I
3904,the,O
3904,hypothesis,B
3904,",",O
3904,and,O
3904,at,B
3904,each,I
3904,position,I
3904,",",O
3904,it,O
3904,tries,B
3904,to,I
3904,match,I
3904,the,O
3904,current,B
3904,word,I
3904,in,B
3904,the,O
3904,hypothesis,O
3904,with,B
3904,an,O
3904,attention,B
3904,-,I
3904,weighted,I
3904,representation,I
3904,of,B
3904,the,O
3904,premise,B
3904,.,O
3905,Learning,O
3905,Natural,B
3905,Language,I
3905,Inference,I
3905,with,O
3905,LSTM,O
3906,In,O
3906,this,O
3906,paper,O
3906,",",O
3906,we,O
3906,propose,O
3906,a,O
3906,special,O
3906,long,O
3906,short,O
3906,-,O
3906,term,O
3906,memory,O
3906,(,O
3906,LSTM,O
3906,),O
3906,architecture,O
3906,for,O
3906,NLI,B
3906,.,O
3907,It,O
3907,employs,B
3907,two,B
3907,LSTMs,I
3907,to,B
3907,model,I
3907,the,O
3907,left,B
3907,and,I
3907,right,I
3907,contexts,I
3907,of,B
3907,the,O
3907,target,B
3907,separately,O
3907,",",O
3907,then,O
3907,performs,B
3907,predictions,B
3907,based,B
3907,on,I
3907,concatenated,B
3907,context,I
3907,representations,I
3907,;,O
3908,We,O
3908,have,O
3908,the,O
3908,following,O
3908,observations,O
3908,:,O
3908,(,O
3908,1,O
3908,),O
3908,First,O
3908,of,B
3908,all,O
3908,",",O
3908,we,O
3908,can,O
3908,see,B
3908,that,I
3908,when,O
3908,we,O
3908,set,B
3908,d,I
3908,to,B
3908,300,B
3908,",",O
3908,our,B
3908,model,I
3908,achieves,B
3908,an,O
3908,accuracy,B
3908,of,O
3908,86.1,B
3908,%,I
3908,on,B
3908,the,O
3908,test,B
3908,data,I
3908,",",O
3908,which,O
3908,to,O
3908,the,O
3908,best,O
3908,of,O
3908,our,O
3908,knowledge,O
3908,is,O
3908,the,O
3908,highest,O
3908,on,O
3908,and,O
3908,|?|,O
3908,M,O
3908,is,O
3908,the,O
3908,number,O
3908,of,O
3908,parameters,O
3908,excluding,O
3908,the,O
3908,word,O
3908,embeddings,O
3908,.,O
3909,(,O
3909,2,O
3909,),O
3909,If,O
3909,we,O
3909,compare,B
3909,our,B
3909,m,I
3909,LSTM,I
3909,model,I
3909,with,B
3909,our,O
3909,implementation,O
3909,of,O
3909,the,O
3909,word,O
3909,-,O
3909,by,O
3909,-,O
3909,word,O
3909,attention,O
3909,model,O
3909,by,O
3909,under,B
3909,the,O
3909,same,B
3909,setting,I
3909,with,O
3909,d,B
3909,=,B
3909,150,B
3909,",",O
3909,we,O
3909,can,O
3909,see,B
3909,that,I
3909,our,O
3909,performance,O
3909,on,B
3909,the,O
3909,test,B
3909,data,I
3909,(,O
3909,85.7,O
3909,%,O
3909,),O
3909,is,B
3909,higher,B
3909,than,B
3909,that,O
3909,of,O
3909,their,B
3909,model,O
3909,(,O
3909,82.6,O
3909,%,O
3909,),O
3909,.,O
3910,(,O
3910,3,O
3910,),O
3910,The,O
3910,performance,B
3910,of,B
3910,mLSTM,B
3910,with,B
3910,bi,B
3910,-,I
3910,LSTM,I
3910,sentence,I
3910,modeling,I
3910,compared,B
3910,with,O
3910,the,O
3910,model,B
3910,with,O
3910,standard,B
3910,LSTM,O
3910,sentence,O
3910,modeling,O
3910,when,B
3910,d,B
3910,is,O
3910,set,B
3910,to,B
3910,150,B
3910,shows,B
3910,that,I
3910,using,O
3910,bi,O
3910,-,O
3910,LSTM,O
3910,to,O
3910,process,O
3910,the,O
3910,original,B
3910,sentences,I
3910,helps,B
3910,(,O
3910,86.0,B
3910,%,I
3910,vs.,I
3910,85.7,I
3910,%,O
3910,on,B
3910,the,O
3910,test,B
3910,data,I
3910,),O
3910,",",O
3910,but,O
3910,the,O
3910,difference,O
3910,is,O
3910,small,O
3910,and,O
3910,the,O
3910,complexity,O
3910,of,O
3910,bi,O
3910,-,O
3910,LSTM,O
3910,is,O
3910,much,O
3910,higher,O
3910,than,O
3910,LSTM,O
3910,.,O
3911,(,O
3911,4,O
3911,),O
3911,Interestingly,O
3911,",",O
3911,when,O
3911,we,O
3911,experimented,B
3911,with,I
3911,the,I
3911,m,B
3911,LSTM,I
3911,model,I
3911,using,B
3911,the,O
3911,pre-trained,B
3911,word,I
3911,embeddings,I
3911,instead,B
3911,of,I
3911,LSTMgenerated,B
3911,hidden,I
3911,states,I
3911,as,B
3911,initial,B
3911,representations,I
3911,of,O
3911,the,O
3911,premise,B
3911,and,I
3911,the,O
3911,hypothesis,O
3911,",",O
3911,we,O
3911,were,O
3911,able,B
3911,to,I
3911,achieve,I
3911,an,O
3911,accuracy,B
3911,of,O
3911,85.3,B
3911,%,I
3911,on,B
3911,the,O
3911,test,B
3911,data,I
3911,",",O
3911,which,O
3911,is,B
3911,still,O
3911,better,B
3911,than,B
3911,previously,B
3911,reported,I
3911,state,I
3911,of,O
3911,the,O
3911,art,O
3911,.,O
3912,Experiments,O
3912,on,B
3912,Document,B
3912,Modelling,I
3913,The,O
3913,experimental,O
3913,results,O
3913,indicate,B
3913,that,O
3913,NVDM,B
3913,achieves,B
3913,the,O
3913,best,B
3913,performance,I
3913,on,B
3913,both,B
3913,datasets,I
3913,.,O
3914,For,B
3914,the,O
3914,experiments,B
3914,on,B
3914,RCV1,B
3914,-,I
3914,v2,I
3914,dataset,I
3914,",",O
3914,the,O
3914,NVDM,B
3914,with,B
3914,latent,B
3914,variable,I
3914,of,B
3914,50,B
3914,dimension,I
3914,performs,B
3914,even,B
3914,better,I
3914,than,B
3914,the,O
3914,fDARN,B
3914,with,O
3914,200,B
3914,dimension,O
3914,.,O
3915,Dataset,O
3915,&,O
3915,Setup,O
3915,for,B
3915,Answer,B
3915,Sentence,I
3915,Selection,I
3916,The,O
3916,word,B
3916,embeddings,I
3916,(,I
3916,K,I
3916,=,I
3916,50,I
3916,),I
3916,are,B
3916,obtained,B
3916,by,B
3916,running,I
3916,the,O
3916,word2vec,B
3916,tool,I
3916,on,B
3916,the,O
3916,English,B
3916,Wikipedia,I
3916,dump,I
3916,and,O
3916,the,O
3916,AQUAINT,B
3916,5,I
3916,corpus,I
3916,.,O
3917,We,O
3917,use,B
3917,LSTMs,B
3917,with,B
3917,3,B
3917,layers,I
3917,and,O
3917,50,B
3917,hidden,I
3917,units,I
3917,",",O
3917,and,O
3917,apply,B
3917,40,B
3917,%,I
3917,dropout,I
3917,after,B
3917,the,O
3917,embedding,B
3917,layer,I
3917,.,O
3918,MemNet,B
3918,:,O
3918,It,O
3918,applies,B
3918,attention,B
3918,mechanism,I
3918,over,B
3918,the,O
3918,word,B
3918,embeddings,I
3918,multiple,I
3918,times,I
3918,and,O
3918,predicts,B
3918,sentiments,B
3918,based,B
3918,on,I
3918,the,O
3918,top,B
3918,-,I
3918,most,I
3918,sentence,I
3918,representations,I
3918,;,O
3919,For,O
3919,the,O
3919,construction,O
3919,of,B
3919,the,O
3919,inference,B
3919,network,I
3919,",",O
3919,we,O
3919,use,B
3919,an,O
3919,MLP,B
3919,(,O
3919,Eq.,O
3920,10,O
3920,),O
3920,with,B
3920,2,B
3920,layers,I
3920,and,O
3920,tanh,B
3920,units,I
3920,of,B
3920,50,B
3920,dimension,I
3920,",",O
3920,and,O
3920,an,O
3920,MLP,B
3920,(,O
3920,Eq.,O
3921,17,O
3921,),O
3921,with,B
3921,2,B
3921,layers,I
3921,and,O
3921,tanh,B
3921,units,I
3921,of,B
3921,150,B
3921,dimension,I
3921,for,B
3921,modelling,I
3921,the,O
3921,joint,B
3921,representation,I
3921,.,O
3922,During,B
3922,training,B
3922,we,O
3922,carry,B
3922,out,I
3922,stochastic,B
3922,estimation,I
3922,by,B
3922,taking,I
3922,one,B
3922,sample,I
3922,for,B
3922,computing,I
3922,the,O
3922,gradients,B
3922,",",O
3922,while,O
3922,in,B
3922,prediction,B
3922,we,O
3922,use,B
3922,20,B
3922,samples,I
3922,to,B
3922,calculate,I
3922,the,O
3922,expectation,B
3922,of,B
3922,the,O
3922,lower,B
3922,bound,I
3922,.,O
3923,The,O
3923,LSTM,O
3923,+,O
3923,Att,O
3923,performs,B
3923,slightly,B
3923,better,I
3923,than,B
3923,the,O
3923,vanilla,B
3923,LSTM,O
3923,model,O
3923,",",O
3923,and,O
3923,our,B
3923,NASM,I
3923,improves,B
3923,the,O
3923,results,B
3923,further,O
3923,.,O
3924,Since,O
3924,the,O
3924,QASent,O
3924,dataset,O
3924,is,O
3924,biased,O
3924,towards,O
3924,lexical,O
3924,overlapping,O
3924,features,O
3924,",",O
3924,after,B
3924,combining,I
3924,with,B
3924,a,O
3924,co-occurrence,B
3924,word,I
3924,count,I
3924,feature,I
3924,",",O
3924,our,B
3924,best,I
3924,model,I
3924,NASM,O
3924,outperforms,B
3924,all,B
3924,the,O
3924,previous,O
3924,models,O
3924,",",O
3924,including,B
3924,both,O
3924,neural,B
3924,network,I
3924,based,I
3924,models,O
3924,and,O
3924,classifiers,B
3924,with,O
3924,a,O
3924,set,B
3924,of,B
3924,hand,B
3924,-,I
3924,crafted,I
3924,features,O
3924,(,O
3924,e.g.,O
3925,Similarly,O
3925,",",O
3925,on,B
3925,the,O
3925,Wik,B
3925,-,I
3925,iQA,I
3925,dataset,I
3925,",",O
3925,all,B
3925,of,I
3925,our,I
3925,models,I
3925,outperform,B
3925,the,O
3925,previous,B
3925,distributional,I
3925,models,O
3925,by,B
3925,a,O
3925,large,B
3925,margin,I
3925,.,O
3926,By,O
3926,including,B
3926,a,O
3926,word,B
3926,count,I
3926,feature,I
3926,",",O
3926,our,B
3926,models,I
3926,improve,B
3926,further,I
3926,and,O
3926,achieve,B
3926,the,I
3926,state,B
3926,-,I
3926,of,I
3926,-,O
3926,the,O
3926,-,O
3926,art,O
3926,.,O
3927,This,O
3927,paper,O
3927,introduces,B
3927,a,O
3927,neural,B
3927,variational,B
3927,framework,I
3927,for,B
3927,generative,B
3927,models,I
3927,of,B
3927,text,B
3927,",",O
3927,inspired,B
3927,by,I
3927,the,O
3927,variational,O
3927,autoencoder,O
3927,.,O
3928,The,O
3928,principle,O
3928,idea,O
3928,is,O
3928,to,B
3928,build,B
3928,an,O
3928,inference,B
3928,network,I
3928,",",O
3928,implemented,B
3928,by,I
3928,a,O
3928,deep,B
3928,neural,I
3928,network,O
3928,conditioned,B
3928,on,I
3928,text,B
3928,",",O
3928,to,O
3928,approximate,O
3928,the,O
3928,intractable,B
3928,distributions,I
3928,over,B
3928,the,O
3928,latent,B
3928,variables,I
3928,.,O
3929,Instead,O
3929,of,O
3929,providing,O
3929,an,O
3929,analytic,O
3929,approximation,O
3929,",",O
3929,as,O
3929,in,O
3929,traditional,O
3929,variational,O
3929,Bayes,O
3929,",",O
3929,neural,B
3929,variational,O
3929,inference,O
3929,learns,B
3929,to,I
3929,model,I
3929,the,O
3929,posterior,B
3929,probability,I
3929,",",O
3929,thus,O
3929,endowing,O
3929,the,O
3929,model,O
3929,with,O
3929,strong,O
3929,generalis,O
3929,ation,O
3929,abilities,O
3929,.,O
3930,A,O
3930,primary,B
3930,feature,I
3930,of,I
3930,NVDM,B
3930,is,B
3930,that,O
3930,each,B
3930,word,I
3930,is,O
3930,generated,B
3930,directly,I
3930,from,I
3930,a,O
3930,dense,B
3930,continuous,I
3930,document,I
3930,representation,I
3930,instead,B
3930,of,O
3930,the,O
3930,more,B
3930,common,I
3930,binary,I
3930,semantic,I
3930,vector,I
3930,.,O
3931,BILSTM,O
3931,-,O
3931,ATT,O
3931,-G,O
3931,:,O
3931,It,O
3931,models,B
3931,left,I
3931,and,I
3931,right,I
3931,contexts,I
3931,using,B
3931,two,B
3931,attention,I
3931,-,O
3931,based,O
3931,LSTMs,O
3931,and,O
3931,introduces,B
3931,gates,B
3931,to,B
3931,measure,I
3931,the,I
3931,importance,B
3931,of,I
3931,left,O
3931,context,O
3931,",",O
3931,right,O
3931,context,O
3931,",",O
3931,and,O
3931,the,O
3931,entire,O
3931,sentence,O
3931,for,B
3931,the,O
3931,prediction,B
3931,;,O
3932,The,O
3932,NASM,B
3932,(,O
3932,is,B
3932,a,O
3932,supervised,B
3932,conditional,I
3932,model,I
3932,which,O
3932,imbues,B
3932,LSTMs,B
3932,with,B
3932,a,O
3932,latent,B
3932,stochastic,I
3932,attention,I
3932,mechanism,I
3932,to,B
3932,model,O
3932,the,O
3932,semantics,B
3932,of,B
3932,question,B
3932,-,I
3932,answer,I
3932,pairs,I
3932,and,O
3932,predict,O
3932,their,O
3932,relatedness,O
3932,.,O
3933,The,O
3933,attention,B
3933,model,I
3933,is,O
3933,designed,B
3933,to,I
3933,focus,B
3933,on,B
3933,the,O
3933,phrases,B
3933,of,B
3933,an,O
3933,answer,B
3933,that,O
3933,are,O
3933,strongly,B
3933,connected,I
3933,to,O
3933,the,O
3933,question,B
3933,semantics,I
3933,and,O
3933,is,O
3933,modelled,B
3933,by,I
3933,a,O
3933,latent,B
3933,distribution,I
3933,.,O
3934,Bayesian,O
3934,inference,O
3934,provides,B
3934,a,O
3934,natural,B
3934,safeguard,I
3934,against,B
3934,overfitting,B
3934,",",O
3934,especially,O
3934,as,O
3934,the,O
3934,training,O
3934,sets,O
3934,available,O
3934,for,O
3934,this,O
3934,task,O
3934,are,O
3934,small,O
3934,.,O
3935,By,O
3935,using,B
3935,the,O
3935,reparameteris,B
3935,ation,I
3935,method,I
3935,",",O
3935,the,O
3935,inference,B
3935,network,I
3935,is,O
3935,trained,B
3935,through,I
3935,back,B
3935,-,I
3935,propagating,I
3935,unbiased,B
3935,and,I
3935,low,I
3935,variance,I
3935,gradients,I
3935,w.r.t.,B
3936,the,O
3936,latent,B
3936,variables,I
3936,.,O
3937,Within,O
3937,this,O
3937,framework,O
3937,",",O
3937,we,O
3937,propose,B
3937,a,O
3937,Neural,B
3937,Variational,I
3937,Document,B
3937,Model,I
3937,(,I
3937,NVDM,I
3937,),I
3937,for,B
3937,document,O
3937,modelling,O
3937,and,O
3937,a,O
3937,Neural,O
3937,Answer,O
3937,Selection,O
3937,Model,O
3937,(,O
3937,NASM,O
3937,),O
3937,for,O
3937,question,B
3937,answering,I
3937,",",O
3937,a,O
3937,task,O
3937,that,O
3937,selects,O
3937,the,O
3937,sentences,O
3937,that,O
3937,correctly,O
3937,answer,O
3937,a,O
3937,factoid,O
3937,question,O
3937,from,O
3937,a,O
3937,set,O
3937,of,O
3937,candidate,O
3937,sentences,O
3937,.,O
3938,This,O
3938,analysis,O
3938,confirms,B
3938,the,O
3938,effectiveness,B
3938,of,B
3938,char-,B
3938,embeddings,I
3938,",",O
3938,as,O
3938,its,O
3938,addition,B
3938,increased,B
3938,the,O
3938,F1,B
3938,and,I
3938,EM,I
3938,scores,I
3938,",",O
3938,by,B
3938,2.7,B
3938,%,I
3938,and,O
3938,3.1,O
3938,%,O
3938,",",O
3938,respectively,O
3938,.,O
3939,Most,O
3939,importantly,O
3939,",",O
3939,when,B
3939,the,O
3939,convolutional,B
3939,attention,I
3939,was,O
3939,replaced,B
3939,by,B
3939,the,O
3939,standard,B
3939,attention,O
3939,mechanism,O
3939,proposed,O
3939,in,B
3939,",",O
3939,the,O
3939,performance,B
3939,dropped,B
3939,by,O
3939,2.4,B
3939,%,I
3939,in,O
3939,F1,B
3939,and,O
3939,2.5,B
3939,%,O
3939,in,O
3939,EM,B
3939,.,O
3940,Moreover,O
3940,",",O
3940,the,O
3940,tests,O
3940,also,O
3940,indicate,B
3940,that,O
3940,the,O
3940,reduction,B
3940,layer,I
3940,is,O
3940,capable,B
3940,of,I
3940,producing,I
3940,useful,B
3940,word,I
3940,representations,I
3940,when,B
3940,compressing,B
3940,the,O
3940,embeddings,B
3940,.,O
3941,Indeed,O
3941,",",O
3941,when,O
3941,we,O
3941,replaced,B
3941,that,O
3941,layer,O
3941,by,O
3941,a,O
3941,standard,B
3941,feedforward,I
3941,layer,O
3941,with,B
3941,the,O
3941,same,B
3941,reduction,I
3941,ratio,I
3941,",",O
3941,there,O
3941,was,O
3941,a,O
3941,drop,B
3941,of,B
3941,2.1,B
3941,%,I
3941,and,I
3941,2.5,I
3941,%,O
3941,in,B
3941,the,O
3941,F1,B
3941,and,O
3941,EM,O
3941,scores,O
3941,",",O
3941,respectively,O
3941,.,O
3942,RAM,B
3942,:,O
3942,RAM,O
3942,is,B
3942,a,O
3942,multilayer,B
3942,architecture,I
3942,where,B
3942,each,B
3942,layer,I
3942,consists,B
3942,of,I
3942,attention,B
3942,-,I
3942,based,I
3942,aggregation,I
3942,of,O
3942,word,O
3942,features,O
3942,and,O
3942,a,O
3942,GRU,B
3942,cell,I
3942,to,B
3942,learn,I
3942,the,O
3942,sentence,B
3942,representation,I
3942,.,O
3943,We,O
3943,have,O
3943,trained,B
3943,our,O
3943,FABIR,B
3943,model,I
3943,during,B
3943,54,B
3943,epochs,I
3943,with,B
3943,a,O
3943,batch,B
3943,size,I
3943,of,B
3943,75,B
3943,in,B
3943,a,O
3943,GPU,B
3943,NVidia,I
3943,Titan,I
3943,X,I
3943,with,O
3943,12,B
3943,GB,I
3943,of,O
3943,RAM,B
3943,.,O
3944,We,O
3944,developed,B
3944,our,B
3944,model,I
3944,in,B
3944,Tensorflow,B
3944,and,O
3944,made,O
3944,it,O
3944,available,O
3944,at,O
3944,https://worksheets.codalab.org/worksheets/,O
3944,0xee647ea284674396831ecb5aae9ca297,O
3944,/,O
3944,for,O
3944,replicability,O
3944,.,O
3945,We,O
3945,pre-processed,B
3945,the,O
3945,texts,B
3945,with,B
3945,the,O
3945,NLTK,B
3945,Tokenizer,I
3945,.,O
3946,For,B
3946,regularization,B
3946,",",O
3946,we,O
3946,applied,B
3946,residual,B
3946,and,I
3946,attention,I
3946,dropout,I
3946,of,B
3946,0.9,B
3946,in,B
3946,processing,B
3946,layers,I
3946,and,O
3946,of,O
3946,0.8,B
3946,in,O
3946,the,O
3946,reduction,B
3946,layer,I
3946,.,O
3947,In,B
3947,the,O
3947,character,B
3947,-,I
3947,level,I
3947,embedding,I
3947,process,I
3947,",",O
3947,a,O
3947,dropout,B
3947,of,B
3947,0.75,B
3947,was,O
3947,added,B
3947,before,I
3947,the,O
3947,convolution,B
3947,.,O
3948,Additionally,O
3948,",",O
3948,a,O
3948,dropout,B
3948,of,B
3948,0.8,B
3948,was,O
3948,added,B
3948,before,I
3948,each,B
3948,convolutional,I
3948,layer,I
3948,in,B
3948,the,O
3948,answer,B
3948,selector,I
3948,.,O
3949,We,O
3949,set,B
3949,processing,B
3949,layers,I
3949,dimension,I
3949,d,B
3949,model,I
3949,to,B
3949,100,B
3949,",",O
3949,the,O
3949,number,B
3949,of,I
3949,heads,I
3949,n,B
3949,heads,O
3949,in,B
3949,each,B
3949,attention,I
3949,sublayer,I
3949,to,O
3949,4,B
3949,",",O
3949,the,O
3949,feed,B
3949,-,I
3949,forward,I
3949,hidden,I
3949,size,I
3949,to,O
3949,200,B
3949,in,O
3949,processing,O
3949,layers,O
3949,and,O
3949,400,B
3949,in,O
3949,the,O
3949,reduction,B
3949,layer,I
3949,.,O
3950,in,O
3950,machine,O
3950,translation,O
3950,",",O
3950,we,O
3950,have,O
3950,applied,O
3950,a,O
3950,similar,O
3950,architecture,O
3950,to,O
3950,the,O
3950,domain,O
3950,of,O
3950,question,O
3950,-,O
3950,answering,O
3950,",",O
3950,a,O
3950,model,O
3950,that,O
3950,we,O
3950,have,O
3950,named,B
3950,Fully,B
3950,Attention,I
3950,-,O
3950,Based,O
3950,Information,O
3950,Retriever,O
3950,(,O
3950,FABIR,O
3950,),O
3950,.,O
3951,Our,O
3951,goal,O
3951,then,O
3951,was,O
3951,to,B
3951,verify,I
3951,how,B
3951,much,I
3951,performance,I
3951,we,O
3951,can,O
3951,get,B
3951,exclusively,I
3951,from,I
3951,the,O
3951,attention,B
3951,mechanism,I
3951,",",O
3951,without,B
3951,combining,I
3951,it,I
3951,with,I
3951,several,B
3951,other,I
3951,techniques,I
3951,.,O
3952,Convolutional,O
3952,attention,O
3952,:,O
3952,a,O
3952,novel,B
3952,attention,O
3952,mechanism,O
3952,that,O
3952,encodes,B
3952,many,I
3952,-,I
3952,to,I
3952,-,O
3952,many,O
3952,relationships,O
3952,between,B
3952,words,B
3952,",",O
3952,enabling,B
3952,richer,B
3952,contextual,I
3952,representations,I
3952,.,O
3953,We,O
3953,propose,B
3953,a,O
3953,new,B
3953,architecture,I
3953,",",O
3953,named,B
3953,Target,B
3953,-,I
3953,Specific,I
3953,Transformation,I
3953,Networks,I
3953,(,I
3953,TNet,I
3953,),I
3953,",",O
3953,to,O
3953,solve,O
3953,the,O
3953,above,O
3953,issues,O
3953,in,O
3953,the,O
3953,task,O
3953,of,O
3953,target,O
3953,sentiment,O
3953,classification,O
3953,.,O
3954,Reduction,O
3954,layer,O
3954,:,O
3954,a,O
3954,new,B
3954,layer,O
3954,design,O
3954,that,O
3954,fits,B
3954,the,O
3954,pipeline,B
3954,proposed,B
3954,by,I
3954,Vaswani,B
3954,et,I
3954,al,I
3954,.,I
3955,Column,O
3955,-,O
3955,wise,O
3955,cross,O
3955,-,O
3955,attention,O
3955,:,O
3955,we,O
3955,modify,B
3955,the,O
3955,crossattention,B
3955,operation,I
3955,by,O
3955,and,O
3955,propose,B
3955,a,O
3955,new,B
3955,technique,I
3955,that,O
3955,is,O
3955,better,B
3955,suited,I
3955,to,I
3955,question,B
3955,-,O
3955,answering,O
3955,.,O
3956,A,O
3956,Fully,O
3956,Attention,O
3956,-,O
3956,Based,O
3956,Information,B
3956,Retriever,I
3957,That,O
3957,is,O
3957,",",O
3957,in,O
3957,fact,O
3957,",",O
3957,the,O
3957,proposed,O
3957,focus,O
3957,of,O
3957,recent,O
3957,open,B
3957,-,I
3957,domain,I
3957,QA,I
3957,datasets,O
3957,",",O
3957,such,O
3957,as,O
3957,SQuAD,O
3957,.,O
3958,A,O
3958,QA,B
3958,system,O
3958,must,O
3958,then,O
3958,provide,O
3958,an,O
3958,answer,O
3958,A,O
3958,by,O
3958,selecting,O
3958,a,O
3958,snippet,O
3958,from,O
3958,P,O
3958,.,O
3959,Regarding,B
3959,EM,B
3959,and,I
3959,F,I
3959,1,I
3959,scores,I
3959,",",O
3959,FABIR,B
3959,and,O
3959,BiDAF,O
3959,showed,B
3959,similar,B
3959,performances,I
3959,.,O
3960,In,O
3960,this,O
3960,section,O
3960,we,O
3960,analyze,B
3960,the,O
3960,performance,B
3960,of,B
3960,FABIR,B
3960,and,I
3960,BiDAF,I
3960,in,O
3960,the,O
3960,different,O
3960,types,O
3960,of,O
3960,question,O
3960,in,O
3960,SQuAD,O
3960,.,O
3961,shows,B
3961,that,O
3961,shorter,B
3961,answers,I
3961,are,B
3961,easier,B
3961,for,B
3961,both,B
3961,models,I
3961,:,O
3961,while,O
3961,they,O
3961,reach,O
3961,more,O
3961,than,O
3961,75,O
3961,%,O
3961,F1,O
3961,for,O
3961,answers,O
3961,that,O
3961,are,O
3961,shorter,O
3961,than,O
3961,four,O
3961,words,O
3961,",",O
3961,for,O
3961,answers,O
3961,longer,O
3961,than,O
3961,ten,O
3961,words,O
3961,these,O
3961,scores,O
3961,drop,O
3961,to,O
3961,60.4,O
3961,%,O
3961,and,O
3961,67.3,O
3961,%,O
3961,for,O
3961,FABIR,O
3961,and,O
3961,BiDAF,O
3961,",",O
3961,respectively,O
3961,.,O
3962,shows,O
3962,that,O
3962,both,O
3962,models,O
3962,had,O
3962,their,O
3962,best,B
3962,performance,I
3962,with,B
3962,"""",I
3962,when,I
3962,"""",O
3962,questions,O
3962,.,O
3963,The,O
3963,third,B
3963,removes,B
3963,both,B
3963,forms,I
3963,of,I
3963,attention,I
3963,and,O
3963,additionally,O
3963,uses,B
3963,a,O
3963,regular,B
3963,objective,I
3963,function,I
3963,based,B
3963,on,I
3963,the,O
3963,inner,B
3963,product,I
3963,s,I
3963,=,I
3963,r,I
3963,w,I
3963,for,B
3963,a,O
3963,sentence,B
3963,representation,I
3963,r,O
3963,and,O
3963,relation,B
3963,class,I
3963,embedding,I
3963,w.,O
3964,TNet,B
3964,firstly,B
3964,encodes,I
3964,the,O
3964,context,B
3964,information,I
3964,into,B
3964,word,I
3964,embeddings,I
3964,and,O
3964,generates,B
3964,the,O
3964,contextualized,B
3964,word,O
3964,representations,O
3964,with,B
3964,LSTMs,B
3964,.,O
3965,Together,O
3965,with,O
3965,"""",O
3965,when,O
3965,"""",O
3965,questions,O
3965,",",O
3965,"""",O
3965,how,O
3965,long,O
3965,"""",O
3965,and,O
3965,"""",O
3965,how,O
3965,many,O
3965,"""",O
3965,also,O
3965,proved,B
3965,easier,B
3965,to,B
3965,respond,B
3965,",",O
3965,as,O
3965,they,O
3965,possess,B
3965,the,O
3965,same,B
3965,property,I
3965,of,B
3965,having,I
3965,a,O
3965,smaller,B
3965,universe,I
3965,of,O
3965,possible,B
3965,answers,I
3965,.,O
3966,In,O
3966,contrast,O
3966,to,O
3966,these,O
3966,",",O
3966,"""",O
3966,how,O
3966,"""",O
3966,and,O
3966,"""",O
3966,why,O
3966,"""",O
3966,questions,O
3966,resulted,O
3966,in,O
3966,considerably,B
3966,lower,I
3966,F1,I
3966,and,O
3966,EM,O
3966,scores,O
3966,",",O
3966,as,O
3966,they,O
3966,can,O
3966,be,O
3966,answered,O
3966,by,O
3966,any,O
3966,sentence,O
3966,",",O
3966,and,O
3966,hence,O
3966,require,O
3966,a,O
3966,deeper,O
3966,understanding,O
3966,of,O
3966,the,O
3966,text,O
3966,.,O
3967,Questions,B
3967,which,O
3967,expect,B
3967,a,I
3967,"""",I
3967,yes,I
3967,"""",O
3967,or,O
3967,a,O
3967,"""",O
3967,no,O
3967,"""",O
3967,as,B
3967,an,O
3967,answer,B
3967,are,B
3967,also,B
3967,difficult,I
3967,because,O
3967,it,O
3967,is,O
3967,not,O
3967,always,O
3967,possible,O
3967,to,O
3967,find,O
3967,those,O
3967,words,O
3967,in,O
3967,a,O
3967,snippet,O
3967,from,O
3967,the,O
3967,passage,O
3967,.,O
3968,It,O
3968,is,O
3968,curious,O
3968,that,O
3968,shorter,B
3968,passages,I
3968,showed,B
3968,the,O
3968,worst,B
3968,performance,I
3968,for,B
3968,both,B
3968,models,I
3968,.,O
3969,In,O
3969,this,O
3969,paper,O
3969,",",O
3969,we,O
3969,instead,O
3969,take,B
3969,the,O
3969,approach,B
3969,of,B
3969,converting,B
3969,questions,I
3969,to,B
3969,(,B
3969,uninterpretable,I
3969,),I
3969,vectorial,I
3969,representations,I
3969,which,O
3969,require,B
3969,no,I
3969,pre-defined,B
3969,grammars,I
3969,or,I
3969,lexicons,I
3969,and,O
3969,can,B
3969,query,B
3969,any,B
3969,KB,I
3969,independent,B
3969,of,O
3969,its,O
3969,schema,B
3969,.,O
3970,Following,O
3970,",",O
3970,we,O
3970,focus,B
3970,on,B
3970,answering,B
3970,simple,B
3970,factual,I
3970,questions,I
3970,on,O
3970,a,O
3970,broad,B
3970,range,I
3970,of,I
3970,topics,I
3970,",",O
3970,more,O
3970,specifically,O
3970,",",O
3970,those,O
3970,for,O
3970,which,O
3970,single,O
3970,KB,O
3970,triples,O
3970,stand,O
3970,for,O
3970,both,O
3970,the,O
3970,question,O
3970,and,O
3970,an,O
3970,answer,O
3970,(,O
3970,of,O
3970,which,O
3970,there,O
3970,maybe,O
3970,many,O
3970,),O
3970,.,O
3971,Our,O
3971,approach,O
3971,is,O
3971,based,B
3971,on,I
3971,learning,B
3971,low,B
3971,-,I
3971,dimensional,I
3971,vector,I
3971,embeddings,I
3971,of,B
3971,words,B
3971,and,I
3971,of,O
3971,KB,B
3971,triples,I
3971,so,B
3971,that,I
3971,representations,B
3971,of,O
3971,questions,B
3971,and,O
3971,corresponding,O
3971,answers,O
3971,end,B
3971,up,I
3971,being,O
3971,similar,B
3971,in,B
3971,the,O
3971,embedding,B
3971,space,I
3971,.,O
3972,In,O
3972,order,O
3972,to,O
3972,avoid,O
3972,transferring,O
3972,the,O
3972,cost,O
3972,of,O
3972,manual,O
3972,intervention,O
3972,to,O
3972,the,O
3972,one,O
3972,of,O
3972,labeling,O
3972,large,O
3972,amounts,O
3972,of,O
3972,data,O
3972,",",O
3972,we,O
3972,make,B
3972,use,I
3972,of,O
3972,weak,B
3972,supervision,I
3972,.,O
3973,We,O
3973,show,O
3973,empirically,O
3973,that,O
3973,our,O
3973,model,B
3973,is,O
3973,able,B
3973,to,I
3973,take,B
3973,advantage,I
3973,of,I
3973,noisy,B
3973,and,I
3973,indirect,I
3973,supervision,I
3973,by,B
3973,(,O
3973,i,O
3973,),O
3973,automatically,B
3973,generating,I
3973,questions,I
3973,from,B
3973,KB,B
3973,triples,I
3973,and,O
3973,treating,B
3973,this,I
3973,as,I
3973,training,B
3973,data,B
3973,;,O
3973,and,O
3973,(,O
3973,ii,O
3973,),O
3973,supplementing,B
3973,this,O
3973,with,B
3973,a,O
3973,data,O
3973,set,O
3973,of,O
3973,questions,O
3973,collaboratively,B
3973,marked,I
3973,as,O
3973,paraphrases,B
3973,but,O
3973,with,O
3973,no,O
3973,associated,B
3973,answers,I
3973,.,O
3974,We,O
3974,end,B
3974,up,I
3974,learning,I
3974,meaningful,B
3974,vectorial,I
3974,representations,I
3974,for,B
3974,questions,B
3974,involving,B
3974,up,O
3974,to,O
3974,800,B
3974,k,I
3974,words,I
3974,and,O
3974,for,O
3974,triples,B
3974,of,B
3974,an,O
3974,mostly,B
3974,automatically,I
3974,created,I
3974,KB,I
3974,with,B
3974,2.4,B
3974,M,I
3974,entities,I
3974,and,O
3974,600,B
3974,k,O
3974,relationships,O
3974,.,O
3975,To,O
3975,integrate,O
3975,the,O
3975,target,B
3975,information,I
3975,into,B
3975,the,O
3975,word,B
3975,representations,I
3975,",",O
3975,TNet,O
3975,introduces,B
3975,a,O
3975,novel,B
3975,Target,O
3975,-,O
3975,Specific,O
3975,Transformation,O
3975,(,O
3975,TST,O
3975,),O
3975,component,O
3975,for,B
3975,generating,I
3975,the,O
3975,target,O
3975,-,O
3975,specific,O
3975,word,O
3975,representations,O
3975,.,O
3976,This,O
3976,paper,O
3976,addresses,O
3976,the,O
3976,challenging,O
3976,problem,O
3976,of,O
3976,open,B
3976,-,I
3976,domain,I
3976,question,I
3976,answering,I
3976,",",O
3976,which,O
3976,consists,O
3976,of,O
3976,building,O
3976,systems,O
3976,able,O
3976,to,O
3976,answer,O
3976,questions,O
3976,from,O
3976,any,O
3976,domain,O
3976,.,O
3977,First,O
3977,",",O
3977,we,O
3977,can,O
3977,see,B
3977,that,I
3977,multitasking,B
3977,with,B
3977,paraphrase,B
3977,data,I
3977,is,B
3977,essential,B
3977,since,O
3977,it,O
3977,improves,B
3977,F1,B
3977,from,B
3977,0.60,B
3977,to,B
3977,0.68,B
3977,.,O
3978,Fine,O
3978,-,O
3978,tuning,O
3978,the,O
3978,embedding,B
3978,model,I
3978,is,B
3978,very,B
3978,beneficial,I
3978,to,B
3978,optimize,I
3978,the,O
3978,top,B
3978,of,B
3978,the,O
3978,list,O
3978,and,O
3978,grants,B
3978,a,O
3978,bump,B
3978,of,O
3978,5,B
3978,points,I
3978,of,O
3978,F1,B
3978,:,O
3978,carefully,O
3978,tuning,O
3978,the,O
3978,similarity,O
3978,makes,O
3978,a,O
3978,clear,O
3978,difference,O
3978,.,O
3979,All,O
3979,versions,O
3979,of,O
3979,our,O
3979,system,O
3979,greatly,B
3979,outperform,I
3979,paralex,B
3979,:,O
3979,the,O
3979,fine,B
3979,-,I
3979,tuned,I
3979,model,I
3979,improves,B
3979,the,O
3979,F1,B
3979,-,O
3979,score,O
3979,by,B
3979,almost,B
3979,20,I
3979,points,I
3979,and,O
3979,",",O
3979,according,O
3979,to,O
3979,",",O
3979,is,O
3979,better,O
3979,in,O
3979,precision,O
3979,for,O
3979,all,O
3979,levels,O
3979,of,O
3979,recall,O
3979,.,O
3980,As,O
3980,expected,O
3980,",",O
3980,string,B
3980,matching,I
3980,greatly,B
3980,improves,I
3980,results,B
3980,",",O
3980,both,B
3980,in,O
3980,precision,B
3980,and,I
3980,recall,I
3980,",",O
3980,and,O
3980,also,O
3980,significantly,B
3980,reduces,I
3980,evaluation,B
3980,time,I
3980,.,O
3981,The,O
3981,final,B
3981,F1,I
3981,obtained,B
3981,by,I
3981,our,B
3981,fine,I
3981,-,I
3981,tuned,I
3981,model,I
3981,is,B
3981,even,B
3981,better,I
3981,then,B
3981,the,O
3981,result,B
3981,of,B
3981,paralex,B
3981,in,B
3981,reranking,B
3981,",",O
3981,which,O
3981,is,O
3981,pretty,O
3981,remarkable,O
3981,",",O
3981,because,O
3981,this,O
3981,time,O
3981,",",O
3981,this,O
3981,setting,O
3981,advantages,O
3981,it,O
3981,quite,O
3981,a,O
3981,lot,O
3981,.,O
3982,We,O
3982,use,B
3982,uncased,B
3982,version,I
3982,of,B
3982,BERT,B
3982,base,I
3982,.,O
3983,Contrary,O
3983,to,B
3983,the,O
3983,previous,O
3983,attention,O
3983,-,O
3983,based,O
3983,approaches,O
3983,which,O
3983,apply,O
3983,the,O
3983,same,O
3983,target,O
3983,representation,O
3983,to,O
3983,determine,O
3983,the,O
3983,attention,O
3983,scores,O
3983,of,B
3983,individual,B
3983,context,I
3983,words,I
3983,",",O
3983,TST,B
3983,firstly,O
3983,generates,B
3983,different,B
3983,representations,I
3983,of,O
3983,the,O
3983,target,O
3983,conditioned,B
3983,on,I
3983,individual,O
3983,context,O
3983,words,O
3983,",",O
3983,then,O
3983,it,O
3983,consolidates,B
3983,each,B
3983,context,O
3983,word,O
3983,with,B
3983,its,O
3983,tailor,B
3983,-,O
3983,made,O
3983,target,O
3983,representation,O
3983,to,O
3983,obtain,O
3983,the,O
3983,transformed,B
3983,word,O
3983,representation,O
3983,.,O
3984,We,O
3984,use,O
3984,batch,B
3984,size,I
3984,of,B
3984,20,B
3984,for,B
3984,two,B
3984,reading,I
3984,comprehension,I
3984,tasks,I
3984,and,O
3984,192,B
3984,for,O
3984,two,O
3984,open,O
3984,-,O
3984,domain,O
3984,QA,O
3984,tasks,O
3984,.,O
3985,For,B
3985,opendomain,B
3985,QA,I
3985,tasks,I
3985,",",O
3985,we,O
3985,retrieve,B
3985,50,B
3985,Wikipedia,I
3985,articles,I
3985,through,B
3985,TF,B
3985,-,I
3985,IDF,I
3985,(,O
3985,Chen,O
3985,et,O
3985,al.,O
3986,",",O
3986,2017,O
3986,),O
3986,and,O
3986,further,O
3986,run,O
3986,to,O
3986,retrieve,B
3986,20,O
3986,(,O
3986,for,O
3986,train,O
3986,),O
3986,or,O
3986,80,O
3986,(,O
3986,for,O
3986,development,O
3986,and,O
3986,test,O
3986,),O
3986,paragraphs,O
3986,.,O
3987,We,O
3987,try,B
3987,10,B
3987,",",I
3987,20,I
3987,",",O
3987,40,O
3987,and,O
3987,80,O
3987,paragraphs,O
3987,on,O
3987,the,O
3987,development,B
3987,set,I
3987,to,B
3987,choose,I
3987,the,O
3987,number,B
3987,of,I
3987,paragraphs,O
3987,to,O
3987,use,O
3987,on,O
3987,the,O
3987,test,B
3987,set,O
3987,.,O
3988,To,O
3988,avoid,O
3988,local,B
3988,optima,I
3988,",",O
3988,we,O
3988,perform,B
3988,annealing,B
3988,:,O
3988,at,O
3988,training,O
3988,step,O
3988,t,O
3988,",",O
3988,the,O
3988,model,O
3988,optimizes,O
3988,on,O
3988,MML,O
3988,objective,O
3988,with,O
3988,a,O
3988,probability,O
3988,of,O
3988,min,O
3988,(,O
3988,t,O
3988,/,O
3988,?,O
3989,6,O
3989,First,B
3989,of,O
3989,all,O
3989,",",O
3989,we,O
3989,observe,B
3989,that,O
3989,First,O
3989,-,O
3989,Only,O
3989,is,B
3989,a,O
3989,strong,B
3989,baseline,I
3989,across,O
3989,all,O
3989,the,O
3989,datasets,O
3989,.,O
3990,Second,O
3990,",",O
3990,while,O
3990,MML,B
3990,achieves,B
3990,comparable,B
3990,result,I
3990,to,B
3990,the,O
3990,First,B
3990,-,I
3990,Only,I
3990,baseline,I
3990,",",O
3990,our,B
3990,learning,I
3990,method,I
3990,outperforms,B
3990,others,O
3990,by,B
3990,2,B
3990,+,I
3990,F1,I
3990,/,I
3990,ROUGE,I
3990,-,O
3990,L,O
3990,/,O
3990,EM,O
3990,consistently,O
3990,on,B
3990,all,B
3990,datasets,I
3990,.,O
3991,Lastly,O
3991,",",O
3991,our,B
3991,method,I
3991,achieves,B
3991,the,I
3991,new,B
3991,state,B
3991,-,I
3991,of,I
3991,the,O
3991,-,O
3991,art,O
3991,on,B
3991,NARRATIVEQA,B
3991,",",O
3991,TRIVIAQA,B
3991,-,O
3991,OPEN,O
3991,and,O
3991,NATURALQUESTIONS,B
3991,-,O
3991,OPEN,O
3991,",",O
3991,and,O
3991,is,O
3991,comparable,B
3991,to,B
3991,the,O
3991,state,O
3991,-,O
3991,of,O
3991,-,O
3991,the,O
3991,-,O
3991,art,O
3991,on,O
3991,TRIVIAQA,O
3991,",",O
3991,despite,O
3991,our,O
3991,aggressive,O
3991,truncation,O
3991,of,O
3991,documents,O
3991,.,O
3992,In,O
3992,this,O
3992,paper,O
3992,",",O
3992,we,O
3992,show,O
3992,it,O
3992,is,O
3992,possible,O
3992,to,O
3992,formulate,B
3992,a,O
3992,wide,B
3992,range,I
3992,of,I
3992,weakly,I
3992,supervised,I
3992,QA,I
3992,tasks,I
3992,as,B
3992,discrete,B
3992,latent,I
3992,-,I
3992,variable,I
3992,learning,I
3992,problems,I
3992,.,O
3993,We,O
3993,demonstrate,B
3993,that,B
3993,for,B
3993,many,B
3993,recently,I
3993,introduced,I
3993,tasks,I
3993,",",I
3993,which,O
3993,we,O
3993,group,B
3993,into,I
3993,three,B
3993,categories,I
3993,as,O
3993,given,O
3993,in,O
3993,",",O
3993,it,O
3993,is,O
3993,relatively,B
3993,easy,I
3993,to,B
3993,precompute,I
3993,a,O
3993,discrete,B
3993,",",O
3993,task,O
3993,-,O
3993,specific,O
3993,set,O
3993,of,O
3993,possible,O
3993,solutions,O
3993,that,O
3993,contains,O
3993,the,O
3993,correct,B
3993,solution,I
3993,along,B
3993,with,I
3993,a,O
3993,modest,B
3993,number,I
3993,of,O
3993,spurious,O
3993,options,O
3993,.,O
3994,The,O
3994,learning,B
3994,challenge,I
3994,is,B
3994,then,O
3994,to,B
3994,determine,I
3994,which,B
3994,solution,I
3994,in,B
3994,the,O
3994,set,B
3994,is,O
3994,the,O
3994,correct,B
3994,one,I
3994,",",O
3994,while,B
3994,estimating,I
3994,a,O
3994,complete,B
3994,QA,I
3994,model,I
3994,.,O
3995,As,O
3995,the,O
3995,context,O
3995,information,O
3995,carried,O
3995,by,O
3995,the,O
3995,representations,O
3995,from,O
3995,the,O
3995,LSTM,O
3995,layer,O
3995,will,O
3995,be,O
3995,lost,O
3995,after,O
3995,the,O
3995,non-linear,O
3995,TST,O
3995,",",O
3995,we,O
3995,design,B
3995,a,O
3995,contextpreserving,B
3995,mechanism,I
3995,to,B
3995,contextualize,I
3995,the,O
3995,generated,B
3995,target,I
3995,-,I
3995,specific,I
3995,word,I
3995,representations,O
3995,.,O
3996,Intuitively,O
3996,",",O
3996,these,O
3996,hard,B
3996,updates,I
3996,more,O
3996,strongly,B
3996,enforce,I
3996,our,O
3996,prior,B
3996,beliefs,I
3996,that,O
3996,there,B
3996,is,I
3996,a,O
3996,single,B
3996,correct,I
3996,solution,I
3996,.,O
3997,We,O
3997,model,B
3997,the,O
3997,set,B
3997,of,I
3997,possible,I
3997,solutions,I
3997,as,B
3997,a,O
3997,discrete,B
3997,latent,I
3997,variable,I
3997,",",O
3997,and,O
3997,develop,B
3997,a,O
3997,learning,B
3997,strategy,I
3997,that,O
3997,uses,B
3997,hard,B
3997,-,I
3997,EM,I
3997,-,O
3997,style,O
3997,parameter,O
3997,updates,O
3997,.,O
3998,This,O
3998,algorithm,O
3998,repeatedly,O
3998,(,O
3998,i,O
3998,),O
3998,predicts,B
3998,the,O
3998,most,B
3998,likely,I
3998,solution,I
3998,according,B
3998,to,B
3998,the,O
3998,current,B
3998,model,B
3998,from,B
3998,the,O
3998,precomputed,B
3998,set,I
3998,",",O
3998,and,O
3998,(,O
3998,ii,O
3998,),O
3998,updates,B
3998,the,O
3998,model,O
3998,parameters,O
3998,to,O
3998,further,O
3998,encourage,O
3998,its,O
3998,own,B
3998,prediction,I
3998,.,O
3999,A,O
3999,Discrete,O
3999,Hard,O
3999,EM,O
3999,Approach,O
3999,for,O
3999,Weakly,B
3999,Supervised,I
3999,Question,I
3999,Answering,I
4000,Many,O
4000,question,B
4000,answering,I
4000,(,I
4000,QA,I
4000,),I
4000,tasks,O
4000,only,O
4000,provide,O
4000,weak,O
4000,supervision,O
4000,for,O
4000,how,O
4000,the,O
4000,answer,O
4000,should,O
4000,be,O
4000,computed,O
4000,.,O
4001,Despite,O
4001,its,O
4001,simplicity,O
4001,",",O
4001,we,O
4001,show,O
4001,that,O
4001,this,O
4001,approach,O
4001,significantly,O
4001,outperforms,O
4001,previous,O
4001,methods,O
4001,on,O
4001,six,O
4001,QA,B
4001,tasks,O
4001,",",O
4001,including,O
4001,absolute,O
4001,gains,O
4001,of,O
4001,2,O
4001,-,O
4001,10,O
4001,%,O
4001,",",O
4001,and,O
4001,achieves,O
4001,the,O
4001,stateof,O
4001,-,O
4001,the,O
4001,-,O
4001,art,O
4001,on,O
4001,five,O
4001,of,O
4001,them,O
4001,.,O
4002,We,O
4002,also,O
4002,run,O
4002,the,O
4002,ablations,O
4002,of,B
4002,our,O
4002,single,B
4002,model,I
4002,on,B
4002,SQ,B
4002,u,I
4002,AD,I
4002,dev,I
4002,set,I
4002,to,O
4002,evaluate,O
4002,the,O
4002,individual,O
4002,contribution,O
4002,.,O
4003,As,O
4003,shows,O
4003,",",O
4003,both,B
4003,syntactic,B
4003,embeddings,I
4003,and,O
4003,semantic,B
4003,embeddings,O
4003,contribute,B
4003,towards,B
4003,the,O
4003,model,B
4003,'s,I
4003,performance,I
4003,and,O
4003,the,O
4003,POS,B
4003,tags,I
4003,seem,O
4003,to,B
4003,be,I
4003,more,B
4003,important,I
4003,.,O
4004,For,B
4004,ablating,O
4004,integral,B
4004,query,B
4004,matching,I
4004,",",O
4004,the,O
4004,result,B
4004,drops,B
4004,about,B
4004,2,B
4004,%,I
4004,on,O
4004,both,O
4004,metrics,O
4004,and,O
4004,it,O
4004,shows,B
4004,that,I
4004,the,O
4004,integral,O
4004,information,O
4004,of,B
4004,query,O
4004,for,O
4004,each,B
4004,word,I
4004,in,B
4004,passage,B
4004,is,B
4004,crucial,B
4004,.,O
4005,The,O
4005,query,B
4005,-,I
4005,based,I
4005,similarity,I
4005,matching,I
4005,accounts,B
4005,for,I
4005,about,B
4005,10,I
4005,%,I
4005,performance,I
4005,degradation,I
4005,",",O
4005,which,O
4005,proves,B
4005,the,O
4005,effectiveness,B
4005,of,B
4005,alignment,B
4005,context,I
4005,words,I
4005,against,B
4005,query,O
4005,.,O
4006,To,O
4006,help,O
4006,the,O
4006,CNN,B
4006,feature,I
4006,extractor,I
4006,locate,B
4006,sentiment,B
4006,indicators,I
4006,more,B
4006,accurately,I
4006,",",O
4006,we,O
4006,adopt,B
4006,a,B
4006,proximity,B
4006,strategy,I
4006,to,O
4006,scale,O
4006,the,O
4006,input,B
4006,of,B
4006,convolutional,B
4006,layer,I
4006,with,B
4006,positional,B
4006,relevance,I
4006,between,B
4006,a,O
4006,word,O
4006,and,O
4006,the,O
4006,target,O
4006,.,O
4007,For,B
4007,context,B
4007,-,I
4007,based,I
4007,similarity,I
4007,matching,I
4007,",",O
4007,we,O
4007,simply,O
4007,took,B
4007,out,I
4007,the,O
4007,M,B
4007,3,I
4007,from,B
4007,the,O
4007,linear,B
4007,function,I
4007,and,O
4007,it,O
4007,is,O
4007,proved,B
4007,to,B
4007,be,I
4007,contributory,B
4007,to,O
4007,the,O
4007,performance,B
4007,of,B
4007,full,B
4007,-,O
4007,orientation,O
4007,matching,O
4007,.,O
4008,The,O
4008,tokenizers,B
4008,we,O
4008,use,B
4008,in,I
4008,the,O
4008,step,B
4008,of,B
4008,preprocessing,B
4008,data,B
4008,are,O
4008,from,B
4008,Stanford,B
4008,CoreNLP,I
4008,.,O
4009,We,O
4009,also,O
4009,use,B
4009,part,B
4009,-,I
4009,of,I
4009,-,O
4009,speech,O
4009,tagger,O
4009,and,O
4009,named,B
4009,-,O
4009,entity,O
4009,recognition,O
4009,tagger,O
4009,in,B
4009,Stanford,B
4009,CoreNLP,I
4009,utilities,I
4009,to,B
4009,transform,I
4009,the,O
4009,passage,B
4009,and,O
4009,question,O
4009,.,O
4010,For,B
4010,the,O
4010,skip,B
4010,-,I
4010,gram,I
4010,model,I
4010,",",O
4010,our,B
4010,model,O
4010,refers,B
4010,to,I
4010,the,O
4010,word2,B
4010,vec,I
4010,module,I
4010,in,B
4010,open,B
4010,source,I
4010,software,I
4010,library,I
4010,",",O
4010,Tensorflow,B
4010,",",O
4010,the,O
4010,skip,O
4010,window,O
4010,is,O
4010,set,B
4010,as,I
4010,2,B
4010,.,O
4011,For,O
4011,the,O
4011,memory,B
4011,networks,I
4011,",",O
4011,we,O
4011,set,B
4011,the,O
4011,number,B
4011,of,I
4011,layer,I
4011,as,B
4011,3,B
4011,.,O
4012,To,O
4012,improve,O
4012,the,O
4012,reliability,B
4012,and,I
4012,stabllity,I
4012,",",O
4012,we,O
4012,screen,B
4012,out,I
4012,the,O
4012,sentences,B
4012,whose,B
4012,length,B
4012,are,B
4012,shorter,B
4012,than,I
4012,9,I
4012,.,O
4013,We,O
4013,use,B
4013,100,B
4013,one,I
4013,dimensional,I
4013,filters,B
4013,for,B
4013,CNN,B
4013,in,B
4013,the,O
4013,character,B
4013,level,I
4013,embedding,I
4013,",",O
4013,with,B
4013,width,B
4013,of,B
4013,5,B
4013,for,O
4013,each,B
4013,one,O
4013,.,O
4014,We,O
4014,use,O
4014,the,O
4014,AdaDelta,B
4014,(,I
4014,Zeiler,I
4014,",",I
4014,2012,I
4014,),I
4014,optimizer,I
4014,with,B
4014,a,O
4014,initial,B
4014,learning,I
4014,rate,I
4014,as,B
4014,0.001,B
4014,.,O
4015,We,O
4015,set,B
4015,the,I
4015,hidden,B
4015,size,I
4015,as,B
4015,100,B
4015,for,B
4015,all,B
4015,the,O
4015,LSTM,O
4015,and,O
4015,GRU,O
4015,layers,B
4015,and,O
4015,apply,B
4015,dropout,B
4015,between,B
4015,layers,O
4015,with,B
4015,a,O
4015,dropout,O
4015,ratio,O
4015,as,O
4015,0.2,B
4015,.,O
4016,In,O
4016,this,O
4016,paper,O
4016,",",O
4016,we,O
4016,introduce,B
4016,the,O
4016,Multi,B
4016,-,I
4016,layer,I
4016,Embedding,I
4016,with,I
4016,Memory,I
4016,Networks,I
4016,(,I
4016,MEMEN,I
4016,),I
4016,",",O
4016,an,O
4016,end,O
4016,-,O
4016,to,O
4016,-,O
4016,end,O
4016,neural,O
4016,network,O
4016,for,B
4016,machine,B
4016,comprehension,I
4016,task,I
4016,.,O
4017,Transformation,O
4017,Networks,O
4017,for,O
4017,Target,B
4017,-,I
4017,Oriented,I
4017,Sentiment,I
4017,Classification,I
4018,Our,O
4018,model,O
4018,consists,B
4018,of,I
4018,three,B
4018,parts,I
4018,:,O
4019,1,O
4019,),O
4019,the,O
4019,encoding,B
4019,of,B
4019,context,I
4019,and,I
4019,query,I
4019,",",O
4019,in,B
4019,which,I
4019,we,O
4019,add,B
4019,useful,B
4019,syntactic,I
4019,and,O
4019,semantic,O
4019,information,O
4019,in,O
4019,the,O
4019,embedding,B
4019,of,O
4019,every,B
4019,word,I
4019,",",O
4019,2,O
4019,),O
4019,the,O
4019,high,B
4019,-,I
4019,efficiency,I
4019,multilayer,I
4019,memory,I
4019,network,I
4019,of,O
4019,full,B
4019,-,O
4019,orientation,O
4019,matching,O
4019,to,B
4019,match,I
4019,the,O
4019,question,B
4019,and,O
4019,context,O
4019,",",O
4019,3,O
4019,),O
4019,the,O
4019,pointer,B
4019,-,O
4019,network,O
4019,based,O
4019,answer,B
4019,boundary,I
4019,prediction,I
4019,layer,I
4019,to,O
4019,get,O
4019,the,O
4019,location,B
4019,of,O
4019,the,O
4019,answer,O
4019,in,O
4019,the,O
4019,passage,B
4019,.,O
4020,MEMEN,O
4020,:,O
4020,Multi-layer,O
4020,Embedding,O
4020,with,O
4020,Memory,O
4020,Networks,O
4020,for,O
4020,Machine,B
4020,Comprehension,I
4021,As,O
4021,we,O
4021,can,O
4021,see,B
4021,in,O
4021,",",O
4021,our,B
4021,model,I
4021,outperforms,B
4021,all,B
4021,other,I
4021,baselines,I
4021,and,O
4021,achieves,B
4021,the,I
4021,state,B
4021,-,I
4021,of,I
4021,-,O
4021,the,O
4021,-,O
4021,art,O
4021,result,O
4021,on,O
4021,all,O
4021,subsets,O
4021,on,O
4021,TriviaQA,O
4021,.,O
4022,We,O
4022,also,O
4022,use,B
4022,the,O
4022,Stanford,B
4022,Question,I
4022,Answering,I
4022,Dataset,I
4022,(,I
4022,SQuAD,I
4022,),I
4022,v,I
4022,1.1,I
4022,to,B
4022,conduct,O
4022,our,O
4022,experiments,O
4022,.,O
4023,The,O
4023,results,O
4023,of,B
4023,this,O
4023,dataset,O
4023,are,O
4023,all,O
4023,exhibited,O
4023,on,O
4023,a,O
4023,leaderboard,O
4023,",",O
4023,and,O
4023,top,O
4023,methods,O
4023,are,O
4023,almost,O
4023,all,O
4023,ensemble,O
4023,models,O
4023,",",O
4023,our,B
4023,model,I
4023,achieves,B
4023,an,O
4023,exact,B
4023,match,I
4023,score,I
4023,of,O
4023,75.37,B
4023,%,I
4023,and,O
4023,an,O
4023,F1,B
4023,score,O
4023,of,O
4023,82,O
4023,.,O
4024,66,O
4024,%,O
4024,",",O
4024,which,O
4024,is,B
4024,competitive,B
4024,to,O
4024,state,B
4024,-,I
4024,of,B
4024,-,O
4024,the,O
4024,-,O
4024,art,O
4024,method,O
4024,.,O
4025,We,O
4025,note,B
4025,that,O
4025,the,O
4025,deep,B
4025,residual,I
4025,coattention,I
4025,yielded,B
4025,the,O
4025,highest,B
4025,contribution,I
4025,to,B
4025,model,B
4025,performance,I
4025,",",O
4025,followed,B
4025,by,I
4025,the,O
4025,mixed,B
4025,objective,I
4025,.,O
4026,The,O
4026,sparse,B
4026,mixture,I
4026,of,B
4026,experts,B
4026,layer,I
4026,in,B
4026,the,O
4026,decoder,B
4026,added,B
4026,minor,B
4026,improvements,I
4026,to,B
4026,the,O
4026,model,B
4026,performance,I
4026,.,O
4027,LSTM,O
4027,-,O
4027,based,O
4027,models,O
4027,relying,B
4027,on,I
4027,sequential,B
4027,information,I
4027,can,B
4027,perform,I
4027,well,B
4027,for,B
4027,formal,B
4027,sentences,I
4027,by,B
4027,capturing,I
4027,more,B
4027,useful,I
4027,context,I
4027,features,I
4027,;,O
4028,To,O
4028,preprocess,B
4028,the,O
4028,corpus,B
4028,",",O
4028,we,O
4028,use,B
4028,the,O
4028,reversible,B
4028,tokenizer,I
4028,from,B
4028,Stanford,B
4028,CoreNLP,I
4028,.,O
4029,For,B
4029,word,B
4029,embeddings,I
4029,",",O
4029,we,O
4029,use,B
4029,GloVe,B
4029,embeddings,O
4029,pretrained,B
4029,on,I
4029,the,O
4029,840B,B
4029,Common,I
4029,Crawl,I
4029,corpus,I
4029,as,O
4029,well,O
4029,as,O
4029,character,O
4029,ngram,O
4029,embeddings,O
4029,by,O
4029,.,O
4030,In,O
4030,addition,O
4030,",",O
4030,we,O
4030,concatenate,B
4030,these,B
4030,embeddings,I
4030,with,B
4030,context,B
4030,vectors,I
4030,(,I
4030,CoVe,I
4030,),I
4030,trained,O
4030,on,O
4030,.,O
4031,For,O
4031,out,B
4031,of,I
4031,vocabulary,I
4031,words,I
4031,",",O
4031,we,O
4031,set,B
4031,the,O
4031,embeddings,B
4031,and,I
4031,context,I
4031,vectors,I
4031,to,B
4031,zero,B
4031,.,O
4032,We,O
4032,perform,B
4032,word,B
4032,dropout,I
4032,on,B
4032,the,O
4032,document,B
4032,which,O
4032,zeros,B
4032,a,O
4032,word,O
4032,embedding,O
4032,with,B
4032,probability,B
4032,0.075,I
4032,.,O
4033,In,B
4033,addition,O
4033,",",O
4033,we,O
4033,swap,B
4033,the,O
4033,first,B
4033,maxout,I
4033,layer,I
4033,of,B
4033,the,O
4033,highway,B
4033,maxout,O
4033,network,O
4033,in,O
4033,the,O
4033,DCN,B
4033,decoder,I
4033,with,B
4033,a,O
4033,sparse,B
4033,mixture,I
4033,of,O
4033,experts,B
4033,layer,O
4033,.,O
4034,To,O
4034,address,O
4034,this,O
4034,problem,O
4034,",",O
4034,we,O
4034,propose,B
4034,a,O
4034,mixed,B
4034,objective,I
4034,that,O
4034,combines,B
4034,traditional,B
4034,cross,I
4034,entropy,I
4034,loss,I
4034,over,B
4034,positions,B
4034,with,I
4034,a,O
4034,measure,B
4034,of,I
4034,word,I
4034,overlap,I
4034,trained,B
4034,with,O
4034,reinforcement,B
4034,learning,I
4034,.,O
4035,We,O
4035,obtain,B
4035,the,O
4035,latter,B
4035,objective,I
4035,using,B
4035,self,B
4035,-,I
4035,critical,I
4035,policy,I
4035,learning,I
4035,in,B
4035,which,I
4035,the,O
4035,reward,B
4035,is,O
4035,based,B
4035,on,I
4035,word,B
4035,overlap,I
4035,between,B
4035,the,O
4035,proposed,B
4035,answer,I
4035,and,O
4035,the,O
4035,ground,B
4035,truth,I
4035,answer,O
4035,.,O
4036,In,O
4036,addition,O
4036,to,O
4036,our,O
4036,mixed,O
4036,training,O
4036,objective,O
4036,",",O
4036,we,O
4036,extend,B
4036,the,O
4036,Dynamic,B
4036,Coattention,I
4036,Network,I
4036,(,I
4036,DCN,I
4036,),I
4036,by,O
4036,with,B
4036,a,O
4036,deep,B
4036,residual,I
4036,coattention,O
4036,encoder,O
4036,.,O
4037,DCN,O
4037,+,O
4037,:,O
4037,MIXED,O
4037,OBJECTIVE,O
4037,AND,O
4037,DEEP,O
4037,RESIDUAL,O
4037,COATTENTION,O
4037,FOR,O
4037,QUESTION,B
4037,ANSWERING,I
4038,For,B
4038,ungrammatical,B
4038,text,I
4038,",",O
4038,CNN,B
4038,-,I
4038,based,I
4038,models,I
4038,may,B
4038,have,I
4038,some,B
4038,advantages,I
4038,because,O
4038,CNN,O
4038,aims,O
4038,to,O
4038,extract,O
4038,the,O
4038,most,O
4038,informative,O
4038,n-gram,O
4038,features,O
4038,and,O
4038,is,O
4038,thus,O
4038,less,O
4038,sensitive,O
4038,to,O
4038,informal,O
4038,texts,O
4038,without,O
4038,strong,O
4038,sequential,O
4038,patterns,O
4038,.,O
4039,Comparison,O
4039,to,O
4039,baseline,B
4039,DCN,O
4039,with,O
4039,CoVe.,O
4040,DCN,O
4040,+,O
4040,outperforms,B
4040,the,O
4040,baseline,B
4040,by,B
4040,3.2,B
4040,%,I
4040,exact,I
4040,match,I
4040,accuracy,I
4040,and,O
4040,3.2,O
4040,%,O
4040,F1,O
4040,on,B
4040,the,O
4040,SQuAD,B
4040,development,I
4040,set,I
4040,.,O
4041,shows,B
4041,the,O
4041,consistent,B
4041,performance,I
4041,gain,I
4041,of,B
4041,DCN,B
4041,+,I
4041,over,B
4041,the,O
4041,baseline,B
4041,across,B
4041,question,B
4041,types,I
4041,",",O
4041,question,O
4041,lengths,O
4041,",",O
4041,and,O
4041,answer,B
4041,lengths,O
4041,.,O
4042,In,O
4042,particular,O
4042,",",O
4042,DCN,B
4042,+,I
4042,provides,B
4042,a,O
4042,significant,B
4042,advantage,I
4042,for,B
4042,long,B
4042,questions,I
4042,.,O
4043,This,O
4043,baseline,O
4043,uses,B
4043,a,O
4043,similar,B
4043,architecture,I
4043,to,B
4043,our,O
4043,proposed,B
4043,neural,I
4043,multitask,I
4043,learning,I
4043,framework,I
4043,",",O
4043,except,O
4043,that,O
4043,it,O
4043,only,O
4043,optimizes,B
4043,the,O
4043,network,B
4043,for,B
4043,the,O
4043,main,B
4043,loss,I
4043,regarding,B
4043,the,O
4043,citation,B
4043,intent,I
4043,classification,I
4043,(,I
4043,L,I
4043,1,I
4043,),I
4043,and,O
4043,does,O
4043,not,O
4043,include,O
4043,the,O
4043,structural,O
4043,scaffolds,O
4043,.,O
4044,Our,O
4044,code,O
4044,and,O
4044,data,O
4044,are,O
4044,available,O
4044,at,O
4044,:,O
4044,https://github.com/,B
4044,allenai/scicite,I
4044,.,O
4045,To,O
4045,address,O
4045,these,O
4045,limitations,O
4045,",",O
4045,we,O
4045,introduce,B
4045,Sci,B
4045,-,I
4045,Cite,I
4045,",",O
4045,a,O
4045,new,B
4045,dataset,I
4045,of,B
4045,citation,B
4045,intents,I
4045,that,B
4045,is,I
4045,significantly,B
4045,larger,I
4045,",",O
4045,more,O
4045,coarse,O
4045,-,O
4045,grained,O
4045,and,O
4045,generaldomain,O
4045,compared,B
4045,with,I
4045,existing,B
4045,datasets,I
4045,.,O
4046,We,O
4046,consider,B
4046,three,B
4046,intent,I
4046,categories,I
4046,outlined,O
4046,in,O
4046,:,O
4046,BACK,B
4046,-,I
4046,GROUND,I
4046,",",O
4046,METHOD,B
4046,and,O
4046,RESULTCOMPARISON,B
4046,.,O
4047,Citation,O
4047,intent,O
4047,of,B
4047,sentence,B
4047,extractions,I
4047,was,O
4047,labeled,B
4047,through,I
4047,the,O
4047,crowdsourcing,B
4047,platform,I
4047,.,O
4048,Citation,O
4048,contexts,O
4048,were,O
4048,annotated,B
4048,by,I
4048,850,B
4048,crowdsource,I
4048,workers,I
4048,who,O
4048,made,O
4048,a,O
4048,total,B
4048,of,I
4048,"29,926",I
4048,annotations,I
4048,and,I
4048,individually,B
4048,made,O
4048,between,O
4048,4,B
4048,and,O
4048,240,O
4048,annotations,O
4048,.,O
4049,Each,O
4049,sentence,B
4049,was,B
4049,annotated,B
4049,",",O
4049,on,B
4049,average,I
4049,",",O
4049,3.74,B
4049,times,I
4049,.,O
4050,This,O
4050,resulted,B
4050,in,I
4050,a,O
4050,total,B
4050,"9,159",I
4050,crowdsourced,B
4050,instances,I
4050,which,O
4050,were,O
4050,divided,B
4050,to,I
4050,training,B
4050,and,I
4050,validation,I
4050,sets,I
4050,with,B
4050,90,B
4050,%,I
4050,of,B
4050,the,O
4050,data,B
4050,used,B
4050,for,I
4050,the,O
4050,training,O
4050,set,O
4050,.,O
4051,We,O
4051,implement,B
4051,our,O
4051,proposed,B
4051,scaffold,I
4051,framework,I
4051,using,B
4051,the,O
4051,AllenNLP,B
4051,library,I
4051,.,O
4052,For,B
4052,word,B
4052,representations,I
4052,",",O
4052,we,O
4052,use,B
4052,100,B
4052,-,I
4052,dimensional,I
4052,GloVe,I
4052,vectors,I
4052,trained,B
4052,on,I
4052,a,O
4052,corpus,B
4052,of,B
4052,6B,B
4052,tokens,I
4052,from,B
4052,Wikipedia,B
4052,and,I
4052,Gigaword,I
4052,.,O
4053,For,O
4053,contextual,B
4053,representations,I
4053,",",O
4053,we,O
4053,use,B
4053,ELMo,B
4053,vectors,I
4053,released,O
4053,by,O
4053,with,B
4053,output,B
4053,dimension,I
4053,size,I
4053,of,B
4053,"1,024",B
4053,which,O
4053,have,O
4053,been,O
4053,trained,B
4053,on,I
4053,a,O
4053,dataset,B
4053,of,O
4053,5.5,B
4053,B,I
4053,tokens,I
4053,.,O
4054,For,O
4054,each,B
4054,of,B
4054,scaffold,I
4054,tasks,I
4054,",",O
4054,we,O
4054,use,B
4054,a,O
4054,single,B
4054,-,I
4054,layer,I
4054,MLP,I
4054,with,B
4054,20,B
4054,hidden,I
4054,nodes,I
4054,",",O
4054,ReLU,B
4054,activation,I
4054,and,I
4054,a,O
4054,Dropout,B
4054,rate,I
4054,of,O
4054,0.2,B
4054,between,B
4054,the,O
4054,hidden,O
4054,and,O
4054,input,O
4054,layers,O
4054,.,O
4055,We,O
4055,use,B
4055,a,O
4055,single,B
4055,-,I
4055,layer,I
4055,BiLSTM,I
4055,with,B
4055,a,O
4055,hidden,B
4055,dimension,I
4055,size,I
4055,of,B
4055,50,B
4055,for,O
4055,each,O
4055,direction,O
4055,11,O
4055,.,O
4056,We,O
4056,use,O
4056,Beaker,B
4056,12,O
4056,for,B
4056,running,B
4056,the,I
4056,experiments,I
4056,.,O
4057,Batch,O
4057,size,O
4057,is,B
4057,8,B
4057,for,B
4057,ACL,B
4057,-,I
4057,ARC,I
4057,dataset,I
4057,and,O
4057,32,B
4057,for,O
4057,SciCite,B
4057,dataset,O
4057,(,O
4057,recall,O
4057,that,O
4057,SciCite,O
4057,is,O
4057,larger,O
4057,than,O
4057,ACL,O
4057,-,O
4057,ARC,O
4057,),O
4057,.,O
4058,To,O
4058,this,O
4058,end,O
4058,",",O
4058,we,O
4058,propose,B
4058,a,O
4058,neural,B
4058,multitask,I
4058,learning,I
4058,framework,I
4058,to,O
4058,incorporate,O
4058,knowledge,B
4058,into,B
4058,citations,B
4058,from,B
4058,the,O
4058,structure,B
4058,of,I
4058,scientific,I
4058,papers,I
4058,.,O
4059,A,O
4059,strong,B
4059,context,I
4059,-,I
4059,free,I
4059,benchmark,I
4059,model,I
4059,which,B
4059,uses,I
4059,similar,B
4059,multimodal,I
4059,approach,I
4059,on,B
4059,an,O
4059,ensemble,B
4059,of,I
4059,trees,I
4059,.,O
4060,In,O
4060,particular,O
4060,",",O
4060,we,O
4060,propose,O
4060,two,B
4060,auxiliary,I
4060,tasks,I
4060,as,B
4060,structural,B
4060,scaffolds,I
4060,to,B
4060,improve,I
4060,citation,B
4060,intent,I
4060,prediction,I
4060,:,O
4060,1,O
4060,(,O
4060,1,O
4060,),O
4060,predicting,O
4060,the,O
4060,section,O
4060,title,O
4060,in,O
4060,which,O
4060,the,O
4060,citation,O
4060,occurs,O
4060,and,O
4060,(,O
4060,2,O
4060,),O
4060,predicting,O
4060,whether,O
4060,a,O
4060,sentence,O
4060,needs,O
4060,a,O
4060,citation,O
4060,.,O
4061,Our,O
4061,contributions,O
4061,are,O
4061,:,O
4061,(,O
4061,i,O
4061,),O
4061,we,O
4061,propose,O
4061,a,O
4061,neural,B
4061,scaffold,I
4061,framework,I
4061,for,B
4061,citation,B
4061,intent,I
4061,classification,I
4061,to,B
4061,incorporate,I
4061,into,I
4061,citations,B
4061,knowledge,B
4061,from,B
4061,structure,B
4061,of,I
4061,scientific,I
4061,papers,I
4061,;,O
4061,(,O
4061,ii,O
4061,),O
4061,we,O
4061,achieve,O
4061,a,O
4061,new,O
4061,state,O
4061,-,O
4061,of,O
4061,-,O
4061,the,O
4061,-,O
4061,art,O
4061,of,O
4061,67.9,O
4061,%,O
4061,F1,O
4061,on,O
4061,the,O
4061,ACL,O
4061,-,O
4061,ARC,O
4061,citations,O
4061,benchmark,O
4061,",",O
4061,an,O
4061,absolute,O
4061,13.3,O
4061,%,O
4061,increase,O
4061,over,O
4061,the,O
4061,previous,O
4061,state,O
4061,-,O
4061,of,O
4061,-,O
4061,the,O
4061,-,O
4061,art,O
4061,;,O
4061,and,O
4061,(,O
4061,iii,O
4061,),O
4061,we,O
4061,introduce,O
4061,SciCite,O
4061,",",O
4061,a,O
4061,new,O
4061,dataset,O
4061,of,O
4061,citation,O
4061,intents,O
4061,which,O
4061,is,O
4061,at,O
4061,least,O
4061,five,O
4061,times,O
4061,as,O
4061,large,O
4061,as,O
4061,existing,O
4061,datasets,O
4061,and,O
4061,covers,O
4061,a,O
4061,variety,O
4061,of,O
4061,scientific,O
4061,domains,O
4061,.,O
4062,On,B
4062,two,B
4062,datasets,I
4062,",",O
4062,we,O
4062,show,B
4062,that,I
4062,the,O
4062,proposed,B
4062,neural,I
4062,scaffold,I
4062,model,I
4062,outperforms,B
4062,existing,B
4062,methods,I
4062,by,B
4062,large,B
4062,margins,I
4062,.,O
4063,Structural,O
4063,Scaffolds,O
4063,for,O
4063,Citation,B
4063,Intent,I
4063,Classification,I
4063,in,I
4063,Scientific,I
4063,Publications,I
4064,In,O
4064,this,O
4064,work,O
4064,",",O
4064,we,O
4064,approach,O
4064,the,O
4064,problem,O
4064,of,O
4064,citation,B
4064,intent,I
4064,classification,I
4064,by,O
4064,modeling,O
4064,the,O
4064,language,O
4064,expressed,O
4064,in,O
4064,the,O
4064,citation,O
4064,context,O
4064,.,O
4065,We,O
4065,observe,B
4065,that,O
4065,our,O
4065,scaffold,B
4065,-,I
4065,enhanced,I
4065,models,I
4065,achieve,B
4065,clear,B
4065,improvements,I
4065,over,B
4065,the,I
4065,state,B
4065,-,O
4065,of,O
4065,-,O
4065,the,O
4065,-,O
4065,art,O
4065,approach,O
4065,on,O
4065,this,O
4065,task,O
4065,.,O
4066,Generally,O
4066,we,O
4066,observe,O
4066,that,O
4066,results,B
4066,on,B
4066,categories,B
4066,with,B
4066,more,B
4066,number,I
4066,of,I
4066,instances,I
4066,are,B
4066,higher,B
4066,.,O
4067,Starting,O
4067,with,B
4067,the,O
4067,',O
4067,BiLSTM,O
4067,-,O
4067,Attn,O
4067,',O
4067,baseline,O
4067,with,O
4067,a,O
4067,macro,B
4067,F1,B
4067,score,I
4067,of,B
4067,51.8,B
4067,",",O
4067,adding,B
4067,the,O
4067,first,B
4067,scaffold,I
4067,task,I
4067,in,I
4067,',O
4067,BiLSTM,O
4067,-,O
4067,Attn,O
4067,+,O
4067,section,O
4067,title,O
4067,scaffold,O
4067,',O
4067,improves,B
4067,the,O
4067,F1,O
4067,score,O
4067,to,B
4067,56.9,B
4067,(?=,I
4067,5.1,I
4067,),I
4067,.,O
4068,Adding,B
4068,the,O
4068,second,B
4068,scaffold,I
4068,in,I
4068,',O
4068,BiLSTM,B
4068,-,I
4068,Attn,I
4068,+,I
4068,citation,I
4068,worthiness,I
4068,scaffold,O
4068,',O
4068,also,O
4068,results,B
4068,in,O
4068,similar,B
4068,improvements,I
4068,:,O
4068,56.3,B
4068,(?=,I
4068,4.5,I
4068,),I
4068,.,O
4069,We,O
4069,observe,B
4069,that,I
4069,all,B
4069,three,I
4069,of,I
4069,our,I
4069,components,I
4069,lead,B
4069,to,I
4069,noticeable,B
4069,improvements,I
4069,over,B
4069,these,O
4069,baselines,B
4069,.,O
4070,Adding,O
4070,both,B
4070,scaffolds,I
4070,results,B
4070,in,I
4070,further,B
4070,improvements,I
4070,.,O
4071,When,O
4071,both,O
4071,scaffolds,O
4071,are,O
4071,used,B
4071,simultaneously,I
4071,in,I
4071,',O
4071,BiLSTM,B
4071,-,I
4071,Attn,I
4071,+,I
4071,both,O
4071,scaffolds,O
4071,',O
4071,",",O
4071,the,O
4071,F1,B
4071,score,I
4071,further,O
4071,improves,B
4071,to,I
4071,63.1,B
4071,(,I
4071,?=,I
4071,11.3,I
4071,),I
4071,",",O
4071,suggesting,O
4071,that,O
4071,the,O
4071,two,O
4071,tasks,O
4071,provide,O
4071,complementary,O
4071,signal,O
4071,that,O
4071,is,O
4071,useful,O
4071,for,O
4071,citation,O
4071,intent,O
4071,prediction,O
4071,.,O
4072,The,O
4072,best,O
4072,result,O
4072,is,O
4072,achieved,O
4072,when,O
4072,we,O
4072,also,O
4072,add,B
4072,ELMo,I
4072,vectors,I
4072,to,B
4072,the,O
4072,input,B
4072,representations,I
4072,in,B
4072,',O
4072,BiLSTM,B
4072,-,I
4072,Attn,I
4072,w,I
4072,/,I
4072,ELMo,O
4072,+,O
4072,both,O
4072,scaffolds,O
4072,',O
4072,",",O
4072,achieving,B
4072,an,O
4072,F1,B
4072,of,B
4072,67.9,B
4072,",",O
4072,a,O
4072,major,B
4072,improvement,I
4072,from,B
4072,the,O
4072,previous,B
4072,state,I
4072,-,O
4072,of,O
4072,-,O
4072,the,O
4072,-,O
4072,art,O
4072,results,O
4072,of,O
4072,54.6,B
4072,(,I
4072,?=,I
4072,13.3,I
4072,),I
4072,.,O
4073,And,O
4073,the,O
4073,best,B
4073,results,I
4073,are,O
4073,obtained,O
4073,by,B
4073,using,I
4073,ELMo,B
4073,representation,I
4073,in,B
4073,addition,I
4073,to,I
4073,both,B
4073,scaffolds,I
4073,.,O
4074,Each,O
4074,scaffold,O
4074,task,O
4074,improves,B
4074,model,B
4074,performance,I
4074,.,O
4075,We,O
4075,note,B
4075,that,O
4075,the,O
4075,scaffold,B
4075,tasks,I
4075,provide,B
4075,major,B
4075,contributions,I
4075,on,B
4075,top,I
4075,of,I
4075,the,O
4075,ELMo,B
4075,-,I
4075,enabled,I
4075,baseline,I
4075,(,I
4075,?=,I
4075,13.6,I
4075,),I
4075,",",O
4075,demonstrating,O
4075,the,O
4075,efficacy,O
4075,of,O
4075,using,O
4075,structural,O
4075,scaffolds,O
4075,for,O
4075,citation,O
4075,intent,O
4075,prediction,O
4075,.,O
4076,We,O
4076,also,O
4076,experimented,B
4076,with,I
4076,adding,B
4076,features,I
4076,used,B
4076,in,B
4076,to,O
4076,our,B
4076,best,I
4076,model,I
4076,and,O
4076,not,O
4076,only,O
4076,we,O
4076,did,O
4076,not,O
4076,see,O
4076,any,O
4076,improvements,O
4076,",",O
4076,but,O
4076,we,O
4076,observed,B
4076,at,B
4076,least,I
4076,1.7,I
4076,%,I
4076,decline,I
4076,in,O
4076,performance,B
4076,.,O
4077,For,O
4077,example,O
4077,on,B
4077,ACL,B
4077,-,I
4077,ARC,I
4077,",",O
4077,the,O
4077,results,B
4077,on,O
4077,the,O
4077,BACKGROUND,B
4077,category,B
4077,are,B
4077,the,O
4077,highest,B
4077,as,B
4077,this,O
4077,category,O
4077,is,B
4077,the,O
4077,most,B
4077,common,I
4077,.,O
4078,Conversely,O
4078,",",O
4078,the,O
4078,results,O
4078,on,O
4078,the,O
4078,FUTUREWORK,B
4078,category,I
4078,are,B
4078,the,O
4078,lowest,B
4078,.,O
4079,This,O
4079,category,O
4079,has,O
4079,the,O
4079,fewest,B
4079,data,I
4079,points,I
4079,(,O
4079,see,O
4079,distribution,O
4079,of,O
4079,the,O
4079,categories,O
4079,in,O
4079,),O
4079,and,O
4079,thus,B
4079,it,O
4079,is,O
4079,harder,B
4079,for,B
4079,the,O
4079,model,B
4079,to,B
4079,learn,I
4079,the,O
4079,optimal,B
4079,parameters,I
4079,for,O
4079,correct,B
4079,classification,I
4079,in,O
4079,this,O
4079,category,O
4079,.,O
4080,A,O
4080,bi-directional,B
4080,LSTM,I
4080,equipped,B
4080,with,I
4080,hierarchical,B
4080,fusion,I
4080,",",O
4080,proposed,O
4080,by,O
4080,.,O
4081,As,O
4081,can,O
4081,be,O
4081,seen,O
4081,from,O
4081,",",O
4081,our,O
4081,HSLN,B
4081,-,I
4081,CNN,I
4081,model,I
4081,uni-formly,O
4081,suffers,B
4081,a,I
4081,little,I
4081,more,I
4081,from,O
4081,the,O
4081,component,B
4081,removal,I
4081,than,B
4081,the,O
4081,HSLN,O
4081,-,O
4081,RNN,O
4081,model,O
4081,",",O
4081,indicating,O
4081,that,O
4081,the,O
4081,HSLN,O
4081,-,O
4081,RNN,O
4081,model,O
4081,is,O
4081,more,O
4081,robust,O
4081,.,O
4082,Last,O
4082,but,O
4082,not,O
4082,the,O
4082,least,O
4082,",",O
4082,the,O
4082,dropout,B
4082,regularization,I
4082,and,I
4082,attention,I
4082,-,I
4082,based,I
4082,pooling,I
4082,components,I
4082,we,O
4082,add,B
4082,to,I
4082,our,B
4082,system,I
4082,can,O
4082,help,O
4082,further,B
4082,improve,I
4082,the,O
4082,model,B
4082,in,B
4082,a,O
4082,limited,B
4082,extent,I
4082,.,O
4083,When,B
4083,the,I
4083,context,B
4083,enriching,I
4083,layer,I
4083,is,B
4083,removed,B
4083,",",O
4083,both,B
4083,models,I
4083,experience,B
4083,the,O
4083,most,B
4083,significant,I
4083,performance,I
4083,drop,I
4083,and,O
4083,can,O
4083,only,O
4083,be,O
4083,on,B
4083,par,I
4083,with,I
4083,the,O
4083,previous,B
4083,stateof,I
4083,-,I
4083,the,O
4083,-,O
4083,art,O
4083,results,O
4083,",",O
4083,strongly,O
4083,demonstrating,O
4083,that,O
4083,this,O
4083,proposed,O
4083,component,O
4083,is,O
4083,the,O
4083,key,O
4083,to,O
4083,the,O
4083,performance,O
4083,improvement,O
4083,of,O
4083,our,O
4083,model,O
4083,.,O
4084,Furthermore,O
4084,",",O
4084,even,B
4084,without,I
4084,the,O
4084,label,B
4084,sequence,I
4084,optimization,I
4084,layer,I
4084,",",O
4084,our,B
4084,model,I
4084,still,O
4084,significantly,B
4084,outperforms,I
4084,the,O
4084,best,B
4084,published,I
4084,methods,I
4084,that,O
4084,are,O
4084,empowered,B
4084,by,I
4084,this,B
4084,layer,O
4084,",",O
4084,indicating,O
4084,that,O
4084,the,O
4084,context,O
4084,enriching,O
4084,layer,O
4084,we,O
4084,propose,O
4084,can,O
4084,help,O
4084,optimize,O
4084,the,O
4084,label,O
4084,sequence,O
4084,by,O
4084,considering,O
4084,the,O
4084,context,O
4084,information,O
4084,from,O
4084,the,O
4084,surrounding,O
4084,sentences,O
4084,.,O
4085,The,O
4085,token,B
4085,embeddings,I
4085,were,O
4085,pre-trained,B
4085,on,I
4085,a,O
4085,large,B
4085,corpus,I
4085,combining,B
4085,Wikipedia,B
4085,",",I
4085,PubMed,I
4085,",",O
4085,and,O
4085,PMC,O
4085,texts,O
4085,(,O
4085,Moen,O
4085,and,O
4085,Ananiadou,O
4085,",",O
4085,2013,O
4085,),O
4085,using,B
4085,the,O
4085,word2vec,B
4085,tool,I
4085,4,O
4085,(,O
4085,denoted,O
4085,as,O
4085,"""",O
4085,Word2vec-,O
4085,wiki+P.M.,O
4085,"""",O
4086,The,O
4086,learning,B
4086,rate,I
4086,is,O
4086,initially,B
4086,set,I
4086,as,O
4086,0.003,B
4086,and,O
4086,decayed,B
4086,by,I
4086,0.9,B
4086,after,B
4086,each,B
4086,epoch,I
4086,.,O
4087,The,O
4087,window,B
4087,sizes,I
4087,of,B
4087,the,O
4087,CNN,B
4087,encoder,I
4087,in,B
4087,the,O
4087,sentence,B
4087,encoding,I
4087,layer,I
4087,are,B
4087,2,B
4087,",",I
4087,3,I
4087,",",O
4087,4,O
4087,and,O
4087,5,O
4087,.,O
4088,They,O
4088,are,O
4088,fixed,B
4088,during,I
4088,the,O
4088,training,B
4088,phase,I
4088,to,B
4088,avoid,I
4088,over-fitting,B
4088,.,O
4089,The,O
4089,model,O
4089,is,O
4089,trained,B
4089,using,I
4089,the,O
4089,Adam,B
4089,optimization,I
4089,method,I
4089,(,O
4089,Kingma,O
4089,and,O
4089,Ba,O
4089,",",O
4089,2014,O
4089,),O
4089,.,O
4090,For,B
4090,regularization,B
4090,",",O
4090,dropout,B
4090,(,O
4090,Srivastava,O
4090,et,O
4090,al.,O
4091,",",O
4091,2014,O
4091,),O
4091,is,O
4091,applied,B
4091,to,I
4091,each,B
4091,layer,I
4091,.,O
4092,Memn2n,B
4092,:,O
4092,The,O
4092,original,O
4092,memory,B
4092,network,O
4092,as,O
4092,proposed,O
4092,by,O
4092,Contrasting,O
4092,to,O
4092,CMN,O
4092,",",O
4092,the,O
4092,model,O
4092,generates,B
4092,the,O
4092,memory,O
4092,representations,O
4092,for,B
4092,each,B
4092,historical,I
4092,utterance,I
4092,using,B
4092,an,O
4092,embedding,B
4092,matrix,I
4092,B,I
4092,as,O
4092,used,O
4092,in,O
4092,equation,O
4092,7,O
4092,",",O
4092,without,B
4092,sequential,B
4092,modeling,I
4092,.,O
4093,To,O
4093,reduce,O
4093,this,O
4093,gap,O
4093,",",O
4093,we,O
4093,adopted,B
4093,the,O
4093,dropout,B
4093,with,B
4093,expectation,B
4093,-,I
4093,linear,I
4093,regularization,I
4093,introduced,O
4093,by,O
4093,to,O
4093,explicitly,O
4093,control,O
4093,the,O
4093,inference,B
4093,gap,O
4093,and,O
4093,thus,O
4093,improve,B
4093,the,O
4093,generaliza,B
4093,-,O
4093,tion,O
4093,performance,O
4093,.,O
4094,Hyperparameters,O
4094,were,O
4094,optimized,B
4094,via,I
4094,grid,B
4094,search,I
4094,based,B
4094,on,I
4094,the,O
4094,validation,B
4094,set,I
4094,and,O
4094,the,O
4094,best,O
4094,configuration,O
4094,is,O
4094,shown,O
4094,in,O
4094,.,O
4095,In,O
4095,this,O
4095,work,O
4095,",",O
4095,we,O
4095,present,B
4095,a,O
4095,hierarchical,B
4095,neural,I
4095,network,I
4095,model,I
4095,for,B
4095,the,O
4095,sequential,O
4095,sentence,O
4095,classification,O
4095,task,O
4095,",",O
4095,which,O
4095,we,O
4095,call,B
4095,a,O
4095,hierarchical,O
4095,sequential,O
4095,labeling,O
4095,network,O
4095,(,O
4095,HSLN,O
4095,),O
4095,.,O
4096,Our,O
4096,model,O
4096,first,B
4096,uses,I
4096,a,O
4096,RNN,B
4096,or,I
4096,CNN,I
4096,layer,I
4096,to,B
4096,individually,I
4096,encode,I
4096,the,O
4096,sentence,B
4096,representation,I
4096,from,B
4096,the,O
4096,sequence,O
4096,of,O
4096,word,O
4096,embeddings,O
4096,",",O
4096,then,O
4096,uses,O
4096,another,B
4096,bi,I
4096,-,I
4096,LSTM,I
4096,layer,O
4096,to,O
4096,take,B
4096,as,I
4096,input,I
4096,the,O
4096,individual,B
4096,sentence,O
4096,representation,O
4096,and,O
4096,output,B
4096,the,O
4096,contextualized,B
4096,sentence,O
4096,representation,O
4096,",",O
4096,subsequently,B
4096,uses,O
4096,a,O
4096,single,B
4096,-,O
4096,hidden,O
4096,-,O
4096,layer,O
4096,feed,O
4096,-,O
4096,forward,O
4096,network,O
4096,to,O
4096,transform,O
4096,the,O
4096,sentence,O
4096,representation,O
4096,to,O
4096,the,O
4096,probability,B
4096,vector,I
4096,",",O
4096,and,O
4096,finally,O
4096,optimizes,B
4096,the,O
4096,predicted,B
4096,label,I
4096,sequence,O
4096,jointly,O
4096,via,B
4096,a,O
4096,CRF,B
4096,layer,O
4096,.,O
4097,Hierarchical,O
4097,Neural,O
4097,Networks,O
4097,for,O
4097,Sequential,B
4097,Sentence,I
4097,Classification,I
4097,in,I
4097,Medical,I
4097,Scientific,I
4097,Abstracts,I
4098,This,O
4098,hampers,O
4098,the,O
4098,traditional,O
4098,sentence,O
4098,classification,O
4098,approaches,O
4098,to,O
4098,the,O
4098,problem,O
4098,of,O
4098,sequential,B
4098,sentence,O
4098,classification,O
4098,",",O
4098,where,O
4098,structured,O
4098,prediction,O
4098,is,O
4098,needed,O
4098,for,O
4098,better,O
4098,over,O
4098,all,O
4098,classification,O
4098,performance,O
4098,.,O
4099,In,O
4099,this,O
4099,paper,O
4099,",",O
4099,we,O
4099,propose,B
4099,the,O
4099,usage,B
4099,of,I
4099,translations,I
4099,as,B
4099,compelling,B
4099,and,I
4099,effective,I
4099,domain,I
4099,-,I
4099,free,I
4099,contexts,I
4099,",",O
4099,or,O
4099,contexts,O
4099,that,O
4099,are,O
4099,always,O
4099,available,O
4099,no,O
4099,matter,O
4099,what,O
4099,the,O
4099,task,O
4099,domain,O
4099,is,O
4099,.,O
4100,In,O
4100,this,O
4100,paper,O
4100,",",O
4100,we,O
4100,propose,O
4100,a,O
4100,method,B
4100,to,B
4100,mitigate,I
4100,the,O
4100,possible,B
4100,problems,I
4100,when,B
4100,using,I
4100,translated,B
4100,sentences,I
4100,as,B
4100,context,B
4100,based,O
4100,on,O
4100,the,O
4100,following,O
4100,observations,O
4100,.,O
4101,Based,O
4101,on,O
4101,these,O
4101,observations,O
4101,",",O
4101,we,O
4101,present,B
4101,a,O
4101,neural,B
4101,attentionbased,I
4101,multiple,I
4101,context,I
4101,fixing,I
4101,attachment,I
4101,(,I
4101,MCFA,I
4101,),I
4101,.,O
4102,MCFA,B
4102,is,B
4102,a,O
4102,series,B
4102,of,I
4102,modules,I
4102,that,O
4102,uses,B
4102,all,B
4102,the,I
4102,sentence,I
4102,vectors,I
4102,(,O
4102,e.g.,O
4103,as,B
4103,context,B
4103,to,B
4103,fix,I
4103,a,B
4103,sentence,I
4103,vector,I
4103,(,O
4103,e.g.,O
4104,MCFA,O
4104,computes,B
4104,two,B
4104,sentence,I
4104,usability,I
4104,metrics,I
4104,to,B
4104,control,I
4104,the,O
4104,noise,B
4104,when,I
4104,fixing,I
4104,vectors,I
4104,:,O
4104,(,O
4104,a,O
4104,),O
4104,self,B
4104,usability,O
4104,?,O
4105,i,O
4105,(,O
4105,a,O
4105,),O
4105,weighs,B
4105,the,O
4105,confidence,B
4105,of,B
4105,using,I
4105,sentence,B
4105,a,O
4105,in,B
4105,solving,I
4105,the,O
4105,task,B
4105,.,O
4106,(,O
4106,b,O
4106,),O
4106,relative,B
4106,usability,I
4106,?,O
4107,r,O
4107,(,O
4107,a,O
4107,",",O
4107,b,O
4107,),O
4107,weighs,B
4107,the,O
4107,confidence,B
4107,of,I
4107,using,B
4107,sentence,B
4107,a,O
4107,in,O
4107,fixing,B
4107,sentence,O
4107,b.,O
4108,(,O
4108,1,O
4108,),O
4108,MCFA,O
4108,is,O
4108,attached,B
4108,after,I
4108,encoding,B
4108,the,I
4108,sentence,I
4108,",",O
4108,which,O
4108,makes,B
4108,it,I
4108,widely,I
4108,adaptable,I
4108,to,B
4108,other,I
4108,models,I
4108,.,O
4109,(,O
4109,3,O
4109,),O
4109,MCFA,O
4109,moves,B
4109,the,O
4109,vectors,B
4109,inside,B
4109,the,O
4109,same,B
4109,space,I
4109,",",O
4109,thus,O
4109,preserves,B
4109,the,O
4109,meaning,B
4109,of,B
4109,vector,B
4109,dimensions,I
4109,.,O
4110,Tokenization,B
4110,is,O
4110,done,B
4110,using,I
4110,the,O
4110,polyglot,B
4110,library,I
4110,7,O
4110,.,O
4111,Training,B
4111,is,O
4111,done,B
4111,via,I
4111,stochastic,B
4111,gradient,I
4111,descent,I
4111,over,B
4111,shuffled,B
4111,mini-batches,I
4111,with,B
4111,the,O
4111,Adadelta,B
4111,update,I
4111,rule,I
4111,.,O
4112,We,O
4112,experiment,B
4112,on,I
4112,using,I
4112,only,B
4112,one,I
4112,additional,I
4112,context,I
4112,(,I
4112,N,I
4112,=,I
4112,1,I
4112,),I
4112,and,O
4112,using,O
4112,all,B
4112,ten,I
4112,languages,I
4112,at,I
4112,once,I
4112,(,O
4112,N,O
4112,=,O
4112,10,O
4112,),O
4112,.,O
4113,For,B
4113,our,B
4113,CNN,I
4113,",",O
4113,we,O
4113,use,O
4113,rectified,O
4113,linear,O
4113,units,O
4113,and,O
4113,three,O
4113,filters,O
4113,with,O
4113,different,O
4113,window,O
4113,sizes,O
4113,h,O
4113,=,O
4113,3,O
4113,",",O
4113,4,O
4113,",",O
4113,5,O
4113,with,O
4113,100,O
4113,feature,O
4113,maps,O
4113,each,O
4113,",",O
4113,following,O
4113,.,O
4114,For,O
4114,the,O
4114,final,B
4114,sentence,I
4114,vector,I
4114,",",O
4114,we,O
4114,concatenate,B
4114,the,O
4114,feature,B
4114,maps,I
4114,to,B
4114,get,I
4114,a,O
4114,300,B
4114,-,I
4114,dimension,I
4114,vector,O
4114,.,O
4115,We,O
4115,use,B
4115,dropout,B
4115,on,B
4115,all,B
4115,nonlinear,I
4115,connections,I
4115,with,B
4115,a,O
4115,dropout,O
4115,rate,O
4115,of,B
4115,0.5,B
4115,.,O
4116,In,O
4116,this,O
4116,baseline,O
4116,",",O
4116,we,O
4116,use,B
4116,only,B
4116,self,I
4116,history,I
4116,for,B
4116,classifying,I
4116,emotion,B
4116,of,B
4116,utterance,B
4116,u,I
4116,i,I
4116,.,O
4117,We,O
4117,also,O
4117,use,O
4117,an,O
4117,l,B
4117,2,I
4117,constraint,I
4117,of,B
4117,3,B
4117,",",O
4117,following,O
4117,for,O
4117,accurate,O
4117,comparisons,O
4117,.,O
4118,We,O
4118,use,O
4118,FastText,B
4118,pre-trained,I
4118,vectors,I
4118,8,O
4118,for,B
4118,all,B
4118,our,I
4118,data,I
4118,sets,I
4118,and,O
4118,their,O
4118,corresponding,O
4118,additional,O
4118,context,O
4118,.,O
4119,During,B
4119,training,B
4119,",",O
4119,we,O
4119,use,B
4119,mini-batch,B
4119,size,I
4119,of,B
4119,50,B
4119,.,O
4120,We,O
4120,perform,B
4120,early,B
4120,stopping,I
4120,using,B
4120,a,O
4120,random,B
4120,10,I
4120,%,I
4120,of,B
4120,the,O
4120,training,B
4120,set,I
4120,as,B
4120,the,O
4120,development,B
4120,set,O
4120,.,O
4121,Translations,O
4121,as,O
4121,Additional,O
4121,Contexts,O
4121,for,O
4121,Sentence,B
4121,Classification,I
4122,We,O
4122,show,B
4122,that,O
4122,CNN,B
4122,+,I
4122,MCFA,I
4122,achieves,B
4122,state,B
4122,of,I
4122,the,I
4122,art,I
4122,performance,I
4122,on,B
4122,three,B
4122,of,O
4122,the,O
4122,four,O
4122,data,O
4122,sets,O
4122,and,O
4122,performs,B
4122,competitively,B
4122,on,O
4122,one,B
4122,data,O
4122,set,O
4122,.,O
4123,When,B
4123,N,B
4123,=,I
4123,1,I
4123,",",O
4123,MCFA,B
4123,increases,B
4123,the,I
4123,performance,B
4123,of,I
4123,a,O
4123,normal,B
4123,CNN,I
4123,from,B
4123,85.0,B
4123,to,B
4123,87.6,B
4123,",",O
4123,beating,B
4123,the,O
4123,current,B
4123,state,I
4123,of,O
4123,the,O
4123,art,O
4123,on,B
4123,the,O
4123,CR,B
4123,data,I
4123,set,I
4123,.,O
4124,When,O
4124,N,B
4124,=,I
4124,10,I
4124,",",O
4124,MCFA,B
4124,additionally,B
4124,beats,I
4124,the,I
4124,state,B
4124,of,I
4124,the,O
4124,art,O
4124,on,B
4124,the,O
4124,TREC,B
4124,data,I
4124,set,I
4124,.,O
4125,Finally,O
4125,",",O
4125,our,B
4125,ensemble,I
4125,classifier,I
4125,additionally,B
4125,outperforms,I
4125,all,B
4125,competing,I
4125,models,I
4125,on,B
4125,the,O
4125,MR,B
4125,data,I
4125,set,I
4125,.,O
4126,On,B
4126,all,B
4126,data,I
4126,sets,I
4126,except,B
4126,SUBJ,B
4126,",",O
4126,the,O
4126,accuracy,O
4126,of,B
4126,CNN,I
4126,+,I
4126,B1,I
4126,decreases,B
4126,from,I
4126,the,O
4126,base,B
4126,CNN,O
4126,accuracy,O
4126,",",O
4126,while,O
4126,the,O
4126,accuracy,O
4126,of,O
4126,our,O
4126,model,O
4126,always,O
4126,improves,O
4126,from,O
4126,the,O
4126,base,O
4126,CNN,O
4126,accuracy,O
4126,.,O
4127,CMN,B
4127,N,O
4127,A,O
4127,:,O
4127,Single,B
4127,layer,I
4127,variant,I
4127,of,B
4127,the,O
4127,CMN,O
4127,with,B
4127,no,B
4127,attention,I
4127,module,I
4127,.,O
4128,We,O
4128,also,O
4128,compare,O
4128,two,O
4128,different,O
4128,kinds,O
4128,of,O
4128,additional,O
4128,context,O
4128,:,O
4128,topics,B
4128,(,O
4128,TopCNN,O
4128,),O
4128,and,O
4128,translations,B
4128,(,O
4128,CNN,O
4128,+,O
4128,B1,O
4128,",",O
4128,CNN,O
4128,+,O
4128,B2,O
4128,",",O
4128,CNN,O
4128,+,O
4128,MCFA,O
4128,),O
4128,.,O
4129,Overall,O
4129,",",O
4129,we,O
4129,conclude,B
4129,that,I
4129,translations,O
4129,are,B
4129,better,B
4129,additional,I
4129,contexts,I
4129,than,B
4129,topics,O
4129,.,O
4130,When,O
4130,using,B
4130,a,O
4130,single,B
4130,context,I
4130,(,O
4130,i.e.,O
4131,TopCNN,O
4131,word,O
4131,",",O
4131,TopCNN,O
4131,sent,O
4131,",",O
4131,and,O
4131,our,O
4131,models,O
4131,when,O
4131,N,O
4131,=,O
4131,1,O
4131,),O
4131,",",O
4131,translations,B
4131,always,B
4131,outperform,I
4131,topics,B
4131,even,O
4131,when,O
4131,using,B
4131,the,O
4131,baseline,O
4131,methods,O
4131,.,O
4132,Using,B
4132,topics,B
4132,as,B
4132,additional,B
4132,context,I
4132,also,O
4132,decreases,B
4132,the,O
4132,performance,B
4132,of,B
4132,the,O
4132,CNN,B
4132,classifier,I
4132,on,B
4132,most,B
4132,data,I
4132,sets,I
4132,",",O
4132,giving,O
4132,an,O
4132,adverse,O
4132,effect,O
4132,to,O
4132,the,O
4132,CNN,O
4132,classifier,O
4132,.,O
4133,The,O
4133,results,O
4133,in,O
4133,rows,O
4133,1,O
4133,",",O
4133,2,O
4133,show,O
4133,that,O
4133,using,B
4133,level,B
4133,-,I
4133,attention,I
4133,mechanism,I
4133,based,B
4133,on,I
4133,multi-level,B
4133,feature,I
4133,maps,I
4133,significantly,B
4133,improves,I
4133,the,O
4133,performance,B
4133,over,B
4133,single,B
4133,visual,I
4133,-,O
4133,textual,O
4133,feature,O
4133,comparison,O
4133,.,O
4134,By,O
4134,comparing,O
4134,rows,O
4134,2,O
4134,",",O
4134,4,O
4134,",",O
4134,5,O
4134,",",O
4134,7,O
4134,",",O
4134,we,O
4134,see,B
4134,that,I
4134,non-linear,B
4134,mapping,I
4134,in,B
4134,our,O
4134,model,B
4134,is,B
4134,really,B
4134,important,I
4134,",",O
4134,and,O
4134,replacing,B
4134,any,B
4134,mapping,O
4134,with,B
4134,a,O
4134,linear,B
4134,one,I
4134,significantly,B
4134,degrades,I
4134,the,O
4134,performance,B
4134,.,O
4135,We,O
4135,can,O
4135,also,B
4135,see,I
4135,that,I
4135,non-linear,B
4135,mapping,I
4135,seems,B
4135,more,B
4135,important,I
4135,on,B
4135,the,O
4135,visual,B
4135,side,I
4135,",",O
4135,but,O
4135,best,O
4135,results,O
4135,are,O
4135,obtained,O
4135,with,O
4135,both,O
4135,text,O
4135,and,O
4135,visual,O
4135,non-linear,O
4135,mappings,O
4135,.,O
4136,The,O
4136,results,O
4136,in,O
4136,rows,O
4136,1,O
4136,",",O
4136,3,O
4136,and,O
4136,2,O
4136,",",O
4136,6,O
4136,show,B
4136,the,O
4136,importance,B
4136,of,B
4136,using,I
4136,a,O
4136,strong,B
4136,contextualized,I
4136,text,I
4136,embedding,I
4136,as,B
4136,the,O
4136,performance,B
4136,drops,B
4136,significantly,I
4136,.,O
4137,We,O
4137,also,O
4137,study,O
4137,the,O
4137,use,O
4137,of,O
4137,softmax,B
4137,on,B
4137,the,O
4137,heatmaps,O
4137,",",O
4137,comparing,O
4137,rows,O
4137,2,O
4137,",",O
4137,8,O
4137,",",O
4137,we,O
4137,see,O
4137,that,O
4137,applying,B
4137,softmax,O
4137,leads,B
4137,to,I
4137,a,O
4137,very,B
4137,negative,I
4137,effect,I
4137,on,O
4137,the,O
4137,performance,B
4137,.,O
4138,We,O
4138,use,B
4138,a,O
4138,batch,B
4138,size,I
4138,of,B
4138,B,B
4138,=,I
4138,32,I
4138,",",O
4138,where,O
4138,for,O
4138,a,O
4138,batch,O
4138,of,O
4138,image,O
4138,-,O
4138,caption,O
4138,pairs,O
4138,each,O
4138,image,O
4138,(,O
4138,caption,O
4138,),O
4138,is,O
4138,only,O
4138,related,O
4138,to,O
4138,one,O
4138,caption,O
4138,(,O
4138,image,O
4138,),O
4138,.,O
4139,We,O
4139,use,B
4139,10,B
4139,%,I
4139,of,B
4139,the,O
4139,training,B
4139,set,I
4139,as,B
4139,a,O
4139,held,B
4139,-,I
4139,out,I
4139,validation,I
4139,set,O
4139,for,B
4139,hyperparameter,B
4139,tuning,I
4139,.,O
4140,We,O
4140,use,O
4140,D,B
4140,=,I
4140,1024,I
4140,for,B
4140,common,B
4140,space,I
4140,mapping,I
4140,dimension,I
4140,and,O
4140,?,O
4141,=,O
4141,0.25,O
4141,for,B
4141,Leaky,B
4141,ReLU,I
4141,in,B
4141,the,O
4141,non-linear,B
4141,mappings,I
4141,.,O
4142,Image,O
4142,-,O
4142,caption,O
4142,pairs,O
4142,are,O
4142,sampled,B
4142,randomly,B
4142,with,B
4142,a,O
4142,uniform,B
4142,distribution,I
4142,.,O
4143,Both,O
4143,visual,O
4143,and,O
4143,textual,O
4143,networks,O
4143,weights,O
4143,are,B
4143,fixed,B
4143,during,I
4143,training,B
4143,and,O
4143,only,O
4143,common,B
4143,space,I
4143,mapping,I
4143,weights,O
4143,are,O
4143,trainable,B
4143,.,O
4144,We,O
4144,train,B
4144,the,O
4144,network,B
4144,for,B
4144,20,B
4144,epochs,I
4144,with,B
4144,the,O
4144,Adam,B
4144,optimizer,I
4144,with,O
4144,lr,B
4144,=,I
4144,0.001,I
4144,where,B
4144,the,O
4144,learning,B
4144,rate,I
4144,is,O
4144,divided,B
4144,by,I
4144,2,B
4144,once,B
4144,at,I
4144,the,O
4144,10,B
4144,-,I
4144,th,I
4144,epoch,I
4144,and,O
4144,again,B
4144,at,O
4144,the,O
4144,15,B
4144,-,O
4144,th,O
4144,epoch,O
4144,.,O
4145,We,O
4145,regularize,B
4145,weights,B
4145,of,B
4145,the,O
4145,mappings,B
4145,with,B
4145,l,B
4145,2,I
4145,regularization,I
4145,with,O
4145,reg,B
4145,value,I
4145,=,I
4145,0.0005,I
4145,.,O
4146,For,B
4146,VGG,B
4146,",",I
4146,we,O
4146,take,B
4146,outputs,B
4146,from,B
4146,{,B
4146,conv,I
4146,4,I
4146,1,I
4146,",",O
4146,conv,O
4146,4,O
4146,3,O
4146,",",O
4146,conv5,O
4146,1,O
4146,",",O
4146,conv5,O
4146,3,O
4146,},O
4146,and,O
4146,map,B
4146,to,I
4146,semantic,B
4146,feature,I
4146,maps,I
4146,with,B
4146,dimension,I
4146,18181024,B
4146,",",O
4146,and,O
4146,for,O
4146,PNAS,B
4146,-,I
4146,Net,I
4146,we,O
4146,take,O
4146,outputs,O
4146,from,O
4146,{,O
4146,Cell,O
4146,5,O
4146,",",O
4146,Cell,O
4146,7,O
4146,",",O
4146,Cell,O
4146,9,O
4146,",",O
4146,Cell,O
4146,11,O
4146,},O
4146,pointing,O
4146,game,O
4146,accuracy,O
4146,attention,O
4146,correctness,O
4146,Ours,O
4146,Ours,O
4146,Ours,O
4146,Ours,O
4146,Class,O
4147,In,O
4147,this,O
4147,work,O
4147,",",O
4147,we,O
4147,propose,O
4147,to,O
4147,explicitly,B
4147,learn,I
4147,a,O
4147,non-linear,B
4147,mapping,I
4147,of,B
4147,the,O
4147,visual,B
4147,and,I
4147,textual,I
4147,modalities,I
4147,into,B
4147,a,O
4147,common,B
4147,space,I
4147,",",O
4147,and,O
4147,do,O
4147,so,O
4147,at,B
4147,different,B
4147,granularity,I
4147,for,B
4147,each,B
4147,domain,I
4147,.,O
4148,This,O
4148,common,B
4148,space,I
4148,mapping,I
4148,is,O
4148,trained,B
4148,with,B
4148,weak,B
4148,supervision,I
4148,and,I
4148,exploited,B
4148,at,B
4148,test,B
4148,-,I
4148,time,I
4148,with,O
4148,a,O
4148,multi,B
4148,-,O
4148,level,O
4148,multimodal,O
4148,attention,B
4148,mechanism,I
4148,",",O
4148,where,B
4148,a,O
4148,natural,B
4148,formalism,I
4148,for,B
4148,computing,I
4148,attention,O
4148,heatmaps,O
4148,at,O
4148,each,B
4148,level,O
4148,",",O
4148,attended,B
4148,features,I
4148,and,O
4148,pertinence,B
4148,scoring,I
4148,",",O
4148,enables,O
4148,us,O
4148,to,O
4148,solve,B
4148,the,O
4148,phrase,B
4148,grounding,I
4148,task,I
4148,elegantly,B
4148,and,O
4148,effectively,O
4148,.,O
4149,Multi,O
4149,-,O
4149,level,O
4149,Multimodal,O
4149,Common,O
4149,Semantic,O
4149,Space,O
4149,for,O
4149,Image,B
4149,-,O
4149,Phrase,O
4149,Grounding,O
4150,We,O
4150,address,O
4150,the,O
4150,problem,O
4150,of,O
4150,phrase,B
4150,grounding,I
4150,by,O
4150,learning,O
4150,a,O
4150,multi,O
4150,-,O
4150,level,O
4150,common,O
4150,semantic,O
4150,space,O
4150,shared,O
4150,by,O
4150,the,O
4150,textual,O
4150,and,O
4150,visual,O
4150,modalities,O
4150,.,O
4151,To,O
4151,optimize,O
4151,the,O
4151,parameters,O
4151,",",O
4151,we,O
4151,use,O
4151,Stochastic,B
4151,Gradient,I
4151,Descent,I
4151,(,I
4151,SGD,I
4151,),I
4151,optimizer,I
4151,",",O
4151,starting,B
4151,with,I
4151,an,O
4151,initial,B
4151,learning,I
4151,Utterances,I
4151,whose,B
4151,history,I
4151,has,I
4151,atleast,B
4151,3,I
4151,similar,I
4151,emotion,I
4151,labels,I
4151,in,O
4151,either,O
4151,own,O
4151,history,O
4151,or,O
4151,the,O
4151,history,O
4151,of,O
4151,the,O
4151,other,O
4151,person,O
4151,",",O
4151,is,O
4151,counted,O
4151,in,O
4151,case,O
4151,1,O
4151,or,O
4151,2,O
4151,",",O
4151,respectively,O
4151,.,O
4152,The,O
4152,results,O
4152,show,B
4152,that,I
4152,our,O
4152,method,B
4152,significantly,B
4152,outperforms,I
4152,all,I
4152,state,I
4152,-,I
4152,of,I
4152,-,O
4152,the,O
4152,-,O
4152,art,O
4152,methods,O
4152,in,B
4152,all,O
4152,conditions,O
4152,and,O
4152,all,O
4152,datasets,O
4152,.,O
4153,It,O
4153,shows,O
4153,that,O
4153,the,O
4153,3rd,B
4153,level,I
4153,dominates,B
4153,the,O
4153,selection,B
4153,while,O
4153,the,O
4153,4th,B
4153,level,O
4153,is,O
4153,also,O
4153,important,B
4153,for,I
4153,several,B
4153,categories,I
4153,such,B
4153,as,I
4153,scene,B
4153,and,I
4153,animals,I
4153,.,O
4154,The,O
4154,1st,B
4154,level,I
4154,is,O
4154,exploited,B
4154,mostly,I
4154,for,I
4154,the,O
4154,animals,B
4154,and,I
4154,people,I
4154,categories,I
4154,.,O
4155,For,O
4155,fair,O
4155,comparison,O
4155,with,O
4155,To,O
4155,get,O
4155,a,O
4155,deeper,O
4155,understanding,O
4155,of,O
4155,our,O
4155,model,B
4155,",",O
4155,we,O
4155,first,O
4155,report,O
4155,in,O
4155,category,O
4155,-,O
4155,wise,O
4155,pointing,O
4155,game,O
4155,accuracy,O
4155,and,O
4155,attention,O
4155,correctness,O
4155,(,O
4155,percentage,O
4155,of,O
4155,the,O
4155,heatmap,O
4155,falling,O
4155,into,O
4155,the,O
4155,ground,O
4155,truth,O
4155,bounding,O
4155,box,O
4155,),O
4155,and,O
4155,compare,O
4155,with,O
4155,the,O
4155,state,B
4155,-,O
4155,of,O
4155,-,O
4155,the,O
4155,-,O
4155,art,O
4155,method,O
4155,on,B
4155,Flickr30,B
4155,k,I
4155,.,O
4156,We,O
4156,observe,B
4156,that,I
4156,our,B
4156,method,I
4156,obtains,B
4156,a,O
4156,higher,B
4156,performance,I
4156,on,B
4156,almost,B
4156,all,I
4156,categories,I
4156,even,O
4156,when,O
4156,VGG16,O
4156,is,O
4156,used,O
4156,as,O
4156,the,O
4156,visual,O
4156,backbone,O
4156,.,O
4157,The,O
4157,model,O
4157,based,B
4157,on,B
4157,PNASNet,B
4157,consistently,B
4157,outperforms,I
4157,the,O
4157,state,O
4157,-,O
4157,of,O
4157,-,O
4157,the,O
4157,-,O
4157,art,O
4157,on,O
4157,all,B
4157,categories,I
4157,on,O
4157,both,B
4157,metrics,I
4157,.,O
4158,The,O
4158,full,B
4158,sentence,I
4158,selection,I
4158,relies,B
4158,mostly,I
4158,on,I
4158,the,O
4158,3rd,B
4158,level,I
4158,as,O
4158,well,O
4158,",",O
4158,while,O
4158,for,B
4158,some,B
4158,sentences,I
4158,the,O
4158,4th,B
4158,model,I
4158,has,O
4158,been,B
4158,selected,B
4158,.,O
4159,The,O
4159,majority,B
4159,class,I
4159,baseline,I
4159,is,B
4159,61.5,B
4159,%,I
4159,which,O
4159,corresponds,B
4159,to,I
4159,all,B
4159,queries,I
4159,being,I
4159,classified,I
4159,non-wellformed,I
4159,.,O
4160,The,O
4160,question,B
4160,word,I
4160,baseline,I
4160,that,O
4160,classifies,B
4160,any,B
4160,query,I
4160,starting,B
4160,with,I
4160,a,O
4160,question,O
4160,word,O
4160,word,O
4160,n-grams,O
4160,char,O
4160,n-grams,O
4160,POS,O
4160,n,O
4160,-grams,O
4160,pwf,O
4160,(,O
4160,q,O
4160,),O
4160,:,O
4161,We,O
4161,construct,B
4161,and,I
4161,publicly,I
4161,release,I
4161,a,O
4161,dataset,B
4161,of,B
4161,"25,100",I
4161,queries,I
4161,annotated,B
4161,with,I
4161,the,O
4161,probability,B
4161,of,O
4161,being,O
4161,a,O
4161,well,B
4161,-,I
4161,formed,I
4161,natural,I
4161,language,I
4161,question,I
4161,(,O
4161,2.1,O
4161,),O
4161,.,O
4162,An,O
4162,annealing,B
4162,approach,I
4162,halves,B
4162,the,O
4162,lr,B
4162,every,B
4162,20,B
4162,epochs,I
4162,and,O
4162,termination,B
4162,is,O
4162,decided,B
4162,using,I
4162,an,O
4162,early,B
4162,-,I
4162,stop,I
4162,measure,I
4162,with,B
4162,a,O
4162,patience,B
4162,of,B
4162,12,B
4162,by,B
4162,monitoring,I
4162,the,O
4162,validation,B
4162,loss,I
4162,.,O
4163,Our,O
4163,dataset,O
4163,ise,O
4163,available,B
4163,for,I
4163,download,I
4163,at,I
4163,http://goo.gl/language/,B
4163,query-wellformedness,I
4163,.,O
4164,Thus,O
4164,",",O
4164,in,O
4164,this,O
4164,paper,O
4164,we,O
4164,present,O
4164,a,O
4164,model,O
4164,to,B
4164,predict,I
4164,whether,O
4164,a,O
4164,given,B
4164,query,I
4164,is,B
4164,a,O
4164,well,B
4164,-,I
4164,formed,I
4164,natural,I
4164,language,I
4164,question,I
4164,.,O
4165,We,O
4165,then,O
4165,train,B
4165,a,O
4165,feed,B
4165,-,I
4165,forward,I
4165,neural,I
4165,network,I
4165,classifier,I
4165,that,O
4165,uses,B
4165,the,O
4165,lexical,B
4165,and,I
4165,syntactic,I
4165,features,I
4165,extracted,B
4165,from,I
4165,the,O
4165,query,B
4165,on,B
4165,this,O
4165,data,B
4165,(,O
4165,2.2,O
4165,),O
4165,.,O
4166,The,O
4166,best,B
4166,performance,I
4166,obtained,B
4166,is,O
4166,70.7,B
4166,%,I
4166,while,B
4166,using,I
4166,word,B
4166,-,I
4166,1,I
4166,",",I
4166,2,I
4166,-,O
4166,grams,O
4166,and,O
4166,POS,B
4166,-,O
4166,1,O
4166,",",O
4166,2,O
4166,",",O
4166,3,O
4166,-,O
4166,grams,O
4166,as,O
4166,features,O
4166,.,O
4167,Although,O
4167,character,B
4167,-,I
4167,3,I
4167,",",I
4167,4,I
4167,grams,I
4167,gave,B
4167,improvement,I
4167,over,I
4167,word,B
4167,unigrams,I
4167,and,I
4167,bigrams,I
4167,",",O
4167,the,O
4167,performance,B
4167,did,O
4167,not,B
4167,sustain,B
4167,when,B
4167,combined,B
4167,with,B
4167,POS,B
4167,tags,I
4167,.,O
4168,Using,B
4168,POS,B
4168,n-grams,I
4168,gave,B
4168,a,O
4168,strong,B
4168,boost,I
4168,of,B
4168,5.2,B
4168,points,I
4168,over,B
4168,word,B
4168,unigrams,I
4168,and,I
4168,bigrams,I
4168,.,O
4169,The,O
4169,first,O
4169,model,O
4169,is,O
4169,a,O
4169,random,B
4169,token,I
4169,generation,I
4169,.,O
4170,The,O
4170,second,O
4170,one,O
4170,is,O
4170,the,O
4170,MLE,B
4170,trained,I
4170,LSTM,I
4170,G,I
4170,?,O
4171,The,O
4171,third,O
4171,one,O
4171,is,O
4171,scheduled,B
4171,sampling,I
4171,.,O
4172,Gradient,O
4172,clipping,O
4172,is,O
4172,used,B
4172,for,I
4172,regularization,B
4172,with,B
4172,a,O
4172,norm,B
4172,set,B
4172,to,I
4172,40,B
4172,.,O
4173,The,O
4173,fourth,O
4173,one,O
4173,is,O
4173,the,O
4173,Policy,B
4173,Gradient,I
4173,with,I
4173,BLEU,I
4173,(,I
4173,PG,I
4173,-,I
4173,BLEU,O
4173,),O
4173,.,O
4174,To,O
4174,setup,O
4174,the,O
4174,synthetic,O
4174,data,O
4174,experiments,O
4174,",",O
4174,we,O
4174,first,B
4174,initialize,I
4174,the,O
4174,parameters,B
4174,of,B
4174,an,I
4174,LSTM,B
4174,network,I
4174,following,B
4174,the,O
4174,normal,B
4174,distribution,I
4174,N,I
4174,(,I
4174,0,I
4174,",",O
4174,1,O
4174,),O
4174,as,B
4174,the,O
4174,oracle,B
4174,describing,B
4174,the,O
4174,real,O
4174,data,O
4174,distribution,O
4174,G,O
4174,oracle,O
4174,(,O
4174,x,O
4174,t,O
4174,|x,O
4174,1,O
4174,",",O
4174,.,O
4175,In,B
4175,SeqGAN,B
4175,algorithm,I
4175,",",O
4175,the,O
4175,training,B
4175,set,I
4175,for,B
4175,the,O
4175,discriminator,B
4175,is,B
4175,comprised,I
4175,by,I
4175,the,O
4175,generated,B
4175,examples,I
4175,with,B
4175,the,O
4175,label,B
4175,0,I
4175,and,O
4175,the,O
4175,instances,B
4175,from,B
4175,S,B
4175,with,O
4175,the,O
4175,label,O
4176,In,O
4176,the,O
4176,scheduled,B
4176,sampling,I
4176,",",O
4176,the,O
4176,training,B
4176,process,I
4176,gradually,B
4176,changes,I
4176,from,B
4176,a,O
4176,fully,B
4176,guided,I
4176,scheme,I
4176,feeding,I
4176,the,O
4176,true,O
4176,previous,O
4176,tokens,O
4176,into,B
4176,LSTM,I
4176,",",O
4176,towards,B
4176,a,O
4176,less,B
4176,guided,O
4176,scheme,O
4176,which,O
4176,mostly,O
4176,feeds,O
4176,the,O
4176,LSTM,O
4176,with,B
4176,its,O
4176,generated,B
4176,tokens,O
4176,.,O
4177,For,O
4177,different,O
4177,tasks,O
4177,",",O
4177,one,O
4177,should,O
4177,design,O
4177,specific,O
4177,structure,O
4177,for,O
4177,the,O
4177,convolutional,O
4177,layer,O
4177,and,O
4177,in,B
4177,our,B
4177,synthetic,I
4177,data,I
4177,experiments,I
4177,",",O
4177,the,O
4177,kernel,O
4177,size,O
4177,is,O
4177,from,B
4177,1,B
4177,to,I
4177,T,I
4177,and,O
4177,the,O
4177,number,B
4177,of,B
4177,each,B
4177,kernel,O
4177,size,O
4177,is,O
4177,between,B
4177,100,B
4177,to,O
4177,200,O
4177,3,O
4177,.,O
4178,Dropout,O
4178,),O
4178,and,O
4178,L2,O
4178,regularization,O
4178,are,O
4178,used,O
4178,to,B
4178,avoid,I
4178,over-fitting,B
4178,.,O
4179,A,O
4179,curriculum,B
4179,rate,I
4179,?,I
4180,is,O
4180,used,O
4180,to,B
4180,control,I
4180,the,I
4180,probability,B
4180,of,B
4180,replacing,B
4180,the,O
4180,true,O
4180,tokens,O
4180,with,B
4180,the,O
4180,generated,B
4180,ones,I
4180,.,O
4181,In,O
4181,this,O
4181,paper,O
4181,",",O
4181,to,O
4181,address,O
4181,the,O
4181,above,O
4181,two,O
4181,issues,O
4181,",",O
4181,we,O
4181,follow,O
4181,),O
4181,and,O
4181,consider,B
4181,the,O
4181,sequence,B
4181,generation,I
4181,procedure,I
4181,as,B
4181,a,O
4181,sequential,B
4181,decision,I
4181,making,I
4181,process,I
4181,.,O
4182,The,O
4182,generative,B
4182,model,I
4182,is,B
4182,treated,B
4182,as,I
4182,an,O
4182,agent,B
4182,of,I
4182,reinforcement,I
4182,learning,I
4182,(,I
4182,RL,I
4182,),I
4182,;,O
4182,the,O
4182,state,B
4182,is,O
4182,the,O
4182,generated,O
4182,tokens,O
4182,so,O
4182,far,O
4182,and,O
4182,the,O
4182,action,B
4182,is,O
4182,the,O
4182,next,B
4182,token,I
4182,to,I
4182,be,I
4182,generated,O
4182,.,O
4183,Unlike,O
4183,the,O
4183,work,O
4183,in,O
4183,),O
4183,that,O
4183,requires,O
4183,a,O
4183,task,O
4183,-,O
4183,specific,O
4183,sequence,B
4183,score,O
4183,",",O
4183,such,O
4183,as,O
4183,BLEU,O
4183,in,O
4183,machine,O
4183,translation,O
4183,",",O
4183,to,B
4183,give,O
4183,the,O
4183,reward,O
4183,",",O
4183,we,O
4183,employ,B
4183,a,O
4183,discriminator,B
4183,to,O
4183,evaluate,O
4183,the,O
4183,sequence,O
4183,and,O
4183,feedback,B
4183,the,O
4183,evaluation,B
4183,to,O
4183,guide,O
4183,the,O
4183,learning,B
4183,of,B
4183,the,O
4183,generative,B
4183,model,I
4183,.,O
4184,We,O
4184,use,B
4184,the,O
4184,word2,B
4184,vec,I
4184,skip,I
4184,-,I
4184,gram,I
4184,model,I
4184,to,B
4184,learn,I
4184,initial,B
4184,word,I
4184,representations,I
4184,on,B
4184,Wikipedia,B
4184,.,O
4185,The,O
4185,dimension,B
4185,size,I
4185,of,B
4185,the,O
4185,memory,B
4185,cells,I
4185,d,I
4185,is,O
4185,set,B
4185,as,I
4185,50,B
4185,.,O
4186,To,O
4186,solve,O
4186,the,O
4186,problem,O
4186,that,O
4186,the,O
4186,gradient,O
4186,can,O
4186,not,O
4186,pass,O
4186,back,O
4186,to,O
4186,the,O
4186,generative,B
4186,model,I
4186,when,O
4186,the,O
4186,output,O
4186,is,O
4186,discrete,O
4186,",",O
4186,we,O
4186,regard,B
4186,the,O
4186,generative,O
4186,model,O
4186,as,B
4186,a,I
4186,stochastic,B
4186,parametrized,I
4186,policy,I
4186,.,O
4187,In,B
4187,our,O
4187,policy,B
4187,gradient,I
4187,",",O
4187,we,O
4187,employ,B
4187,Monte,B
4187,Carlo,I
4187,(,I
4187,MC,I
4187,),I
4187,search,I
4187,to,B
4187,approximate,I
4187,the,O
4187,state,B
4187,-,I
4187,action,I
4187,value,I
4187,.,O
4188,We,O
4188,directly,B
4188,train,I
4188,the,O
4188,policy,B
4188,(,I
4188,generative,I
4188,model,I
4188,),I
4188,via,B
4188,policy,O
4188,gradient,O
4188,",",O
4188,which,O
4188,naturally,B
4188,avoids,I
4188,the,O
4188,differentiation,B
4188,difficulty,I
4188,for,B
4188,discrete,B
4188,data,I
4188,in,B
4188,a,I
4188,conventional,B
4188,GAN,I
4188,.,O
4189,As,O
4189,a,O
4189,new,O
4189,way,O
4189,of,O
4189,training,O
4189,generative,O
4189,models,O
4189,",",O
4189,Generative,O
4189,Adversarial,O
4189,Net,O
4189,(,O
4189,GAN,O
4189,),O
4189,that,O
4189,uses,O
4189,a,O
4189,discriminative,O
4189,model,O
4189,to,O
4189,guide,O
4189,the,O
4189,training,O
4189,of,O
4189,the,O
4189,generative,O
4189,model,O
4189,has,O
4189,enjoyed,O
4189,considerable,O
4189,success,O
4189,in,O
4189,generating,B
4189,real,I
4189,-,I
4189,valued,I
4189,data,I
4189,.,O
4190,However,O
4190,",",O
4190,it,O
4190,has,O
4190,limitations,O
4190,when,O
4190,the,O
4190,goal,O
4190,is,O
4190,for,O
4190,generating,B
4190,sequences,I
4190,of,I
4190,discrete,I
4190,tokens,I
4190,.,O
4191,Since,O
4191,the,O
4191,evaluation,O
4191,metric,O
4191,is,O
4191,fundamentally,O
4191,instructive,O
4191,",",O
4191,we,O
4191,can,O
4191,see,B
4191,the,O
4191,impact,B
4191,of,I
4191,SeqGAN,I
4191,",",O
4191,which,O
4191,outperforms,B
4191,other,B
4191,baselines,I
4191,significantly,I
4191,.,O
4192,A,O
4192,significance,B
4192,T,I
4192,-,I
4192,test,I
4192,on,B
4192,the,O
4192,NLL,B
4192,oracle,I
4192,score,I
4192,distribution,I
4192,of,B
4192,the,O
4192,generated,B
4192,sequences,I
4192,from,B
4192,the,O
4192,compared,B
4192,models,I
4192,is,O
4192,also,O
4192,performed,O
4192,",",O
4192,which,O
4192,demonstrates,B
4192,the,O
4192,significant,B
4192,improvement,I
4192,of,O
4192,SeqGAN,B
4192,over,B
4192,all,I
4192,compared,O
4192,models,O
4192,.,O
4193,Additionally,O
4193,",",O
4193,SeqGAN,B
4193,outperforms,B
4193,PG,B
4193,-,I
4193,BLEU,I
4193,",",O
4193,which,O
4193,means,O
4193,the,O
4193,discriminative,O
4193,signal,O
4193,in,O
4193,GAN,O
4193,is,O
4193,more,O
4193,general,O
4193,and,O
4193,effective,O
4193,than,O
4193,a,O
4193,predefined,O
4193,score,O
4193,(,O
4193,e.g.,O
4194,After,O
4194,about,O
4194,150,B
4194,training,I
4194,epochs,I
4194,",",O
4194,both,B
4194,the,I
4194,maximum,B
4194,likelihood,I
4194,estimation,I
4194,and,I
4194,the,O
4194,schedule,O
4194,sampling,O
4194,methods,O
4194,converge,B
4194,to,I
4194,a,O
4194,relatively,B
4194,high,I
4194,NLL,I
4194,oracle,I
4194,score,I
4194,",",O
4194,whereas,O
4194,SeqGAN,B
4194,can,O
4194,improve,B
4194,the,O
4194,limit,O
4194,of,O
4194,the,O
4194,generator,B
4194,with,B
4194,the,O
4194,same,B
4194,structure,I
4194,as,B
4194,the,O
4194,baselines,B
4194,significantly,O
4194,.,O
4195,Hyperparameters,O
4195,are,O
4195,decided,B
4195,using,I
4195,a,O
4195,Random,B
4195,Search,I
4195,.,O
4196,This,O
4196,indicates,B
4196,the,O
4196,prospect,B
4196,of,I
4196,applying,I
4196,adversarial,I
4196,training,I
4196,strategies,I
4196,to,B
4196,discrete,B
4196,sequence,I
4196,generative,I
4196,models,I
4196,to,O
4196,breakthrough,O
4196,the,O
4196,limitations,B
4196,of,O
4196,MLE,O
4196,.,O
4197,We,O
4197,can,O
4197,see,B
4197,that,O
4197,SCNN,B
4197,-,I
4197,VAE,I
4197,-,O
4197,Semi,O
4197,has,O
4197,the,O
4197,best,B
4197,classification,I
4197,accuracy,I
4197,of,B
4197,65.5,B
4197,.,O
4198,On,O
4198,the,O
4198,other,O
4198,hand,O
4198,",",O
4198,LCNN,B
4198,-,I
4198,VAE,I
4198,-,O
4198,Semi,O
4198,has,O
4198,the,O
4198,best,B
4198,NLL,I
4198,result,I
4198,.,O
4199,We,O
4199,use,B
4199,an,O
4199,LSTM,B
4199,as,B
4199,an,O
4199,encoder,B
4199,for,B
4199,VAE,B
4199,and,I
4199,explore,B
4199,LSTMs,B
4199,and,O
4199,CNNs,O
4199,as,O
4199,decoders,B
4199,.,O
4200,Following,O
4200,",",O
4200,we,O
4200,use,O
4200,KL,B
4200,cost,I
4200,annealing,I
4200,strategy,I
4200,.,O
4201,We,O
4201,set,B
4201,the,O
4201,initial,B
4201,weight,I
4201,of,B
4201,KL,B
4201,cost,I
4201,term,I
4201,to,B
4201,be,I
4201,0.01,B
4201,and,O
4201,increase,B
4201,it,O
4201,linearly,B
4201,until,B
4201,a,O
4201,given,B
4201,iteration,I
4201,T,I
4201,.,O
4202,We,O
4202,use,O
4202,batch,B
4202,size,I
4202,of,B
4202,32,B
4202,and,O
4202,all,O
4202,model,O
4202,are,O
4202,trained,O
4202,for,O
4202,40,O
4202,epochs,O
4202,.,O
4203,We,O
4203,use,O
4203,Gumbel,B
4203,-,I
4203,softmax,I
4203,to,B
4203,sample,I
4203,y,B
4203,from,I
4203,q,I
4203,(,I
4203,y|x,I
4203,),I
4203,.,O
4204,We,O
4204,use,O
4204,Adam,B
4204,to,B
4204,optimize,I
4204,all,B
4204,models,I
4204,and,O
4204,the,O
4204,learning,B
4204,rate,I
4204,is,O
4204,selected,B
4204,from,I
4204,[,B
4204,2e,I
4204,-,I
4204,3,I
4204,",",I
4204,1,I
4204,e,I
4204,-,O
4204,3,O
4204,",",O
4204,7.5,O
4204,e,O
4204,-,O
4204,4,O
4204,],O
4204,and,O
4204,?,O
4205,Following,O
4205,",",O
4205,we,O
4205,also,O
4205,use,O
4205,drop,B
4205,word,I
4205,for,B
4205,the,O
4205,LSTM,B
4205,decoder,I
4205,",",O
4205,the,O
4205,drop,O
4205,word,O
4205,ratio,O
4205,is,O
4205,selected,B
4205,from,I
4205,[,O
4205,0,B
4205,",",O
4205,0.3,O
4205,",",O
4205,0.5,O
4205,",",O
4205,0.7,O
4205,],O
4205,.,O
4206,Based,O
4206,on,O
4206,validation,B
4206,performance,I
4206,",",O
4206,context,B
4206,window,I
4206,length,I
4206,K,I
4206,is,O
4206,set,B
4206,to,I
4206,be,O
4206,40,B
4206,and,O
4206,the,O
4206,number,B
4206,of,I
4206,hops,I
4206,R,I
4206,is,O
4206,fixed,B
4206,at,I
4206,3,B
4206,hops,O
4206,.,O
4207,We,O
4207,use,O
4207,a,O
4207,vocabulary,B
4207,size,I
4207,of,B
4207,20,B
4207,k,I
4207,for,B
4207,both,B
4207,data,I
4207,sets,I
4207,and,O
4207,set,B
4207,the,O
4207,word,B
4207,embedding,I
4207,dimension,I
4207,to,B
4207,be,I
4207,512,B
4207,.,O
4208,For,B
4208,CNNs,B
4208,",",O
4208,we,O
4208,explore,O
4208,several,O
4208,different,O
4208,configurations,O
4208,.,O
4209,We,O
4209,set,B
4209,the,O
4209,convolution,B
4209,filter,I
4209,size,I
4209,to,B
4209,be,I
4209,3,B
4209,and,O
4209,gradually,O
4209,increase,O
4209,the,O
4209,depth,O
4209,and,O
4209,dilation,O
4209,from,O
4209,[,O
4209,1,O
4209,",",O
4209,2,O
4209,",",O
4209,4,O
4209,],O
4209,",",O
4209,],O
4209,to,O
4209,.,O
4210,For,O
4210,the,O
4210,CNN,B
4210,decoder,I
4210,",",O
4210,we,O
4210,use,B
4210,a,O
4210,dropout,B
4210,ratio,I
4210,of,B
4210,0.1,B
4210,at,B
4210,each,B
4210,layer,I
4210,.,O
4211,The,O
4211,number,B
4211,of,I
4211,channels,I
4211,for,B
4211,convolutions,B
4211,in,B
4211,CNN,B
4211,decoders,I
4211,is,B
4211,512,B
4211,internally,I
4211,and,O
4211,1024,B
4211,externally,I
4211,",",O
4211,as,O
4211,shown,O
4211,in,O
4211,Section,O
4211,2.3,O
4211,.,O
4212,Empirically,O
4212,",",O
4212,we,O
4212,find,B
4212,learning,B
4212,rate,I
4212,1e,B
4212,-,I
4212,3,I
4212,and,I
4212,?1,I
4212,=,I
4212,0.5,I
4212,to,B
4212,perform,I
4212,the,O
4212,best,B
4212,.,O
4213,We,O
4213,select,B
4213,dropout,B
4213,ratio,I
4213,of,B
4213,LSTMs,B
4213,(,I
4213,both,I
4213,encoder,I
4213,and,I
4213,decoder,I
4213,),I
4213,from,B
4213,[,O
4213,0.3,B
4213,",",I
4213,0.5,I
4213,],O
4213,.,O
4214,We,O
4214,propose,B
4214,the,O
4214,use,O
4214,of,O
4214,a,O
4214,dilated,B
4214,CNN,I
4214,as,B
4214,a,O
4214,decoder,B
4214,in,B
4214,VAE,B
4214,",",O
4214,inspired,O
4214,by,O
4214,the,O
4214,recent,O
4214,success,O
4214,of,O
4214,using,O
4214,CNNs,O
4214,for,O
4214,audio,O
4214,",",O
4214,image,O
4214,and,O
4214,language,O
4214,modeling,O
4214,(,O
4214,van,O
4214,den,O
4214,.,O
4215,In,O
4215,contrast,O
4215,with,O
4215,prior,O
4215,work,O
4215,where,O
4215,extremely,O
4215,large,O
4215,CNNs,O
4215,are,O
4215,used,O
4215,",",O
4215,we,O
4215,exploit,B
4215,the,O
4215,dilated,B
4215,CNN,I
4215,for,B
4215,its,O
4215,flexibility,B
4215,in,O
4215,varying,O
4215,the,O
4215,amount,O
4215,of,O
4215,conditioning,B
4215,context,I
4215,.,O
4216,Improved,O
4216,Variational,O
4216,Autoencoders,O
4216,for,O
4216,Text,B
4216,Modeling,I
4216,using,O
4216,Dilated,O
4216,Convolutions,O
4217,We,O
4217,propose,B
4217,a,I
4217,conversational,B
4217,memory,I
4217,network,I
4217,(,I
4217,CMN,I
4217,),I
4217,",",O
4217,which,O
4217,uses,B
4217,a,O
4217,multimodal,B
4217,approach,I
4217,for,B
4217,emotion,B
4217,detection,I
4217,in,B
4217,utterances,B
4217,(,O
4217,a,O
4217,unit,O
4217,of,B
4217,speech,I
4217,bound,I
4217,by,I
4217,breathes,I
4217,or,I
4217,pauses,I
4217,),O
4217,of,O
4217,such,O
4217,conversational,O
4217,videos,O
4217,.,O
4218,Recent,O
4218,work,O
4218,on,O
4218,generative,B
4218,text,I
4218,modeling,I
4218,has,O
4218,found,O
4218,that,O
4218,variational,O
4218,autoencoders,O
4218,(,O
4218,VAE,O
4218,),O
4218,with,O
4218,LSTM,O
4218,decoders,O
4218,perform,O
4218,worse,O
4218,than,O
4218,simpler,O
4218,LSTM,O
4218,language,O
4218,models,O
4218,(,O
4218,Bowman,O
4218,et,O
4218,al.,O
4219,The,O
4219,results,O
4219,for,B
4219,language,B
4219,modeling,I
4219,are,O
4219,shown,O
4219,in,O
4219,.,O
4220,For,B
4220,SCNN,B
4220,",",I
4220,MCNN,I
4220,and,I
4220,LCNN,I
4220,",",O
4220,the,O
4220,VAE,B
4220,results,I
4220,improve,B
4220,over,I
4220,LM,B
4220,results,O
4220,from,B
4220,345.3,B
4220,to,B
4220,337.8,B
4220,",",O
4220,338.3,B
4220,to,O
4220,336.2,B
4220,",",O
4220,and,O
4220,335.4,B
4220,to,O
4220,333.9,B
4220,respectively,O
4220,.,O
4221,When,B
4221,LCNN,B
4221,is,O
4221,used,B
4221,as,I
4221,the,O
4221,decoder,B
4221,",",O
4221,we,O
4221,obtain,B
4221,an,O
4221,optimal,B
4221,trade,I
4221,off,I
4221,between,B
4221,using,I
4221,contextual,B
4221,information,I
4221,and,I
4221,latent,I
4221,representation,I
4221,.,O
4222,LCNN,O
4222,-,O
4222,VAE,O
4222,achieves,B
4222,a,O
4222,NLL,B
4222,of,B
4222,333.9,B
4222,",",O
4222,which,O
4222,improves,B
4222,over,I
4222,LSTM,B
4222,-,O
4222,LM,O
4222,with,B
4222,NLL,O
4222,of,O
4222,334.9,B
4222,.,O
4223,In,O
4223,this,O
4223,paper,O
4223,",",O
4223,we,O
4223,propose,B
4223,a,O
4223,novel,B
4223,adversarial,I
4223,learning,I
4223,framework,I
4223,",",O
4223,RankGAN,B
4223,",",O
4223,for,O
4223,generating,O
4223,highquality,O
4223,language,O
4223,descriptions,O
4223,.,O
4224,As,O
4224,opposed,O
4224,to,O
4224,performing,O
4224,a,O
4224,binary,O
4224,classification,O
4224,task,O
4224,",",O
4224,we,O
4224,propose,O
4224,to,O
4224,train,B
4224,the,O
4224,ranker,B
4224,to,O
4224,rank,O
4224,the,O
4224,machine,B
4224,-,I
4224,written,I
4224,sentences,I
4224,lower,B
4224,than,I
4224,human,B
4224,-,O
4224,written,O
4224,sentences,O
4224,with,B
4224,respect,I
4224,to,O
4224,a,O
4224,reference,B
4224,sentence,I
4224,which,B
4224,is,I
4224,human-written,B
4224,.,O
4225,RankGAN,O
4225,learns,B
4225,the,I
4225,model,B
4225,from,B
4225,the,O
4225,relative,B
4225,ranking,I
4225,information,I
4225,between,B
4225,the,O
4225,machine,O
4225,-,O
4225,written,O
4225,and,O
4225,the,O
4225,human,O
4225,-,O
4225,written,O
4225,sentences,O
4225,in,B
4225,an,O
4225,adversarial,B
4225,framework,I
4225,.,O
4226,In,O
4226,the,O
4226,proposed,O
4226,RankGAN,O
4226,",",O
4226,we,O
4226,relax,B
4226,the,O
4226,training,B
4226,of,B
4226,the,O
4226,discriminator,B
4226,to,I
4226,a,O
4226,learning,B
4226,-,I
4226,to,O
4226,-,O
4226,rank,O
4226,optimization,O
4226,problem,O
4226,.,O
4227,Specifically,O
4227,",",O
4227,the,O
4227,proposed,B
4227,new,B
4227,adversarial,I
4227,network,I
4227,consists,B
4227,of,I
4227,two,B
4227,neural,I
4227,network,O
4227,models,O
4227,",",O
4227,a,O
4227,generator,O
4227,and,O
4227,a,O
4227,ranker,O
4227,.,O
4228,Our,O
4228,proposed,B
4228,CMN,I
4228,incorporates,O
4228,these,O
4228,factors,O
4228,by,B
4228,using,I
4228,emotional,B
4228,context,I
4228,information,I
4228,present,B
4228,in,I
4228,the,O
4228,conversation,B
4228,history,I
4228,.,O
4229,Accordingly,O
4229,",",O
4229,we,O
4229,train,B
4229,the,O
4229,generator,B
4229,to,B
4229,synthesize,I
4229,sentences,I
4229,which,B
4229,confuse,I
4229,the,O
4229,ranker,B
4229,so,B
4229,that,I
4229,machine,B
4229,-,I
4229,written,I
4229,sentences,O
4229,are,O
4229,ranked,B
4229,higher,I
4229,than,I
4229,human,B
4229,-,O
4229,written,O
4229,sentences,O
4229,in,O
4229,regard,O
4229,to,O
4229,the,O
4229,reference,O
4229,.,O
4230,During,B
4230,learning,B
4230,",",O
4230,we,O
4230,adopt,B
4230,the,O
4230,policy,B
4230,gradient,I
4230,technique,I
4230,to,B
4230,overcome,I
4230,the,O
4230,non-differentiable,B
4230,problem,I
4230,.,O
4231,Consequently,O
4231,",",O
4231,by,O
4231,viewing,B
4231,a,O
4231,set,B
4231,of,B
4231,data,I
4231,samples,B
4231,collectively,I
4231,and,O
4231,evaluating,B
4231,their,O
4231,quality,B
4231,through,B
4231,relative,B
4231,ranking,I
4231,",",O
4231,the,O
4231,discriminator,B
4231,is,O
4231,able,B
4231,to,B
4231,make,I
4231,better,B
4231,assessment,I
4231,of,O
4231,the,O
4231,quality,O
4231,of,O
4231,the,O
4231,samples,O
4231,",",O
4231,which,O
4231,in,O
4231,turn,O
4231,helps,B
4231,the,O
4231,generator,B
4231,to,O
4231,learn,O
4231,better,O
4231,.,O
4232,Our,O
4232,method,O
4232,is,O
4232,suitable,B
4232,for,I
4232,language,B
4232,learning,I
4232,in,B
4232,comparison,I
4232,to,I
4232,conventional,B
4232,GANs,I
4232,.,O
4233,Adversarial,O
4233,Ranking,O
4233,for,O
4233,Language,B
4233,Generation,I
4234,Simulation,O
4234,on,B
4234,synthetic,B
4234,data,I
4235,It,O
4235,can,O
4235,be,O
4235,seen,O
4235,that,O
4235,the,O
4235,proposed,O
4235,RankGAN,B
4235,performs,B
4235,more,B
4235,favourably,I
4235,against,B
4235,the,O
4235,compared,B
4235,methods,I
4235,.,O
4236,While,O
4236,MLE,B
4236,",",I
4236,PG,I
4236,-,I
4236,BLEU,I
4236,and,I
4236,SeqGAN,I
4236,tend,B
4236,to,I
4236,converge,B
4236,after,B
4236,200,B
4236,training,I
4236,epochs,I
4236,",",O
4236,the,O
4236,proposed,B
4236,RankGAN,I
4236,consistently,B
4236,improves,I
4236,the,O
4236,language,B
4236,generator,I
4236,and,O
4236,achieves,B
4236,relatively,B
4236,lower,I
4236,NLL,B
4236,score,I
4236,.,O
4237,It,O
4237,is,O
4237,worth,B
4237,noting,I
4237,that,O
4237,the,O
4237,proposed,B
4237,RankGAN,I
4237,achieves,B
4237,better,B
4237,performance,I
4237,than,B
4237,that,O
4237,of,O
4237,PG,B
4237,-,I
4237,BLEU,I
4237,.,O
4238,Results,O
4238,on,O
4238,Chinese,B
4238,poems,I
4238,composition,I
4239,It,O
4239,improves,B
4239,speakerbased,B
4239,emotion,I
4239,modeling,I
4239,by,B
4239,using,I
4239,memory,B
4239,networks,I
4239,which,O
4239,are,O
4239,efficient,B
4239,in,I
4239,capturing,I
4239,long,B
4239,-,I
4239,term,I
4239,dependencies,I
4239,and,O
4239,summarizing,B
4239,task,B
4239,-,O
4239,specific,O
4239,details,O
4239,using,O
4239,attention,O
4239,models,O
4239,.,O
4240,Following,O
4240,the,O
4240,evaluation,O
4240,protocol,O
4240,in,O
4240,",",O
4240,we,O
4240,compute,O
4240,the,O
4240,BLEU,O
4240,-,O
4240,2,O
4240,score,O
4240,and,O
4240,estimate,B
4240,the,O
4240,similarity,B
4240,between,B
4240,the,O
4240,human,B
4240,-,O
4240,written,O
4240,poem,O
4240,and,O
4240,the,O
4240,machine,O
4240,-,O
4240,created,O
4240,one,O
4240,.,O
4241,It,O
4241,can,O
4241,be,O
4241,seen,B
4241,that,I
4241,the,I
4241,proposed,B
4241,Rank,I
4241,GAN,I
4241,performs,B
4241,more,B
4241,favourably,I
4241,compared,B
4241,to,I
4241,the,O
4241,state,B
4241,-,I
4241,of,I
4241,-,O
4241,the,O
4241,-,O
4241,art,O
4241,methods,O
4241,in,B
4241,terms,I
4241,of,O
4241,BLEU,B
4241,-,O
4241,2,O
4241,score,O
4241,.,O
4242,RankGAN,B
4242,outperforms,B
4242,the,O
4242,compared,B
4242,method,I
4242,in,B
4242,terms,I
4242,of,I
4242,the,O
4242,human,B
4242,evaluation,I
4242,score,I
4242,.,O
4243,Results,O
4243,on,O
4243,COCO,B
4243,image,I
4243,captions,I
4244,RankGAN,B
4244,achieves,B
4244,better,B
4244,performance,I
4244,than,B
4244,the,O
4244,other,B
4244,methods,I
4244,in,B
4244,terms,I
4244,of,I
4244,different,B
4244,BLEU,I
4244,scores,I
4244,.,O
4245,These,O
4245,examples,O
4245,show,O
4245,that,O
4245,our,B
4245,model,I
4245,is,O
4245,able,B
4245,to,I
4245,generate,I
4245,fluent,B
4245,",",I
4245,novel,I
4245,sentences,I
4245,that,O
4245,are,O
4245,not,B
4245,existing,I
4245,in,I
4245,the,O
4245,training,B
4245,set,I
4245,.,O
4246,As,O
4246,can,O
4246,be,O
4246,seen,O
4246,",",O
4246,the,O
4246,human,B
4246,-,I
4246,written,I
4246,sentences,I
4246,get,B
4246,the,O
4246,highest,B
4246,score,I
4246,comparing,B
4246,to,I
4246,the,O
4246,language,B
4246,models,I
4246,.,O
4247,Among,B
4247,the,O
4247,GANs,B
4247,approaches,I
4247,",",O
4247,RankGAN,B
4247,receives,B
4247,better,B
4247,score,I
4247,than,B
4247,SeqGAN,B
4247,",",O
4247,which,O
4247,is,O
4247,consistent,O
4247,to,O
4247,the,O
4247,finding,O
4247,in,O
4247,the,O
4247,Chinese,O
4247,poem,O
4247,composition,O
4247,.,O
4248,Results,O
4248,on,O
4248,Shakespeare,B
4248,'s,I
4248,plays,I
4249,As,O
4249,can,O
4249,be,O
4249,seen,O
4249,",",O
4249,the,O
4249,proposed,B
4249,method,I
4249,achieves,B
4249,consistently,B
4249,higher,I
4249,BLEU,I
4249,score,I
4249,than,B
4249,the,O
4249,other,B
4249,methods,I
4249,in,B
4249,terms,I
4249,of,I
4249,the,O
4249,different,B
4249,n-grams,I
4249,criteria,I
4249,.,O
4250,Specifically,O
4250,",",O
4250,the,O
4250,memory,B
4250,cells,I
4250,of,B
4250,CMN,B
4250,are,B
4250,continuous,B
4250,vectors,I
4250,that,O
4250,store,B
4250,the,O
4250,context,B
4250,information,I
4250,found,B
4250,in,I
4250,the,O
4250,utterance,B
4250,histories,I
4250,.,O
4251,The,O
4251,results,O
4251,indicate,O
4251,the,O
4251,proposed,B
4251,RankGAN,I
4251,is,B
4251,able,I
4251,to,I
4251,capture,I
4251,the,O
4251,transition,B
4251,pattern,I
4251,among,B
4251,the,O
4251,words,B
4251,",",O
4251,even,O
4251,if,O
4251,the,O
4251,training,O
4251,sentences,O
4251,are,O
4251,novel,O
4251,",",O
4251,delicate,O
4251,and,O
4251,complicated,O
4251,.,O
4252,In,O
4252,this,O
4252,paper,O
4252,",",O
4252,we,O
4252,propose,O
4252,a,O
4252,new,O
4252,algorithmic,O
4252,framework,O
4252,called,B
4252,Leak,B
4252,GAN,I
4252,to,B
4252,address,I
4252,both,B
4252,the,I
4252,non-informativeness,I
4252,and,I
4252,the,O
4252,sparsity,O
4252,issues,O
4252,.,O
4253,LeakGAN,B
4253,is,O
4253,a,O
4253,new,O
4253,way,O
4253,of,O
4253,providing,B
4253,richer,B
4253,information,I
4253,from,B
4253,the,O
4253,discriminator,B
4253,to,B
4253,the,O
4253,generator,B
4253,by,B
4253,borrowing,I
4253,the,O
4253,recent,B
4253,advances,I
4253,in,B
4253,hierarchical,B
4253,reinforcement,I
4253,learning,I
4253,.,O
4254,The,O
4254,MANAGER,B
4254,is,O
4254,along,B
4254,shortterm,B
4254,memory,I
4254,network,I
4254,(,I
4254,LSTM,I
4254,),I
4254,and,O
4254,serves,B
4254,as,I
4254,a,O
4254,mediator,B
4254,.,O
4255,In,O
4255,each,O
4255,step,O
4255,",",O
4255,it,O
4255,receives,B
4255,generator,B
4255,D,I
4255,'s,I
4255,high,I
4255,-,I
4255,level,I
4255,feature,I
4255,representation,I
4255,",",O
4255,e.g.,O
4256,",",O
4256,the,O
4256,feature,O
4256,map,O
4256,of,O
4256,the,O
4256,CNN,O
4256,",",O
4256,and,O
4256,uses,O
4256,it,O
4256,to,O
4256,form,B
4256,the,O
4256,guiding,B
4256,goal,I
4256,for,B
4256,the,O
4256,WORKER,B
4256,module,I
4256,in,O
4256,that,O
4256,timestep,O
4256,.,O
4257,As,O
4257,illustrated,O
4257,in,O
4257,",",O
4257,we,O
4257,specifically,O
4257,introduce,B
4257,a,O
4257,hierarchical,B
4257,generator,I
4257,G,I
4257,",",O
4257,which,O
4257,consists,B
4257,of,I
4257,a,O
4257,high,B
4257,-,I
4257,level,I
4257,MANAGER,I
4257,module,I
4257,and,O
4257,a,O
4257,low,B
4257,-,O
4257,level,O
4257,WORKER,O
4257,module,O
4257,.,O
4258,Next,O
4258,",",O
4258,given,B
4258,the,I
4258,goal,I
4258,embedding,I
4258,produced,B
4258,by,I
4258,the,O
4258,MAN,B
4258,-,I
4258,AGER,I
4258,",",O
4258,the,O
4258,WORKER,B
4258,first,B
4258,encodes,I
4258,current,B
4258,generated,I
4258,words,I
4258,with,B
4258,another,B
4258,LSTM,I
4258,",",O
4258,then,B
4258,combines,I
4258,the,O
4258,output,B
4258,of,B
4258,the,O
4258,LSTM,O
4258,and,O
4258,the,O
4258,goal,O
4258,embedding,O
4258,to,B
4258,take,I
4258,a,O
4258,final,B
4258,action,I
4258,at,B
4258,current,O
4258,state,O
4258,.,O
4259,For,O
4259,the,O
4259,discriminator,O
4259,",",O
4259,we,O
4259,choose,B
4259,the,O
4259,CNN,B
4259,architecture,I
4259,as,B
4259,the,O
4259,feature,B
4259,extractor,I
4259,and,I
4259,the,O
4259,binary,O
4259,classifier,O
4259,.,O
4260,For,B
4260,the,O
4260,synthetic,B
4260,data,I
4260,experiment,I
4260,",",O
4260,the,O
4260,CNN,B
4260,kernel,I
4260,size,I
4260,ranges,B
4260,from,B
4260,1,I
4260,to,I
4260,T,I
4260,.,O
4261,CMN,B
4261,also,O
4261,models,B
4261,interplay,B
4261,of,B
4261,these,O
4261,memories,B
4261,to,B
4261,capture,I
4261,interspeaker,B
4261,dependencies,I
4261,.,O
4262,For,O
4262,the,O
4262,generator,B
4262,",",O
4262,we,O
4262,adopt,B
4262,LSTM,B
4262,as,B
4262,the,O
4262,architectures,B
4262,of,I
4262,MANAGER,I
4262,and,I
4262,WORKER,I
4262,to,B
4262,capture,I
4262,the,O
4262,sequence,B
4262,context,I
4262,information,I
4262,.,O
4263,The,O
4263,number,B
4263,of,I
4263,each,B
4263,kernel,I
4263,is,O
4263,between,B
4263,100,B
4263,and,I
4263,200,I
4263,.,O
4264,In,O
4264,this,O
4264,case,O
4264,",",O
4264,the,O
4264,feature,B
4264,of,I
4264,text,I
4264,is,B
4264,a,O
4264,"1,720",B
4264,dimensional,I
4264,vector,I
4264,.,O
4265,Dropout,B
4265,with,B
4265,the,O
4265,keep,B
4265,rate,I
4265,0.75,I
4265,and,O
4265,L2,B
4265,regularization,I
4265,are,O
4265,performed,B
4265,to,I
4265,avoid,I
4265,overfitting,B
4265,.,O
4266,The,O
4266,MANAGER,B
4266,produces,B
4266,the,O
4266,16,B
4266,-,I
4266,dimensional,I
4266,goal,I
4266,embedding,I
4266,feature,B
4266,vector,I
4266,wt,O
4266,using,B
4266,the,O
4266,feature,O
4266,map,O
4266,extracted,B
4266,by,I
4266,CNN,B
4266,.,O
4267,The,O
4267,goal,B
4267,duration,I
4267,time,I
4267,c,I
4267,is,B
4267,a,I
4267,hyperparameter,B
4267,set,B
4267,as,I
4267,4,B
4267,after,B
4267,some,B
4267,preliminary,I
4267,experiments,I
4267,.,O
4268,Long,O
4268,Text,B
4268,Generation,I
4268,via,O
4268,Adversarial,O
4268,Training,O
4268,with,O
4268,Leaked,O
4268,Information,O
4269,(,O
4269,i,O
4269,),O
4269,In,B
4269,the,O
4269,pre-training,B
4269,stage,I
4269,",",O
4269,LeakGAN,B
4269,has,O
4269,already,B
4269,shown,I
4269,observable,B
4269,performance,I
4269,superiority,I
4269,compared,B
4269,to,I
4269,other,B
4269,models,I
4269,",",O
4269,which,O
4269,indicates,O
4269,that,O
4269,the,O
4269,proposed,O
4269,hierarchical,O
4269,architecture,O
4269,itself,O
4269,brings,O
4269,improvement,O
4269,over,O
4269,the,O
4269,previous,O
4269,ones,O
4269,.,O
4270,CMN,O
4270,first,O
4270,extracts,B
4270,multimodal,B
4270,features,I
4270,(,I
4270,audio,I
4270,",",I
4270,visual,I
4270,",",O
4270,and,O
4270,text,O
4270,),O
4270,for,B
4270,all,B
4270,utterances,I
4270,in,B
4270,a,O
4270,video,B
4270,.,O
4271,(,O
4271,ii,O
4271,),O
4271,In,O
4271,the,O
4271,adversarial,B
4271,training,I
4271,stage,I
4271,",",O
4271,Leak,B
4271,GAN,I
4271,shows,B
4271,a,O
4271,better,O
4271,speed,O
4271,of,O
4271,convergence,O
4271,",",O
4271,and,O
4271,the,O
4271,local,B
4271,minimum,I
4271,it,O
4271,explores,B
4271,is,B
4271,significantly,B
4271,better,O
4271,than,B
4271,previous,B
4271,results,I
4271,.,O
4272,In,B
4272,all,B
4272,measured,I
4272,metrics,I
4272,",",O
4272,LeakGAN,B
4272,shows,B
4272,significant,B
4272,performance,I
4272,gain,I
4272,compared,B
4272,to,I
4272,baseline,B
4272,models,I
4272,.,O
4273,The,O
4273,results,O
4273,of,B
4273,the,O
4273,BLEU,B
4273,scores,I
4273,on,B
4273,the,O
4273,COCO,B
4273,dataset,I
4273,indicate,B
4273,that,O
4273,Leak,B
4273,GAN,I
4273,performs,B
4273,significantly,B
4273,better,I
4273,than,B
4273,baseline,B
4273,models,I
4273,in,B
4273,mid-length,B
4273,text,I
4273,generation,I
4273,task,I
4273,.,O
4274,The,O
4274,results,O
4274,on,O
4274,Chinese,O
4274,Poems,O
4274,indicate,B
4274,that,O
4274,LeakGAN,B
4274,successfully,B
4274,handles,I
4274,the,O
4274,short,B
4274,text,I
4274,generation,I
4274,tasks,I
4274,.,O
4275,The,O
4275,performance,B
4275,on,B
4275,two,B
4275,datasets,I
4275,indicates,B
4275,that,I
4275,the,O
4275,generated,B
4275,sentences,I
4275,of,B
4275,Leak,B
4275,GAN,I
4275,are,O
4275,of,O
4275,higher,B
4275,global,I
4275,consistency,I
4275,and,O
4275,better,B
4275,readability,I
4275,than,B
4275,those,I
4275,of,O
4275,SeqGAN,B
4275,.,O
4276,For,B
4276,dialogue,O
4276,generation,O
4276,",",O
4276,we,O
4276,set,B
4276,the,O
4276,maximum,B
4276,length,I
4276,to,B
4276,15,B
4276,words,I
4276,for,O
4276,each,B
4276,generated,I
4276,sentence,I
4276,.,O
4277,Conversational,O
4277,Memory,O
4277,Network,O
4277,for,O
4277,Emotion,B
4277,Recognition,I
4277,in,I
4277,Dyadic,I
4277,Dialogue,I
4277,Videos,I
4278,Based,O
4278,on,O
4278,the,O
4278,performance,O
4278,on,O
4278,the,O
4278,validation,O
4278,set,O
4278,",",O
4278,we,O
4278,set,O
4278,the,O
4278,hidden,B
4278,size,I
4278,to,O
4278,512,B
4278,",",O
4278,embedding,B
4278,size,O
4278,to,O
4278,64,B
4278,and,O
4278,vocabulary,B
4278,size,O
4278,to,O
4278,40,B
4278,K,I
4278,for,O
4278,baseline,O
4278,models,O
4278,and,O
4278,the,O
4278,proposed,O
4278,model,O
4278,.,O
4279,The,O
4279,parameters,B
4279,are,O
4279,updated,B
4279,by,I
4279,the,O
4279,Adam,B
4279,algorithm,I
4279,(,I
4279,Kingma,I
4279,and,I
4279,Ba,I
4279,",",I
4279,2014,I
4279,),I
4279,and,O
4279,initialized,B
4279,by,O
4279,sampling,B
4279,from,B
4279,the,O
4279,uniform,O
4279,distribution,O
4279,(,O
4279,[?,O
4280,The,O
4280,initial,B
4280,learning,I
4280,rate,I
4280,is,O
4280,0.002,B
4280,and,O
4280,the,O
4280,model,B
4280,is,O
4280,trained,B
4280,in,I
4280,minibatches,B
4280,with,B
4280,a,O
4280,batch,B
4280,size,I
4280,of,B
4280,256,B
4280,.,O
4281,To,O
4281,address,O
4281,this,O
4281,problem,O
4281,",",O
4281,we,O
4281,propose,B
4281,a,O
4281,novel,B
4281,Auto,I
4281,-,I
4281,Encoder,I
4281,Matching,I
4281,model,I
4281,to,O
4281,learn,O
4281,utterance,B
4281,-,O
4281,level,O
4281,dependency,O
4281,.,O
4282,First,O
4282,",",O
4282,motivated,O
4282,by,O
4282,",",O
4282,we,O
4282,use,B
4282,two,B
4282,auto-,I
4282,encoders,I
4282,to,B
4282,learn,I
4282,the,O
4282,semantic,B
4282,representations,I
4282,of,B
4282,inputs,B
4282,and,I
4282,responses,I
4282,in,B
4282,an,O
4282,unsupervised,B
4282,style,I
4282,.,O
4283,Second,O
4283,",",O
4283,given,B
4283,the,O
4283,utterance,B
4283,-,I
4283,level,I
4283,representations,I
4283,",",O
4283,the,O
4283,mapping,B
4283,module,I
4283,is,O
4283,taught,B
4283,to,I
4283,learn,I
4283,the,O
4283,utterance,O
4283,-,O
4283,level,O
4283,dependency,O
4283,.,O
4284,An,O
4284,Auto,O
4284,-,O
4284,Encoder,O
4284,Matching,O
4284,Model,O
4284,for,O
4284,Learning,O
4284,Utterance,O
4284,-,O
4284,Level,O
4284,Semantic,O
4284,Dependency,O
4284,in,O
4284,Dialogue,B
4284,Generation,I
4285,However,O
4285,",",O
4285,conversation,B
4285,generation,I
4285,is,O
4285,a,O
4285,much,O
4285,more,O
4285,complex,O
4285,and,O
4285,flexible,O
4285,task,O
4285,as,O
4285,there,O
4285,are,O
4285,less,O
4285,"""",O
4285,word,O
4285,-,O
4285,to,O
4285,-,O
4285,words,O
4285,"""",O
4285,relations,O
4285,between,O
4285,inputs,O
4285,and,O
4285,responses,O
4285,.,O
4286,The,O
4286,proposed,B
4286,AEM,I
4286,model,I
4286,significantly,B
4286,outperforms,I
4286,the,O
4286,Seq2Seq,B
4286,model,O
4286,.,O
4287,We,O
4287,observe,B
4287,that,O
4287,performance,B
4287,improves,B
4287,further,I
4287,with,I
4287,the,O
4287,availability,B
4287,of,I
4287,more,I
4287,alias,I
4287,information,I
4287,.,O
4288,Other,O
4288,matrices,O
4288,are,O
4288,initialized,B
4288,with,I
4288,random,B
4288,values,I
4288,following,B
4288,a,O
4288,Gaussian,B
4288,distribution,I
4288,.,O
4289,It,O
4289,demonstrates,B
4289,the,O
4289,effectiveness,B
4289,of,I
4289,utterance,I
4289,-,I
4289,level,I
4289,dependency,I
4289,on,B
4289,improving,I
4289,the,O
4289,quality,B
4289,of,O
4289,generated,O
4289,text,O
4289,.,O
4290,The,O
4290,improvement,B
4290,from,I
4290,the,O
4290,AEM,B
4290,model,I
4290,to,B
4290,the,O
4290,AEM,O
4290,+,O
4290,Attention,O
4290,model,O
4290,2,O
4290,is,B
4290,0.68,B
4290,BLEU,I
4290,-,I
4290,4,I
4290,point,I
4290,.,O
4291,We,O
4291,find,B
4291,that,O
4291,the,O
4291,AEM,B
4291,model,I
4291,achieves,B
4291,significant,B
4291,improvement,I
4291,on,B
4291,the,O
4291,diversity,B
4291,of,I
4291,generated,I
4291,text,I
4291,.,O
4292,Also,O
4292,",",O
4292,it,O
4292,should,O
4292,be,O
4292,noticed,B
4292,that,I
4292,the,I
4292,attention,B
4292,mechanism,I
4292,performs,B
4292,almost,B
4292,the,O
4292,same,O
4292,compared,B
4292,to,I
4292,the,O
4292,AEM,B
4292,model,I
4292,(,O
4292,31.2,O
4292,K,O
4292,vs.,O
4292,34.6,O
4292,K,O
4292,in,O
4292,terms,O
4292,of,O
4292,Dist,O
4292,-,O
4292,3,O
4292,),O
4292,",",O
4292,which,O
4292,indicates,O
4292,that,O
4292,the,O
4292,utterance,O
4292,-,O
4292,level,O
4292,dependency,O
4292,and,O
4292,the,O
4292,word,O
4292,-,O
4292,level,O
4292,dependency,O
4292,are,O
4292,both,O
4292,indispensable,O
4292,for,O
4292,dialogue,O
4292,generation,O
4292,.,O
4293,Therefore,O
4293,",",O
4293,by,O
4293,combining,B
4293,the,O
4293,two,B
4293,dependencies,I
4293,together,O
4293,",",O
4293,the,O
4293,AEM,B
4293,+,I
4293,Attention,I
4293,model,I
4293,achieves,B
4293,the,O
4293,best,B
4293,results,I
4293,.,O
4294,shows,O
4294,the,O
4294,results,O
4294,of,B
4294,human,B
4294,evaluation,I
4294,.,O
4295,The,O
4295,inter-annotator,B
4295,agreement,I
4295,is,B
4295,satisfactory,B
4295,considering,O
4295,the,O
4295,difficulty,O
4295,of,O
4295,human,O
4295,evaluation,O
4295,.,O
4296,The,O
4296,Pearson,B
4296,'s,I
4296,correlation,I
4296,coefficient,I
4296,is,B
4296,0.69,B
4296,on,B
4296,coherence,B
4296,and,O
4296,0.57,B
4296,on,O
4296,fluency,B
4296,",",O
4296,with,O
4296,p,O
4296,<,O
4296,0.0001,O
4296,.,O
4297,First,O
4297,",",O
4297,it,O
4297,is,O
4297,clear,B
4297,that,I
4297,the,O
4297,AEM,B
4297,model,I
4297,outperforms,B
4297,the,O
4297,Seq2Seq,B
4297,model,O
4297,with,B
4297,a,O
4297,large,B
4297,margin,I
4297,",",O
4297,which,O
4297,proves,O
4297,the,O
4297,effectiveness,O
4297,of,O
4297,the,O
4297,AEM,O
4297,model,O
4297,on,O
4297,generating,O
4297,high,O
4297,quality,O
4297,responses,O
4297,.,O
4298,Second,O
4298,",",O
4298,it,O
4298,is,O
4298,interesting,B
4298,to,I
4298,note,I
4298,that,I
4298,with,I
4298,the,O
4298,attention,B
4298,mechanism,I
4298,",",O
4298,the,O
4298,coherence,B
4298,is,O
4298,decreased,B
4298,slightly,I
4298,in,I
4298,the,O
4298,Seq2Seq,B
4298,model,I
4298,but,O
4298,increased,B
4298,significantly,I
4298,in,O
4298,the,O
4298,AEM,B
4298,model,O
4298,.,O
4299,In,O
4299,this,O
4299,paper,O
4299,",",O
4299,we,O
4299,analyze,O
4299,emotion,B
4299,detection,I
4299,in,O
4299,videos,O
4299,of,O
4299,dyadic,O
4299,conversations,O
4299,.,O
4300,Therefore,O
4300,",",O
4300,it,O
4300,is,O
4300,expected,B
4300,that,I
4300,the,O
4300,AEM,B
4300,+,I
4300,Attention,I
4300,model,I
4300,achieves,B
4300,the,O
4300,best,B
4300,G-score,I
4300,.,O
4301,This,O
4301,work,O
4301,pro-Code,O
4301,available,O
4301,at,O
4301,:,O
4301,https://github.com/enigmaeth/skip-thought-gan,B
4301,poses,O
4301,an,O
4301,approach,O
4301,for,O
4301,text,O
4301,generation,O
4301,using,O
4301,Generative,O
4301,Adversarial,O
4301,Networks,O
4301,with,O
4301,Skip,O
4301,-,O
4301,Thought,O
4301,vectors,O
4301,.,O
4302,The,O
4302,Skip,B
4302,-,I
4302,Thought,I
4302,encoder,I
4302,for,O
4302,the,O
4302,model,O
4302,encodes,B
4302,sentences,B
4302,with,B
4302,length,B
4302,less,B
4302,than,I
4302,30,B
4302,words,I
4302,using,B
4302,2400,B
4302,GRU,I
4302,units,I
4302,with,O
4302,word,B
4302,vector,I
4302,dimensionality,B
4302,of,I
4302,620,B
4302,to,B
4302,produce,I
4302,4800,B
4302,-,O
4302,dimensional,O
4302,combineskip,O
4302,vectors,O
4302,.,O
4303,The,I
4303,combine,B
4303,-,I
4303,skip,I
4303,vectors,I
4303,",",O
4303,with,B
4303,the,O
4303,first,B
4303,2400,I
4303,dimensions,I
4303,being,B
4303,uni-skip,B
4303,model,I
4303,and,O
4303,the,O
4303,last,B
4303,2400,O
4303,bi-skip,O
4303,model,O
4303,",",O
4303,are,O
4303,used,O
4303,as,O
4303,they,O
4303,have,O
4303,been,O
4303,found,B
4303,to,I
4303,be,I
4303,the,O
4303,best,B
4303,performing,I
4303,in,I
4303,the,O
4303,experiments,O
4304,Attempts,O
4304,have,O
4304,been,O
4304,made,O
4304,for,O
4304,utilizing,O
4304,GANs,O
4304,with,O
4304,word,O
4304,embeddings,O
4304,for,O
4304,text,B
4304,generation,I
4304,.,O
4305,Numerous,O
4305,efforts,O
4305,have,O
4305,been,O
4305,made,O
4305,in,O
4305,the,O
4305,field,O
4305,of,O
4305,natural,B
4305,language,I
4305,text,I
4305,generation,I
4305,for,O
4305,tasks,O
4305,such,O
4305,as,O
4305,sentiment,O
4305,analysis,O
4305,and,O
4305,machine,O
4305,translation,O
4305,.,O
4306,Among,O
4306,the,O
4306,ablations,O
4306,",",O
4306,the,O
4306,proposed,B
4306,EDD,I
4306,-,I
4306,LG,I
4306,(,I
4306,shared,I
4306,),I
4306,method,I
4306,works,B
4306,way,B
4306,better,I
4306,than,B
4306,the,O
4306,other,B
4306,variants,I
4306,in,B
4306,terms,I
4306,of,B
4306,BLEU,B
4306,and,I
4306,METEOR,I
4306,metrics,I
4306,by,O
4306,achieving,B
4306,an,O
4306,improvement,B
4306,of,O
4306,8,B
4306,%,I
4306,and,O
4306,6,O
4306,%,O
4306,in,O
4306,the,O
4306,scores,B
4306,respectively,O
4306,over,O
4306,the,O
4306,baseline,O
4306,method,O
4306,for,B
4306,50,B
4306,K,I
4306,dataset,I
4306,and,O
4306,an,O
4306,improvement,O
4306,of,O
4306,10,B
4306,%,O
4306,and,O
4306,7,O
4306,%,O
4306,in,O
4306,the,O
4306,scores,O
4306,respectively,O
4306,for,O
4306,100,B
4306,K,O
4306,dataset,O
4306,.,O
4307,We,O
4307,start,B
4307,with,B
4307,baseline,B
4307,model,I
4307,which,O
4307,we,O
4307,take,B
4307,as,I
4307,a,O
4307,simple,B
4307,encoder,I
4307,and,I
4307,decoder,I
4307,network,I
4307,with,O
4307,only,B
4307,the,I
4307,local,I
4307,loss,I
4307,(,I
4307,ED,I
4307,-,I
4307,Local,O
4307,),O
4307,.,O
4308,Further,O
4308,we,O
4308,have,O
4308,experimented,B
4308,with,B
4308,encoder,B
4308,-,I
4308,decoder,I
4308,and,I
4308,a,I
4308,discriminator,I
4308,network,I
4308,with,O
4308,only,B
4308,global,I
4308,loss,I
4308,(,I
4308,EDD,I
4308,-,O
4308,Global,O
4308,),O
4308,to,B
4308,distinguish,I
4308,the,O
4308,ground,B
4308,truth,I
4308,paraphrase,I
4308,with,O
4308,the,O
4308,predicted,B
4308,one,I
4308,.,O
4309,Another,O
4309,variation,B
4309,of,I
4309,our,I
4309,model,I
4309,is,O
4309,used,B
4309,both,B
4309,the,I
4309,global,I
4309,and,I
4309,local,I
4309,loss,I
4309,(,I
4309,EDD,I
4309,-,I
4309,LG,I
4309,),I
4309,.,O
4310,Finally,O
4310,",",O
4310,we,O
4310,make,B
4310,the,I
4310,discriminator,B
4310,share,B
4310,weights,B
4310,with,B
4310,the,O
4310,encoder,B
4310,and,O
4310,train,B
4310,this,O
4310,network,B
4310,with,O
4310,both,B
4310,the,O
4310,losses,O
4310,(,O
4310,EDD,O
4310,-,O
4310,LG,O
4310,(,O
4310,shared,O
4310,),O
4310,),O
4310,.,O
4311,Our,O
4311,model,O
4311,consists,B
4311,of,I
4311,a,O
4311,sequential,B
4311,encoder,I
4311,-,I
4311,decoder,I
4311,that,O
4311,is,B
4311,further,B
4311,trained,I
4311,using,B
4311,a,O
4311,pairwise,B
4311,discriminator,I
4311,.,O
4312,The,O
4312,encoder,B
4312,-,I
4312,decoder,I
4312,architecture,I
4312,has,O
4312,been,O
4312,widely,B
4312,used,I
4312,for,I
4312,machine,B
4312,translation,I
4312,and,O
4312,machine,O
4312,comprehension,O
4312,tasks,O
4312,.,O
4313,In,O
4313,general,O
4313,",",O
4313,the,O
4313,model,O
4313,ensures,B
4313,a,O
4313,',O
4313,local,O
4313,',O
4313,loss,O
4313,that,O
4313,is,O
4313,incurred,B
4313,for,I
4313,each,B
4313,recurrent,I
4313,unit,I
4313,cell,I
4313,.,O
4314,To,O
4314,ensure,O
4314,that,B
4314,the,O
4314,whole,B
4314,sentence,I
4314,is,B
4314,correctly,B
4314,encoded,I
4314,",",O
4314,we,O
4314,make,B
4314,further,I
4314,use,I
4314,of,I
4314,a,O
4314,pair,B
4314,-,I
4314,wise,I
4314,discriminator,I
4314,that,O
4314,encodes,O
4314,the,O
4314,whole,O
4314,sentence,O
4314,and,O
4314,obtains,B
4314,an,O
4314,embedding,B
4314,for,O
4314,it,O
4314,.,O
4315,We,O
4315,further,B
4315,ensure,I
4315,that,I
4315,this,O
4315,is,O
4315,close,B
4315,to,B
4315,the,I
4315,desired,B
4315,ground,I
4315,-,I
4315,truth,I
4315,embeddings,I
4315,while,O
4315,being,O
4315,far,B
4315,from,B
4315,other,B
4315,(,I
4315,sentences,I
4315,in,I
4315,the,O
4315,corpus,O
4315,),O
4315,embeddings,O
4315,.,O
4316,This,O
4316,model,O
4316,thus,O
4316,provides,B
4316,a,O
4316,',O
4316,global,O
4316,',O
4316,loss,O
4316,that,O
4316,ensures,B
4316,the,O
4316,sentence,O
4316,embedding,O
4316,as,O
4316,a,O
4316,whole,O
4316,is,O
4316,close,B
4316,to,I
4316,other,B
4316,semantically,I
4316,related,I
4316,sentence,O
4316,embeddings,O
4316,.,O
4317,In,O
4317,this,O
4317,paper,O
4317,",",O
4317,we,O
4317,propose,O
4317,a,O
4317,method,O
4317,for,O
4317,obtaining,B
4317,sentence,I
4317,-,I
4317,level,I
4317,embeddings,I
4317,.,O
4318,This,O
4318,suggests,B
4318,that,O
4318,gathering,B
4318,contexts,I
4318,temporally,I
4318,through,B
4318,sequential,B
4318,processing,I
4318,is,B
4318,indeed,O
4318,a,O
4318,superior,B
4318,method,I
4318,over,B
4318,non-temporal,B
4318,memory,I
4318,representations,I
4318,.,O
4319,Residual,O
4319,LSTM,O
4319,is,B
4319,also,O
4319,the,O
4319,current,B
4319,state,I
4319,-,I
4319,of,I
4319,-,O
4319,the,O
4319,-,O
4319,art,O
4319,on,B
4319,the,O
4319,MSCOCO,B
4319,dataset,I
4319,.,O
4320,For,O
4320,the,O
4320,Quora,O
4320,dataset,O
4320,",",O
4320,there,O
4320,were,O
4320,no,O
4320,known,O
4320,baseline,O
4320,results,O
4320,",",O
4320,so,O
4320,we,O
4320,compare,B
4320,our,O
4320,model,O
4320,with,O
4320,(,O
4320,1,O
4320,),O
4320,standard,B
4320,VAE,I
4320,model,O
4320,i.e.,B
4321,",",O
4321,the,O
4321,unsupervised,B
4321,version,I
4321,",",O
4321,and,O
4321,(,O
4321,2,O
4321,),O
4321,a,O
4321,"""",O
4321,supervised,O
4321,"""",O
4321,variant,O
4321,VAE,O
4321,-,O
4321,S,O
4321,of,B
4321,the,O
4321,unsupervised,O
4321,model,O
4321,.,O
4322,The,O
4322,dimension,O
4322,of,B
4322,the,O
4322,embedding,B
4322,vector,I
4322,is,B
4322,set,B
4322,to,I
4322,300,B
4322,",",O
4322,the,O
4322,dimension,O
4322,of,O
4322,both,B
4322,encoder,I
4322,and,I
4322,decoder,I
4322,is,O
4322,600,B
4322,",",O
4322,and,O
4322,the,O
4322,latent,B
4322,space,I
4322,dimension,O
4322,is,O
4322,1100,B
4322,.,O
4323,Batch,O
4323,size,O
4323,is,O
4323,kept,B
4323,at,I
4323,32,B
4323,.,O
4324,Number,O
4324,of,B
4324,units,O
4324,in,B
4324,LSTM,B
4324,are,O
4324,set,B
4324,to,I
4324,be,I
4324,the,O
4324,maximum,B
4324,length,I
4324,of,O
4324,the,O
4324,sequence,B
4324,in,O
4324,the,O
4324,training,B
4324,data,I
4324,.,O
4325,The,O
4325,number,B
4325,of,I
4325,layers,I
4325,in,B
4325,the,O
4325,encoder,B
4325,is,B
4325,1,B
4325,and,O
4325,in,O
4325,decoder,B
4326,2,B
4326,.,O
4327,Models,O
4327,are,O
4327,trained,B
4327,with,B
4327,stochastic,B
4327,gradient,I
4327,descent,I
4327,with,O
4327,learning,B
4327,rate,I
4327,fixed,B
4327,at,I
4327,a,O
4327,value,O
4327,of,B
4327,5,O
4327,10,O
4327,?,O
4328,5,O
4328,with,B
4328,dropout,B
4328,rate,I
4328,of,B
4328,30,B
4328,%,I
4328,.,O
4329,Models,O
4329,are,O
4329,trained,B
4329,for,I
4329,a,O
4329,predefined,B
4329,number,I
4329,of,I
4329,iterations,I
4329,",",O
4329,rather,B
4329,than,I
4329,a,O
4329,fixed,B
4329,number,O
4329,of,O
4329,epochs,O
4329,.,O
4330,In,O
4330,this,O
4330,paper,O
4330,",",O
4330,we,O
4330,present,B
4330,a,O
4330,deep,B
4330,generative,I
4330,framework,I
4330,for,B
4330,automatically,I
4330,generating,I
4330,paraphrases,B
4330,",",O
4330,given,B
4330,a,O
4330,sentence,B
4330,.,O
4331,To,O
4331,address,O
4331,this,O
4331,limitation,O
4331,",",O
4331,we,O
4331,present,O
4331,a,O
4331,mechanism,B
4331,to,O
4331,condition,O
4331,our,B
4331,VAE,I
4331,model,I
4331,on,B
4331,the,O
4331,original,B
4331,sentence,I
4331,for,O
4331,which,O
4331,we,O
4331,wish,O
4331,to,O
4331,generate,O
4331,the,O
4331,paraphrases,B
4331,.,O
4332,CMN,B
4332,self,O
4332,which,O
4332,uses,B
4332,only,I
4332,single,B
4332,history,I
4332,channel,I
4332,also,O
4332,provides,B
4332,lesser,B
4332,performance,I
4332,when,O
4332,compared,B
4332,to,I
4332,CMN,O
4332,.,O
4333,Our,O
4333,framework,B
4333,combines,B
4333,the,O
4333,power,B
4333,of,B
4333,sequenceto,B
4333,-,I
4333,sequence,I
4333,models,I
4333,",",I
4333,specifically,B
4333,the,O
4333,long,B
4333,short,I
4333,-,O
4333,term,O
4333,memory,O
4333,(,O
4333,LSTM,O
4333,),O
4333,",",O
4333,and,O
4333,deep,O
4333,generative,O
4333,models,O
4333,",",O
4333,specifically,O
4333,the,O
4333,variational,B
4333,autoencoder,I
4333,(,O
4333,VAE,O
4333,),O
4333,",",O
4333,to,O
4333,develop,O
4333,a,O
4333,novel,B
4333,",",O
4333,end,O
4333,-,O
4333,to,O
4333,-,O
4333,end,O
4333,deep,O
4333,learning,O
4333,architecture,O
4333,for,B
4333,the,O
4333,task,B
4333,of,O
4333,paraphrase,B
4333,generation,I
4333,.,O
4334,Unlike,O
4334,these,O
4334,methods,O
4334,where,O
4334,number,O
4334,of,B
4334,classes,O
4334,are,O
4334,finite,O
4334,",",O
4334,and,O
4334,do,O
4334,not,O
4334,require,O
4334,any,O
4334,intermediate,B
4334,representation,I
4334,",",O
4334,our,B
4334,method,I
4334,conditions,B
4334,both,B
4334,the,I
4334,sides,I
4334,(,O
4334,i.e.,B
4335,encoder,O
4335,and,O
4335,decoder,O
4335,),O
4335,of,B
4335,VAE,B
4335,on,B
4335,the,O
4335,intermediate,B
4335,representation,I
4335,of,O
4335,the,O
4335,input,B
4335,question,I
4335,obtained,B
4335,through,I
4335,LSTM,B
4335,.,O
4336,In,O
4336,contrast,O
4336,",",O
4336,our,O
4336,deep,B
4336,generative,I
4336,model,I
4336,enjoys,B
4336,a,O
4336,simple,B
4336,",",O
4336,modular,O
4336,architecture,O
4336,",",O
4336,and,O
4336,can,B
4336,generate,I
4336,not,O
4336,just,O
4336,a,O
4336,single,B
4336,but,O
4336,multiple,B
4336,",",O
4336,semantically,O
4336,sensible,O
4336,",",O
4336,paraphrases,O
4336,for,O
4336,any,O
4336,given,O
4336,sentence,O
4336,.,O
4337,This,O
4337,is,O
4337,in,O
4337,contrast,O
4337,to,O
4337,the,O
4337,proposed,B
4337,method,I
4337,where,B
4337,all,B
4337,variations,I
4337,will,O
4337,be,O
4337,of,B
4337,relatively,B
4337,better,I
4337,quality,I
4337,since,O
4337,they,O
4337,are,B
4337,the,O
4337,top,B
4337,beam,I
4337,-,I
4337,search,I
4337,result,I
4337,",",O
4337,generated,B
4337,based,I
4337,on,I
4337,different,B
4337,z,I
4337,sampled,B
4337,from,I
4337,a,O
4337,latent,B
4337,space,I
4337,.,O
4338,A,O
4338,Deep,O
4338,Generative,O
4338,Framework,O
4338,for,O
4338,Paraphrase,B
4338,Generation,I
4339,In,O
4339,this,O
4339,paper,O
4339,",",O
4339,we,O
4339,address,O
4339,the,O
4339,problem,O
4339,of,O
4339,generating,B
4339,paraphrases,I
4339,automatically,I
4339,.,O
4340,Furthermore,O
4340,",",O
4340,the,O
4340,paraphrases,B
4340,generated,B
4340,by,I
4340,our,B
4340,system,I
4340,are,B
4340,well,B
4340,-,I
4340,formed,I
4340,",",O
4340,semantically,B
4340,sensible,I
4340,",",O
4340,and,O
4340,grammatically,B
4340,correct,I
4340,for,O
4340,the,O
4340,most,O
4340,part,O
4340,.,O
4341,When,O
4341,comparing,O
4341,our,O
4341,results,O
4341,with,O
4341,the,O
4341,state,O
4341,-,O
4341,of,B
4341,-,O
4341,the,O
4341,-,O
4341,art,O
4341,baseline,O
4341,",",O
4341,the,O
4341,average,B
4341,metric,I
4341,of,O
4341,the,O
4341,VAE,B
4341,-,O
4341,SVG,O
4341,model,O
4341,is,O
4341,able,B
4341,to,I
4341,give,I
4341,a,O
4341,10,B
4341,%,I
4341,absolute,I
4341,point,I
4341,performance,I
4341,improvement,I
4341,for,B
4341,the,O
4341,TER,B
4341,metric,O
4341,",",O
4341,a,O
4341,significant,O
4341,number,O
4341,with,O
4341,respect,O
4341,to,O
4341,the,O
4341,difference,O
4341,between,O
4341,the,O
4341,best,O
4341,and,O
4341,second,O
4341,best,O
4341,baseline,O
4341,which,O
4341,only,O
4341,stands,O
4341,at,O
4341,2,O
4341,%,O
4341,absolute,O
4341,point,O
4341,.,O
4342,",",O
4342,we,O
4342,report,O
4342,the,O
4342,results,O
4342,for,B
4342,MSCOCO,B
4342,dataset,I
4342,.,O
4343,As,O
4343,we,O
4343,can,O
4343,see,O
4343,",",O
4343,we,O
4343,have,B
4343,a,O
4343,significant,B
4343,improvement,I
4343,w.r.t.,B
4344,the,O
4344,baselines,B
4344,.,O
4345,Overall,O
4345,",",O
4345,predictions,B
4345,on,B
4345,valence,B
4345,and,I
4345,arousal,I
4345,levels,I
4345,also,O
4345,show,B
4345,similar,B
4345,results,I
4345,which,O
4345,reinforce,O
4345,our,O
4345,hypothesis,O
4345,of,O
4345,CMN,O
4345,'s,O
4345,ability,O
4345,to,O
4345,model,O
4345,emotional,O
4345,dynamics,O
4345,.,O
4346,Both,O
4346,variations,O
4346,of,B
4346,our,O
4346,supervised,B
4346,model,I
4346,i.e.,B
4347,",",O
4347,VAE,B
4347,-,I
4347,SVG,I
4347,and,O
4347,VAE,O
4347,-,O
4347,SVG,O
4347,-,O
4347,eq,O
4347,perform,B
4347,better,I
4347,than,B
4347,the,I
4347,state,B
4347,-,O
4347,of,O
4347,-,O
4347,the,O
4347,-,O
4347,art,O
4347,with,B
4347,VAE,O
4347,-,O
4347,SVG,O
4347,performing,B
4347,slightly,B
4347,better,O
4347,than,O
4347,VAE,O
4347,-,O
4347,SVG,O
4347,-,O
4347,eq,O
4347,.,O
4348,For,B
4348,the,I
4348,BLEU,B
4348,and,I
4348,METEOR,I
4348,",",O
4348,our,O
4348,best,B
4348,results,I
4348,are,B
4348,4.7,B
4348,%,I
4348,and,O
4348,4,O
4348,%,O
4348,absolute,O
4348,point,O
4348,improvement,O
4348,over,B
4348,the,O
4348,state,B
4348,-,I
4348,of,I
4348,-,O
4348,the,O
4348,-,O
4348,art,O
4348,.,O
4349,In,O
4349,",",O
4349,we,O
4349,report,O
4349,results,O
4349,for,O
4349,the,O
4349,Quora,B
4349,dataset,I
4349,.,O
4350,As,O
4350,we,O
4350,can,O
4350,see,O
4350,",",O
4350,both,B
4350,variations,I
4350,of,B
4350,our,O
4350,model,B
4350,perform,B
4350,significantly,B
4350,better,I
4350,than,B
4350,unsupervised,B
4350,VAE,B
4350,and,O
4350,VAE,O
4350,-,O
4350,S,O
4350,",",O
4350,which,O
4350,is,O
4350,not,O
4350,surprising,O
4350,.,O
4351,We,O
4351,also,O
4351,report,O
4351,the,O
4351,results,B
4351,on,O
4351,different,O
4351,training,B
4351,sizes,O
4351,",",O
4351,and,O
4351,as,O
4351,expected,O
4351,",",O
4351,as,O
4351,we,O
4351,increase,B
4351,the,O
4351,training,O
4351,data,O
4351,size,O
4351,",",O
4351,results,O
4351,improve,B
4351,.,O
4352,Comparing,B
4352,the,O
4352,results,B
4352,across,B
4352,different,B
4352,variants,I
4352,of,B
4352,supervised,B
4352,model,I
4352,",",O
4352,VAE,B
4352,-,I
4352,SVG,I
4352,-,O
4352,eq,O
4352,performs,B
4352,the,O
4352,best,B
4352,.,O
4353,We,O
4353,also,O
4353,experimented,B
4353,with,I
4353,generating,B
4353,paraphrases,I
4353,through,B
4353,beam,B
4353,-,I
4353,search,I
4353,",",O
4353,and,O
4353,",",O
4353,unlike,O
4353,MSCOCO,O
4353,",",O
4353,it,O
4353,turns,B
4353,out,I
4353,that,I
4353,beam,O
4353,search,O
4353,improves,B
4353,the,O
4353,results,B
4353,significantly,B
4353,.,O
4354,When,O
4354,comparing,B
4354,the,O
4354,best,B
4354,variant,I
4354,of,I
4354,our,I
4354,model,I
4354,with,B
4354,unsupervised,B
4354,model,O
4354,(,O
4354,VAE,B
4354,),I
4354,",",O
4354,we,O
4354,are,O
4354,able,B
4354,to,I
4354,get,I
4354,more,B
4354,than,I
4354,27,I
4354,%,I
4354,absolute,I
4354,point,I
4354,(,O
4354,more,O
4354,than,O
4354,3,O
4354,times,O
4354,),O
4354,boost,B
4354,in,B
4354,BLEU,B
4354,score,I
4354,",",O
4354,and,O
4354,more,O
4354,than,O
4354,19,O
4354,%,O
4354,absolute,O
4354,point,O
4354,(,O
4354,more,O
4354,than,O
4354,2,O
4354,times,O
4354,),O
4354,boost,O
4354,in,O
4354,METEOR,B
4354,;,O
4354,and,O
4354,when,O
4354,comparing,O
4354,with,O
4354,VAE,O
4354,-,O
4354,S,O
4354,",",O
4354,we,O
4354,are,O
4354,able,O
4354,to,O
4354,get,O
4354,a,O
4354,boost,O
4354,of,O
4354,almost,O
4354,19,O
4354,%,O
4354,absolute,O
4354,points,O
4354,in,O
4354,BLEU,O
4354,(,O
4354,2,O
4354,times,O
4354,),O
4354,and,O
4354,more,O
4354,than,O
4354,10,O
4354,%,O
4354,absolute,O
4354,points,O
4354,in,O
4354,METEOR,O
4354,(,O
4354,1.5,O
4354,times,O
4354,),O
4354,.,O
4355,c,O
4355,-,O
4355,LSTM,O
4355,:,O
4355,Biredectional,B
4355,LSTM,O
4355,is,B
4355,used,B
4355,to,B
4355,capture,I
4355,the,O
4355,context,B
4355,from,B
4355,the,O
4355,surrounding,B
4355,utterances,I
4355,to,O
4355,generate,O
4355,contextaware,B
4355,utterance,I
4355,representation,I
4355,.,O
4356,In,O
4356,this,O
4356,variant,B
4356,attention,I
4356,is,O
4356,applied,B
4356,applied,O
4356,to,O
4356,the,O
4356,c,B
4356,-,I
4356,LSTM,I
4356,output,I
4356,at,B
4356,each,B
4356,timestamp,I
4356,by,O
4356,following,O
4356,Eqs.,O
4357,TFN,B
4357,:,O
4358,We,O
4358,apply,B
4358,a,O
4358,cross-validation,B
4358,procedure,I
4358,on,B
4358,the,O
4358,training,B
4358,data,I
4358,to,B
4358,select,I
4358,suitable,B
4358,hyperparameters,I
4358,.,O
4359,This,O
4359,is,O
4359,specific,B
4359,to,I
4359,multimodal,B
4359,scenario,I
4359,.,O
4360,Tensor,O
4360,outer,O
4360,product,O
4360,is,O
4360,used,B
4360,to,I
4360,capture,I
4360,intermodality,B
4360,and,I
4360,intra-modality,I
4360,interactions,I
4360,.,O
4361,MFN,B
4361,),O
4361,:,O
4361,Specific,O
4361,to,O
4361,multimodal,B
4361,scenario,I
4361,",",O
4361,this,O
4361,model,O
4361,utilizes,B
4361,multi-view,B
4361,learning,I
4361,by,B
4361,modeling,I
4361,view,I
4361,-,I
4361,specific,O
4361,and,O
4361,cross,O
4361,-,O
4361,view,O
4361,interactions,O
4361,.,O
4362,CNN,B
4362,:,O
4362,This,O
4362,is,O
4362,identical,B
4362,to,I
4362,our,B
4362,textual,I
4362,feature,I
4362,extractor,I
4362,network,I
4362,(,O
4362,Section,O
4362,3.2,O
4362,),O
4362,and,O
4362,it,O
4362,does,B
4362,not,I
4362,use,I
4362,contextual,B
4362,information,I
4362,from,O
4362,the,O
4362,surrounding,O
4362,utterances,O
4362,.,O
4363,Memnet,B
4363,:,O
4363,As,O
4363,described,O
4363,in,O
4363,",",O
4363,the,O
4363,current,B
4363,utterance,I
4363,is,O
4363,fed,B
4363,to,I
4363,a,O
4363,memory,B
4363,network,I
4363,",",O
4363,where,B
4363,the,O
4363,memories,B
4363,correspond,B
4363,to,O
4363,preceding,B
4363,utterances,I
4363,.,O
4364,The,O
4364,output,B
4364,from,B
4364,the,O
4364,memory,B
4364,network,I
4364,is,O
4364,used,B
4364,as,I
4364,the,O
4364,final,B
4364,utterance,I
4364,representation,I
4364,for,B
4364,emotion,B
4364,classification,I
4364,.,O
4365,CMN,B
4365,:,O
4365,This,O
4365,state,B
4365,-,I
4365,of,I
4365,-,O
4365,the,O
4365,-,O
4365,art,O
4365,method,O
4365,models,B
4365,utterance,B
4365,context,I
4365,from,B
4365,dialogue,B
4365,history,I
4365,using,B
4365,two,B
4365,distinct,I
4365,GRUs,I
4365,for,B
4365,two,O
4365,speakers,O
4365,.,O
4366,Our,O
4366,proposed,O
4366,DialogueRNN,B
4366,system,I
4366,employs,B
4366,three,B
4366,gated,I
4366,recurrent,I
4366,units,I
4366,(,I
4366,GRU,I
4366,),I
4366,to,O
4366,model,O
4366,these,O
4366,aspects,O
4366,.,O
4367,The,O
4367,incoming,B
4367,utterance,I
4367,is,O
4367,fed,B
4367,into,I
4367,two,B
4367,GRUs,I
4367,called,B
4367,global,B
4367,GRU,I
4367,and,I
4367,party,I
4367,GRU,O
4367,to,O
4367,update,O
4367,the,O
4367,context,O
4367,and,O
4367,party,O
4367,Copyright,O
4367,2019,O
4367,",",O
4367,Association,O
4367,for,O
4367,the,O
4367,Advancement,O
4367,of,O
4367,Artificial,O
4367,Intelligence,O
4367,(,O
4367,www.aaai.org,O
4367,),O
4367,.,O
4368,The,O
4368,global,B
4368,GRU,I
4368,encodes,B
4368,corresponding,B
4368,party,I
4368,information,I
4368,while,B
4368,encoding,I
4368,an,O
4368,utterance,B
4368,.,O
4369,We,O
4369,propose,B
4369,a,O
4369,novel,B
4369,CNN,I
4369,architecture,I
4369,that,O
4369,addresses,O
4369,some,O
4369,of,O
4369,the,O
4369,shortcomings,O
4369,of,O
4369,previous,O
4369,approaches,O
4369,.,O
4370,Attending,O
4370,over,O
4370,this,O
4370,GRU,O
4370,gives,B
4370,contextual,I
4370,representation,I
4370,that,O
4370,has,B
4370,information,I
4370,of,I
4370,all,B
4370,preceding,I
4370,utterances,I
4370,by,B
4370,different,B
4370,parties,I
4370,in,B
4370,the,O
4370,conversation,B
4370,.,O
4371,The,O
4371,speaker,O
4371,state,O
4371,depends,B
4371,on,I
4371,this,O
4371,context,B
4371,through,B
4371,attention,B
4371,and,I
4371,the,O
4371,speaker,O
4371,'s,O
4371,previous,O
4371,state,O
4371,.,O
4372,Finally,O
4372,",",O
4372,the,O
4372,updated,B
4372,speaker,I
4372,state,I
4372,is,O
4372,fed,B
4372,into,I
4372,the,O
4372,emotion,B
4372,GRU,I
4372,to,B
4372,decode,I
4372,the,O
4372,emotion,O
4372,representation,O
4372,of,B
4372,the,O
4372,given,B
4372,utterance,I
4372,",",O
4372,which,O
4372,is,O
4372,used,B
4372,for,I
4372,emotion,O
4372,classification,O
4372,.,O
4373,This,O
4373,ensures,O
4373,that,O
4373,at,B
4373,time,I
4373,t,I
4373,",",O
4373,the,O
4373,speaker,B
4373,state,I
4373,directly,B
4373,gets,I
4373,information,I
4373,from,I
4373,the,O
4373,speaker,O
4373,'s,O
4373,previous,O
4373,state,O
4373,and,O
4373,global,B
4373,GRU,I
4373,which,B
4373,has,I
4373,information,O
4373,on,O
4373,the,O
4373,preceding,B
4373,parties,I
4373,.,O
4374,At,O
4374,time,O
4374,t,O
4374,",",O
4374,the,O
4374,emotion,B
4374,GRU,I
4374,cell,I
4374,gets,B
4374,the,O
4374,emotion,O
4374,representation,O
4374,of,O
4374,t,O
4374,?,O
4375,DialogueRNN,O
4375,:,O
4375,An,O
4375,Attentive,O
4375,RNN,O
4375,for,O
4375,Emotion,B
4375,Detection,I
4375,in,I
4375,Conversations,I
4376,As,O
4376,expected,O
4376,",",O
4376,on,B
4376,average,I
4376,Di,B
4376,-,I
4376,alogue,I
4376,RNN,I
4376,outperforms,B
4376,all,B
4376,the,I
4376,baseline,I
4376,methods,I
4376,",",O
4376,including,B
4376,the,O
4376,state,B
4376,-,O
4376,of,O
4376,-,O
4376,the,O
4376,-,O
4376,art,O
4376,CMN,O
4376,",",O
4376,on,O
4376,both,O
4376,of,O
4376,the,O
4376,datasets,O
4376,.,O
4377,As,O
4377,evidenced,O
4377,by,B
4377,",",O
4377,for,B
4377,IEMOCAP,B
4377,dataset,I
4377,",",O
4377,our,B
4377,model,I
4377,surpasses,B
4377,the,I
4377,state,B
4377,-,I
4377,of,I
4377,-,O
4377,the,O
4377,-,O
4377,art,O
4377,method,O
4377,CMN,O
4377,by,O
4377,2.77,B
4377,%,I
4377,accuracy,I
4377,and,O
4377,3.76,B
4377,%,O
4377,f,O
4377,1,O
4377,-,O
4377,score,O
4377,on,O
4377,average,O
4377,.,O
4378,AVEC,B
4378,DialogueRNN,B
4378,outperforms,B
4378,CMN,B
4378,for,B
4378,valence,B
4378,",",I
4378,arousal,I
4378,",",O
4378,expectancy,O
4378,",",O
4378,and,O
4378,power,O
4378,attributes,O
4378,;,O
4378,see,O
4378,.,O
4379,Our,O
4379,CNN,B
4379,architecture,I
4379,relies,B
4379,on,I
4379,a,O
4379,novel,B
4379,multi-level,I
4379,attention,I
4379,mechanism,I
4379,to,I
4379,capture,I
4379,both,O
4379,entity,B
4379,-,I
4379,specific,I
4379,attention,O
4379,(,O
4379,primary,B
4379,attention,O
4379,at,B
4379,the,O
4379,input,B
4379,level,I
4379,",",O
4379,with,B
4379,respect,I
4379,to,O
4379,the,O
4379,target,B
4379,entities,I
4379,),O
4379,and,O
4379,relation,B
4379,-,O
4379,specific,O
4379,pooling,O
4379,attention,O
4379,(,O
4379,secondary,B
4379,attention,O
4379,with,O
4379,respect,O
4379,to,O
4379,the,O
4379,target,O
4379,relations,O
4379,),O
4379,.,O
4380,Following,O
4380,",",O
4380,using,B
4380,explicit,B
4380,listener,I
4380,state,I
4380,update,I
4380,yields,B
4380,slightly,B
4380,worse,I
4380,performance,I
4380,than,B
4380,regular,B
4380,DialogueRNN,I
4380,.,O
4381,BiDialogueRNN,B
4381,:,O
4381,Since,O
4381,BiDialogueRNN,O
4381,captures,O
4381,context,O
4381,from,O
4381,the,O
4381,future,O
4381,utterances,O
4381,",",O
4381,we,O
4381,expect,O
4381,improved,O
4381,performance,O
4381,from,O
4381,it,O
4381,over,O
4381,DialogueRNN,O
4381,.,O
4382,This,O
4382,is,O
4382,confirmed,O
4382,in,O
4382,",",O
4382,where,O
4382,BiDialogueRNN,O
4382,outperforms,B
4382,Dialogue,B
4382,RNN,I
4382,on,B
4382,average,O
4382,on,O
4382,both,B
4382,datasets,I
4382,.,O
4383,TC,O
4383,-,O
4383,LSTM,O
4383,:,O
4383,Two,B
4383,LSTMs,I
4383,are,O
4383,used,B
4383,to,I
4383,model,B
4383,the,O
4383,left,B
4383,and,I
4383,right,I
4383,context,I
4383,of,B
4383,the,O
4383,target,B
4383,separately,O
4383,",",O
4383,then,O
4383,the,O
4383,concatenation,B
4383,of,O
4383,two,O
4383,representations,O
4383,is,O
4383,used,O
4383,to,O
4383,predict,B
4383,the,O
4383,label,B
4383,.,O
4384,MemNet,B
4384,:,O
4384,It,O
4384,uses,B
4384,the,O
4384,attention,B
4384,mechanism,I
4384,over,B
4384,the,O
4384,word,B
4384,embedding,I
4384,over,O
4384,multiple,B
4384,rounds,I
4384,to,B
4384,aggregate,I
4384,the,O
4384,information,B
4384,in,B
4384,the,O
4384,sentence,B
4384,",",O
4384,the,O
4384,vector,O
4384,of,O
4384,the,O
4384,final,O
4384,round,O
4384,is,O
4384,used,O
4384,for,O
4384,the,O
4384,prediction,O
4384,.,O
4385,IAN,B
4385,:,O
4385,IAN,O
4385,adopts,B
4385,two,B
4385,LSTMs,I
4385,to,I
4385,derive,I
4385,the,I
4385,representations,B
4385,of,B
4385,the,O
4385,context,B
4385,and,I
4385,the,O
4385,target,O
4385,phrase,O
4385,interactively,O
4385,and,O
4385,the,O
4385,concatenation,B
4385,is,O
4385,fed,B
4385,to,O
4385,the,O
4385,softmax,B
4385,layer,I
4385,.,O
4386,BILSTM,O
4386,-,O
4386,ATT,O
4386,-G,O
4386,:,O
4386,It,O
4386,models,B
4386,left,B
4386,and,I
4386,right,I
4386,contexts,I
4386,using,B
4386,two,B
4386,attention,I
4386,-,O
4386,based,O
4386,LSTMs,O
4386,and,O
4386,makes,B
4386,use,I
4386,of,I
4386,a,O
4386,special,B
4386,gate,I
4386,layer,I
4386,to,B
4386,combine,I
4386,these,O
4386,two,O
4386,representations,O
4386,.,O
4387,TNet,O
4387,-,O
4387,AS,O
4387,:,O
4387,Without,B
4387,using,I
4387,an,O
4387,attention,B
4387,module,I
4387,",",O
4387,TNet,O
4387,adopts,O
4387,a,O
4387,convolutional,O
4387,layer,O
4387,to,O
4387,get,O
4387,salient,O
4387,features,O
4387,from,O
4387,the,O
4387,transformed,O
4387,word,O
4387,representations,O
4387,originated,O
4387,from,O
4387,a,O
4387,bidirectional,O
4387,LSTM,O
4387,layer,O
4387,.,O
4388,The,O
4388,number,B
4388,of,I
4388,units,I
4388,in,B
4388,the,O
4388,encoder,B
4388,and,I
4388,the,O
4388,decoder,O
4388,is,B
4388,100,B
4388,and,O
4388,the,O
4388,latent,B
4388,variable,I
4388,is,O
4388,of,O
4388,size,B
4388,50,I
4388,and,O
4388,the,O
4388,number,O
4388,of,O
4388,layers,O
4388,of,O
4388,both,O
4388,Transformer,B
4388,blocks,I
4388,is,O
4388,2,B
4388,",",O
4388,the,O
4388,number,O
4388,of,O
4388,selfattention,O
4388,heads,O
4388,is,O
4388,8,B
4388,.,O
4389,We,O
4389,introduce,B
4389,a,O
4389,novel,B
4389,pair,I
4389,-,I
4389,wise,I
4389,margin,I
4389,-,O
4389,based,O
4389,objective,O
4389,function,O
4389,that,O
4389,proves,B
4389,superior,B
4389,to,B
4389,standard,B
4389,loss,I
4389,functions,I
4389,.,O
4390,In,O
4390,this,O
4390,work,O
4390,",",O
4390,the,O
4390,KL,B
4390,weight,I
4390,is,O
4390,set,B
4390,to,I
4390,be,I
4390,1e,B
4390,-,I
4390,4,I
4390,.,O
4391,In,O
4391,this,O
4391,paper,O
4391,",",O
4391,we,O
4391,proposed,B
4391,a,O
4391,classifier,B
4391,-,I
4391,agnostic,I
4391,framework,I
4391,which,O
4391,named,B
4391,Aspect,B
4391,-,O
4391,term,O
4391,Semi-supervised,O
4391,Variational,O
4391,Autoencoder,O
4391,(,O
4391,Kingma,O
4391,and,O
4391,Welling,O
4391,",",O
4391,2014,O
4391,),O
4391,based,O
4391,on,O
4391,Transformer,O
4391,(,O
4391,ASVAET,O
4391,),O
4391,.,O
4392,The,O
4392,variational,B
4392,autoencoder,I
4392,offers,B
4392,the,O
4392,flexibility,B
4392,to,B
4392,customize,I
4392,the,O
4392,model,B
4392,structure,I
4392,.,O
4393,Specifically,O
4393,",",O
4393,the,O
4393,representation,B
4393,of,B
4393,the,O
4393,lexical,B
4393,context,I
4393,is,O
4393,extracted,B
4393,by,I
4393,the,O
4393,encoder,B
4393,and,O
4393,the,O
4393,aspect,B
4393,-,I
4393,term,I
4393,sentiment,I
4393,polarity,I
4393,is,O
4393,inferred,B
4393,from,I
4393,the,O
4393,specific,B
4393,ATSA,I
4393,classifier,I
4393,.,O
4394,By,O
4394,regarding,O
4394,the,O
4394,aspect,B
4394,sentiment,B
4394,polarity,I
4394,of,B
4394,the,O
4394,unlabeled,B
4394,data,I
4394,as,B
4394,the,O
4394,discrete,B
4394,latent,I
4394,variable,I
4394,",",O
4394,the,O
4394,model,B
4394,implicitly,B
4394,induces,I
4394,the,O
4394,sentiment,O
4394,polarity,O
4394,via,B
4394,the,O
4394,variational,B
4394,inference,I
4394,.,O
4395,In,B
4395,addition,O
4395,",",O
4395,by,B
4395,separating,I
4395,the,O
4395,representation,B
4395,of,B
4395,the,O
4395,input,B
4395,sentence,I
4395,",",O
4395,the,O
4395,classifier,B
4395,becomes,B
4395,an,O
4395,independent,B
4395,module,I
4395,in,O
4395,our,B
4395,framework,I
4395,",",O
4395,which,O
4395,endows,O
4395,the,O
4395,method,O
4395,with,O
4395,the,O
4395,ability,O
4395,to,O
4395,integrate,O
4395,different,O
4395,classifiers,O
4395,.,O
4396,Variational,O
4396,Semi-supervised,O
4396,Aspect,B
4396,-,I
4396,term,I
4396,Sentiment,I
4396,Analysis,I
4396,via,O
4396,Transformer,O
4397,ACSA,B
4397,is,O
4397,to,O
4397,infer,O
4397,the,O
4397,sentiment,O
4397,polarity,O
4397,with,O
4397,regard,O
4397,to,O
4397,the,O
4397,predefined,O
4397,categories,O
4397,",",O
4397,e.g.,O
4398,On,O
4398,the,O
4398,other,O
4398,hand,O
4398,",",O
4398,ATSA,B
4398,aims,O
4398,at,O
4398,classifying,O
4398,the,O
4398,sentiment,O
4398,polarity,O
4398,of,O
4398,a,O
4398,given,O
4398,aspect,O
4398,word,O
4398,or,O
4398,phrase,O
4398,in,O
4398,the,O
4398,text,O
4398,.,O
4399,From,O
4399,the,O
4399,",",O
4399,the,O
4399,ASVAET,B
4399,is,O
4399,able,B
4399,to,I
4399,improve,I
4399,supervised,B
4399,performance,I
4399,consistently,O
4399,for,B
4399,all,B
4399,classifiers,I
4399,.,O
4400,The,O
4400,ASVAET,O
4400,outperforms,B
4400,the,O
4400,compared,B
4400,semisupervised,I
4400,methods,I
4400,evidently,O
4400,.,O
4401,The,O
4401,TNet,B
4401,-,I
4401,AS,I
4401,outperforms,B
4401,the,O
4401,other,B
4401,three,I
4401,models,I
4401,.,O
4402,For,B
4402,the,O
4402,MemNet,B
4402,",",O
4402,the,O
4402,test,B
4402,accuracy,I
4402,can,O
4402,be,O
4402,improved,B
4402,by,B
4402,about,B
4402,2,I
4402,%,I
4402,by,O
4402,the,O
4402,TSSVAE,B
4402,",",O
4402,and,O
4402,so,O
4402,as,O
4402,the,O
4402,Macro,O
4402,-,O
4402,averaged,O
4402,F1,O
4402,.,O
4403,Compared,O
4403,with,O
4403,the,O
4403,other,B
4403,two,I
4403,semi-supervised,I
4403,methods,I
4403,",",O
4403,the,O
4403,ASVAET,B
4403,also,O
4403,shows,B
4403,better,B
4403,results,I
4403,.,O
4404,The,O
4404,adoption,B
4404,of,I
4404,indomain,B
4404,pre-trained,I
4404,word,I
4404,vectors,I
4404,is,O
4404,beneficial,B
4404,for,I
4404,the,O
4404,performance,B
4404,compared,B
4404,with,I
4404,the,O
4404,Glove,B
4404,vectors,O
4404,.,O
4405,ATAE,O
4405,-,O
4405,LSTM,O
4405,is,B
4405,a,O
4405,classical,B
4405,LSTM,O
4405,-,O
4405,based,O
4405,network,O
4405,for,B
4405,the,O
4405,APC,B
4405,task,I
4405,",",O
4405,which,O
4405,applies,B
4405,the,O
4405,attention,B
4405,mechanism,I
4405,to,B
4405,focus,I
4405,on,I
4405,the,O
4405,important,B
4405,words,I
4405,in,B
4405,the,O
4405,context,B
4405,.,O
4406,is,B
4406,a,O
4406,baseline,B
4406,model,I
4406,of,B
4406,the,O
4406,ATSM,B
4406,variations,I
4406,for,B
4406,Chinese,B
4406,language,I
4406,-,I
4406,oriented,I
4406,ABSA,I
4406,task,I
4406,.,O
4407,GANN,B
4407,is,B
4407,novel,B
4407,neural,I
4407,network,I
4407,model,I
4407,for,B
4407,APC,B
4407,task,I
4407,aimed,B
4407,to,I
4407,solve,I
4407,the,O
4407,shortcomings,B
4407,of,I
4407,traditional,I
4407,RNNs,I
4407,and,I
4407,CNNs,I
4407,.,O
4408,We,O
4408,observe,B
4408,that,I
4408,our,O
4408,novel,B
4408,attentionbased,I
4408,architecture,I
4408,achieves,B
4408,new,B
4408,state,I
4408,-,I
4408,of,I
4408,-,O
4408,the,O
4408,-,O
4408,art,O
4408,results,O
4408,on,O
4408,this,O
4408,relation,O
4408,classification,O
4408,dataset,O
4408,.,O
4409,AEN,B
4409,-,O
4409,is,B
4409,an,O
4409,attentional,B
4409,encoder,I
4409,network,I
4409,based,B
4409,on,I
4409,the,O
4409,pretrained,B
4409,BERT,I
4409,model,I
4409,",",O
4409,which,O
4409,aims,B
4409,to,I
4409,solve,I
4409,the,O
4409,aspect,B
4409,polarity,I
4409,classification,I
4409,.,O
4410,BERT,B
4410,-,O
4410,is,B
4410,a,O
4410,BERT,O
4410,-,O
4410,adapted,O
4410,model,O
4410,for,B
4410,Review,B
4410,Reading,I
4410,Comprehension,I
4410,(,I
4410,RRC,I
4410,),I
4410,task,I
4410,",",O
4410,a,O
4410,task,O
4410,inspired,O
4410,by,O
4410,machine,O
4410,reading,O
4410,comprehension,O
4410,(,O
4410,MRC,O
4410,),O
4410,",",O
4410,it,O
4410,could,O
4410,be,O
4410,adapted,O
4410,to,O
4410,aspect,O
4410,-,O
4410,level,O
4410,sentiment,O
4410,classification,O
4410,task,O
4410,.,O
4411,BERT,O
4411,-,O
4411,BASE,O
4411,is,B
4411,the,O
4411,basic,B
4411,pretrained,I
4411,BERT,O
4411,model,O
4411,.,O
4412,We,O
4412,adapt,B
4412,it,I
4412,to,B
4412,ABSA,B
4412,multi-task,I
4412,learning,I
4412,",",O
4412,which,O
4412,equips,B
4412,the,O
4412,same,B
4412,ability,I
4412,to,O
4412,automatically,O
4412,extract,O
4412,aspect,B
4412,terms,I
4412,and,O
4412,classify,B
4412,aspects,B
4412,polarity,I
4412,as,B
4412,LCF,B
4412,-,I
4412,ATEPC,I
4412,model,I
4412,.,O
4413,is,B
4413,a,O
4413,domain,B
4413,-,I
4413,adapted,I
4413,BERT,B
4413,-,O
4413,based,O
4413,model,O
4413,proposed,B
4413,for,I
4413,the,O
4413,APC,B
4413,task,B
4413,",",O
4413,which,O
4413,finetuned,B
4413,the,O
4413,BERT,O
4413,-,O
4413,BASE,O
4413,model,O
4413,on,B
4413,task,O
4413,-,O
4413,related,O
4413,corpus,O
4413,.,O
4414,LCF,O
4414,-,O
4414,ATEPC,O
4414,5,O
4414,is,B
4414,the,O
4414,multi,B
4414,-task,I
4414,learning,I
4414,model,I
4414,for,B
4414,the,O
4414,ATE,B
4414,and,I
4414,APC,I
4414,tasks,I
4414,",",O
4414,which,O
4414,is,O
4414,based,O
4414,on,O
4414,the,O
4414,the,O
4414,BERT,O
4414,-,O
4414,SPC,O
4414,model,O
4414,and,O
4414,local,O
4414,context,O
4414,focus,O
4414,mechanism,O
4414,.,O
4415,LCF,O
4415,-,O
4415,ATE,B
4415,are,B
4415,the,I
4415,variations,B
4415,of,I
4415,the,O
4415,LCF,O
4415,-,O
4415,ATEPC,O
4415,model,O
4415,which,O
4415,only,O
4415,optimize,B
4415,for,I
4415,the,O
4415,ATE,O
4415,task,O
4415,.,O
4416,LCF,O
4416,-,O
4416,APC,B
4416,are,B
4416,the,O
4416,variations,B
4416,of,I
4416,LCF,O
4416,-,O
4416,ATEPC,O
4416,and,O
4416,it,O
4416,only,O
4416,optimize,B
4416,for,I
4416,the,O
4416,APC,O
4416,task,O
4416,during,B
4416,training,B
4416,process,I
4416,.,O
4417,The,O
4417,codes,O
4417,for,O
4417,this,O
4417,paper,O
4417,are,O
4417,available,O
4417,at,O
4417,https://github.com/yangheng95/LCF-ATEPC,B
4418,Att,O
4418,-,O
4418,Input,B
4418,-,O
4418,CNN,O
4418,relies,B
4418,only,I
4418,on,I
4418,the,O
4418,primal,B
4418,attention,I
4418,at,B
4418,the,O
4418,input,O
4418,level,O
4418,",",O
4418,performing,B
4418,standard,B
4418,max,I
4418,-,O
4418,pooling,O
4418,after,B
4418,the,O
4418,convolution,B
4418,layer,I
4418,to,B
4418,generate,I
4418,the,O
4418,network,B
4418,output,I
4418,w,I
4418,O,I
4418,",",O
4418,in,O
4418,which,O
4418,the,O
4418,new,O
4418,objective,O
4418,function,O
4418,is,O
4418,utilized,O
4418,.,O
4419,Aiming,O
4419,to,O
4419,automatically,O
4419,extract,O
4419,aspects,O
4419,from,O
4419,the,O
4419,text,O
4419,efficiently,O
4419,and,O
4419,analyze,O
4419,the,O
4419,sentiment,O
4419,polarity,O
4419,of,O
4419,aspects,O
4419,simultaneously,O
4419,",",O
4419,this,O
4419,paper,O
4419,proposes,B
4419,a,O
4419,multi-task,B
4419,learning,I
4419,model,I
4419,for,B
4419,aspect,B
4419,-,I
4419,based,I
4419,sentiment,O
4419,analysis,O
4419,.,O
4420,The,O
4420,LCF,B
4420,-,I
4420,ATEPC,I
4420,3,I
4420,model,I
4420,proposed,O
4420,in,O
4420,this,O
4420,paper,O
4420,is,B
4420,a,O
4420,novel,B
4420,multilingual,I
4420,and,I
4420,multi-task,I
4420,-,O
4420,oriented,O
4420,model,O
4420,.,O
4421,The,O
4421,proposed,O
4421,model,O
4421,is,O
4421,based,B
4421,on,I
4421,multi-head,B
4421,self,I
4421,-,I
4421,attention,I
4421,(,I
4421,MHSA,I
4421,),I
4421,and,I
4421,integrates,B
4421,the,O
4421,pre-trained,B
4421,and,O
4421,the,O
4421,local,O
4421,context,O
4421,focus,O
4421,mechanism,O
4421,",",O
4421,namely,B
4421,LCF,B
4421,-,O
4421,ATEPC,O
4421,.,O
4422,By,O
4422,training,B
4422,on,I
4422,a,O
4422,small,B
4422,amount,I
4422,of,I
4422,annotated,I
4422,data,I
4422,of,O
4422,aspect,O
4422,and,O
4422,their,O
4422,polarity,O
4422,",",O
4422,the,O
4422,model,O
4422,can,O
4422,be,O
4422,adapted,B
4422,to,I
4422,a,O
4422,large,B
4422,-,I
4422,scale,I
4422,dataset,I
4422,",",O
4422,automatically,B
4422,extracting,I
4422,the,O
4422,aspects,B
4422,and,O
4422,predicting,B
4422,the,O
4422,sentiment,B
4422,polarities,I
4422,.,O
4423,Most,O
4423,of,O
4423,the,O
4423,existing,O
4423,work,O
4423,focuses,O
4423,on,O
4423,the,O
4423,subtask,O
4423,of,O
4423,aspect,B
4423,term,I
4423,polarity,I
4423,inferring,I
4423,and,O
4423,ignores,O
4423,the,O
4423,significance,O
4423,of,O
4423,aspect,O
4423,term,O
4423,extraction,O
4423,.,O
4424,By,O
4424,integrating,O
4424,the,O
4424,domain,O
4424,-,O
4424,adapted,O
4424,BERT,O
4424,model,O
4424,",",O
4424,the,O
4424,LCF,O
4424,-,O
4424,ATEPC,O
4424,model,O
4424,achieved,O
4424,the,O
4424,state,O
4424,-,O
4424,of,O
4424,the,O
4424,-,O
4424,art,O
4424,performance,O
4424,of,O
4424,aspect,B
4424,term,O
4424,extraction,O
4424,and,O
4424,aspect,O
4424,polarity,O
4424,classification,O
4424,in,O
4424,four,O
4424,Chinese,O
4424,review,O
4424,datasets,O
4424,.,O
4425,The,O
4425,APC,B
4425,task,O
4425,is,O
4425,a,O
4425,kind,O
4425,of,O
4425,classification,O
4425,problem,O
4425,.,O
4426,Our,O
4426,full,O
4426,dual,O
4426,attention,O
4426,model,O
4426,Att,O
4426,-,O
4426,Pooling,O
4426,-,O
4426,CNN,O
4426,achieves,B
4426,an,O
4426,even,B
4426,more,I
4426,favorable,I
4426,F1-,I
4426,score,I
4426,of,B
4426,88,B
4426,%,I
4426,.,O
4427,The,O
4427,researches,O
4427,concerning,O
4427,APC,O
4427,tasks,O
4427,is,O
4427,more,O
4427,abundant,O
4427,than,O
4427,the,O
4427,ATE,B
4427,task,O
4427,",",O
4427,and,O
4427,a,O
4427,large,O
4427,number,O
4427,of,O
4427,deep,O
4427,learning,O
4427,-,O
4427,based,O
4427,models,O
4427,have,O
4427,been,O
4427,proposed,O
4427,to,O
4427,solve,O
4427,APC,O
4427,problems,O
4427,",",O
4427,such,O
4427,as,O
4427,the,O
4427,models,O
4427,;,O
4427,;,O
4427,;,O
4427,based,O
4427,on,O
4427,long,O
4427,short,O
4427,-,O
4427,term,O
4427,memory,O
4427,(,O
4427,LSTM,O
4427,),O
4427,and,O
4427,the,O
4427,methodologies,O
4427,based,O
4427,on,O
4427,transformer,O
4427,.,O
4428,The,O
4428,CDM,B
4428,layer,I
4428,works,B
4428,better,I
4428,on,I
4428,twitter,B
4428,dataset,I
4428,because,O
4428,there,O
4428,are,O
4428,a,O
4428,lot,O
4428,of,O
4428,non-standard,O
4428,grammar,O
4428,usage,O
4428,and,O
4428,language,O
4428,abbreviations,O
4428,within,O
4428,it,O
4428,",",O
4428,and,O
4428,the,O
4428,local,O
4428,context,O
4428,focus,O
4428,techniques,O
4428,can,O
4428,promote,O
4428,to,O
4428,infer,O
4428,the,O
4428,polarity,O
4428,of,O
4428,terms,O
4428,.,O
4429,After,O
4429,optimizing,O
4429,the,O
4429,model,O
4429,parameters,O
4429,according,O
4429,to,O
4429,the,O
4429,empirical,O
4429,result,O
4429,",",O
4429,the,O
4429,joint,B
4429,model,O
4429,based,O
4429,on,B
4429,BERT,I
4429,-,I
4429,BASE,I
4429,achieved,B
4429,hopeful,B
4429,performance,I
4429,on,O
4429,all,B
4429,three,I
4429,datasets,I
4429,and,O
4429,even,B
4429,surpassed,I
4429,other,B
4429,proposed,I
4429,BERT,O
4429,based,O
4429,improved,O
4429,models,O
4429,on,O
4429,some,B
4429,datasets,O
4429,",",O
4429,such,O
4429,as,O
4429,BERT,O
4429,-,O
4429,PT,O
4429,",",O
4429,AEN,O
4429,-,O
4429,BERT,O
4429,",",O
4429,SDGCN,O
4429,-,O
4429,BERT,O
4429,",",O
4429,and,O
4429,soon,O
4429,.,O
4430,ATEPC,O
4430,-,O
4430,Fusion,O
4430,is,B
4430,a,O
4430,supplementary,B
4430,scheme,I
4430,of,B
4430,LCF,B
4430,mechanism,I
4430,",",O
4430,and,O
4430,it,O
4430,adopts,B
4430,a,O
4430,moderate,B
4430,approach,I
4430,to,B
4430,generate,I
4430,local,B
4430,context,I
4430,features,I
4430,.,O
4431,The,O
4431,experimental,O
4431,results,O
4431,show,B
4431,that,O
4431,its,O
4431,performance,B
4431,is,O
4431,also,O
4431,better,B
4431,than,I
4431,the,O
4431,existing,B
4431,BERT,I
4431,-,I
4431,based,I
4431,models,I
4431,.,O
4432,Compared,O
4432,with,O
4432,the,O
4432,BERT,B
4432,-,I
4432,BASE,I
4432,model,I
4432,",",O
4432,BERT,O
4432,-,O
4432,SPC,O
4432,significantly,B
4432,improves,I
4432,the,O
4432,accuracy,B
4432,and,I
4432,F,I
4432,1,I
4432,score,I
4432,of,B
4432,aspect,B
4432,polarity,I
4432,classification,I
4432,.,O
4433,In,O
4433,addition,O
4433,",",O
4433,for,B
4433,the,O
4433,first,B
4433,time,I
4433,",",O
4433,BERT,B
4433,-,I
4433,SPC,I
4433,has,B
4433,increased,I
4433,the,O
4433,F,B
4433,1,I
4433,score,I
4433,of,B
4433,ATE,B
4433,subtask,I
4433,on,B
4433,three,B
4433,datasets,I
4433,up,B
4433,to,I
4433,99,B
4433,%,I
4433,.,O
4434,For,O
4434,each,O
4434,of,O
4434,the,O
4434,tasks,O
4434,",",O
4434,we,O
4434,compare,B
4434,SuBiLSTM,I
4434,and,I
4434,SuBiLSTM,O
4434,-,O
4434,Tied,O
4434,with,B
4434,a,I
4434,single,B
4434,-,O
4434,layer,O
4434,BiLSTM,O
4434,and,O
4434,a,O
4434,2,O
4434,-,O
4434,layer,O
4434,BiLSTM,O
4434,encoder,O
4434,with,O
4434,the,O
4434,same,B
4434,hidden,I
4434,dimension,I
4434,.,O
4435,In,O
4435,this,O
4435,paper,O
4435,",",O
4435,we,O
4435,propose,B
4435,a,O
4435,simple,B
4435,",",O
4435,general,O
4435,and,O
4435,effective,O
4435,technique,O
4435,to,B
4435,compute,I
4435,contextual,B
4435,representations,I
4435,that,B
4435,capture,I
4435,long,B
4435,range,I
4435,dependencies,I
4435,.,O
4436,For,B
4436,each,B
4436,token,I
4436,t,I
4436,",",O
4436,we,O
4436,encode,B
4436,both,I
4436,its,O
4436,prefix,B
4436,and,I
4436,suffix,I
4436,in,B
4436,both,O
4436,the,O
4436,forward,B
4436,and,O
4436,reverse,O
4436,direction,O
4436,.,O
4437,With,B
4437,Att,B
4437,-,I
4437,Input,I
4437,-,O
4437,CNN,O
4437,",",O
4437,we,O
4437,achieve,B
4437,an,B
4437,F1-score,B
4437,of,B
4437,87.5,B
4437,%,I
4437,",",O
4437,thus,O
4437,already,O
4437,outperforming,B
4437,not,O
4437,only,O
4437,the,O
4437,original,O
4437,winner,O
4437,of,O
4437,the,O
4437,SemEval,O
4437,task,O
4437,",",O
4437,an,O
4437,SVM,O
4437,-,O
4437,based,O
4437,approach,O
4437,(,O
4437,82.2,O
4437,%,O
4437,),O
4437,",",O
4437,but,O
4437,also,O
4437,the,O
4437,wellknown,B
4437,CR,I
4437,-,O
4437,CNN,O
4437,model,O
4437,(,O
4437,84.1,O
4437,%,O
4437,),O
4437,with,O
4437,a,O
4437,relative,O
4437,improvement,O
4437,of,O
4437,4.04,O
4437,%,O
4437,",",O
4437,and,O
4437,the,O
4437,newly,B
4437,released,I
4437,DRNNs,I
4437,(,O
4437,85.8,O
4437,%,O
4437,),O
4437,with,O
4437,a,O
4437,relative,O
4437,improvement,O
4437,of,O
4437,2.0,O
4437,%,O
4437,",",O
4437,although,O
4437,the,O
4437,latter,O
4437,approach,O
4437,depends,O
4437,on,O
4437,the,O
4437,Stanford,O
4437,parser,O
4437,to,O
4437,obtain,O
4437,dependency,O
4437,parse,O
4437,information,O
4437,.,O
4438,Further,O
4438,",",O
4438,we,O
4438,combine,B
4438,the,O
4438,prefix,B
4438,and,I
4438,suffix,I
4438,representations,I
4438,by,B
4438,a,O
4438,simple,B
4438,max,I
4438,-,I
4438,pooling,I
4438,operation,I
4438,to,B
4438,produce,I
4438,a,O
4438,richer,B
4438,contextual,I
4438,representation,I
4438,of,O
4438,t,O
4438,in,B
4438,both,I
4438,the,O
4438,forward,B
4438,and,O
4438,reverse,O
4438,direction,O
4438,.,O
4439,Recurrent,O
4439,neural,O
4439,networks,O
4439,have,O
4439,become,O
4439,ubiquitous,O
4439,in,O
4439,computing,B
4439,representations,I
4439,of,I
4439,sequential,I
4439,data,I
4439,",",O
4439,especially,O
4439,textual,O
4439,data,O
4439,in,O
4439,natural,O
4439,language,O
4439,processing,O
4439,.,O
4440,Using,O
4440,SuBiLSTM,O
4440,we,O
4440,achieve,O
4440,new,O
4440,state,O
4440,-,O
4440,of,O
4440,-,O
4440,the,O
4440,-,O
4440,art,O
4440,results,O
4440,for,O
4440,fine,B
4440,-,O
4440,grained,O
4440,sentiment,O
4440,classification,O
4440,and,O
4440,question,B
4440,classification,O
4440,.,O
4441,Recurrent,O
4441,Neural,O
4441,Networks,O
4441,(,O
4441,RNN,O
4441,),O
4441,),O
4441,have,O
4441,emerged,O
4441,as,O
4441,a,O
4441,powerful,O
4441,tool,O
4441,for,O
4441,modeling,B
4441,sequential,I
4441,data,I
4441,.,O
4442,The,O
4442,relative,B
4442,performance,I
4442,of,B
4442,SuBiL,B
4442,-,I
4442,STM,I
4442,and,I
4442,SuBiLSTM,I
4442,-,O
4442,Tied,O
4442,are,B
4442,fairly,B
4442,close,I
4442,to,O
4442,each,O
4442,other,O
4442,",",O
4442,as,O
4442,shown,O
4442,by,O
4442,the,O
4442,relative,O
4442,gains,O
4442,in,O
4442,.,O
4443,SuBiLSTM,O
4443,-,O
4443,Tied,O
4443,works,B
4443,better,B
4443,on,B
4443,small,B
4443,datasets,I
4443,(,I
4443,SST,I
4443,and,I
4443,TREC,I
4443,),I
4443,",",O
4443,probably,O
4443,owing,O
4443,to,O
4443,the,O
4443,regularizing,O
4443,effect,O
4443,of,O
4443,using,O
4443,the,O
4443,same,O
4443,LSTM,O
4443,to,O
4443,encode,O
4443,both,O
4443,suffixes,O
4443,and,O
4443,prefixes,O
4443,.,O
4444,The,O
4444,training,B
4444,complexity,I
4444,for,B
4444,both,I
4444,the,O
4444,models,B
4444,is,B
4444,similar,B
4444,and,O
4444,hence,O
4444,",",O
4444,with,B
4444,half,B
4444,the,O
4444,parameters,O
4444,",",O
4444,SuBILSTM,B
4444,-,I
4444,Tied,I
4444,should,B
4444,be,I
4444,the,O
4444,more,B
4444,favored,I
4444,model,I
4444,for,O
4444,sentence,B
4444,modeling,I
4444,tasks,I
4444,.,O
4445,For,B
4445,the,O
4445,larger,B
4445,datasets,I
4445,(,I
4445,SNLI,I
4445,and,I
4445,QUORA,I
4445,),I
4445,",",O
4445,SuBILSTM,B
4445,slightly,O
4445,edges,B
4445,out,I
4445,the,O
4445,tied,B
4445,version,I
4445,owing,B
4445,to,I
4445,its,O
4445,larger,O
4445,capacity,O
4445,.,O
4446,The,O
4446,ARE,B
4446,model,I
4446,(,I
4446,),I
4446,incorrectly,B
4446,classifies,I
4446,most,B
4446,instances,I
4446,of,I
4446,happy,I
4446,as,B
4446,neutral,B
4446,(,O
4446,43.51,O
4446,%,O
4446,),O
4446,;,O
4446,thus,O
4446,",",O
4446,it,O
4446,shows,O
4446,reduced,O
4446,accuracy,O
4446,(,O
4446,35.15,O
4446,%,O
4446,),O
4446,in,O
4446,predicting,O
4446,the,O
4446,the,O
4446,happy,O
4446,class,O
4446,.,O
4447,Mintz,B
4447,:,O
4447,Multi-class,B
4447,logistic,I
4447,regression,I
4447,model,I
4447,proposed,O
4447,by,O
4447,for,B
4447,distant,B
4447,supervision,I
4447,paradigm,I
4447,.,O
4448,The,O
4448,model,O
4448,proposed,O
4448,by,O
4448,is,O
4448,a,O
4448,feature,B
4448,-,I
4448,based,I
4448,structured,I
4448,perceptron,I
4448,model,O
4448,with,B
4448,efficient,B
4448,beam,I
4448,-,O
4448,search,O
4448,.,O
4449,Overall,O
4449,",",O
4449,most,O
4449,of,O
4449,the,O
4449,emotion,B
4449,classes,I
4449,are,O
4449,frequently,B
4449,confused,I
4449,with,I
4449,the,O
4449,neutral,B
4449,class,I
4449,.,O
4450,Interestingly,O
4450,",",O
4450,the,O
4450,TRE,B
4450,model,I
4450,(,O
4450,),O
4450,shows,B
4450,greater,B
4450,prediction,I
4450,gains,I
4450,in,B
4450,predicting,I
4450,the,O
4450,happy,B
4450,class,I
4450,when,O
4450,compared,B
4450,to,I
4450,the,O
4450,ARE,O
4450,model,O
4450,(,O
4450,35.15,O
4450,%,O
4450,to,O
4450,75.,O
4451,The,O
4451,MDRE,B
4451,model,I
4451,),I
4451,compensates,B
4451,for,I
4451,the,O
4451,weaknesses,B
4451,of,B
4451,the,O
4451,previous,B
4451,two,I
4451,models,I
4451,(,I
4451,ARE,I
4451,and,I
4451,TRE,I
4451,),O
4451,and,O
4451,benefits,B
4451,from,I
4451,their,O
4451,strengths,B
4451,to,B
4451,a,O
4451,surprising,B
4451,degree,I
4451,.,O
4452,Furthermore,O
4452,",",O
4452,the,O
4452,occurrence,B
4452,of,B
4452,the,O
4452,incorrect,B
4452,"""",I
4452,sad,I
4452,-,I
4452,to,I
4452,-,O
4452,happy,O
4452,"""",O
4452,cases,O
4452,in,B
4452,the,O
4452,TRE,B
4452,model,I
4452,is,O
4452,reduced,B
4452,from,I
4452,16,O
4452,.,O
4453,Among,O
4453,the,O
4453,variants,O
4453,of,B
4453,the,O
4453,RNN,O
4453,function,O
4453,",",O
4453,we,O
4453,use,B
4453,GRUs,B
4453,as,B
4453,they,I
4453,yield,I
4453,comparable,B
4453,performance,I
4453,to,B
4453,that,I
4453,of,O
4453,the,O
4453,LSTM,B
4453,and,O
4453,include,B
4453,a,O
4453,smaller,B
4453,number,I
4453,of,O
4453,weight,B
4453,parameters,I
4453,.,O
4454,We,O
4454,use,O
4454,a,O
4454,max,B
4454,encoder,I
4454,step,I
4454,of,B
4454,750,B
4454,for,B
4454,the,O
4454,audio,B
4454,input,I
4454,",",O
4454,based,O
4454,on,O
4454,the,O
4454,implementation,O
4454,choices,O
4454,presented,O
4454,in,O
4454,and,O
4454,128,B
4454,for,O
4454,the,O
4454,text,B
4454,input,O
4454,because,O
4454,it,O
4454,covers,B
4454,the,O
4454,maximum,B
4454,length,I
4454,of,O
4454,the,O
4454,transcripts,B
4454,.,O
4455,In,O
4455,preparing,O
4455,the,O
4455,textual,O
4455,dataset,O
4455,",",O
4455,we,O
4455,first,O
4455,use,O
4455,the,O
4455,released,B
4455,transcripts,I
4455,of,B
4455,the,O
4455,IEMOCAP,B
4455,dataset,O
4455,for,B
4455,simplicity,B
4455,.,O
4456,The,O
4456,vocabulary,B
4456,size,I
4456,of,B
4456,the,O
4456,dataset,B
4456,is,B
4456,"3,747",B
4456,",",O
4456,including,B
4456,the,O
4456,"""",O
4456,UNK,O
4456,"""",O
4456,token,O
4456,",",O
4456,which,O
4456,represents,B
4456,unknown,B
4456,words,I
4456,",",O
4456,and,O
4456,the,O
4456,"""",O
4456,PAD,O
4456,"""",O
4456,token,O
4456,",",O
4456,which,O
4456,is,O
4456,used,B
4456,to,I
4456,indicate,I
4456,padding,B
4456,information,I
4456,added,B
4456,while,I
4456,preparing,I
4456,mini-batch,B
4456,data,I
4456,.,O
4457,The,O
4457,number,O
4457,of,O
4457,hidden,O
4457,units,O
4457,and,O
4457,the,O
4457,number,O
4457,of,O
4457,layers,O
4457,in,B
4457,the,O
4457,RNN,B
4457,for,B
4457,each,B
4457,model,I
4457,(,I
4457,ARE,I
4457,",",I
4457,TRE,I
4457,",",O
4457,MDRE,O
4457,and,O
4457,MDREA,O
4457,),O
4457,are,O
4457,selected,B
4457,based,I
4457,on,I
4457,extensive,B
4457,hyperparameter,I
4457,search,I
4457,experiments,I
4457,.,O
4458,The,O
4458,weights,B
4458,of,B
4458,the,O
4458,hidden,B
4458,units,I
4458,are,O
4458,initialized,B
4458,using,I
4458,orthogonal,B
4459,They,O
4459,employ,B
4459,a,O
4459,segment,B
4459,-,I
4459,based,I
4459,decoder,I
4459,instead,B
4459,of,I
4459,token,B
4459,-,O
4459,based,O
4459,decoding,O
4459,.,O
4460,weights,O
4460,],O
4460,",",O
4460,and,O
4460,the,O
4460,text,B
4460,embedding,I
4460,layer,I
4460,is,O
4460,initialized,B
4460,from,I
4460,pretrained,B
4460,word,I
4460,-,I
4460,embedding,O
4460,vectors,O
4460,.,O
4461,To,O
4461,overcome,O
4461,these,O
4461,limitations,O
4461,",",O
4461,we,O
4461,propose,O
4461,a,O
4461,model,O
4461,that,O
4461,uses,B
4461,high,B
4461,-,I
4461,level,I
4461,text,I
4461,transcription,I
4461,",",O
4461,as,O
4461,well,O
4461,as,O
4461,low,B
4461,-,O
4461,level,O
4461,audio,O
4461,signals,O
4461,",",O
4461,to,O
4461,utilize,O
4461,the,O
4461,information,B
4461,contained,B
4461,within,I
4461,low,O
4461,-,O
4461,resource,O
4461,datasets,O
4461,to,O
4461,a,O
4461,greater,O
4461,degree,O
4461,.,O
4462,In,O
4462,this,O
4462,paper,O
4462,",",O
4462,we,O
4462,propose,B
4462,a,O
4462,novel,B
4462,deep,I
4462,dual,I
4462,recurrent,I
4462,encoder,I
4462,model,I
4462,that,O
4462,simultaneously,B
4462,utilizes,I
4462,audio,B
4462,and,I
4462,text,I
4462,data,I
4462,in,O
4462,recognizing,O
4462,emotions,B
4462,from,B
4462,speech,B
4462,.,O
4463,MULTIMODAL,O
4463,SPEECH,B
4463,EMOTION,I
4463,RECOGNITION,I
4463,USING,O
4463,AUDIO,O
4463,AND,O
4463,TEXT,O
4464,First,O
4464,",",O
4464,our,O
4464,ARE,B
4464,model,I
4464,shows,B
4464,the,O
4464,baseline,B
4464,performance,I
4464,because,O
4464,we,O
4464,use,B
4464,minimal,B
4464,audio,I
4464,features,I
4464,",",O
4464,such,B
4464,as,I
4464,the,O
4464,MFCC,B
4464,and,I
4464,prosodic,I
4464,features,O
4464,with,B
4464,simple,B
4464,architectures,I
4464,.,O
4465,On,O
4465,the,O
4465,other,O
4465,hand,O
4465,",",O
4465,the,O
4465,TRE,B
4465,model,I
4465,shows,B
4465,higher,B
4465,performance,I
4465,gain,I
4465,compared,B
4465,to,I
4465,the,O
4465,ARE,B
4465,.,O
4466,Second,O
4466,",",O
4466,the,O
4466,newly,O
4466,proposed,O
4466,model,O
4466,",",O
4466,MDRE,B
4466,",",O
4466,shows,B
4466,a,O
4466,substantial,B
4466,performance,I
4466,gain,I
4466,.,O
4467,It,O
4467,thus,O
4467,achieves,B
4467,the,I
4467,state,B
4467,-,I
4467,of,B
4467,-,O
4467,the,O
4467,-,O
4467,art,O
4467,performance,O
4467,with,B
4467,a,O
4467,WAP,B
4467,value,I
4467,of,O
4467,0.718,B
4467,.,O
4468,Lastly,O
4468,",",O
4468,the,O
4468,attention,O
4468,model,O
4468,",",O
4468,MDREA,B
4468,",",O
4468,also,O
4468,outperforms,B
4468,the,O
4468,best,B
4468,existing,I
4468,research,I
4468,results,I
4468,(,I
4468,WAP,I
4468,0.690,I
4468,to,I
4468,0.688,I
4468,),I
4468,.,O
4469,The,O
4469,label,B
4469,accuracy,I
4469,of,B
4469,the,O
4469,processed,B
4469,transcripts,I
4469,is,B
4469,5.53,B
4469,%,I
4469,WER,I
4469,.,O
4470,(,O
4470,SPTree,B
4470,),O
4470,recently,O
4470,proposed,B
4470,a,O
4470,LSTM,B
4470,-,I
4470,based,I
4470,model,I
4470,with,B
4470,a,O
4470,sequence,B
4470,layer,I
4470,for,B
4470,entity,B
4470,identification,I
4470,",",O
4470,and,O
4470,a,O
4470,tree,B
4470,-,O
4470,based,O
4470,dependency,O
4470,layer,O
4470,which,B
4470,identifies,I
4470,relations,B
4470,between,I
4470,pairs,I
4470,of,I
4470,candidate,I
4470,entities,I
4470,using,O
4470,the,O
4470,shortest,O
4470,dependency,O
4470,path,O
4470,between,O
4470,them,O
4470,.,O
4471,The,O
4471,TRE,B
4471,-,I
4471,ASR,I
4471,",",I
4471,MDRE,I
4471,-,O
4471,ASR,O
4471,and,O
4471,MDREA,O
4471,-,O
4471,ASR,O
4471,models,O
4471,reflect,B
4471,degraded,B
4471,performance,I
4471,compared,B
4471,to,I
4471,that,O
4471,of,O
4471,the,O
4471,TRE,O
4471,",",O
4471,MDRE,O
4471,and,O
4471,MDREA,O
4471,models,O
4471,.,O
4472,From,O
4472,this,O
4472,result,O
4472,",",O
4472,we,O
4472,note,B
4472,that,O
4472,textual,B
4472,data,I
4472,are,B
4472,informative,B
4472,in,B
4472,emotion,B
4472,prediction,I
4472,tasks,I
4472,",",O
4472,and,O
4472,the,O
4472,recurrent,B
4472,encoder,I
4472,model,I
4472,is,B
4472,effective,B
4472,in,O
4472,understanding,O
4472,these,O
4472,types,B
4472,of,I
4472,sequential,I
4472,data,O
4472,.,O
4473,Majority,B
4473,is,B
4473,the,O
4473,basic,B
4473,baseline,I
4473,",",O
4473,which,O
4473,chooses,B
4473,the,O
4473,largest,B
4473,sentiment,I
4473,polarity,I
4473,in,B
4473,the,O
4473,training,B
4473,set,I
4473,to,B
4473,each,I
4473,instance,B
4473,in,O
4473,the,O
4473,test,B
4473,set,O
4473,.,O
4474,MemNet,B
4474,applys,B
4474,multi-hop,B
4474,attentions,I
4474,on,B
4474,the,O
4474,word,O
4474,embeddings,O
4474,",",O
4474,learns,B
4474,the,O
4474,attention,B
4474,weights,I
4474,on,O
4474,context,B
4474,word,O
4474,vectors,O
4474,with,B
4474,respect,I
4474,to,I
4474,the,O
4474,averaged,B
4474,query,I
4474,vector,I
4474,.,O
4475,IAN,B
4475,interactively,B
4475,learns,I
4475,the,O
4475,coarse,B
4475,-,I
4475,grained,I
4475,attentions,I
4475,between,B
4475,the,O
4475,context,B
4475,and,I
4475,aspect,I
4475,",",O
4475,and,O
4475,concatenate,B
4475,the,O
4475,vectors,B
4475,for,B
4475,prediction,B
4475,.,O
4476,BILSTM,O
4476,-,O
4476,ATT,O
4476,-G,O
4476,(,O
4476,Liu,O
4476,and,O
4476,Zhang,O
4476,",",O
4476,2017,O
4476,),O
4476,models,B
4476,left,B
4476,and,O
4476,right,B
4476,context,I
4476,with,B
4476,two,B
4476,attention,I
4476,-,O
4476,based,O
4476,LSTMs,O
4476,and,O
4476,utilizes,B
4476,gates,B
4476,to,B
4476,control,I
4476,the,O
4476,importance,B
4476,of,B
4476,left,O
4476,context,O
4476,",",O
4476,right,O
4476,context,O
4476,and,O
4476,the,O
4476,entire,B
4476,sentence,I
4476,for,B
4476,prediction,B
4476,.,O
4477,RAM,B
4477,learns,B
4477,multi-hop,B
4477,attentions,B
4477,on,B
4477,the,O
4477,hidden,B
4477,states,I
4477,of,B
4477,bidirectional,B
4477,LSTM,I
4477,networks,I
4477,for,B
4477,context,B
4477,words,I
4477,",",O
4477,and,O
4477,proposes,B
4477,to,B
4477,use,I
4477,GRU,B
4477,network,I
4477,to,O
4477,get,O
4477,the,O
4477,aggregated,B
4477,vector,I
4477,from,B
4477,the,O
4477,attentions,O
4477,.,O
4478,MGAN,O
4478,-,O
4478,C,O
4478,only,O
4478,employs,B
4478,the,O
4478,coarse,B
4478,-,O
4478,grained,O
4478,attentions,O
4478,for,B
4478,prediction,B
4478,",",O
4478,which,O
4478,is,O
4478,similar,O
4478,with,O
4478,IAN,O
4478,.,O
4479,MGAN,O
4479,-,O
4479,F,O
4479,only,O
4479,utilizes,B
4479,the,O
4479,proposed,B
4479,fine,I
4479,-,O
4479,grained,O
4479,attentions,O
4479,for,B
4479,prediction,B
4479,.,O
4480,MGAN,O
4480,-,O
4480,CF,O
4480,adopts,B
4480,both,I
4480,the,O
4480,coarse,B
4480,-,O
4480,grained,O
4480,and,O
4480,fine,O
4480,-,O
4480,grained,O
4480,attentions,O
4480,",",O
4480,while,O
4480,without,O
4480,applying,O
4480,the,O
4480,aspect,O
4480,alignment,O
4480,loss,O
4480,.,O
4481,We,O
4481,also,O
4481,employed,B
4481,our,B
4481,previous,I
4481,approach,I
4481,for,B
4481,extraction,B
4481,of,B
4481,opinion,B
4481,entities,I
4481,and,I
4481,relations,I
4481,to,B
4481,this,B
4481,task,I
4481,.,O
4482,MGAN,B
4482,is,B
4482,the,O
4482,complete,B
4482,multi-grained,I
4482,attention,I
4482,network,I
4482,model,I
4482,.,O
4483,In,O
4483,our,O
4483,experiments,O
4483,",",O
4483,word,B
4483,embeddings,I
4483,for,B
4483,both,I
4483,context,B
4483,and,I
4483,aspect,I
4483,words,I
4483,are,O
4483,initialized,B
4483,by,I
4483,Glove,B
4483,.,O
4484,The,O
4484,dimension,B
4484,of,B
4484,word,B
4484,embedding,I
4484,d,I
4484,v,I
4484,and,O
4484,hidden,B
4484,stated,I
4484,are,O
4484,1,O
4484,The,O
4484,detailed,O
4484,task,O
4484,introduction,O
4484,can,O
4484,be,O
4484,found,O
4484,in,O
4484,http://alt.qcri.org/semeval2014/task4/.,O
4485,set,O
4485,to,O
4485,300,B
4485,.,O
4486,The,O
4486,weight,B
4486,matrix,I
4486,and,I
4486,bias,I
4486,are,B
4486,initialized,B
4486,by,B
4486,sampling,B
4486,from,B
4486,a,O
4486,uniform,B
4486,distribution,I
4486,U,I
4486,(,I
4486,0.01,I
4486,",",I
4486,0.01,O
4486,),O
4486,.,O
4487,The,O
4487,coefficient,B
4487,?,O
4488,of,B
4488,L,B
4488,2,I
4488,regularization,I
4488,item,O
4488,is,B
4488,10,O
4488,?,O
4489,of,O
4489,aspect,O
4489,alignment,O
4489,loss,O
4489,and,O
4489,dropout,B
4489,rate,I
4489,are,O
4489,set,B
4489,to,I
4489,0.5,B
4489,.,O
4490,In,O
4490,this,O
4490,paper,O
4490,",",O
4490,we,O
4490,propose,B
4490,a,O
4490,multi,B
4490,-grained,I
4490,attention,I
4490,network,I
4490,to,O
4490,address,O
4490,the,O
4490,above,O
4490,two,O
4490,issues,O
4490,in,O
4490,aspect,O
4490,level,O
4490,sentiment,O
4490,classification,O
4490,.,O
4491,Specifically,O
4491,",",O
4491,we,O
4491,propose,O
4491,a,O
4491,fine,B
4491,-,I
4491,grained,I
4491,attention,I
4491,mechanism,I
4491,(,O
4491,i.e.,O
4492,F-,O
4492,Aspect2Context,O
4492,and,O
4492,F,O
4492,-,O
4492,Context2Aspect,O
4492,),O
4492,",",O
4492,which,O
4492,is,O
4492,employed,O
4492,to,B
4492,characterize,I
4492,the,O
4492,word,B
4492,-,O
4492,level,O
4492,interactions,O
4492,between,B
4492,aspect,B
4492,and,O
4492,context,O
4492,words,O
4492,",",O
4492,and,O
4492,relieve,B
4492,the,O
4492,information,B
4492,loss,I
4492,occurred,B
4492,in,I
4492,coarse,B
4492,-,O
4492,grained,O
4492,attention,O
4492,mechanism,O
4492,.,O
4493,In,O
4493,addition,O
4493,",",O
4493,we,O
4493,utilize,B
4493,the,O
4493,bidirectional,B
4493,coarsegrained,I
4493,attention,I
4493,(,O
4493,i.e.,O
4494,C-,O
4494,Aspect2Context,O
4494,and,O
4494,C,O
4494,-,O
4494,Context2Aspect,O
4494,),O
4494,and,O
4494,combine,B
4494,them,I
4494,with,I
4494,finegrained,B
4494,attention,I
4494,vectors,I
4494,to,B
4494,compose,I
4494,the,O
4494,multigrained,B
4494,attention,O
4494,network,O
4494,for,B
4494,the,O
4494,final,B
4494,sentiment,I
4494,polarity,I
4494,prediction,I
4494,",",O
4494,which,O
4494,can,O
4494,leverage,O
4494,the,O
4494,advantages,O
4494,of,O
4494,them,O
4494,.,O
4495,We,O
4495,train,B
4495,our,B
4495,model,I
4495,using,B
4495,Adadelta,B
4495,with,B
4495,gradient,B
4495,clipping,I
4495,.,O
4496,More,O
4496,importantly,O
4496,",",O
4496,in,B
4496,order,O
4496,to,B
4496,make,I
4496,use,I
4496,of,B
4496,the,O
4496,valuable,B
4496,aspect,B
4496,-,I
4496,level,I
4496,interaction,I
4496,information,I
4496,",",O
4496,we,O
4496,design,B
4496,an,O
4496,aspect,O
4496,alignment,O
4496,loss,O
4496,in,O
4496,the,O
4496,objective,B
4496,function,I
4496,to,O
4496,enhance,O
4496,the,O
4496,difference,B
4496,of,O
4496,the,O
4496,attention,B
4496,weights,I
4496,towards,B
4496,the,O
4496,aspects,B
4496,which,B
4496,have,I
4496,the,O
4496,same,B
4496,context,I
4496,and,O
4496,different,B
4496,sentiment,I
4496,polarities,I
4496,.,O
4497,Multi,O
4497,-,O
4497,grained,O
4497,Attention,O
4497,Network,O
4497,for,O
4497,Aspect,B
4497,-,O
4497,Level,O
4497,Sentiment,O
4497,Classification,O
4498,We,O
4498,propose,O
4498,a,O
4498,novel,O
4498,multi-grained,O
4498,attention,O
4498,network,O
4498,(,O
4498,MGAN,O
4498,),O
4498,model,O
4498,for,O
4498,aspect,B
4498,level,I
4498,sentiment,I
4498,classification,I
4498,.,O
4499,(,O
4499,1,O
4499,),O
4499,Majority,B
4499,performs,B
4499,worst,B
4499,since,O
4499,it,O
4499,only,O
4499,utilizes,O
4499,the,O
4499,data,O
4499,distribution,O
4499,information,O
4499,.,O
4500,Our,O
4500,method,O
4500,MGAN,B
4500,outperforms,B
4500,Majority,B
4500,and,I
4500,Feature,I
4500,+,I
4500,SVM,I
4500,since,O
4500,MGAN,O
4500,could,O
4500,learn,O
4500,the,O
4500,high,O
4500,quality,O
4500,representation,O
4500,for,O
4500,prediction,O
4500,.,O
4501,(,O
4501,2,O
4501,),O
4501,ATAE,B
4501,-,I
4501,LSTM,B
4501,is,B
4501,better,B
4501,than,B
4501,LSTM,O
4501,since,O
4501,it,O
4501,employs,O
4501,attention,O
4501,mechanism,O
4501,on,O
4501,the,O
4501,hidden,O
4501,states,O
4501,and,O
4501,combines,O
4501,with,O
4501,attention,O
4501,embedding,O
4501,to,O
4501,generate,O
4501,the,O
4501,final,O
4501,representation,O
4501,.,O
4502,TD,O
4502,-,O
4502,LSTM,O
4502,performs,B
4502,slightly,B
4502,better,I
4502,than,B
4502,ATAE,B
4502,-,O
4502,LSTM,O
4502,",",O
4502,and,O
4502,it,O
4502,employs,O
4502,two,O
4502,LSTM,O
4502,networks,O
4502,to,O
4502,capture,O
4502,the,O
4502,left,O
4502,and,O
4502,right,O
4502,context,O
4502,of,O
4502,the,O
4502,aspect,O
4502,.,O
4503,TD,O
4503,-,O
4503,LSTM,O
4503,performs,O
4503,worse,B
4503,than,B
4503,our,B
4503,method,I
4503,MGAN,I
4503,since,O
4503,it,O
4503,could,O
4503,not,O
4503,properly,O
4503,pay,O
4503,more,O
4503,attentions,O
4503,on,O
4503,the,O
4503,important,O
4503,parts,O
4503,of,O
4503,the,O
4503,context,O
4503,.,O
4504,(,O
4504,3,O
4504,),O
4504,IAN,B
4504,achieves,B
4504,slightly,B
4504,better,I
4504,results,I
4504,with,B
4504,the,O
4504,previous,B
4504,LSTM,I
4504,-,I
4504,based,I
4504,methods,I
4504,",",O
4504,which,O
4504,interactively,O
4504,learns,O
4504,the,O
4504,attended,O
4504,aspect,O
4504,and,O
4504,context,O
4504,vector,O
4504,as,O
4504,final,O
4504,representation,O
4504,.,O
4505,Our,O
4505,method,O
4505,consistently,B
4505,performs,I
4505,better,B
4505,than,B
4505,IAN,B
4505,since,O
4505,we,O
4505,utilize,O
4505,the,O
4505,finegrained,O
4505,attention,O
4505,vectors,O
4505,to,O
4505,relieve,O
4505,the,O
4505,information,O
4505,loss,O
4505,in,O
4505,IAN,O
4505,.,O
4506,We,O
4506,regularize,B
4506,our,B
4506,network,I
4506,using,I
4506,dropout,B
4506,with,B
4506,the,O
4506,drop,B
4506,-,I
4506,out,I
4506,rate,I
4506,tuned,B
4506,using,O
4506,development,B
4506,set,I
4506,.,O
4507,BILSTM,O
4507,-,O
4507,ATT,O
4507,-,O
4507,G,O
4507,models,B
4507,left,B
4507,context,I
4507,and,I
4507,right,I
4507,context,O
4507,using,B
4507,attention,B
4507,-,O
4507,based,O
4507,LSTMs,O
4507,",",O
4507,which,O
4507,achieves,B
4507,better,B
4507,performance,I
4507,than,B
4507,MemNet,B
4507,.,O
4508,RAM,B
4508,performs,B
4508,better,B
4508,than,B
4508,other,B
4508,baselines,I
4508,.,O
4509,Our,O
4509,proposed,O
4509,MGAN,O
4509,consistently,B
4509,performs,I
4509,better,B
4509,than,B
4509,MemNet,B
4509,",",O
4509,BILSTM,B
4509,-,I
4509,ATT,I
4509,-,O
4509,G,O
4509,and,O
4509,RAM,B
4509,on,O
4509,all,O
4509,three,O
4509,datasets,O
4509,.,O
4510,In,O
4510,this,O
4510,paper,O
4510,",",O
4510,we,O
4510,propose,B
4510,a,O
4510,novel,B
4510,progressive,I
4510,self,I
4510,-,I
4510,supervised,I
4510,attention,I
4510,learning,I
4510,approach,I
4510,for,B
4510,neural,B
4510,ASC,I
4510,models,I
4510,.,O
4511,Our,O
4511,method,O
4511,is,O
4511,able,B
4511,to,I
4511,automatically,I
4511,and,I
4511,incrementally,I
4511,mine,I
4511,attention,B
4511,supervision,I
4511,information,I
4511,from,B
4511,a,O
4511,training,B
4511,corpus,I
4511,",",O
4511,which,O
4511,can,O
4511,be,O
4511,exploited,B
4511,to,O
4511,guide,O
4511,the,O
4511,training,O
4511,of,B
4511,attention,O
4511,mechanisms,O
4511,in,B
4511,ASC,B
4511,models,I
4511,.,O
4512,The,O
4512,basic,O
4512,idea,O
4512,behind,O
4512,our,O
4512,approach,O
4512,roots,B
4512,in,I
4512,the,O
4512,following,O
4512,fact,O
4512,:,O
4512,the,O
4512,context,B
4512,word,I
4512,with,B
4512,the,O
4512,maximum,B
4512,attention,I
4512,weight,I
4512,has,O
4512,the,O
4512,greatest,B
4512,impact,I
4512,on,B
4512,the,O
4512,sentiment,B
4512,prediction,I
4512,of,B
4512,an,O
4512,input,B
4512,sentence,I
4512,.,O
4513,We,O
4513,used,B
4513,pre-trained,B
4513,Glo,I
4513,Ve,I
4513,vectors,I
4513,to,B
4513,initialize,I
4513,the,O
4513,word,B
4513,embeddings,I
4513,with,B
4513,vector,B
4513,dimension,I
4513,300,B
4513,.,O
4514,For,B
4514,out,B
4514,-,I
4514,of,I
4514,-,O
4514,vocabulary,O
4514,words,O
4514,",",O
4514,we,O
4514,randomly,B
4514,sampled,I
4514,their,O
4514,embeddings,B
4514,from,B
4514,the,O
4514,uniform,B
4514,distribution,I
4514,",",O
4514,as,O
4514,implemented,O
4514,in,O
4514,.,O
4515,To,O
4515,alleviate,O
4515,overfitting,B
4515,",",O
4515,we,O
4515,employed,B
4515,dropout,O
4515,strategy,O
4515,(,O
4515,Hinton,O
4515,et,O
4515,al.,O
4516,",",O
4516,2012,O
4516,),O
4516,on,B
4516,the,O
4516,input,B
4516,word,I
4516,embeddings,I
4516,of,B
4516,the,O
4516,LSTM,B
4516,and,O
4516,the,O
4516,ultimate,O
4516,aspect,O
4516,-,O
4516,related,O
4516,sentence,O
4516,representation,O
4516,.,O
4517,Adam,O
4517,(,O
4517,Kingma,O
4517,and,O
4517,Ba,O
4517,",",O
4517,2015,O
4517,),O
4517,was,O
4517,adopted,B
4517,as,O
4517,the,O
4517,optimizer,B
4517,with,B
4517,the,O
4517,learning,B
4517,rate,I
4517,0.001,B
4517,.,O
4518,We,O
4518,have,B
4518,3,B
4518,hidden,B
4518,layers,I
4518,in,B
4518,our,B
4518,network,I
4518,and,O
4518,the,O
4518,dimensionality,B
4518,of,B
4518,the,O
4518,hidden,O
4518,units,O
4518,is,B
4518,100,B
4518,.,O
4519,All,O
4519,hyper,O
4519,-,O
4519,parameters,O
4519,were,O
4519,tuned,B
4519,on,I
4519,20,B
4519,%,I
4519,randomly,I
4519,held,I
4519,-,O
4519,out,O
4519,training,O
4519,data,O
4519,.,O
4520,When,O
4520,implementing,O
4520,our,B
4520,approach,I
4520,",",O
4520,we,O
4520,empirically,B
4520,set,I
4520,the,O
4520,maximum,B
4520,iteration,I
4520,number,I
4520,K,I
4520,as,B
4520,5,B
4520,",",O
4520,?,O
4521,in,O
4521,Equation,O
4521,3,O
4521,as,B
4521,0.1,B
4521,on,B
4521,LAPTOP,B
4521,data,I
4521,set,I
4521,",",O
4521,0.5,B
4521,on,O
4521,REST,B
4521,data,O
4521,set,O
4521,and,O
4521,0.1,O
4521,on,O
4521,TWITTER,B
4521,data,O
4521,set,O
4521,",",O
4521,respectively,O
4521,.,O
4522,Progressive,O
4522,Self,O
4522,-,O
4522,Supervised,O
4522,Attention,O
4522,Learning,O
4522,for,O
4522,Aspect,B
4522,-,O
4522,Level,O
4522,Sentiment,O
4522,Analysis,O
4523,In,O
4523,aspect,B
4523,-,I
4523,level,I
4523,sentiment,I
4523,classification,I
4523,(,I
4523,ASC,I
4523,),I
4523,",",O
4523,it,O
4523,is,O
4523,prevalent,O
4523,to,O
4523,equip,O
4523,dominant,O
4523,neural,O
4523,models,O
4523,with,O
4523,attention,O
4523,mechanisms,O
4523,",",O
4523,for,O
4523,the,O
4523,sake,O
4523,of,O
4523,acquiring,O
4523,the,O
4523,importance,O
4523,of,O
4523,each,O
4523,context,O
4523,word,O
4523,on,O
4523,the,O
4523,given,O
4523,aspect,O
4523,.,O
4524,In,O
4524,this,O
4524,paper,O
4524,",",O
4524,we,O
4524,propose,O
4524,a,O
4524,progressive,O
4524,self,O
4524,-,O
4524,supervised,O
4524,attention,O
4524,learning,O
4524,approach,O
4524,for,O
4524,neural,B
4524,ASC,I
4524,models,O
4524,",",O
4524,which,O
4524,automatically,O
4524,mines,O
4524,useful,O
4524,attention,O
4524,supervision,O
4524,information,O
4524,from,O
4524,a,O
4524,training,O
4524,corpus,O
4524,to,O
4524,refine,O
4524,attention,O
4524,mechanisms,O
4524,.,O
4525,Aspect,O
4525,-,O
4525,level,O
4525,sentiment,B
4525,classification,O
4525,(,O
4525,ASC,O
4525,),O
4525,",",O
4525,as,O
4525,an,O
4525,indispensable,O
4525,task,O
4525,in,O
4525,sentiment,O
4525,analysis,O
4525,",",O
4525,aims,O
4525,at,O
4525,inferring,O
4525,the,O
4525,sentiment,O
4525,polarity,O
4525,of,O
4525,an,O
4525,input,O
4525,sentence,O
4525,in,O
4525,a,O
4525,certain,O
4525,aspect,O
4525,.,O
4526,However,O
4526,",",O
4526,the,O
4526,existing,O
4526,attention,O
4526,mechanism,O
4526,in,O
4526,ASC,B
4526,suffers,O
4526,from,O
4526,a,O
4526,major,O
4526,drawback,O
4526,.,O
4527,First,O
4527,",",O
4527,both,B
4527,of,I
4527,our,I
4527,reimplemented,I
4527,MN,I
4527,and,I
4527,TNet,I
4527,are,O
4527,comparable,B
4527,to,I
4527,their,O
4527,original,B
4527,models,I
4527,reported,O
4527,in,O
4527,.,O
4528,When,O
4528,we,O
4528,replace,B
4528,the,O
4528,CNN,B
4528,of,B
4528,TNet,B
4528,with,B
4528,an,O
4528,attention,B
4528,mechanism,I
4528,",",O
4528,TNet,O
4528,-,O
4528,ATT,O
4528,is,O
4528,slightly,B
4528,inferior,I
4528,to,I
4528,TNet,O
4528,.,O
4529,Moreover,O
4529,",",O
4529,when,O
4529,we,O
4529,perform,B
4529,additional,B
4529,K+1,I
4529,-,I
4529,iteration,I
4529,of,B
4529,training,B
4529,on,B
4529,these,O
4529,models,O
4529,",",O
4529,their,O
4529,performance,B
4529,has,O
4529,not,B
4529,changed,I
4529,significantly,I
4529,",",O
4529,suggesting,O
4529,simply,O
4529,increasing,O
4529,training,O
4529,time,O
4529,is,O
4529,unable,O
4529,to,O
4529,enhance,O
4529,the,O
4529,performance,O
4529,of,O
4529,the,O
4529,neural,B
4529,ASC,I
4529,models,O
4529,.,O
4530,All,O
4530,the,O
4530,weights,B
4530,in,B
4530,the,O
4530,network,B
4530,are,O
4530,initialized,B
4530,from,I
4530,small,O
4530,random,B
4530,uniform,I
4530,noise,I
4530,.,O
4531,Finally,O
4531,",",O
4531,when,O
4531,we,O
4531,use,B
4531,both,B
4531,kinds,I
4531,of,I
4531,attention,I
4531,supervision,I
4531,information,I
4531,",",O
4531,no,O
4531,matter,O
4531,for,O
4531,which,O
4531,metric,O
4531,",",O
4531,MN,B
4531,(,I
4531,+,I
4531,AS,I
4531,),I
4531,remarkably,B
4531,outperforms,I
4531,MN,O
4531,on,B
4531,all,B
4531,test,I
4531,sets,I
4531,.,O
4532,RNTN,B
4532,:,O
4532,Recursive,B
4532,Tensor,I
4532,Neural,I
4532,Network,I
4532,),O
4532,is,O
4532,used,O
4532,to,B
4532,model,I
4532,correlations,B
4532,between,B
4532,different,B
4532,dimensions,I
4532,of,B
4532,child,B
4532,nodes,I
4532,vectors,I
4532,.,O
4533,(,O
4533,2014,O
4533,),O
4533,employs,B
4533,Long,B
4533,Short,I
4533,-,I
4533,Term,I
4533,Memory,I
4533,and,O
4533,the,O
4533,bidirectional,B
4533,variant,I
4533,to,B
4533,capture,I
4533,sequential,B
4533,information,I
4533,.,O
4534,Tree-LSTM,B
4534,:,O
4534,Memory,O
4534,cells,O
4534,was,O
4534,introduced,B
4534,by,I
4534,Tree,B
4534,-,I
4534,Structured,I
4534,Long,I
4534,Short,I
4534,-,O
4534,Term,O
4534,Memory,O
4534,and,O
4534,gates,B
4534,into,B
4534,tree,O
4534,-,O
4534,structured,O
4534,neural,O
4534,network,O
4534,",",O
4534,which,O
4534,is,O
4534,beneficial,O
4534,to,O
4534,capture,O
4534,semantic,O
4534,relatedness,O
4534,by,O
4534,parsing,O
4534,syntax,O
4534,trees,O
4534,.,O
4535,CNN,B
4535,:,O
4535,Convolutional,B
4535,Neural,I
4535,Networks,I
4535,),O
4535,is,O
4535,applied,O
4535,to,B
4535,generate,I
4535,task,B
4535,-,I
4535,specific,I
4535,sentence,I
4535,representation,I
4535,.,O
4536,NCSL,B
4536,:,O
4536,designs,O
4536,a,O
4536,Neural,B
4536,Context,I
4536,-,I
4536,Sensitive,I
4536,Lexicon,I
4536,(,I
4536,NSCL,I
4536,),I
4536,to,B
4536,obtain,I
4536,prior,B
4536,sentiment,I
4536,scores,I
4536,of,I
4536,words,I
4536,in,B
4536,the,O
4536,sentence,B
4536,.,O
4537,LR,O
4537,-,O
4537,Bi-LSTM,O
4537,:,O
4537,imposes,B
4537,linguistic,B
4537,roles,I
4537,into,B
4537,neural,B
4537,networks,I
4537,by,B
4537,applying,I
4537,linguistic,O
4537,regularization,O
4537,on,B
4537,intermediate,B
4537,outputs,I
4537,with,B
4537,KL,B
4537,divergence,I
4537,.,O
4538,Self,O
4538,-,O
4538,attention,O
4538,:,O
4538,proposes,B
4538,a,O
4538,selfattention,B
4538,mechanism,I
4538,to,B
4538,learn,I
4538,structured,B
4538,sentence,I
4538,embedding,I
4538,.,O
4539,ID,O
4539,-,O
4539,LSTM,O
4539,:,O
4539,uses,B
4539,reinforcement,B
4539,learning,I
4539,to,B
4539,learn,I
4539,structured,B
4539,sentence,I
4539,representation,I
4539,for,B
4539,sentiment,B
4539,classification,I
4539,.,O
4540,In,O
4540,our,O
4540,experiments,O
4540,",",O
4540,the,O
4540,dimensions,B
4540,of,B
4540,characterlevel,B
4540,embedding,I
4540,and,I
4540,word,I
4540,embedding,O
4540,(,O
4540,Glo,O
4540,Ve,O
4540,),O
4540,are,O
4540,both,O
4540,set,B
4540,to,I
4540,300,B
4540,.,O
4541,We,O
4541,tune,B
4541,our,O
4541,hyperparameters,B
4541,based,B
4541,on,B
4541,ACE05,B
4541,development,I
4541,set,I
4541,and,O
4541,use,B
4541,them,I
4541,for,I
4541,training,B
4541,on,O
4541,ACE04,B
4541,dataset,I
4541,.,O
4542,Kernel,O
4542,sizes,O
4542,of,B
4542,multi-gram,B
4542,convolution,I
4542,for,B
4542,Char,B
4542,-,I
4542,CNN,I
4542,are,O
4542,set,B
4542,to,I
4542,2,B
4542,",",I
4542,3,I
4542,",",O
4542,respectively,O
4542,.,O
4543,The,O
4543,size,B
4543,of,B
4543,mini-batch,B
4543,is,B
4543,60,B
4543,.,O
4544,The,O
4544,dropout,B
4544,rate,I
4544,is,B
4544,0.5,B
4544,",",O
4544,and,O
4544,the,O
4544,coefficient,B
4544,?,O
4545,of,B
4545,L,B
4545,2,I
4545,normalization,I
4545,is,O
4545,set,B
4545,to,I
4545,10,B
4545,?5,I
4545,.,O
4546,is,O
4546,set,B
4546,to,I
4546,10,O
4546,?,O
4547,All,O
4547,the,O
4547,weight,B
4547,matrices,I
4547,are,O
4547,initialized,B
4547,as,B
4547,random,B
4547,orthogonal,I
4547,matrices,O
4547,",",O
4547,and,O
4547,we,O
4547,set,B
4547,all,O
4547,the,O
4547,bias,O
4547,vectors,O
4547,as,O
4547,zero,B
4547,vectors,O
4547,.,O
4548,We,O
4548,optimize,B
4548,the,O
4548,proposed,B
4548,model,I
4548,with,B
4548,RMSprop,B
4548,algorithm,I
4548,",",O
4548,using,B
4548,mini-batch,B
4548,training,I
4548,.,O
4549,In,O
4549,this,O
4549,work,O
4549,",",O
4549,we,O
4549,propose,B
4549,a,O
4549,Multi-,B
4549,sentimentresource,I
4549,Enhanced,I
4549,Attention,I
4549,Network,I
4549,(,I
4549,MEAN,I
4549,),I
4549,for,B
4549,sentence,B
4549,-,I
4549,level,I
4549,sentiment,I
4549,classification,I
4549,to,B
4549,integrate,I
4549,many,B
4549,kinds,I
4549,of,I
4549,sentiment,O
4549,linguistic,O
4549,knowledge,O
4549,into,B
4549,deep,B
4549,neural,I
4549,networks,I
4549,via,B
4549,multi,B
4549,-path,I
4549,attention,O
4549,mechanism,O
4549,.,O
4550,Then,O
4550,",",O
4550,we,O
4550,propose,O
4550,a,O
4550,multisentiment,B
4550,-,I
4550,resource,I
4550,attention,B
4550,module,I
4550,to,I
4550,learn,I
4550,more,B
4550,comprehensive,I
4550,and,I
4550,meaningful,I
4550,sentiment,I
4550,-,O
4550,specific,O
4550,sentence,O
4550,representation,O
4550,by,B
4550,using,I
4550,the,O
4550,three,B
4550,types,I
4550,of,I
4550,sentiment,O
4550,resource,O
4550,words,O
4550,as,B
4550,attention,O
4550,sources,O
4550,attending,B
4550,to,O
4550,the,O
4550,context,B
4550,words,O
4550,respectively,O
4550,.,O
4551,In,O
4551,this,O
4551,way,O
4551,",",O
4551,we,O
4551,can,O
4551,attend,B
4551,to,I
4551,different,B
4551,sentimentrelevant,I
4551,information,I
4551,from,B
4551,different,O
4551,representation,O
4551,subspaces,O
4551,implied,B
4551,by,I
4551,different,O
4551,types,O
4551,of,B
4551,sentiment,B
4551,sources,I
4551,and,I
4551,capture,B
4551,the,O
4551,over,B
4551,all,I
4551,semantics,I
4551,of,O
4551,the,O
4551,sentiment,O
4551,",",O
4551,negation,O
4551,and,O
4551,intensity,O
4551,words,O
4551,for,B
4551,sentiment,O
4551,prediction,O
4551,.,O
4552,Specifically,O
4552,",",O
4552,we,O
4552,first,O
4552,design,B
4552,a,O
4552,coupled,B
4552,word,I
4552,embedding,I
4552,module,I
4552,to,B
4552,model,I
4552,the,O
4552,word,O
4552,representation,O
4552,from,B
4552,character,B
4552,-,I
4552,level,I
4552,and,I
4552,word,O
4552,-,O
4552,level,O
4552,semantics,O
4552,.,O
4553,In,O
4553,this,O
4553,paper,O
4553,",",O
4553,we,O
4553,propose,B
4553,a,O
4553,novel,B
4553,RNN,I
4553,-,I
4553,based,I
4553,model,I
4553,for,B
4553,the,O
4553,joint,B
4553,extraction,I
4553,of,I
4553,entity,I
4553,mentions,I
4553,and,I
4553,relations,I
4553,.,O
4554,A,O
4554,Multi-sentiment,O
4554,-,O
4554,resource,O
4554,Enhanced,O
4554,Attention,O
4554,Network,O
4554,for,O
4554,Sentiment,B
4554,Classification,I
4555,First,O
4555,",",O
4555,our,B
4555,model,I
4555,brings,B
4555,a,O
4555,substantial,B
4555,improvement,I
4555,over,B
4555,the,O
4555,methods,B
4555,that,B
4555,do,I
4555,not,I
4555,leverage,I
4555,sentiment,B
4555,linguistic,I
4555,knowledge,I
4555,(,O
4555,e.g.,O
4556,Second,O
4556,",",O
4556,our,O
4556,model,O
4556,also,O
4556,consistently,B
4556,outperforms,I
4556,LR,B
4556,-,I
4556,Bi,I
4556,-,O
4556,LSTM,O
4556,which,B
4556,integrates,I
4556,linguistic,B
4556,roles,I
4556,of,B
4556,sentiment,B
4556,",",O
4556,negation,O
4556,and,O
4556,intensity,O
4556,words,O
4556,into,B
4556,neural,B
4556,networks,I
4556,via,B
4556,the,O
4556,linguistic,O
4556,regularization,O
4556,.,O
4557,For,O
4557,example,O
4557,",",O
4557,our,O
4557,model,O
4557,achieves,B
4557,2.4,B
4557,%,I
4557,improvements,I
4557,over,B
4557,the,O
4557,MR,B
4557,dataset,I
4557,and,O
4557,0.8,B
4557,%,O
4557,improvements,O
4557,over,O
4557,the,O
4557,SST,B
4557,dataset,O
4557,compared,B
4557,to,I
4557,LR,I
4557,-,I
4557,Bi,I
4557,-,O
4557,LSTM,O
4557,.,O
4558,Comparing,O
4558,the,O
4558,results,O
4558,of,B
4558,AEN,B
4558,-,I
4558,GloVe,I
4558,and,I
4558,AEN,O
4558,-,O
4558,Glo,O
4558,Ve,O
4558,w,O
4558,/,O
4558,o,O
4558,LSR,O
4558,",",O
4558,we,O
4558,observe,B
4558,that,O
4558,the,O
4558,accuracy,B
4558,of,O
4558,AEN,O
4558,-,O
4558,Glo,O
4558,Ve,O
4558,w,O
4558,/,O
4558,o,O
4558,LSR,O
4558,drops,B
4558,significantly,B
4558,on,B
4558,all,B
4558,three,I
4558,datasets,I
4558,.,O
4559,The,O
4559,over,B
4559,all,I
4559,performance,I
4559,of,B
4559,AEN,B
4559,-,I
4559,GloVe,I
4559,and,I
4559,AEN,O
4559,-,O
4559,Glo,O
4559,Ve,O
4559,-,O
4559,BiLSTM,O
4559,is,B
4559,relatively,B
4559,close,I
4559,",",O
4559,AEN,O
4559,-,O
4559,Glo,O
4559,Ve,O
4559,performs,B
4559,better,B
4559,on,B
4559,the,O
4559,Restaurant,B
4559,dataset,I
4559,.,O
4560,More,O
4560,importantly,O
4560,",",O
4560,AEN,B
4560,-,I
4560,Glo,I
4560,Ve,I
4560,has,O
4560,fewer,B
4560,parameters,I
4560,and,O
4560,is,O
4560,easier,B
4560,to,I
4560,parallelize,B
4560,.,O
4561,AEN,O
4561,-,O
4561,Glo,O
4561,Ve,O
4561,'s,O
4561,lightweight,O
4561,level,O
4561,ranks,B
4561,second,B
4561,",",O
4561,since,O
4561,it,O
4561,takes,O
4561,some,O
4561,more,O
4561,parameters,O
4561,than,O
4561,MemNet,O
4561,in,O
4561,modeling,O
4561,hidden,O
4561,states,O
4561,of,O
4561,sequences,O
4561,.,O
4562,As,O
4562,a,O
4562,comparison,O
4562,",",O
4562,the,O
4562,model,B
4562,size,I
4562,of,B
4562,AEN,B
4562,-,I
4562,Glo,I
4562,Ve,I
4562,-,O
4562,BiLSTM,O
4562,is,O
4562,more,B
4562,than,I
4562,twice,B
4562,that,O
4562,of,O
4562,AEN,O
4562,-,O
4562,GloVe,O
4562,",",O
4562,but,O
4562,does,B
4562,not,I
4562,bring,I
4562,any,B
4562,performance,I
4562,improvements,I
4562,.,O
4563,We,O
4563,also,O
4563,design,B
4563,a,O
4563,basic,B
4563,BERT,I
4563,-,I
4563,based,I
4563,model,I
4563,to,B
4563,evaluate,I
4563,the,O
4563,performance,B
4563,of,B
4563,AEN,B
4563,-,O
4563,BERT,O
4563,.,O
4564,MultiR,B
4564,:,O
4564,Probabilistic,B
4564,graphical,I
4564,model,I
4564,for,B
4564,multi,B
4564,instance,I
4564,learning,I
4564,by,O
4564,MIMLRE,B
4564,:,O
4565,Unlike,O
4565,other,O
4565,models,O
4565,",",O
4565,our,O
4565,model,O
4565,does,B
4565,not,I
4565,depend,B
4565,on,B
4565,any,B
4565,dependency,I
4565,tree,I
4565,information,I
4565,.,O
4566,Feature,O
4566,-,O
4566,based,O
4566,SVM,O
4566,is,B
4566,a,O
4566,traditional,B
4566,support,I
4566,vector,I
4566,machine,I
4566,based,O
4566,model,O
4566,with,B
4566,extensive,B
4566,feature,O
4566,engineering,O
4566,.,O
4567,Rec,O
4567,-,O
4567,NN,O
4567,firstly,O
4567,uses,B
4567,rules,B
4567,to,B
4567,transform,I
4567,the,O
4567,dependency,B
4567,tree,I
4567,and,O
4567,put,B
4567,the,O
4567,opinion,B
4567,target,B
4567,at,B
4567,the,O
4567,root,B
4567,",",O
4567,and,O
4567,then,O
4567,learns,B
4567,the,O
4567,sentence,B
4567,representation,I
4567,toward,B
4567,target,O
4567,via,B
4567,semantic,B
4567,composition,I
4567,using,B
4567,Recursive,B
4567,NNs,I
4567,.,O
4568,MemNet,B
4568,uses,B
4568,multi-hops,B
4568,of,B
4568,attention,I
4568,layers,I
4568,on,B
4568,the,O
4568,context,O
4568,word,O
4568,embeddings,O
4568,for,B
4568,sentence,B
4568,representation,I
4568,to,B
4568,explicitly,I
4568,captures,I
4568,the,O
4568,importance,B
4568,of,O
4568,each,B
4568,context,O
4568,word,O
4568,.,O
4569,TD,O
4569,-,O
4569,LSTM,O
4569,extends,B
4569,LSTM,O
4569,by,B
4569,using,I
4569,two,B
4569,LSTM,O
4569,networks,O
4569,to,B
4569,model,I
4569,the,O
4569,left,B
4569,context,I
4569,with,B
4569,target,B
4569,and,O
4569,the,O
4569,right,B
4569,context,O
4569,with,O
4569,target,O
4569,respectively,O
4569,.,O
4570,",",O
4570,2016,O
4570,),O
4570,strengthens,B
4570,the,O
4570,effect,B
4570,of,I
4570,target,B
4570,embeddings,I
4570,",",O
4570,which,B
4570,appends,I
4570,the,O
4570,target,O
4570,embeddings,O
4570,with,B
4570,each,B
4570,word,I
4570,embeddings,O
4570,and,O
4570,use,B
4570,LSTM,B
4570,with,O
4570,attention,B
4570,to,B
4570,get,I
4570,the,O
4570,final,B
4570,representation,I
4570,for,B
4570,classification,B
4570,.,O
4571,IAN,B
4571,learns,B
4571,the,O
4571,representations,B
4571,of,B
4571,the,O
4571,target,B
4571,and,I
4571,context,I
4571,with,B
4571,two,B
4571,LSTMs,I
4571,and,O
4571,attentions,O
4571,interactively,O
4571,",",O
4571,which,B
4571,generates,I
4571,the,O
4571,representations,O
4571,for,B
4571,targets,B
4571,and,O
4571,contexts,O
4571,with,O
4571,respect,O
4571,to,O
4571,each,B
4571,other,I
4571,.,O
4572,RAM,B
4572,strengthens,B
4572,Mem,B
4572,-,I
4572,Net,I
4572,by,B
4572,representing,I
4572,memory,B
4572,with,B
4572,bidirectional,B
4572,LSTM,I
4572,and,O
4572,using,B
4572,a,O
4572,gated,B
4572,recurrent,I
4572,unit,I
4572,network,I
4572,to,B
4572,combine,I
4572,the,O
4572,multiple,B
4572,attention,I
4572,outputs,I
4572,for,B
4572,sentence,B
4572,representation,I
4572,.,O
4573,Our,O
4573,RNN,O
4573,-,O
4573,based,O
4573,model,O
4573,is,B
4573,a,O
4573,multi,B
4573,-,O
4573,layer,O
4573,bidirectional,O
4573,LSTM,O
4573,over,B
4573,a,O
4573,sequence,B
4573,.,O
4574,AEN,O
4574,-,O
4574,GloVe,O
4574,w/,O
4574,o,O
4574,PCT,B
4574,ablates,B
4574,PCT,O
4574,module,O
4574,.,O
4575,AEN,O
4575,-,O
4575,GloVe,O
4575,w/,O
4575,o,O
4575,MHA,B
4575,ablates,B
4575,MHA,O
4575,module,O
4575,.,O
4576,AEN,O
4576,-,O
4576,GloVe,O
4576,w/,O
4576,o,O
4576,LSR,O
4576,ablates,B
4576,label,B
4576,smoothing,I
4576,regularization,I
4576,.,O
4577,AEN-GloVe-BiLSTM,B
4577,replaces,B
4577,the,O
4577,attentional,B
4577,encoder,I
4577,layer,I
4577,with,B
4577,two,B
4577,bidirectional,I
4577,LSTM,I
4577,.,O
4578,BERT,O
4578,-,O
4578,SPC,O
4578,feeds,B
4578,sequence,B
4578,"""",I
4578,[,I
4578,CLS,I
4578,],I
4578,+,I
4578,context,I
4578,+,O
4578,[,O
4578,SEP,O
4578,],O
4578,+,O
4578,target,O
4578,+,O
4578,[,O
4578,SEP,O
4578,],O
4578,"""",O
4578,into,B
4578,the,O
4578,basic,B
4578,BERT,O
4578,model,O
4578,for,B
4578,sentence,B
4578,pair,I
4578,classification,I
4578,task,I
4578,.,O
4579,shows,B
4579,the,O
4579,number,B
4579,of,I
4579,training,I
4579,and,I
4579,test,I
4579,instances,I
4579,in,B
4579,each,B
4579,category,I
4579,.,O
4580,Word,O
4580,embeddings,O
4580,in,B
4580,AEN,B
4580,-,I
4580,Glo,I
4580,Ve,I
4580,do,B
4580,not,I
4580,get,I
4580,updated,I
4580,in,O
4580,the,O
4580,learning,B
4580,process,I
4580,",",O
4580,but,O
4580,we,O
4580,fine,B
4580,-,O
4580,tune,O
4580,pre-trained,B
4580,BERT,I
4580,3,O
4580,in,O
4580,AEN,O
4580,-,O
4580,BERT,O
4580,.,O
4581,Embedding,O
4581,dimension,O
4581,d,O
4581,dim,O
4581,is,B
4581,300,B
4581,for,B
4581,GloVe,B
4581,and,O
4581,is,O
4581,768,B
4581,for,O
4581,pretrained,B
4581,BERT,I
4581,.,O
4582,We,O
4582,encode,B
4582,the,O
4582,output,B
4582,sequence,I
4582,from,B
4582,left,B
4582,-,I
4582,to,I
4582,-,O
4582,right,O
4582,.,O
4583,Dimension,B
4583,of,B
4583,hidden,B
4583,states,I
4583,d,I
4583,hid,I
4583,is,O
4583,set,B
4583,to,I
4583,300,B
4583,.,O
4584,The,O
4584,weights,B
4584,of,B
4584,our,B
4584,model,I
4584,are,O
4584,initialized,B
4584,with,I
4584,Glorot,B
4584,initialization,I
4584,.,O
4585,Adam,O
4585,optimizer,O
4585,(,O
4585,Kingma,O
4585,and,O
4585,Ba,O
4585,",",O
4585,2014,O
4585,),O
4585,is,O
4585,applied,B
4585,to,I
4585,update,B
4585,all,B
4585,the,I
4585,parameters,I
4585,.,O
4586,During,B
4586,training,B
4586,",",O
4586,we,O
4586,set,B
4586,label,B
4586,smoothing,I
4586,parameter,I
4586,to,B
4586,0.2,B
4586,",",O
4586,the,O
4586,coefficient,O
4586,?,O
4587,of,O
4587,L,O
4587,2,O
4587,regularization,O
4587,item,O
4587,is,B
4587,10,O
4587,?,O
4588,5,O
4588,and,O
4588,dropout,B
4588,rate,I
4588,is,B
4588,0.1,B
4588,.,O
4589,This,O
4589,paper,O
4589,propose,B
4589,an,O
4589,attention,B
4589,based,I
4589,model,I
4589,to,O
4589,solve,O
4589,the,O
4589,problems,O
4589,above,O
4589,.,O
4590,Specifically,O
4590,",",O
4590,our,B
4590,model,I
4590,eschews,B
4590,recurrence,B
4590,and,I
4590,employs,B
4590,attention,B
4590,as,B
4590,a,O
4590,competitive,B
4590,alternative,I
4590,to,B
4590,draw,I
4590,the,O
4590,introspective,B
4590,and,O
4590,interactive,O
4590,semantics,O
4590,between,B
4590,target,B
4590,and,O
4590,context,O
4590,words,O
4590,.,O
4591,To,O
4591,deal,O
4591,with,B
4591,the,O
4591,label,B
4591,unreliability,I
4591,issue,I
4591,",",O
4591,we,O
4591,employ,B
4591,a,O
4591,label,O
4591,smoothing,O
4591,regularization,O
4591,to,O
4591,encourage,O
4591,the,O
4591,model,B
4591,to,O
4591,be,O
4591,less,B
4591,confident,I
4591,with,O
4591,fuzzy,B
4591,labels,I
4591,.,O
4592,We,O
4592,also,O
4592,apply,B
4592,pre-trained,B
4592,BERT,I
4592,to,O
4592,this,O
4592,task,O
4592,and,O
4592,show,O
4592,our,O
4592,model,O
4592,enhances,O
4592,the,O
4592,performance,O
4592,of,O
4592,basic,O
4592,BERT,O
4592,model,O
4592,.,O
4593,Attentional,O
4593,Encoder,O
4593,Network,O
4593,for,O
4593,Targeted,B
4593,Sentiment,I
4593,Classification,I
4594,Targeted,O
4594,sentiment,O
4594,classification,O
4594,is,O
4594,a,O
4594,fine,B
4594,-,I
4594,grained,I
4594,sentiment,O
4594,analysis,O
4594,task,O
4594,",",O
4594,which,O
4594,aims,O
4594,at,O
4594,determining,O
4594,the,O
4594,sentiment,O
4594,polarities,O
4594,(,O
4594,e.g.,O
4595,At,B
4595,each,B
4595,time,I
4595,step,I
4595,",",O
4595,we,O
4595,use,B
4595,an,O
4595,attention,B
4595,-,I
4595,like,I
4595,model,I
4595,on,B
4595,the,O
4595,previously,B
4595,decoded,I
4595,time,O
4595,steps,O
4595,",",O
4595,to,B
4595,identify,I
4595,the,O
4595,tokens,B
4595,in,B
4595,a,O
4595,specified,B
4595,relation,I
4595,with,B
4595,the,O
4595,current,B
4595,token,I
4595,.,O
4596,However,O
4596,",",O
4596,these,O
4596,neural,O
4596,network,O
4596,models,O
4596,are,O
4596,still,O
4596,in,O
4596,infancy,O
4596,to,O
4596,deal,O
4596,with,O
4596,the,O
4596,fine,B
4596,-,I
4596,grained,I
4596,targeted,I
4596,sentiment,I
4596,classification,I
4596,task,O
4596,.,O
4597,The,O
4597,over,B
4597,all,I
4597,performance,I
4597,of,B
4597,TD,B
4597,-,I
4597,LSTM,I
4597,is,B
4597,not,B
4597,good,I
4597,since,O
4597,it,O
4597,only,O
4597,makes,B
4597,a,O
4597,rough,B
4597,treatment,I
4597,of,O
4597,the,O
4597,target,B
4597,words,I
4597,.,O
4598,ATAE,O
4598,-,O
4598,LSTM,O
4598,",",O
4598,IAN,O
4598,and,O
4598,RAM,O
4598,are,B
4598,attention,B
4598,based,I
4598,models,I
4598,",",O
4598,they,O
4598,stably,B
4598,exceed,I
4598,the,O
4598,TD,B
4598,-,O
4598,LSTM,O
4598,method,O
4598,on,B
4598,Restaurant,B
4598,and,O
4598,Laptop,O
4598,datasets,O
4598,.,O
4599,RAM,B
4599,is,O
4599,better,B
4599,than,I
4599,other,B
4599,RNN,I
4599,based,I
4599,models,I
4599,",",O
4599,but,O
4599,it,O
4599,does,B
4599,not,I
4599,perform,I
4599,well,B
4599,on,B
4599,Twitter,B
4599,dataset,I
4599,",",O
4599,which,O
4599,might,O
4599,because,O
4599,bidirectional,O
4599,LSTM,O
4599,is,O
4599,not,O
4599,good,O
4599,at,O
4599,modeling,O
4599,small,O
4599,and,O
4599,ungrammatical,O
4599,text,O
4599,.,O
4600,Feature,O
4600,-,O
4600,based,O
4600,SVM,O
4600,is,O
4600,still,B
4600,a,O
4600,competitive,B
4600,baseline,I
4600,",",O
4600,but,O
4600,relying,B
4600,on,I
4600,manually,B
4600,-,O
4600,designed,O
4600,features,O
4600,.,O
4601,Rec,O
4601,-,O
4601,NN,O
4601,gets,B
4601,the,O
4601,worst,B
4601,performances,I
4601,among,B
4601,all,B
4601,neural,I
4601,network,I
4601,baselines,I
4601,as,O
4601,dependency,O
4601,parsing,O
4601,is,O
4601,not,O
4601,guaranteed,O
4601,to,O
4601,work,O
4601,well,O
4601,on,O
4601,ungrammatical,O
4601,short,O
4601,texts,O
4601,such,O
4601,as,O
4601,tweets,O
4601,and,O
4601,comments,O
4601,.,O
4602,Like,B
4602,AEN,B
4602,",",O
4602,Mem,B
4602,Net,I
4602,also,O
4602,eschews,B
4602,recurrence,B
4602,",",O
4602,but,O
4602,its,O
4602,over,B
4602,all,I
4602,performance,I
4602,is,B
4602,not,B
4602,good,I
4602,since,O
4602,it,O
4602,does,O
4602,not,O
4602,model,O
4602,the,O
4602,hidden,O
4602,semantic,O
4602,of,O
4602,embeddings,O
4602,",",O
4602,and,O
4602,the,O
4602,result,O
4602,of,O
4602,the,O
4602,last,O
4602,attention,O
4602,is,O
4602,essentially,O
4602,a,O
4602,linear,O
4602,combination,O
4602,of,O
4602,word,O
4602,embeddings,O
4602,.,O
4603,Majority,B
4603,is,B
4603,a,O
4603,basic,B
4603,baseline,I
4603,method,I
4603,",",O
4603,which,O
4603,assigns,B
4603,the,O
4603,largest,B
4603,sentiment,I
4603,polarity,I
4603,in,B
4603,the,O
4603,training,B
4603,set,I
4603,to,B
4603,each,B
4603,sample,I
4603,in,O
4603,the,O
4603,test,B
4603,set,O
4603,.,O
4604,LSTM,O
4604,only,O
4604,uses,B
4604,one,B
4604,LSTM,O
4604,network,O
4604,to,B
4604,model,I
4604,the,O
4604,context,B
4604,and,O
4604,get,B
4604,the,O
4604,hidden,B
4604,state,I
4604,of,B
4604,each,B
4604,word,I
4604,.,O
4605,TD,O
4605,-,O
4605,LSTM,O
4605,adopts,B
4605,two,B
4605,long,I
4605,short,I
4605,-,O
4605,term,O
4605,memory,O
4605,(,O
4605,LSTM,O
4605,),O
4605,networks,O
4605,to,B
4605,model,I
4605,the,O
4605,left,B
4605,context,I
4605,with,B
4605,target,B
4605,and,O
4605,the,O
4605,right,B
4605,context,O
4605,with,O
4605,target,O
4605,respectively,O
4605,.,O
4606,We,O
4606,also,O
4606,add,B
4606,an,O
4606,additional,B
4606,layer,I
4606,to,I
4606,our,B
4606,network,I
4606,to,O
4606,encode,O
4606,the,O
4606,output,B
4606,sequence,I
4606,from,B
4606,right,B
4606,-,I
4606,to,O
4606,-,O
4606,left,O
4606,and,O
4606,find,O
4606,significant,O
4606,improvement,O
4606,on,O
4606,the,O
4606,performance,O
4606,of,O
4606,relation,O
4606,identification,O
4606,using,O
4606,bi-directional,O
4606,encoding,O
4606,.,O
4607,AE,O
4607,-,O
4607,LSTM,O
4607,represents,B
4607,targets,B
4607,with,B
4607,aspect,B
4607,embeddings,I
4607,.,O
4608,ATAE,O
4608,-,O
4608,LSTM,O
4608,is,O
4608,developed,O
4608,based,B
4608,on,I
4608,AE,B
4608,-,O
4608,LSTM,O
4608,.,O
4609,In,O
4609,our,O
4609,experiments,O
4609,",",O
4609,all,B
4609,word,I
4609,embeddings,I
4609,from,B
4609,context,B
4609,and,I
4609,target,I
4609,are,O
4609,initialized,B
4609,by,I
4609,GloVe,B
4609,2,O
4609,",",O
4609,and,O
4609,all,O
4609,out,O
4609,-,O
4609,of,O
4609,-,O
4609,vocabulary,O
4609,words,O
4609,are,O
4609,initialized,O
4609,by,O
4609,sampling,B
4609,from,O
4609,the,O
4609,uniform,B
4609,distribution,I
4609,U,I
4609,(,I
4609,?0.1,I
4609,",",O
4609,0.1,O
4609,),O
4609,.,O
4610,All,O
4610,weight,B
4610,matrices,I
4610,are,O
4610,given,B
4610,their,I
4610,initial,B
4610,values,I
4610,by,O
4610,sampling,B
4610,from,I
4610,uniform,B
4610,distribution,I
4610,U,I
4610,(,I
4610,?0.1,I
4610,",",I
4610,0.1,I
4610,),I
4610,",",O
4610,and,O
4610,all,O
4610,biases,B
4610,are,O
4610,set,B
4610,to,I
4610,zeros,B
4610,.,O
4611,The,O
4611,dimensions,B
4611,of,B
4611,word,B
4611,embeddings,I
4611,",",I
4611,attention,I
4611,vectors,I
4611,and,I
4611,LSTM,I
4611,hidden,I
4611,states,I
4611,are,O
4611,set,B
4611,to,I
4611,300,B
4611,as,O
4611,in,O
4611,.,O
4612,The,O
4612,coefficient,B
4612,of,B
4612,L,B
4612,2,I
4612,normalization,I
4612,in,B
4612,the,O
4612,objective,B
4612,function,I
4612,is,O
4612,set,B
4612,to,I
4612,10,B
4612,?5,I
4612,",",O
4612,and,O
4612,the,O
4612,dropout,B
4612,rate,I
4612,is,O
4612,set,O
4612,to,O
4612,0.5,B
4612,.,O
4613,To,O
4613,train,B
4613,the,O
4613,parameters,B
4613,of,B
4613,IAN,B
4613,",",O
4613,we,O
4613,employ,B
4613,the,O
4613,Momentum,B
4613,",",O
4613,which,O
4613,adds,B
4613,a,O
4613,fraction,B
4613,?,O
4614,of,B
4614,the,O
4614,update,O
4614,vector,O
4614,in,B
4614,the,O
4614,prior,B
4614,step,I
4614,to,B
4614,the,O
4614,current,B
4614,update,O
4614,vector,O
4614,.,O
4615,Based,O
4615,on,O
4615,the,O
4615,two,O
4615,points,O
4615,analyzed,O
4615,above,O
4615,",",O
4615,we,O
4615,propose,B
4615,an,O
4615,interactive,B
4615,attention,B
4615,network,I
4615,(,I
4615,IAN,I
4615,),I
4615,model,I
4615,which,O
4615,is,O
4615,based,O
4615,on,O
4615,long,B
4615,-,I
4615,short,I
4615,term,I
4615,memory,I
4615,networks,I
4615,(,O
4615,LSTM,O
4615,),O
4615,and,O
4615,attention,O
4615,mechanism,O
4615,.,O
4616,IAN,B
4616,utilizes,B
4616,the,O
4616,attention,B
4616,mechanism,I
4616,associated,B
4616,with,I
4616,a,O
4616,target,B
4616,to,B
4616,get,I
4616,important,B
4616,information,I
4616,from,B
4616,the,O
4616,context,B
4616,and,O
4616,compute,B
4616,context,O
4616,representation,O
4616,for,B
4616,sentiment,B
4616,classification,I
4616,.,O
4617,Further,O
4617,",",O
4617,IAN,O
4617,makes,B
4617,use,I
4617,of,B
4617,the,O
4617,interactive,B
4617,information,I
4617,from,B
4617,context,B
4617,to,B
4617,supervise,I
4617,the,O
4617,modeling,B
4617,of,O
4617,the,O
4617,target,B
4617,which,O
4617,is,O
4617,helpful,O
4617,to,O
4617,judging,O
4617,sentiment,O
4617,.,O
4618,Going,O
4618,out,O
4618,on,O
4618,a,O
4618,limb,O
4618,:,O
4618,Joint,B
4618,Extraction,I
4618,of,I
4618,Entity,I
4618,Mentions,I
4618,and,I
4618,Relations,I
4618,without,O
4618,Dependency,O
4618,Trees,O
4619,Finally,O
4619,",",O
4619,with,B
4619,both,B
4619,target,I
4619,representation,I
4619,and,I
4619,context,I
4619,representation,O
4619,concatenated,O
4619,",",O
4619,IAN,O
4619,predicts,B
4619,the,O
4619,sentiment,B
4619,polarity,I
4619,for,B
4619,the,O
4619,target,O
4619,within,B
4619,its,B
4619,context,O
4619,.,O
4620,Interactive,O
4620,Attention,O
4620,Networks,O
4620,for,O
4620,Aspect,B
4620,-,I
4620,Level,I
4620,Sentiment,I
4620,Classification,I
4621,Previous,O
4621,approaches,O
4621,have,O
4621,realized,O
4621,the,O
4621,importance,O
4621,of,O
4621,targets,O
4621,in,O
4621,sentiment,B
4621,classification,I
4621,and,O
4621,developed,O
4621,various,O
4621,methods,O
4621,with,O
4621,the,O
4621,goal,O
4621,of,O
4621,precisely,O
4621,modeling,O
4621,their,O
4621,contexts,O
4621,via,O
4621,generating,O
4621,target,O
4621,-,O
4621,specific,O
4621,representations,O
4621,.,O
4622,All,O
4622,the,O
4622,other,O
4622,methods,O
4622,are,O
4622,based,B
4622,on,I
4622,LSTM,B
4622,models,I
4622,and,O
4622,better,B
4622,than,I
4622,the,O
4622,Majority,B
4622,method,I
4622,",",O
4622,showing,O
4622,that,O
4622,LSTM,O
4622,has,O
4622,potentials,O
4622,in,O
4622,automatically,O
4622,generating,O
4622,representations,O
4622,and,O
4622,can,O
4622,all,O
4622,bring,O
4622,performance,O
4622,improvement,O
4622,for,O
4622,sentiment,O
4622,classification,O
4622,.,O
4623,The,O
4623,LSTM,B
4623,method,I
4623,gets,B
4623,the,O
4623,worst,B
4623,performance,I
4623,of,B
4623,all,B
4623,the,O
4623,neural,O
4623,network,O
4623,baseline,O
4623,methods,O
4623,",",O
4623,because,O
4623,it,O
4623,treats,O
4623,targets,O
4623,equally,O
4623,with,O
4623,other,O
4623,context,O
4623,words,O
4623,and,O
4623,does,O
4623,not,O
4623,make,O
4623,full,O
4623,use,O
4623,of,O
4623,the,O
4623,target,O
4623,information,O
4623,.,O
4624,TD,O
4624,-,O
4624,LSTM,B
4624,outperforms,B
4624,LSTM,O
4624,over,B
4624,1,B
4624,percent,I
4624,and,I
4624,2,I
4624,percent,O
4624,on,B
4624,the,O
4624,Restaurant,B
4624,and,O
4624,Laptop,O
4624,category,O
4624,respectively,O
4624,",",O
4624,since,O
4624,it,O
4624,develops,O
4624,from,O
4624,the,O
4624,standard,O
4624,LSTM,O
4624,and,O
4624,processes,O
4624,the,O
4624,left,O
4624,and,O
4624,right,O
4624,contexts,O
4624,with,O
4624,targets,O
4624,.,O
4625,Further,O
4625,",",O
4625,both,B
4625,AE,I
4625,-,I
4625,LSTM,I
4625,and,I
4625,ATAE,I
4625,-,O
4625,LSTM,O
4625,stably,B
4625,exceed,I
4625,the,O
4625,TD,B
4625,-,O
4625,LSTM,O
4625,method,O
4625,because,O
4625,of,O
4625,the,O
4625,introduction,O
4625,of,O
4625,attention,O
4625,mechanism,O
4625,.,O
4626,Compared,O
4626,with,O
4626,AE,B
4626,-,I
4626,LSTM,I
4626,",",O
4626,ATAE,B
4626,-,O
4626,LSTM,O
4626,especially,B
4626,enhance,I
4626,the,O
4626,interaction,B
4626,between,B
4626,the,O
4626,context,B
4626,words,I
4626,and,I
4626,target,I
4626,and,O
4626,thus,O
4626,has,O
4626,a,O
4626,better,B
4626,performance,I
4626,than,B
4626,AE,O
4626,-,O
4626,LSTM,O
4626,.,O
4627,The,O
4627,more,B
4627,attentions,I
4627,are,O
4627,paid,B
4627,to,I
4627,targets,B
4627,",",O
4627,the,O
4627,higher,B
4627,accuracy,I
4627,the,O
4627,system,O
4627,achieves,B
4627,.,O
4628,For,B
4628,AE,B
4628,-,I
4628,LSTM,I
4628,and,I
4628,ATAE,I
4628,-,O
4628,LSTM,O
4628,",",O
4628,they,O
4628,capture,B
4628,important,B
4628,information,I
4628,in,B
4628,the,O
4628,context,B
4628,with,B
4628,the,O
4628,supervision,B
4628,of,B
4628,target,B
4628,and,O
4628,generate,B
4628,more,B
4628,reasonable,I
4628,representations,I
4628,for,O
4628,aspect,B
4628,-,O
4628,level,O
4628,sentiment,O
4628,classification,O
4628,.,O
4629,We,O
4629,can,O
4629,also,O
4629,see,B
4629,that,O
4629,AE,B
4629,-,I
4629,LSTM,I
4629,and,I
4629,ATAE,I
4629,-,O
4629,LSTM,O
4629,further,O
4629,emphasize,B
4629,the,I
4629,modeling,B
4629,of,I
4629,targets,B
4629,via,B
4629,the,O
4629,addition,B
4629,of,O
4629,the,O
4629,aspect,O
4629,embedding,O
4629,",",O
4629,which,O
4629,is,O
4629,also,O
4629,the,O
4629,reason,O
4629,of,O
4629,performance,O
4629,improvement,O
4629,.,O
4630,We,O
4630,can,O
4630,see,O
4630,that,O
4630,IAN,B
4630,achieves,B
4630,the,O
4630,best,B
4630,performance,I
4630,among,B
4630,all,B
4630,baselines,I
4630,.,O
4631,Compared,O
4631,with,O
4631,ATAE,B
4631,-,I
4631,LSTM,I
4631,model,I
4631,",",O
4631,IAN,B
4631,improves,B
4631,the,O
4631,performance,B
4631,about,B
4631,1.4,B
4631,%,I
4631,and,I
4631,3.2,I
4631,%,O
4631,on,B
4631,the,O
4631,Restaurant,B
4631,and,O
4631,Laptop,O
4631,categories,O
4631,respectively,O
4631,.,O
4632,In,O
4632,this,O
4632,paper,O
4632,",",O
4632,we,O
4632,discard,O
4632,such,O
4632,an,O
4632,oversimplifying,O
4632,hypothesis,O
4632,and,O
4632,develop,B
4632,a,O
4632,framework,B
4632,based,B
4632,on,I
4632,long,B
4632,shortterm,I
4632,memory,I
4632,(,I
4632,LSTM,I
4632,),I
4632,that,O
4632,takes,B
4632,a,O
4632,sequence,B
4632,of,I
4632,utterances,I
4632,as,B
4632,input,B
4632,and,O
4632,extracts,B
4632,contextual,B
4632,utterancelevel,I
4632,features,I
4632,.,O
4633,Our,O
4633,model,O
4633,preserves,B
4633,the,O
4633,sequential,B
4633,order,I
4633,of,B
4633,utterances,I
4633,and,O
4633,enables,B
4633,consecutive,B
4633,utterances,O
4633,to,B
4633,share,I
4633,information,I
4633,",",O
4633,thus,O
4633,providing,B
4633,contextual,B
4633,information,O
4633,to,O
4633,the,O
4633,utterance,B
4633,-,I
4633,level,I
4633,sentiment,I
4633,classification,I
4633,process,I
4633,.,O
4634,Multimodal,O
4634,sentiment,O
4634,analysis,O
4634,is,O
4634,a,O
4634,developing,O
4634,area,O
4634,of,O
4634,research,O
4634,",",O
4634,which,O
4634,involves,O
4634,the,O
4634,identification,B
4634,of,O
4634,sentiments,O
4634,in,O
4634,videos,O
4634,.,O
4635,Recently,O
4635,",",O
4635,a,O
4635,number,O
4635,of,O
4635,approaches,O
4635,to,O
4635,multimodal,B
4635,sentiment,I
4635,analysis,I
4635,",",O
4635,producing,O
4635,interesting,O
4635,results,O
4635,",",O
4635,have,O
4635,been,O
4635,proposed,O
4635,.,O
4636,Several,O
4636,methods,O
4636,have,O
4636,been,O
4636,proposed,O
4636,for,O
4636,entity,B
4636,mention,I
4636,and,I
4636,relation,I
4636,extraction,I
4636,at,I
4636,the,I
4636,sentencelevel,I
4636,.,O
4637,As,O
4637,expected,O
4637,",",O
4637,trained,B
4637,contextual,I
4637,unimodal,I
4637,features,I
4637,help,B
4637,the,O
4637,hierarchical,B
4637,fusion,I
4637,framework,I
4637,to,B
4637,outperform,I
4637,the,O
4637,non-hierarchical,B
4637,framework,O
4637,.,O
4638,The,O
4638,non-hierarchical,B
4638,model,I
4638,outperforms,B
4638,the,O
4638,baseline,B
4638,uni,I
4638,-,I
4638,SVM,I
4638,",",O
4638,which,O
4638,confirms,O
4638,that,O
4638,it,O
4638,is,O
4638,the,O
4638,contextsensitive,O
4638,learning,O
4638,paradigm,O
4638,that,O
4638,plays,O
4638,the,O
4638,key,O
4638,role,O
4638,in,O
4638,improving,O
4638,performance,O
4638,over,O
4638,the,O
4638,baseline,O
4638,.,O
4639,Since,O
4639,bc,B
4639,-,I
4639,LSTM,I
4639,has,B
4639,access,I
4639,to,I
4639,both,O
4639,the,O
4639,preceding,B
4639,and,I
4639,following,I
4639,information,I
4639,of,B
4639,the,O
4639,utterance,B
4639,sequence,I
4639,",",O
4639,it,O
4639,performs,B
4639,consistently,B
4639,better,I
4639,on,B
4639,all,B
4639,the,O
4639,datasets,O
4639,over,O
4639,sc,O
4639,-,O
4639,LSTM,O
4639,.,O
4640,The,O
4640,performance,B
4640,improvement,I
4640,is,B
4640,in,B
4640,the,O
4640,range,O
4640,of,B
4640,0.3,B
4640,%,I
4640,to,I
4640,1.5,I
4640,%,O
4640,on,B
4640,MOSI,B
4640,and,I
4640,MOUD,I
4640,datasets,I
4640,.,O
4641,Every,O
4641,LSTM,O
4641,network,O
4641,variant,O
4641,has,O
4641,outperformed,B
4641,the,I
4641,baseline,B
4641,uni,I
4641,-,I
4641,SVM,I
4641,on,B
4641,all,B
4641,the,O
4641,datasets,O
4641,by,B
4641,the,O
4641,margin,O
4641,of,O
4641,2,B
4641,%,I
4641,to,I
4641,5,I
4641,%,O
4641,(,O
4641,see,O
4641,),O
4641,.,O
4642,It,O
4642,is,O
4642,to,O
4642,be,O
4642,noted,B
4642,that,O
4642,both,B
4642,sc,I
4642,-,I
4642,LSTM,I
4642,and,I
4642,bc,I
4642,-,O
4642,LSTM,O
4642,perform,B
4642,quite,B
4642,well,I
4642,on,B
4642,the,O
4642,multimodal,B
4642,emotion,I
4642,recognition,I
4642,and,O
4642,sentiment,O
4642,analysis,O
4642,datasets,O
4642,.,O
4643,On,B
4643,the,I
4643,IEMOCAP,B
4643,dataset,I
4643,",",O
4643,the,O
4643,performance,B
4643,improvement,I
4643,of,I
4643,bc,B
4643,-,I
4643,LSTM,I
4643,and,I
4643,sc,I
4643,-,O
4643,LSTM,O
4643,over,B
4643,h-,B
4643,LSTM,O
4643,is,O
4643,in,B
4643,the,O
4643,range,O
4643,of,O
4643,1,B
4643,%,I
4643,to,I
4643,5,I
4643,%,O
4643,.,O
4644,Experimental,O
4644,results,O
4644,in,O
4644,show,B
4644,that,O
4644,the,O
4644,proposed,B
4644,method,I
4644,outperformes,B
4644,by,I
4644,a,O
4644,significant,B
4644,margin,I
4644,.,O
4645,We,O
4645,consider,B
4645,CNN,B
4645,variants,I
4645,with,B
4645,linear,O
4645,filters,O
4645,and,O
4645,RNFs.,O
4646,For,B
4646,RNFs,B
4646,",",O
4646,we,O
4646,adopt,B
4646,two,B
4646,implementations,I
4646,based,B
4646,on,I
4646,GRUs,B
4646,and,I
4646,LSTMs,I
4646,respectively,O
4646,.,O
4647,We,O
4647,also,O
4647,compare,B
4647,against,I
4647,the,O
4647,following,O
4647,RNN,B
4647,variants,I
4647,:,O
4647,GRU,B
4647,",",O
4647,LSTM,B
4647,",",O
4647,GRU,O
4647,with,B
4647,max,B
4647,pooling,I
4647,",",O
4647,and,O
4647,LSTM,O
4647,with,O
4647,max,O
4647,pooling,O
4647,.,O
4648,To,O
4648,overcome,O
4648,this,O
4648,",",O
4648,we,O
4648,propose,B
4648,to,O
4648,employ,O
4648,recurrent,B
4648,neural,I
4648,networks,I
4648,(,I
4648,RNNs,I
4648,),I
4648,as,B
4648,convolution,B
4648,filters,I
4648,of,B
4648,CNN,B
4648,systems,I
4648,for,O
4648,various,O
4648,NLP,O
4648,tasks,O
4648,.,O
4649,Our,O
4649,recurrent,B
4649,neural,I
4649,filters,I
4649,(,I
4649,RNFs,I
4649,),I
4649,can,O
4649,naturally,O
4649,deal,B
4649,with,B
4649,language,B
4649,compositionality,I
4649,with,O
4649,a,O
4649,recurrent,O
4649,function,O
4649,that,B
4649,models,I
4649,word,B
4649,relations,I
4649,",",O
4649,and,O
4649,they,O
4649,are,O
4649,also,O
4649,able,O
4649,to,B
4649,implicitly,I
4649,model,I
4649,long,B
4649,-,I
4649,term,I
4649,dependencies,I
4649,.,O
4650,RNFs,B
4650,are,O
4650,typically,O
4650,applied,B
4650,to,B
4650,word,B
4650,sequences,I
4650,of,B
4650,moderate,B
4650,lengths,I
4650,",",O
4650,which,O
4650,alleviates,B
4650,some,B
4650,well,I
4650,-,I
4650,known,I
4650,drawbacks,I
4650,of,O
4650,RNNs,B
4650,",",O
4650,including,B
4650,their,O
4650,vulnerability,B
4650,to,O
4650,the,O
4650,gradient,B
4650,vanishing,I
4650,and,I
4650,exploding,I
4650,problems,I
4650,.,O
4651,As,O
4651,a,O
4651,result,O
4651,",",O
4651,RNF,B
4651,-,I
4651,based,I
4651,CNN,I
4651,models,I
4651,can,B
4651,be,I
4651,3,B
4651,-,O
4651,8,O
4651,x,O
4651,faster,O
4651,than,B
4651,their,O
4651,RNN,B
4651,counterparts,I
4651,.,O
4652,As,O
4652,in,O
4652,conventional,B
4652,CNNs,I
4652,",",O
4652,the,O
4652,computation,B
4652,of,I
4652,the,O
4652,convolution,B
4652,operation,I
4652,with,B
4652,RNFs,B
4652,can,B
4652,be,I
4652,easily,O
4652,parallelized,B
4652,.,O
4653,We,O
4653,present,B
4653,two,B
4653,RNF,I
4653,-,I
4653,based,I
4653,CNN,I
4653,architectures,I
4653,for,B
4653,sentence,I
4653,classification,I
4653,and,I
4653,answer,I
4653,sentence,O
4653,selection,O
4653,problems,O
4653,.,O
4654,In,O
4654,this,O
4654,work,O
4654,",",O
4654,we,O
4654,model,B
4654,convolution,I
4654,filters,I
4654,with,I
4654,RNNs,I
4654,that,O
4654,naturally,O
4654,capture,O
4654,compositionality,O
4654,and,O
4654,long,O
4654,-,O
4654,term,O
4654,dependencies,O
4654,in,O
4654,language,O
4654,.,O
4655,In,O
4655,particular,O
4655,",",O
4655,CNN,B
4655,-,I
4655,RNF,I
4655,-,O
4655,LSTM,O
4655,achieves,B
4655,53.4,B
4655,%,I
4655,and,I
4655,90.0,I
4655,%,O
4655,accuracies,O
4655,on,B
4655,the,I
4655,fine,B
4655,-,O
4655,grained,O
4655,and,O
4655,binary,O
4655,sentiment,O
4655,classification,O
4655,tasks,O
4655,respectively,O
4655,",",O
4655,which,O
4655,match,B
4655,the,O
4655,state,B
4655,-,O
4655,of,O
4655,the,O
4655,-,O
4655,art,O
4655,results,O
4655,on,O
4655,the,O
4655,Stanford,B
4655,Sentiment,O
4655,Treebank,O
4655,.,O
4656,We,O
4656,find,B
4656,that,I
4656,modifying,B
4656,our,B
4656,objective,I
4656,to,I
4656,include,I
4656,multiple,B
4656,relations,I
4656,improves,B
4656,the,O
4656,recall,B
4656,of,B
4656,our,O
4656,system,O
4656,on,O
4656,relations,O
4656,",",O
4656,leading,B
4656,to,O
4656,slight,B
4656,improvement,I
4656,on,O
4656,the,O
4656,over,B
4656,all,I
4656,performance,I
4656,on,O
4656,relations,O
4656,.,O
4657,CNN,O
4657,-,O
4657,RNF,O
4657,-,O
4657,LSTM,O
4657,also,O
4657,obtains,B
4657,competitive,B
4657,results,I
4657,on,B
4657,answer,B
4657,sentence,I
4657,selection,I
4657,datasets,I
4657,",",O
4657,despite,B
4657,the,I
4657,simple,B
4657,model,I
4657,architecture,I
4657,compared,B
4657,to,I
4657,state,B
4657,-,O
4657,of,O
4657,-,O
4657,the,O
4657,-,O
4657,art,O
4657,systems,O
4657,.,O
4658,Conventional,O
4658,RNN,O
4658,models,O
4658,clearly,O
4658,benefit,B
4658,from,I
4658,max,B
4658,pooling,I
4658,",",O
4658,especially,B
4658,on,I
4658,the,O
4658,task,O
4658,of,O
4658,answer,B
4658,sentence,I
4658,selection,I
4658,.,O
4659,As,O
4659,a,O
4659,result,O
4659,",",O
4659,RNF,B
4659,-,I
4659,based,I
4659,CNN,I
4659,models,I
4659,perform,B
4659,consistently,B
4659,better,I
4659,than,B
4659,max,B
4659,-,O
4659,pooled,O
4659,RNN,O
4659,models,O
4659,.,O
4660,AMN,B
4660,:,O
4660,A,O
4660,state,B
4660,-,I
4660,of,I
4660,-,O
4660,the,O
4660,-,O
4660,art,O
4660,memory,O
4660,network,O
4660,used,B
4660,for,I
4660,ASC,B
4660,.,O
4661,BL,O
4661,-,O
4661,MN,O
4661,:,O
4661,Our,B
4661,basic,I
4661,memory,I
4661,network,I
4661,presented,O
4661,in,O
4661,Section,O
4661,2,O
4661,",",O
4661,which,O
4661,does,B
4661,not,I
4661,use,I
4661,the,O
4661,proposed,B
4661,techniques,I
4661,for,B
4661,capturing,I
4661,target,B
4661,-,O
4661,sensitive,O
4661,sentiments,O
4661,.,O
4662,Here,O
4662,we,O
4662,compare,B
4662,with,I
4662,a,O
4662,state,B
4662,-,I
4662,of,I
4662,-,O
4662,the,O
4662,-,O
4662,art,O
4662,attention,O
4662,-,O
4662,based,O
4662,LSTM,O
4662,for,B
4662,ASC,B
4662,",",O
4662,AE,O
4662,-,O
4662,LSTM,O
4662,.,O
4663,Another,O
4663,attention,B
4663,-,I
4663,based,I
4663,LSTM,I
4663,for,B
4663,ASC,B
4663,reported,O
4663,in,O
4663,.,O
4664,A,O
4664,graphical,B
4664,model,I
4664,which,O
4664,jointly,B
4664,models,I
4664,multiple,I
4664,instances,I
4664,and,I
4664,multiple,O
4664,labels,O
4664,.,O
4665,PHYS,O
4665,relation,O
4665,is,B
4665,easier,B
4665,identified,I
4665,with,B
4665,respect,I
4665,to,I
4665,GPE,B
4665,entity,I
4665,than,B
4665,PER,B
4665,entity,O
4665,.,O
4666,The,O
4666,six,B
4666,proposed,I
4666,techniques,I
4666,",",O
4666,NP,B
4666,",",O
4666,CNP,B
4666,",",O
4666,IT,B
4666,",",O
4666,CI,B
4666,",",O
4666,JCI,B
4666,",",O
4666,and,O
4666,JPI,B
4666,give,B
4666,six,O
4666,target,O
4666,-,O
4666,sensitive,O
4666,memory,O
4666,networks,O
4666,.,O
4667,We,O
4667,use,B
4667,the,O
4667,open,B
4667,-,I
4667,domain,I
4667,word,B
4667,embeddings,I
4667,1,O
4667,for,B
4667,the,O
4667,initialization,B
4667,of,B
4667,word,O
4667,vectors,O
4667,.,O
4668,We,O
4668,initialize,B
4668,other,B
4668,model,I
4668,parameters,I
4668,from,B
4668,a,O
4668,uniform,B
4668,distribution,I
4668,U,I
4668,(,I
4668,-,I
4668,0.05,I
4668,",",I
4668,0.05,O
4668,),O
4668,.,O
4669,The,O
4669,dimension,B
4669,of,I
4669,the,O
4669,word,B
4669,embedding,I
4669,and,O
4669,the,O
4669,size,B
4669,of,O
4669,the,O
4669,hidden,O
4669,layers,O
4669,are,B
4669,300,B
4669,.,O
4670,The,O
4670,learning,B
4670,rate,I
4670,is,O
4670,set,B
4670,to,I
4670,0.01,B
4670,and,O
4670,the,O
4670,dropout,B
4670,rate,O
4670,is,O
4670,set,O
4670,to,O
4670,0.1,B
4670,.,O
4671,Stochastic,O
4671,gradient,O
4671,descent,O
4671,is,O
4671,used,B
4671,as,I
4671,our,B
4671,optimizer,I
4671,.,O
4672,We,O
4672,also,O
4672,compare,B
4672,the,O
4672,memory,B
4672,networks,I
4672,in,B
4672,their,O
4672,multiple,O
4672,computational,O
4672,layers,O
4672,version,O
4672,(,O
4672,i.e.,O
4673,",",O
4673,multiple,O
4673,hops,O
4673,),O
4673,and,O
4673,the,O
4673,number,B
4673,of,I
4673,hops,O
4673,is,O
4673,set,B
4673,to,I
4673,3,B
4673,as,O
4673,used,O
4673,in,B
4673,the,O
4673,mentioned,O
4673,previous,O
4673,studies,O
4673,.,O
4674,We,O
4674,implemented,B
4674,all,B
4674,models,I
4674,in,B
4674,the,O
4674,TensorFlow,B
4674,environment,I
4674,using,B
4674,same,B
4674,input,I
4674,",",I
4674,embedding,I
4674,size,I
4674,",",O
4674,dropout,O
4674,rate,O
4674,",",O
4674,optimizer,O
4674,",",O
4674,etc.,O
4675,To,O
4675,address,O
4675,this,O
4675,problem,O
4675,",",O
4675,we,O
4675,propose,B
4675,target,B
4675,-,I
4675,sensitive,I
4675,memory,I
4675,networks,I
4675,(,I
4675,TMNs,I
4675,),I
4675,",",O
4675,which,O
4675,can,B
4675,capture,I
4675,the,O
4675,sentiment,B
4675,interaction,I
4675,between,B
4675,targets,B
4675,and,I
4675,contexts,I
4675,.,O
4676,Target,O
4676,-,O
4676,Sensitive,O
4676,Memory,O
4676,Networks,O
4676,for,O
4676,Aspect,B
4676,Sentiment,I
4676,Classification,I
4677,By,O
4677,adding,B
4677,bidirectional,B
4677,encoding,I
4677,to,I
4677,our,B
4677,system,I
4677,",",O
4677,we,O
4677,find,B
4677,that,O
4677,we,O
4677,can,O
4677,significantly,B
4677,improve,I
4677,the,O
4677,performance,B
4677,of,B
4677,our,O
4677,system,O
4677,compared,B
4677,to,O
4677,left,B
4677,-,I
4677,to,O
4677,-,O
4677,right,O
4677,encoding,O
4677,.,O
4678,Aspect,O
4678,sentiment,B
4678,classification,O
4678,(,O
4678,ASC,O
4678,),O
4678,is,O
4678,a,O
4678,fundamental,O
4678,task,O
4678,in,O
4678,sentiment,O
4678,analysis,O
4678,.,O
4679,However,O
4679,",",O
4679,we,O
4679,found,O
4679,an,O
4679,important,O
4679,problem,O
4679,with,O
4679,the,O
4679,current,O
4679,MNs,O
4679,in,O
4679,performing,O
4679,the,O
4679,ASC,B
4679,task,O
4679,.,O
4680,Comparing,B
4680,the,O
4680,1,B
4680,-,I
4680,hop,I
4680,memory,I
4680,networks,I
4680,(,I
4680,first,O
4680,nine,O
4680,rows,O
4680,),O
4680,",",O
4680,we,O
4680,see,B
4680,significant,B
4680,performance,I
4680,gains,I
4680,achieved,B
4680,by,I
4680,CNP,B
4680,",",O
4680,CI,O
4680,",",O
4680,JCI,O
4680,",",O
4680,and,O
4680,JPI,O
4680,on,B
4680,both,B
4680,datasets,I
4680,",",O
4680,where,O
4680,each,B
4680,of,I
4680,them,I
4680,has,I
4680,p,B
4680,<,I
4680,0.01,I
4680,over,B
4680,the,O
4680,strongest,B
4680,baseline,I
4680,(,O
4680,BL,O
4680,-,O
4680,MN,O
4680,),O
4680,from,B
4680,paired,B
4680,t-,I
4680,test,I
4680,using,B
4680,F1,B
4680,-,O
4680,Macro,O
4680,.,O
4681,Comparing,O
4681,all,B
4681,TMNs,I
4681,",",O
4681,we,O
4681,see,B
4681,that,I
4681,JCI,B
4681,works,B
4681,the,O
4681,best,B
4681,as,O
4681,it,O
4681,always,O
4681,obtains,O
4681,the,O
4681,top,O
4681,-,O
4681,three,O
4681,scores,O
4681,on,O
4681,two,O
4681,datasets,O
4681,and,O
4681,in,O
4681,two,O
4681,settings,O
4681,.,O
4682,In,B
4682,the,O
4682,3,B
4682,-,I
4682,hop,I
4682,setting,I
4682,",",O
4682,TMNs,B
4682,achieve,B
4682,much,B
4682,better,I
4682,results,I
4682,on,B
4682,Restaurant,B
4682,.,O
4683,JCI,O
4683,",",O
4683,IT,O
4683,",",O
4683,and,O
4683,CI,O
4683,achieve,B
4683,the,O
4683,best,B
4683,scores,I
4683,",",O
4683,outperforming,B
4683,the,O
4683,strongest,B
4683,baseline,I
4683,AMN,I
4683,by,B
4683,2.38,B
4683,%,I
4683,",",O
4683,2.18,O
4683,%,O
4683,",",O
4683,and,O
4683,2.03,O
4683,%,O
4683,.,O
4684,On,B
4684,Laptop,B
4684,",",O
4684,BL,B
4684,-,I
4684,MN,I
4684,and,I
4684,most,I
4684,TMNs,I
4684,(,O
4684,except,O
4684,CNP,O
4684,and,O
4684,JPI,O
4684,),O
4684,perform,B
4684,similarly,B
4684,.,O
4685,CI,O
4685,and,O
4685,JPI,O
4685,also,O
4685,perform,B
4685,well,B
4685,in,B
4685,most,B
4685,cases,I
4685,.,O
4686,IT,O
4686,",",O
4686,NP,O
4686,",",O
4686,and,O
4686,CNP,O
4686,can,O
4686,achieve,B
4686,very,B
4686,good,I
4686,scores,I
4686,in,B
4686,some,B
4686,cases,I
4686,but,O
4686,are,B
4686,less,B
4686,stable,I
4686,.,O
4687,TD,O
4687,-,O
4687,LSTM,O
4687,constructs,B
4687,aspect-specific,B
4687,representation,I
4687,by,B
4687,the,O
4687,left,B
4687,context,I
4687,with,B
4687,aspect,B
4687,and,O
4687,the,O
4687,right,B
4687,context,O
4687,with,O
4687,aspect,O
4687,",",O
4687,then,O
4687,employs,B
4687,two,B
4687,LSTMs,I
4687,to,O
4687,model,O
4687,them,O
4687,respectively,O
4687,.,O
4688,It,O
4688,also,O
4688,improves,B
4688,precision,B
4688,compared,B
4688,to,I
4688,left,B
4688,-,I
4688,toright,I
4688,decoding,I
4688,combined,B
4688,with,I
4688,multiple,B
4688,relations,I
4688,objective,I
4688,.,O
4689,The,O
4689,last,B
4689,hidden,I
4689,states,I
4689,of,B
4689,the,O
4689,two,B
4689,LSTMs,I
4689,are,O
4689,finally,B
4689,concatenated,I
4689,for,B
4689,predicting,I
4689,the,O
4689,sentiment,B
4689,polarity,I
4689,of,O
4689,the,O
4689,aspect,B
4689,.,O
4690,ATAE,O
4690,-,O
4690,LSTM,O
4690,first,O
4690,attaches,B
4690,the,O
4690,aspect,B
4690,embedding,I
4690,to,B
4690,each,B
4690,word,I
4690,embedding,O
4690,to,O
4690,capture,O
4690,aspect,O
4690,-,O
4690,dependent,O
4690,information,O
4690,",",O
4690,and,O
4690,then,O
4690,employs,B
4690,attention,B
4690,mechanism,I
4690,to,O
4690,get,O
4690,the,O
4690,sentence,B
4690,representation,I
4690,for,B
4690,final,B
4690,classification,I
4690,.,O
4691,Mem,O
4691,Net,O
4691,uses,B
4691,a,O
4691,deep,B
4691,memory,I
4691,network,I
4691,on,B
4691,the,I
4691,context,I
4691,word,I
4691,embeddings,I
4691,for,B
4691,sentence,B
4691,representation,I
4691,to,B
4691,capture,I
4691,the,O
4691,relevance,B
4691,between,B
4691,each,B
4691,context,O
4691,word,O
4691,and,O
4691,the,O
4691,aspect,O
4691,.,O
4692,IAN,B
4692,generates,B
4692,the,O
4692,representations,B
4692,for,B
4692,aspect,B
4692,terms,I
4692,and,I
4692,contexts,I
4692,with,B
4692,two,B
4692,attention,I
4692,-,I
4692,based,I
4692,LSTM,I
4692,network,I
4692,separately,O
4692,.,O
4693,RAM,B
4693,[,O
4693,10,O
4693,],O
4693,employs,B
4693,a,O
4693,gated,B
4693,recurrent,I
4693,unit,I
4693,network,I
4693,to,B
4693,model,I
4693,a,O
4693,multiple,B
4693,attention,I
4693,mechanism,I
4693,",",O
4693,and,O
4693,captures,B
4693,the,I
4693,relevance,B
4693,between,B
4693,each,B
4693,context,I
4693,word,I
4693,and,O
4693,the,O
4693,aspect,O
4693,.,O
4694,PBAN,B
4694,appends,B
4694,the,O
4694,position,B
4694,embedding,I
4694,into,B
4694,each,B
4694,word,I
4694,embedding,O
4694,.,O
4695,TSN,B
4695,is,B
4695,a,O
4695,two,B
4695,-,I
4695,stage,I
4695,framework,I
4695,for,B
4695,aspect,B
4695,-,O
4695,level,O
4695,sentiment,O
4695,analysis,O
4695,.,O
4696,AEN,B
4696,mainly,O
4696,consists,B
4696,of,I
4696,an,O
4696,embedding,B
4696,layer,I
4696,",",O
4696,an,O
4696,attentional,B
4696,encoder,I
4696,layer,O
4696,",",O
4696,an,O
4696,aspect,B
4696,-,I
4696,specific,I
4696,attention,I
4696,layer,O
4696,",",O
4696,and,O
4696,an,O
4696,output,B
4696,layer,O
4696,.,O
4697,AEN,B
4697,-,O
4697,BERT,B
4697,is,B
4697,AEN,O
4697,with,B
4697,BERT,O
4697,embedding,O
4697,.,O
4698,In,O
4698,our,O
4698,implementation,O
4698,",",O
4698,we,O
4698,respectively,O
4698,use,B
4698,the,O
4698,GloVe,B
4698,3,I
4698,word,I
4698,vector,I
4698,and,O
4698,the,O
4698,pre-trained,B
4698,language,I
4698,model,I
4698,word,O
4698,representation,O
4698,BERT,O
4698,4,O
4698,to,B
4698,initialize,I
4698,the,O
4698,word,O
4698,embeddings,O
4698,.,O
4699,We,O
4699,find,B
4699,that,I
4699,for,I
4699,some,B
4699,relations,I
4699,it,O
4699,is,B
4699,easier,B
4699,to,I
4699,detect,I
4699,them,O
4699,with,B
4699,respect,I
4699,to,O
4699,one,B
4699,of,I
4699,the,I
4699,entities,I
4699,in,B
4699,the,O
4699,entity,B
4699,pair,I
4699,.,O
4700,The,O
4700,dimension,B
4700,of,B
4700,each,B
4700,word,I
4700,vector,I
4700,is,B
4700,300,B
4700,for,B
4700,GloVe,B
4700,and,O
4700,768,B
4700,for,O
4700,BERT,B
4700,.,O
4701,The,O
4701,number,B
4701,of,B
4701,LSTM,B
4701,hidden,I
4701,units,I
4701,is,O
4701,set,B
4701,to,I
4701,300,B
4701,",",O
4701,and,O
4701,the,O
4701,output,B
4701,dimension,I
4701,of,O
4701,GCN,B
4701,layer,I
4701,is,O
4701,set,O
4701,to,O
4701,600,B
4701,.,O
4702,The,O
4702,weight,B
4702,matrix,I
4702,of,B
4702,last,B
4702,fully,I
4702,connect,I
4702,layer,I
4702,is,O
4702,randomly,B
4702,initialized,I
4702,by,I
4702,a,O
4702,normal,B
4702,distribution,I
4702,N,I
4702,(,I
4702,0,I
4702,",",I
4702,1,I
4702,),I
4702,.,O
4703,Besides,B
4703,the,I
4703,last,B
4703,fully,I
4703,connect,I
4703,layer,I
4703,",",O
4703,all,B
4703,the,O
4703,weight,O
4703,matrices,O
4703,are,O
4703,randomly,B
4703,initialized,I
4703,by,I
4703,a,O
4703,uniform,O
4703,distribution,O
4703,U,O
4703,(,O
4703,?,O
4704,In,O
4704,addition,O
4704,",",O
4704,we,O
4704,add,B
4704,L2-regularization,B
4704,to,B
4704,the,O
4704,last,B
4704,fully,I
4704,connect,I
4704,layer,I
4704,with,B
4704,a,O
4704,weight,B
4704,of,B
4704,0.01,B
4704,.,O
4705,During,B
4705,training,B
4705,",",O
4705,we,O
4705,set,B
4705,dropout,B
4705,to,I
4705,0.5,B
4705,",",O
4705,the,O
4705,batch,B
4705,size,I
4705,is,B
4705,set,O
4705,to,O
4705,32,B
4705,and,O
4705,the,O
4705,optimizer,O
4705,is,O
4705,Adam,B
4705,Optimizer,O
4705,with,B
4705,a,O
4705,learning,B
4705,rate,I
4705,of,B
4705,0.001,B
4705,.,O
4706,We,O
4706,implement,B
4706,our,O
4706,proposed,B
4706,model,I
4706,using,B
4706,Tensorflow,B
4706,5,O
4706,.,O
4707,In,O
4707,this,O
4707,paper,O
4707,",",O
4707,we,O
4707,propose,B
4707,a,O
4707,novel,B
4707,method,I
4707,to,B
4707,model,I
4707,Sentiment,I
4707,Dependencies,I
4707,with,I
4707,Graph,I
4707,Convolutional,I
4707,Networks,I
4707,(,I
4707,SDGCN,I
4707,),I
4707,for,B
4707,aspect,B
4707,-,I
4707,level,I
4707,sentiment,O
4707,classification,O
4707,.,O
4708,GCN,B
4708,is,B
4708,a,O
4708,simple,B
4708,and,I
4708,effective,I
4708,convolutional,I
4708,neural,I
4708,network,I
4708,operating,B
4708,on,I
4708,graphs,B
4708,",",O
4708,which,O
4708,can,B
4708,catch,I
4708,inter-dependent,B
4708,information,I
4708,from,B
4708,rich,B
4708,relational,I
4708,data,I
4708,.,O
4709,In,O
4709,our,O
4709,case,O
4709,",",O
4709,an,O
4709,aspect,B
4709,is,O
4709,treated,B
4709,as,I
4709,a,O
4709,node,B
4709,",",O
4709,and,O
4709,an,O
4709,edge,B
4709,represents,B
4709,the,O
4709,sentiment,B
4709,dependency,I
4709,relation,I
4709,of,B
4709,two,B
4709,nodes,I
4709,.,O
4710,We,O
4710,can,O
4710,observe,B
4710,that,I
4710,adding,B
4710,either,B
4710,attention,I
4710,guided,I
4710,layers,I
4710,or,I
4710,densely,I
4710,connected,I
4710,layers,O
4710,improves,B
4710,the,O
4710,performance,B
4710,of,B
4710,the,O
4710,model,B
4710,.,O
4711,For,B
4711,every,B
4711,node,I
4711,in,B
4711,graph,B
4711,",",O
4711,GCN,B
4711,encodes,B
4711,relevant,B
4711,information,I
4711,about,B
4711,its,O
4711,neighborhoods,B
4711,as,B
4711,a,O
4711,new,B
4711,feature,I
4711,representation,I
4711,vector,I
4711,.,O
4712,Our,O
4712,model,O
4712,learns,B
4712,the,O
4712,sentiment,B
4712,dependencies,I
4712,of,B
4712,aspects,B
4712,via,B
4712,this,O
4712,graph,B
4712,structure,I
4712,.,O
4713,As,O
4713,far,O
4713,as,O
4713,we,O
4713,know,O
4713,",",O
4713,our,O
4713,work,O
4713,is,O
4713,the,O
4713,first,B
4713,to,I
4713,consider,I
4713,the,O
4713,sentiment,O
4713,dependencies,O
4713,between,B
4713,aspects,B
4713,in,B
4713,one,B
4713,sentence,I
4713,for,B
4713,aspect,B
4713,-,I
4713,level,I
4713,sentiment,O
4713,classification,O
4713,task,O
4713,.,O
4714,Furthermore,O
4714,",",O
4714,in,O
4714,order,O
4714,to,O
4714,capture,O
4714,the,O
4714,aspect,O
4714,-,O
4714,specific,O
4714,representations,O
4714,",",O
4714,our,O
4714,model,O
4714,applies,B
4714,bidirectional,B
4714,attention,I
4714,mechanism,I
4714,with,B
4714,position,B
4714,encoding,I
4714,before,B
4714,GCN,B
4714,.,O
4715,Modeling,O
4715,Sentiment,O
4715,Dependencies,O
4715,with,O
4715,Graph,O
4715,Convolutional,O
4715,Networks,O
4715,for,O
4715,Aspect,B
4715,-,I
4715,level,I
4715,Sentiment,O
4715,Classification,O
4716,It,O
4716,is,O
4716,a,O
4716,fine,O
4716,-,O
4716,grained,O
4716,task,O
4716,in,O
4716,sentiment,B
4716,analysis,I
4716,",",O
4716,which,O
4716,aims,O
4716,to,O
4716,infer,O
4716,the,O
4716,sentiment,O
4716,polarities,O
4716,of,O
4716,aspects,O
4716,in,O
4716,their,O
4716,context,O
4716,.,O
4717,Among,B
4717,all,B
4717,the,I
4717,GloVe,I
4717,-,I
4717,based,I
4717,methods,I
4717,",",O
4717,the,O
4717,TD,B
4717,-,O
4717,LSTM,O
4717,approach,O
4717,performs,B
4717,worst,B
4717,because,O
4717,it,O
4717,takes,O
4717,the,O
4717,aspect,O
4717,information,O
4717,into,O
4717,consideration,O
4717,in,O
4717,a,O
4717,very,O
4717,coarse,O
4717,way,O
4717,.,O
4718,After,O
4718,taking,O
4718,the,O
4718,importance,B
4718,of,B
4718,the,O
4718,aspect,B
4718,into,B
4718,account,B
4718,with,B
4718,attention,B
4718,mechanism,I
4718,",",O
4718,they,O
4718,achieve,B
4718,a,O
4718,stable,B
4718,improvement,I
4718,comparing,B
4718,to,I
4718,the,O
4718,TD,B
4718,-,I
4718,LSTM,I
4718,.,O
4719,RAM,B
4719,achieves,B
4719,a,O
4719,better,B
4719,performance,I
4719,than,B
4719,other,B
4719,basic,I
4719,attention,I
4719,-,I
4719,based,I
4719,models,I
4719,",",O
4719,because,O
4719,it,O
4719,combines,O
4719,multiple,O
4719,attentions,O
4719,with,O
4719,a,O
4719,recurrent,O
4719,neural,O
4719,network,O
4719,to,O
4719,capture,O
4719,aspect,O
4719,-,O
4719,specific,O
4719,representations,O
4719,.,O
4720,PBAN,B
4720,achieves,B
4720,a,O
4720,similar,B
4720,performance,I
4720,as,B
4720,RAM,B
4720,by,B
4720,employing,I
4720,a,O
4720,position,B
4720,embedding,I
4720,.,O
4721,We,O
4721,can,O
4721,observe,O
4721,that,O
4721,all,B
4721,the,I
4721,C,I
4721,-,I
4721,AGGCN,I
4721,models,I
4721,with,B
4721,varied,B
4721,values,I
4721,of,I
4721,K,I
4721,are,O
4721,able,O
4721,to,O
4721,outperform,B
4721,the,O
4721,state,B
4721,-,O
4721,of,O
4721,-,O
4721,the,O
4721,-,O
4721,art,O
4721,C,O
4721,-,O
4721,GCN,O
4721,model,O
4721,(,O
4721,reported,O
4721,in,O
4721,),O
4721,.,O
4722,To,O
4722,be,O
4722,specific,O
4722,",",O
4722,PBAN,O
4722,is,O
4722,better,B
4722,than,I
4722,RAM,B
4722,on,B
4722,Restaurant,B
4722,dataset,I
4722,",",O
4722,but,O
4722,worse,B
4722,than,O
4722,RAN,B
4722,on,O
4722,Laptop,B
4722,dataset,O
4722,.,O
4723,AEN,B
4723,is,O
4723,slightly,B
4723,better,I
4723,than,I
4723,TSN,B
4723,",",O
4723,but,O
4723,still,B
4723,worse,I
4723,than,O
4723,RAM,B
4723,and,I
4723,PBAN,I
4723,.,O
4724,Moreover,O
4724,",",O
4724,the,O
4724,two,B
4724,models,I
4724,(,I
4724,SDGCN,I
4724,-,I
4724,A,I
4724,and,I
4724,SDGCN,O
4724,-,O
4724,G,O
4724,),O
4724,with,B
4724,position,B
4724,information,I
4724,gain,B
4724,a,O
4724,significant,B
4724,improvement,I
4724,compared,B
4724,to,I
4724,the,O
4724,two,O
4724,models,O
4724,without,B
4724,position,O
4724,information,O
4724,.,O
4725,Compared,O
4725,with,O
4725,RAM,B
4725,and,I
4725,PBAN,I
4725,",",O
4725,the,O
4725,over,B
4725,all,I
4725,performance,I
4725,of,B
4725,TSN,B
4725,is,O
4725,not,B
4725,perform,I
4725,well,I
4725,on,B
4725,both,I
4725,Restaurant,B
4725,dataset,I
4725,and,O
4725,Laptop,O
4725,dataset,O
4725,",",O
4725,which,O
4725,might,O
4725,because,O
4725,the,O
4725,framework,O
4725,of,O
4725,TSN,O
4725,is,O
4725,too,O
4725,simple,O
4725,to,O
4725,model,O
4725,the,O
4725,representations,O
4725,of,O
4725,context,O
4725,and,O
4725,aspect,O
4725,effectively,O
4725,.,O
4726,Comparing,B
4726,the,O
4726,results,B
4726,of,B
4726,SDGCN,I
4726,-,I
4726,A,I
4726,w/o,I
4726,position,I
4726,and,I
4726,SDGCN,O
4726,-,O
4726,G,O
4726,w/o,O
4726,position,O
4726,",",O
4726,SDGCN,O
4726,-,O
4726,A,O
4726,and,O
4726,SDGCN,O
4726,-,O
4726,G,O
4726,",",O
4726,respectively,O
4726,",",O
4726,we,O
4726,observe,B
4726,that,O
4726,the,O
4726,GCN,B
4726,built,B
4726,with,I
4726,global,B
4726,-,O
4726,relation,O
4726,is,O
4726,slightly,B
4726,higher,I
4726,than,I
4726,built,O
4726,with,O
4726,adjacent,O
4726,-,O
4726,relation,O
4726,in,B
4726,both,I
4726,accuracy,B
4726,and,O
4726,Macro,O
4726,-,O
4726,F1,O
4726,measure,O
4726,.,O
4727,Benefits,O
4727,from,O
4727,the,O
4727,power,B
4727,of,B
4727,pre-trained,B
4727,BERT,B
4727,",",O
4727,BERT,O
4727,-,O
4727,based,O
4727,models,O
4727,have,O
4727,shown,B
4727,huge,B
4727,superiority,I
4727,over,B
4727,GloVe,B
4727,-,O
4727,based,O
4727,models,O
4727,.,O
4728,Furthermore,O
4728,",",O
4728,compared,B
4728,with,I
4728,AEN,B
4728,-,I
4728,BERT,I
4728,",",O
4728,on,B
4728,the,O
4728,Restaurant,B
4728,dataset,I
4728,",",O
4728,SDGCN,B
4728,-,O
4728,BERT,O
4728,achieves,B
4728,absolute,B
4728,increases,I
4728,of,B
4728,1.09,B
4728,%,I
4728,and,I
4728,1.86,I
4728,%,O
4728,in,B
4728,accuracy,B
4728,and,O
4728,Macro,O
4728,-,O
4728,F1,O
4728,measure,O
4728,respectively,O
4728,",",O
4728,and,O
4728,gains,B
4728,absolute,O
4728,increases,O
4728,of,O
4728,1.42,B
4728,%,O
4728,and,O
4728,2.03,O
4728,%,O
4728,in,O
4728,accuracy,O
4728,and,O
4728,Macro,O
4728,-,O
4728,F1,O
4728,measure,O
4728,respectively,O
4728,on,O
4728,the,O
4728,Laptop,B
4728,dataset,O
4728,.,O
4729,(,O
4729,2,O
4729,),O
4729,Overall,O
4729,",",O
4729,transfers,B
4729,of,B
4729,the,O
4729,LSTM,B
4729,and,I
4729,embedding,I
4729,layer,I
4729,are,B
4729,more,B
4729,useful,I
4729,than,B
4729,the,O
4729,output,B
4729,layer,O
4729,.,O
4730,(,O
4730,3,O
4730,),O
4730,Transfer,B
4730,of,I
4730,the,I
4730,embedding,I
4730,layer,I
4730,is,B
4730,more,B
4730,helpful,I
4730,on,B
4730,D3,B
4730,and,I
4730,D4,I
4730,.,O
4731,Sentiment,O
4731,information,O
4731,is,O
4731,not,B
4731,adequately,I
4731,captured,I
4731,by,I
4731,Glo,B
4731,Ve,I
4731,word,I
4731,embeddings,I
4731,.,O
4732,We,O
4732,also,O
4732,notice,B
4732,that,I
4732,the,O
4732,feed,B
4732,-,I
4732,forward,I
4732,layer,I
4732,is,O
4732,effective,B
4732,in,I
4732,our,B
4732,model,I
4732,.,O
4733,In,O
4733,all,O
4733,experiments,O
4733,",",O
4733,300,B
4733,-,I
4733,dimension,I
4733,Glo,I
4733,Ve,I
4733,vectors,I
4733,are,O
4733,used,O
4733,to,B
4733,initialize,I
4733,E,I
4733,and,I
4733,E,O
4733,when,B
4733,pretraining,B
4733,is,O
4733,not,B
4733,conducted,I
4733,for,I
4733,weight,B
4733,initialization,I
4733,.,O
4734,These,O
4734,vectors,B
4734,are,O
4734,also,O
4734,used,B
4734,for,I
4734,initializing,B
4734,E,I
4734,in,B
4734,the,O
4734,pretraining,B
4734,phase,I
4734,.,O
4735,We,O
4735,randomly,B
4735,sample,I
4735,20,B
4735,%,I
4735,of,B
4735,the,O
4735,original,B
4735,training,I
4735,data,I
4735,from,B
4735,the,O
4735,aspectlevel,B
4735,dataset,I
4735,as,B
4735,the,O
4735,development,B
4735,set,I
4735,and,O
4735,only,O
4735,use,O
4735,the,O
4735,remaining,O
4735,80,O
4735,%,O
4735,for,O
4735,training,O
4735,.,O
4736,For,B
4736,all,B
4736,experiments,I
4736,",",O
4736,the,O
4736,dimension,B
4736,of,B
4736,LSTM,B
4736,hidden,I
4736,vectors,I
4736,is,O
4736,set,B
4736,to,I
4736,300,B
4736,",",O
4736,?,O
4737,is,O
4737,set,O
4737,to,O
4737,0.1,O
4737,",",O
4737,and,O
4737,we,O
4737,use,B
4737,dropout,B
4737,with,B
4737,probability,B
4737,0.5,I
4737,on,B
4737,sentence,B
4737,/,I
4737,document,I
4737,representations,I
4737,before,B
4737,the,O
4737,output,B
4737,layer,I
4737,.,O
4738,We,O
4738,use,O
4738,RMSProp,B
4738,as,B
4738,the,O
4738,optimizer,B
4738,with,B
4738,the,O
4738,decay,B
4738,rate,I
4738,set,B
4738,to,I
4738,0.9,B
4738,and,O
4738,the,O
4738,base,B
4738,learning,I
4738,rate,O
4738,set,O
4738,to,O
4738,0.001,B
4738,.,O
4739,The,O
4739,mini,B
4739,-,I
4739,batch,I
4739,size,I
4739,is,O
4739,set,B
4739,to,I
4739,32,B
4739,.,O
4740,Specifically,O
4740,",",O
4740,we,O
4740,explore,B
4740,two,B
4740,transfer,I
4740,methods,I
4740,to,B
4740,incorporate,I
4740,this,O
4740,sort,O
4740,of,O
4740,knowledge,B
4740,-,O
4740,pretraining,B
4740,and,O
4740,multi-task,B
4740,learning,I
4740,.,O
4741,Exploiting,O
4741,Document,O
4741,Knowledge,O
4741,for,O
4741,Aspect,B
4741,-,I
4741,level,I
4741,Sentiment,I
4741,Classification,I
4742,In,O
4742,addition,O
4742,",",O
4742,we,O
4742,notice,O
4742,that,O
4742,the,O
4742,performance,B
4742,of,B
4742,C,I
4742,-,I
4742,AGGCN,I
4742,with,I
4742,full,I
4742,trees,I
4742,outperforms,B
4742,all,B
4742,C,O
4742,-,O
4742,AGGCNs,O
4742,with,O
4742,pruned,O
4742,trees,O
4742,.,O
4743,We,O
4743,observe,B
4743,that,I
4743,PRET,B
4743,is,B
4743,very,B
4743,helpful,I
4743,",",O
4743,and,O
4743,consistently,B
4743,gives,I
4743,a,O
4743,1,B
4743,-,I
4743,3,I
4743,%,I
4743,increase,I
4743,in,B
4743,accuracy,B
4743,over,B
4743,LSTM,B
4743,+,I
4743,ATT,I
4743,across,O
4743,all,O
4743,datasets,O
4743,.,O
4744,MULT,B
4744,gives,B
4744,similar,B
4744,performance,I
4744,as,B
4744,LSTM,B
4744,+,I
4744,ATT,I
4744,on,B
4744,D1,B
4744,and,I
4744,D2,I
4744,",",O
4744,but,O
4744,improvements,O
4744,can,O
4744,be,O
4744,clearly,O
4744,observed,O
4744,for,O
4744,D3,O
4744,and,O
4744,D4,O
4744,.,O
4745,The,O
4745,combination,B
4745,(,I
4745,PRET,I
4745,+,I
4745,MULT,I
4745,),I
4745,over,O
4745,all,O
4745,yields,B
4745,better,B
4745,results,I
4745,.,O
4746,(,O
4746,2,O
4746,),O
4746,The,O
4746,numbers,B
4746,of,B
4746,neutral,I
4746,examples,I
4746,in,B
4746,the,O
4746,test,B
4746,sets,I
4746,of,O
4746,D3,B
4746,and,I
4746,D4,I
4746,are,B
4746,very,B
4746,small,I
4746,.,O
4747,Majority,B
4747,assigns,B
4747,the,O
4747,sentiment,B
4747,polarity,I
4747,that,O
4747,has,O
4747,the,O
4747,largest,B
4747,probability,I
4747,in,B
4747,the,O
4747,training,B
4747,set,I
4747,;,O
4747,2,O
4747,.,O
4748,Simple,O
4748,SVM,B
4748,is,B
4748,a,O
4748,SVM,O
4748,classifier,O
4748,with,B
4748,simple,O
4748,features,O
4748,such,B
4748,as,I
4748,unigrams,B
4748,and,I
4748,bigrams,I
4748,;,O
4748,3,O
4748,.,O
4749,Feature,O
4749,-,O
4749,enhanced,O
4749,SVM,B
4749,is,B
4749,a,O
4749,SVM,O
4749,classifier,O
4749,with,B
4749,a,O
4749,state,B
4749,-,O
4749,of,O
4749,-,O
4749,the,O
4749,-,O
4749,art,O
4749,feature,O
4749,template,O
4749,which,B
4749,contains,I
4749,n-gram,B
4749,features,I
4749,",",O
4749,parse,B
4749,features,O
4749,and,O
4749,lexicon,B
4749,features,O
4749,;,O
4749,4,O
4749,.,O
4750,TD,O
4750,-,O
4750,LSTM,O
4750,adopts,B
4750,two,B
4750,LSTMs,I
4750,to,B
4750,model,I
4750,the,O
4750,left,B
4750,context,I
4750,with,B
4750,target,B
4750,and,O
4750,the,O
4750,right,B
4750,context,O
4750,with,O
4750,target,O
4750,respectively,O
4750,;,O
4750,74.30,O
4750,66.50,O
4750,66.50,O
4750,TD-,O
4750,LSTM,O
4750,75.60,O
4750,68.10,O
4750,70.80,O
4750,AE,O
4750,-,O
4750,LSTM,O
4750,76.60,O
4750,68.90,O
4750,-,O
4750,ATAE,O
4750,-,O
4750,LSTM,O
4750,77.20,O
4750,68.70,O
4750,-,O
4750,GRNN-,O
4750,G3,O
4750,79.55,O
4750,*,O
4750,71.47,O
4750,*,O
4750,70.09,O
4750,*,O
4750,MemNet,O
4750,79.98,O
4750,*,O
4750,70.33,O
4750,*,O
4750,70.52,O
4750,*,O
4750,IAN,O
4750,78.60,O
4750,72.10,O
4750,-,O
4750,LCR,O
4750,-,O
4750,Rot,O
4750,(,O
4750,our,O
4750,approach,O
4750,),O
4750,81.34,O
4750,75.24,O
4750,72.69,O
4750,:,O
4750,The,O
4750,performance,O
4750,(,O
4750,classification,O
4750,accuracy,O
4750,),O
4750,of,O
4750,different,O
4750,methods,O
4750,on,O
4750,three,O
4750,datasets,O
4750,.,O
4751,AE,O
4751,-,O
4751,LSTM,B
4751,is,B
4751,an,O
4751,upgraded,B
4751,version,I
4751,of,B
4751,LSTM,O
4751,.,O
4752,ATAE,O
4752,-,O
4752,LSTM,O
4752,is,O
4752,developed,B
4752,based,I
4752,on,I
4752,AE,B
4752,-,O
4752,LSTM,O
4752,.,O
4753,GRNN,O
4753,-,O
4753,G3,O
4753,adopts,B
4753,a,O
4753,Gated,B
4753,-,O
4753,RNN,O
4753,to,B
4753,represent,I
4753,sentence,B
4753,and,O
4753,use,B
4753,a,O
4753,three,B
4753,-,O
4753,way,O
4753,structure,O
4753,to,O
4753,leverage,O
4753,contexts,B
4753,.,O
4754,MemNet,B
4754,is,B
4754,a,O
4754,deep,B
4754,memory,I
4754,network,I
4754,which,O
4754,considers,B
4754,the,O
4754,content,B
4754,and,I
4754,position,I
4754,of,B
4754,target,B
4754,.,O
4755,IAN,B
4755,interactively,B
4755,learns,I
4755,attentions,B
4755,in,B
4755,the,O
4755,contexts,O
4755,and,O
4755,targets,B
4755,",",O
4755,and,O
4755,generate,B
4755,the,O
4755,representations,B
4755,for,B
4755,targets,O
4755,and,O
4755,contexts,O
4755,separately,O
4755,.,O
4756,Without,B
4756,the,O
4756,feed,B
4756,-,I
4756,forward,I
4756,layer,I
4756,",",O
4756,the,O
4756,result,B
4756,drops,B
4756,to,I
4756,an,O
4756,F1,B
4756,score,I
4756,of,I
4756,67.8,I
4756,.,O
4757,In,O
4757,our,O
4757,work,O
4757,",",O
4757,the,O
4757,dimension,B
4757,of,B
4757,word,B
4757,embedding,I
4757,vectors,I
4757,and,O
4757,hidden,B
4757,state,I
4757,vectors,O
4757,is,B
4757,300,B
4757,.,O
4758,All,O
4758,out,O
4758,-,O
4758,ofvocabulary,O
4758,words,O
4758,and,O
4758,weight,O
4758,matrices,O
4758,are,O
4758,randomly,B
4758,initialized,I
4758,by,I
4758,a,O
4758,uniform,B
4758,distribution,I
4758,U,I
4758,(,I
4758,-,O
4758,0.1,O
4758,",",O
4758,0.1,O
4758,),O
4758,",",O
4758,and,O
4758,all,O
4758,bias,O
4758,are,O
4758,set,B
4758,to,I
4758,zero,B
4758,.,O
4759,Tensor,O
4759,Flow,O
4759,is,O
4759,used,O
4759,for,B
4759,implementing,I
4759,our,O
4759,neural,B
4759,network,I
4759,model,I
4759,.,O
4760,The,O
4760,paired,B
4760,t-,I
4760,test,I
4760,is,O
4760,used,B
4760,for,I
4760,the,O
4760,significance,B
4760,testing,I
4760,.,O
4761,We,O
4761,use,B
4761,GloVe,B
4761,2,I
4761,vectors,I
4761,with,B
4761,300,B
4761,dimensions,I
4761,to,B
4761,initialize,I
4761,the,O
4761,word,B
4761,embeddings,I
4761,",",O
4761,the,O
4761,same,O
4761,as,O
4761,.,O
4762,In,B
4762,model,B
4762,training,I
4762,",",O
4762,the,O
4762,learning,B
4762,rate,I
4762,is,O
4762,set,B
4762,to,I
4762,0.1,B
4762,",",O
4762,the,O
4762,weight,B
4762,for,B
4762,L,B
4762,2,I
4762,-,I
4762,norm,I
4762,regularization,I
4762,is,O
4762,set,O
4762,to,O
4762,1,B
4762,e,I
4762,-,O
4762,5,O
4762,",",O
4762,and,O
4762,dropout,B
4762,rate,O
4762,is,O
4762,set,O
4762,to,O
4762,0.5,B
4762,.,O
4763,We,O
4763,train,B
4763,the,O
4763,model,B
4763,use,B
4763,stochastic,B
4763,gradient,I
4763,descent,I
4763,optimizer,I
4763,with,B
4763,momentum,B
4763,of,B
4763,0.9,B
4763,.,O
4764,With,B
4764,the,O
4764,attempt,O
4764,to,O
4764,better,O
4764,address,O
4764,the,O
4764,two,O
4764,problems,O
4764,",",O
4764,in,O
4764,this,O
4764,paper,O
4764,we,O
4764,propose,B
4764,a,O
4764,left,B
4764,-,I
4764,center,I
4764,-,O
4764,right,O
4764,separated,O
4764,neural,O
4764,network,O
4764,with,O
4764,rotatory,B
4764,attention,I
4764,mechanism,I
4764,(,I
4764,LCR,I
4764,-,O
4764,Rot,O
4764,),O
4764,.,O
4765,On,O
4765,this,O
4765,basis,O
4765,",",O
4765,we,O
4765,further,O
4765,propose,O
4765,a,O
4765,rotatory,B
4765,attention,I
4765,mechanism,I
4765,to,B
4765,take,B
4765,into,I
4765,account,I
4765,the,O
4765,interaction,B
4765,between,B
4765,targets,B
4765,and,I
4765,contexts,I
4765,to,O
4765,better,O
4765,represent,O
4765,targets,O
4765,and,O
4765,contexts,O
4765,.,O
4766,Specifically,O
4766,",",O
4766,we,O
4766,design,B
4766,a,O
4766,left,B
4766,-,I
4766,center,I
4766,-,O
4766,right,O
4766,separated,O
4766,LSTMs,O
4766,that,O
4766,contains,B
4766,three,B
4766,LSTMs,O
4766,",",O
4766,i.e.,B
4767,",",O
4767,left,B
4767,-,I
4767,",",O
4767,center,O
4767,-,O
4767,and,O
4767,right,B
4767,-,O
4767,LSTM,O
4767,",",O
4767,respectively,O
4767,modeling,B
4767,the,O
4767,three,B
4767,parts,I
4767,of,B
4767,a,O
4767,review,B
4767,(,O
4767,left,O
4767,context,O
4767,",",O
4767,target,B
4767,phrase,I
4767,and,O
4767,right,O
4767,context,O
4767,),O
4767,.,O
4768,In,O
4768,general,O
4768,",",O
4768,C,O
4768,-,O
4768,AGGCN,O
4768,with,O
4768,full,O
4768,trees,O
4768,outperforms,B
4768,C,O
4768,-,O
4768,AGGCN,O
4768,with,O
4768,pruned,O
4768,trees,O
4768,and,O
4768,C,O
4768,-,O
4768,GCN,O
4768,against,B
4768,various,B
4768,sentence,I
4768,lengths,I
4768,.,O
4769,The,O
4769,target2context,B
4769,attention,I
4769,is,O
4769,used,O
4769,to,B
4769,capture,I
4769,the,O
4769,most,B
4769,indicative,I
4769,sentiment,I
4769,words,I
4769,in,B
4769,left,B
4769,/,I
4769,right,I
4769,contexts,I
4769,.,O
4770,Subsequently,O
4770,",",O
4770,the,O
4770,context2target,B
4770,attention,I
4770,is,O
4770,used,O
4770,to,B
4770,capture,I
4770,the,O
4770,most,B
4770,important,I
4770,word,I
4770,in,B
4770,the,O
4770,target,B
4770,.,O
4771,This,O
4771,leads,B
4771,to,I
4771,a,O
4771,two,B
4771,-,I
4771,side,I
4771,representation,I
4771,of,B
4771,the,O
4771,target,O
4771,:,O
4771,left,B
4771,-,O
4771,aware,O
4771,target,O
4771,and,O
4771,right,B
4771,-,O
4771,aware,O
4771,target,O
4771,.,O
4772,Finally,O
4772,",",O
4772,we,O
4772,concatenate,B
4772,the,O
4772,component,B
4772,representations,I
4772,as,B
4772,the,O
4772,final,B
4772,representation,I
4772,of,B
4772,the,O
4772,sentence,B
4772,and,O
4772,feed,B
4772,it,I
4772,into,I
4772,a,O
4772,softmax,B
4772,layer,I
4772,to,B
4772,predict,I
4772,the,O
4772,sentiment,B
4772,polarity,I
4772,.,O
4773,Left,O
4773,-,O
4773,Center,O
4773,-,O
4773,Right,O
4773,Separated,O
4773,Neural,O
4773,Network,O
4773,for,O
4773,Aspect,B
4773,-,O
4773,based,O
4773,Sentiment,O
4773,Analysis,O
4773,with,O
4773,Rotatory,O
4773,Attention,O
4774,Aspect,O
4774,-,O
4774,based,O
4774,sentiment,B
4774,analysis,I
4774,is,O
4774,a,O
4774,fine,O
4774,-,O
4774,grained,O
4774,classification,O
4774,task,O
4774,in,O
4774,sentiment,O
4774,analysis,O
4774,",",O
4774,identifying,O
4774,sentiment,O
4774,polarity,O
4774,of,O
4774,a,O
4774,sentence,O
4774,expressed,O
4774,toward,O
4774,a,O
4774,target,O
4774,.,O
4775,In,O
4775,the,O
4775,early,O
4775,studies,O
4775,",",O
4775,methods,O
4775,for,O
4775,the,O
4775,aspect,O
4775,-,O
4775,based,O
4775,sentiment,B
4775,classification,I
4775,task,O
4775,were,O
4775,similar,O
4775,as,O
4775,that,O
4775,used,O
4775,in,O
4775,standard,O
4775,sentiment,O
4775,classification,O
4775,task,O
4775,.,O
4776,We,O
4776,can,O
4776,find,B
4776,that,O
4776,the,O
4776,Majority,B
4776,method,I
4776,is,B
4776,the,O
4776,worst,B
4776,",",I
4776,which,O
4776,means,O
4776,the,O
4776,majority,O
4776,sentiment,O
4776,polarity,O
4776,occupies,B
4776,53.50,B
4776,%,I
4776,",",O
4776,65.00,O
4776,%,O
4776,and,O
4776,50,O
4776,%,O
4776,of,O
4776,all,O
4776,samples,O
4776,on,B
4776,the,O
4776,Restaurant,B
4776,",",O
4776,Laptop,O
4776,and,O
4776,Twitter,O
4776,testing,O
4776,datasets,O
4776,respectively,O
4776,.,O
4777,The,O
4777,Simple,B
4777,SVM,I
4777,model,I
4777,performs,B
4777,better,B
4777,than,B
4777,Majority,B
4777,.,O
4778,Our,O
4778,model,O
4778,achieves,B
4778,significantly,B
4778,better,I
4778,results,I
4778,than,B
4778,feature,B
4778,-,I
4778,enhanced,I
4778,SVM,I
4778,.,O
4779,PCNN,B
4779,:,O
4779,A,O
4779,CNN,B
4779,based,I
4779,relation,I
4779,extraction,I
4779,model,I
4779,by,O
4779,which,O
4779,uses,B
4779,piecewise,B
4779,max,I
4779,-,I
4779,pooling,I
4779,for,B
4779,sentence,B
4779,representation,I
4779,.,O
4780,Moreover,O
4780,",",O
4780,the,O
4780,improvement,B
4780,achieved,B
4780,by,I
4780,C,B
4780,-,I
4780,AGGCN,I
4780,with,I
4780,pruned,I
4780,trees,I
4780,decays,B
4780,when,B
4780,the,O
4780,sentence,B
4780,length,I
4780,increases,B
4780,.,O
4781,Among,O
4781,LSTM,O
4781,based,O
4781,neural,O
4781,networks,O
4781,described,O
4781,in,O
4781,this,O
4781,paper,O
4781,",",O
4781,the,O
4781,basic,B
4781,LSTM,O
4781,approach,O
4781,performs,B
4781,the,O
4781,worst,B
4781,.,O
4782,TD,O
4782,-,O
4782,LSTM,B
4782,obtains,B
4782,an,O
4782,improvement,B
4782,of,B
4782,1,B
4782,-,O
4782,2,O
4782,%,O
4782,over,B
4782,LSTM,O
4782,when,B
4782,target,B
4782,signals,I
4782,are,O
4782,taken,B
4782,into,I
4782,consideration,B
4782,.,O
4783,MemNet,B
4783,achieves,B
4783,better,B
4783,results,I
4783,than,B
4783,other,B
4783,models,I
4783,on,B
4783,the,O
4783,Restaurant,B
4783,dataset,I
4783,",",O
4783,since,O
4783,it,O
4783,considers,O
4783,not,O
4783,only,O
4783,the,O
4783,contexts,O
4783,of,O
4783,targets,O
4783,but,O
4783,also,O
4783,the,O
4783,position,O
4783,of,O
4783,each,O
4783,context,O
4783,word,O
4783,related,O
4783,to,O
4783,the,O
4783,target,O
4783,.,O
4784,IAN,B
4784,considers,B
4784,separate,B
4784,representations,I
4784,of,B
4784,targets,B
4784,and,O
4784,obtains,B
4784,better,B
4784,result,I
4784,on,B
4784,the,O
4784,Laptop,B
4784,dataset,I
4784,.,O
4785,GRNN,O
4785,-,O
4785,G3,O
4785,achieves,B
4785,competitive,B
4785,results,I
4785,on,B
4785,all,B
4785,datasets,I
4785,because,O
4785,of,O
4785,its,O
4785,three,O
4785,-,O
4785,way,O
4785,structure,O
4785,and,O
4785,special,O
4785,gated,O
4785,-,O
4785,RNN,O
4785,model,O
4785,.,O
4786,In,O
4786,the,O
4786,contrast,O
4786,",",O
4786,our,O
4786,LCR,B
4786,-,I
4786,Rot,I
4786,model,I
4786,achieves,B
4786,the,O
4786,best,B
4786,results,I
4786,on,B
4786,the,O
4786,all,B
4786,datasets,I
4786,among,B
4786,all,O
4786,models,O
4786,.,O
4787,With,O
4787,the,O
4787,help,O
4787,of,O
4787,feature,B
4787,engineering,I
4787,",",O
4787,the,O
4787,Feature,O
4787,-,O
4787,enhanced,O
4787,SVM,O
4787,achieves,B
4787,much,B
4787,better,I
4787,results,I
4787,.,O
4788,We,O
4788,use,B
4788,the,O
4788,released,B
4788,handcrafted,I
4788,features,I
4788,",",O
4788,i.e.,B
4789,",",O
4789,the,O
4789,differential,B
4789,entropy,I
4789,(,I
4789,DE,I
4789,),I
4789,in,B
4789,SEED,I
4789,and,I
4789,SEED,O
4789,-,O
4789,IV,O
4789,",",O
4789,and,O
4789,the,O
4789,Short,B
4789,-,O
4789,Time,O
4789,Fourier,O
4789,Transform,O
4789,(,O
4789,STFT,O
4789,),O
4789,in,O
4789,MPED,B
4789,",",O
4789,as,O
4789,the,O
4789,input,O
4789,to,B
4789,feed,I
4789,our,O
4789,model,B
4789,.,O
4790,Thus,O
4790,the,O
4790,sizes,B
4790,d,I
4790,N,I
4790,of,B
4790,the,O
4790,input,B
4790,sample,I
4790,X,I
4790,t,I
4790,are,B
4790,5,I
4790,62,I
4790,",",I
4790,5,O
4790,62,O
4790,and,O
4790,1,O
4790,62,O
4790,for,O
4790,these,O
4790,three,O
4790,datasets,O
4790,",",O
4790,respectively,O
4790,.,O
4791,The,O
4791,learning,B
4791,rate,I
4791,",",I
4791,momentum,I
4791,and,I
4791,weight,I
4791,decay,I
4791,rate,O
4791,are,O
4791,set,B
4791,as,I
4791,0.003,B
4791,",",O
4791,0.9,O
4791,and,O
4791,0.95,O
4791,respectively,O
4791,.,O
4792,C,O
4792,-,O
4792,AGGCN,O
4792,consistently,B
4792,outperforms,I
4792,C,O
4792,-,O
4792,GCN,O
4792,under,B
4792,the,O
4792,same,B
4792,amount,I
4792,of,I
4792,training,I
4792,data,I
4792,.,O
4793,The,O
4793,network,B
4793,is,O
4793,trained,B
4793,using,I
4793,SGD,B
4793,with,B
4793,batch,B
4793,size,I
4793,of,B
4793,200,B
4793,.,O
4794,Moreover,O
4794,",",O
4794,in,B
4794,the,O
4794,experiment,B
4794,",",O
4794,we,O
4794,respectively,O
4794,set,B
4794,the,O
4794,dimension,B
4794,d,I
4794,l,I
4794,of,B
4794,each,B
4794,electrode,I
4794,'s,I
4794,deep,I
4794,representation,I
4794,to,B
4794,32,B
4794,;,O
4794,the,O
4794,parameters,B
4794,d,O
4794,g,O
4794,and,O
4794,K,O
4794,of,O
4794,the,O
4794,global,B
4794,high,I
4794,-,I
4794,level,I
4794,feature,I
4794,to,O
4794,32,O
4794,and,O
4794,6,O
4794,;,O
4794,and,O
4794,the,O
4794,dimension,O
4794,do,O
4794,of,O
4794,the,O
4794,output,B
4794,feature,O
4794,to,O
4794,16,B
4794,without,B
4794,elaborate,B
4794,traversal,I
4794,.,O
4795,Specifically,O
4795,",",O
4795,we,O
4795,implemented,B
4795,BiHDM,B
4795,using,B
4795,Tensor,B
4795,Flow,I
4795,on,B
4795,one,B
4795,Nvidia,I
4795,1080,I
4795,Ti,I
4795,GPU,I
4795,.,O
4796,In,O
4796,addition,O
4796,",",O
4796,we,O
4796,adopt,B
4796,the,O
4796,subtraction,B
4796,as,B
4796,the,O
4796,pairwise,B
4796,operation,I
4796,of,B
4796,the,O
4796,BiHDM,B
4796,model,I
4796,in,O
4796,the,O
4796,experiment,O
4796,section,O
4796,",",O
4796,and,O
4796,discuss,O
4796,the,O
4796,other,O
4796,two,O
4796,types,O
4796,of,O
4796,operations,O
4796,in,O
4796,section,O
4796,III,O
4796,-,O
4796,D.,O
4797,1,O
4797,),O
4797,The,O
4797,subject,B
4797,-,I
4797,dependent,I
4797,experiment,I
4797,:,O
4798,To,O
4798,validate,O
4798,the,O
4798,superiority,O
4798,of,O
4798,BiHDM,O
4798,",",O
4798,we,O
4798,also,O
4798,conduct,O
4798,the,O
4798,same,O
4798,experiments,O
4798,using,B
4798,twelve,B
4798,methods,I
4798,",",O
4798,including,B
4798,linear,I
4798,support,I
4798,vector,I
4798,machine,I
4798,(,I
4798,SVM,I
4798,),I
4798,",",O
4798,random,B
4798,forest,I
4798,(,O
4798,RF,O
4798,),O
4798,",",O
4798,canonical,O
4798,correlation,O
4798,analysis,O
4798,(,O
4798,CCA,O
4798,),O
4798,",",O
4798,group,B
4798,sparse,I
4798,canonical,O
4798,correlation,O
4798,analysis,O
4798,(,O
4798,GSCCA,O
4798,),O
4798,",",O
4798,deep,B
4798,believe,I
4798,network,I
4798,(,O
4798,DBN,O
4798,),O
4798,",",O
4798,graph,O
4798,regularization,O
4798,sparse,O
4798,linear,O
4798,regression,O
4798,(,O
4798,GRSLR,O
4798,),O
4798,",",O
4798,graph,O
4798,convolutional,O
4798,neural,O
4798,network,O
4798,(,O
4798,GCNN,O
4798,),O
4798,",",O
4798,dynamical,B
4798,graph,O
4798,convolutional,O
4798,neural,O
4798,network,O
4798,(,O
4798,DGCNN,O
4798,),O
4798,",",O
4798,domain,O
4798,adversarial,O
4798,neural,O
4798,networks,O
4798,(,O
4798,DANN,O
4798,),O
4798,",",O
4798,bi-hemisphere,B
4798,domain,O
4798,adversarial,O
4798,neural,O
4798,network,O
4798,(,O
4798,BiDANN,O
4798,),O
4798,",",O
4798,EmotionMeter,B
4798,",",O
4798,and,O
4798,attention,B
4798,-,I
4798,long,I
4798,short,I
4798,-,O
4798,term,O
4798,memory,O
4798,(,O
4798,A,O
4798,-,O
4798,LSTM,O
4798,),O
4798,.,O
4799,From,O
4799,",",O
4799,we,O
4799,can,O
4799,see,B
4799,that,O
4799,the,O
4799,proposed,B
4799,BiHDM,I
4799,model,I
4799,outperforms,B
4799,all,B
4799,the,O
4799,compared,O
4799,methods,O
4799,on,B
4799,all,O
4799,the,O
4799,three,O
4799,public,O
4799,EEG,O
4799,emotional,O
4799,datasets,O
4799,",",O
4799,which,O
4799,verifies,B
4799,the,O
4799,effectiveness,B
4799,of,I
4799,BiHDM,O
4799,.,O
4800,Especially,O
4800,for,O
4800,the,O
4800,result,O
4800,on,B
4800,SEED,B
4800,-,I
4800,IV,I
4800,",",O
4800,the,O
4800,proposed,B
4800,method,I
4800,improves,B
4800,over,I
4800,the,O
4800,state,B
4800,-,O
4800,of,O
4800,-,O
4800,the,O
4800,-,O
4800,art,O
4800,method,O
4800,Emotion,O
4800,-,O
4800,Meter,O
4800,by,B
4800,4,B
4800,%,I
4800,.,O
4801,Besides,O
4801,",",O
4801,we,O
4801,can,O
4801,see,B
4801,that,I
4801,the,O
4801,compared,B
4801,method,I
4801,BiDANN,I
4801,",",O
4801,which,O
4801,also,O
4801,considers,B
4801,the,O
4801,bi-hemispheric,B
4801,asymmetry,I
4801,",",O
4801,achieves,B
4801,a,O
4801,comparable,B
4801,performance,I
4801,.,O
4802,shows,B
4802,the,O
4802,t-,B
4802,test,I
4802,statistical,I
4802,analysis,I
4802,results,I
4802,",",O
4802,from,O
4802,which,O
4802,we,O
4802,can,O
4802,see,B
4802,BiHDM,B
4802,is,B
4802,significantly,B
4802,better,I
4802,than,B
4802,the,O
4802,baseline,B
4802,method,I
4802,.,O
4803,This,O
4803,suggests,B
4803,that,I
4803,C,B
4803,-,I
4803,AGGCN,I
4803,can,O
4803,benefit,B
4803,more,I
4803,from,I
4803,larger,B
4803,graphs,I
4803,(,I
4803,full,I
4803,tree,I
4803,),I
4803,.,O
4804,2,O
4804,),O
4804,The,O
4804,subject,B
4804,-,I
4804,independent,I
4804,experiment,I
4804,:,O
4805,In,O
4805,addition,O
4805,",",O
4805,for,O
4805,comparison,O
4805,purpose,O
4805,",",O
4805,we,O
4805,use,B
4805,twelve,B
4805,methods,I
4805,including,B
4805,Kullback,B
4805,-,I
4805,Leibler,I
4805,importance,I
4805,estimation,I
4805,procedure,I
4805,(,I
4805,KLIEP,I
4805,),I
4805,",",O
4805,unconstrained,B
4805,least,I
4805,-,O
4805,squares,O
4805,importance,O
4805,fitting,O
4805,(,O
4805,ULSIF,O
4805,),O
4805,",",O
4805,selective,B
4805,transfer,B
4805,machine,I
4805,(,O
4805,STM,O
4805,),O
4805,",",O
4805,linear,B
4805,SVM,I
4805,",",O
4805,transfer,O
4805,component,O
4805,analysis,O
4805,(,O
4805,TCA,O
4805,),O
4805,",",O
4805,transfer,O
4805,component,O
4805,analysis,O
4805,(,O
4805,TCA,O
4805,),O
4805,",",O
4805,geodesic,B
4805,flow,I
4805,kernel,I
4805,(,O
4805,GFK,O
4805,),O
4805,",",O
4805,DANN,B
4805,",",O
4805,DGCNN,B
4805,",",O
4805,deep,B
4805,adaptation,I
4805,network,I
4805,(,O
4805,DAN,O
4805,),O
4805,",",O
4805,BiDANN,B
4805,",",O
4805,and,O
4805,A,B
4805,-,O
4805,LSTM,O
4805,",",O
4805,to,O
4805,conduct,O
4805,the,O
4805,same,O
4805,experiments,O
4805,.,O
4806,The,O
4806,results,O
4806,are,O
4806,shown,O
4806,in,B
4806,From,O
4806,",",O
4806,it,O
4806,can,O
4806,be,O
4806,clearly,O
4806,seen,B
4806,that,I
4806,the,O
4806,proposed,B
4806,BiHDM,I
4806,method,I
4806,achieves,B
4806,the,O
4806,best,B
4806,performance,I
4806,in,O
4806,the,O
4806,three,B
4806,public,I
4806,datasets,I
4806,",",O
4806,which,O
4806,verifies,B
4806,the,O
4806,effectiveness,B
4806,of,I
4806,BiHDM,O
4806,in,O
4806,dealing,O
4806,with,O
4806,subject,B
4806,-,I
4806,independent,I
4806,EEG,I
4806,emotion,I
4806,recognition,I
4806,.,O
4807,For,B
4807,the,I
4807,three,B
4807,datasets,I
4807,",",I
4807,the,O
4807,improvements,B
4807,on,I
4807,accuracy,B
4807,are,B
4807,2.2,B
4807,%,I
4807,",",O
4807,3.5,O
4807,%,O
4807,and,O
4807,2.4,O
4807,%,O
4807,",",O
4807,respectively,O
4807,",",O
4807,when,O
4807,compared,B
4807,with,I
4807,the,O
4807,existing,B
4807,state,I
4807,-,I
4807,of,I
4807,-,O
4807,the,O
4807,-,O
4807,art,O
4807,methods,O
4807,.,O
4808,shows,O
4808,the,O
4808,t-,B
4808,test,I
4808,statistical,I
4808,analysis,I
4808,results,I
4808,",",O
4808,from,O
4808,which,O
4808,we,O
4808,can,O
4808,see,B
4808,BiHDM,B
4808,is,B
4808,significantly,B
4808,better,I
4808,than,B
4808,the,O
4808,baseline,B
4808,method,I
4808,.,O
4809,Thus,O
4809,",",O
4809,in,O
4809,this,O
4809,paper,O
4809,",",O
4809,we,O
4809,propose,B
4809,a,O
4809,novel,B
4809,neural,I
4809,network,I
4809,model,I
4809,BiHDM,I
4809,to,B
4809,learn,I
4809,the,O
4809,bi-hemispheric,B
4809,discrepancy,I
4809,for,B
4809,EEG,B
4809,emotion,I
4809,recognition,I
4809,.,O
4810,BiHDM,B
4810,aims,B
4810,to,B
4810,obtain,I
4810,the,O
4810,deep,B
4810,discrepant,I
4810,features,I
4810,between,B
4810,the,O
4810,left,B
4810,and,I
4810,right,I
4810,hemispheres,I
4810,",",O
4810,which,O
4810,is,O
4810,expected,B
4810,to,O
4810,contain,O
4810,more,B
4810,discriminative,I
4810,information,I
4810,to,O
4810,recognize,O
4810,the,O
4810,EEG,B
4810,emotion,I
4810,signals,I
4810,.,O
4811,Hence,O
4811,",",O
4811,to,B
4811,avoid,I
4811,losing,I
4811,this,O
4811,intrinsic,B
4811,graph,I
4811,structural,I
4811,information,I
4811,of,B
4811,EEG,I
4811,data,I
4811,",",O
4811,we,O
4811,can,O
4811,simplify,B
4811,the,I
4811,graph,O
4811,structure,O
4811,learning,O
4811,process,O
4811,by,B
4811,using,I
4811,the,O
4811,horizontal,B
4811,and,I
4811,vertical,I
4811,traversing,I
4811,RNNs,I
4811,",",O
4811,which,B
4811,will,I
4811,construct,I
4811,a,O
4811,complete,B
4811,relationship,I
4811,graph,O
4811,and,O
4811,generate,B
4811,discriminative,B
4811,deep,I
4811,features,I
4811,for,B
4811,all,B
4811,the,O
4811,EEG,O
4811,electrodes,O
4811,.,O
4812,After,O
4812,obtaining,O
4812,these,O
4812,deep,B
4812,features,I
4812,of,B
4812,each,B
4812,electrodes,I
4812,",",O
4812,we,O
4812,can,O
4812,extract,B
4812,the,O
4812,asymmetric,B
4812,discrepancy,I
4812,information,I
4812,between,B
4812,two,B
4812,hemispheres,I
4812,by,B
4812,performing,I
4812,specific,B
4812,pairwise,I
4812,operations,I
4812,for,B
4812,any,B
4812,paired,I
4812,symmetric,I
4812,electrodes,O
4812,.,O
4813,A,O
4813,Novel,O
4813,Bi-hemispheric,O
4813,Discrepancy,O
4813,Model,O
4813,for,O
4813,EEG,B
4813,Emotion,I
4813,Recognition,I
4814,When,B
4814,the,O
4814,size,B
4814,of,B
4814,training,B
4814,data,I
4814,increases,B
4814,",",O
4814,we,O
4814,can,O
4814,observe,B
4814,that,I
4814,the,O
4814,performance,B
4814,gap,I
4814,becomes,B
4814,more,B
4814,obvious,I
4814,.,O
4815,Inspired,O
4815,by,O
4815,this,O
4815,study,O
4815,",",O
4815,in,O
4815,this,O
4815,paper,O
4815,",",O
4815,we,O
4815,propose,O
4815,a,O
4815,novel,O
4815,bi-hemispheric,O
4815,discrepancy,O
4815,model,O
4815,(,O
4815,BiHDM,O
4815,),O
4815,to,O
4815,learn,O
4815,the,O
4815,asymmetric,O
4815,differences,O
4815,between,O
4815,two,O
4815,hemispheres,O
4815,for,O
4815,electroencephalograph,B
4815,(,O
4815,EEG,O
4815,),O
4815,emotion,O
4815,recognition,O
4815,.,O
4816,As,O
4816,the,O
4816,first,O
4816,step,O
4816,to,O
4816,make,O
4816,machines,O
4816,capture,O
4816,human,O
4816,emotions,O
4816,",",O
4816,emotion,B
4816,recognition,I
4816,has,O
4816,received,O
4816,substantial,O
4816,attention,O
4816,from,O
4816,human,O
4816,-,O
4816,machine,O
4816,-,O
4816,interaction,O
4816,(,O
4816,HMI,O
4816,),O
4816,and,O
4816,pattern,O
4816,recognition,O
4816,research,O
4816,communities,O
4816,in,O
4816,recent,O
4816,years,O
4816,",",O
4816,",",O
4816,.,O
4817,Many,O
4817,existing,O
4817,works,O
4817,in,O
4817,the,O
4817,aspect,O
4817,-,O
4817,based,B
4817,sentiment,O
4817,analysis,O
4817,task,O
4817,",",O
4817,3,O
4817,use,O
4817,a,O
4817,classifier,O
4817,",",O
4817,such,B
4817,as,I
4817,logistic,O
4817,regression,O
4817,or,O
4817,SVM,O
4817,",",O
4817,based,O
4817,on,O
4817,linguistic,B
4817,features,I
4817,such,O
4817,as,O
4817,n-grams,B
4817,",",O
4817,POS,B
4817,information,I
4817,or,O
4817,more,B
4817,hand,I
4817,-,O
4817,engineered,O
4817,features,O
4817,.,O
4818,More,O
4818,concretely,O
4818,",",O
4818,we,O
4818,define,B
4818,the,O
4818,following,O
4818,sparse,B
4818,representations,I
4818,of,I
4818,locations,I
4818,:,O
4819,Inspired,O
4819,by,O
4819,the,O
4819,recent,O
4819,success,O
4819,of,O
4819,applying,O
4819,deep,O
4819,neural,O
4819,networks,O
4819,on,O
4819,language,O
4819,tasks,O
4819,",",O
4819,we,O
4819,use,B
4819,a,O
4819,bidirectional,B
4819,LSTM,I
4819,to,B
4819,learn,I
4819,a,O
4819,classifier,B
4819,for,B
4819,each,B
4819,of,O
4819,the,O
4819,aspects,O
4819,.,O
4820,Particularly,O
4820,",",O
4820,using,B
4820,80,B
4820,%,I
4820,of,B
4820,the,O
4820,training,B
4820,data,I
4820,",",O
4820,the,O
4820,C,B
4820,-,I
4820,AGGCN,I
4820,model,I
4820,is,O
4820,able,B
4820,to,I
4820,achieve,I
4820,a,O
4820,F,B
4820,1,I
4820,score,I
4820,of,O
4820,66.5,B
4820,",",O
4820,higher,B
4820,than,I
4820,C,O
4820,-,O
4820,GCN,O
4820,trained,B
4820,on,I
4820,the,O
4820,whole,B
4820,dataset,I
4820,.,O
4821,Representations,B
4821,for,B
4821,a,O
4821,location,B
4821,(,I
4821,e,I
4821,l,I
4821,),I
4821,are,O
4821,obtained,O
4821,using,B
4821,one,O
4821,of,O
4821,the,O
4821,following,O
4821,two,O
4821,approaches,O
4821,:,O
4822,SentiHood,B
4822,currently,O
4822,contains,B
4822,annotated,B
4822,sentences,I
4822,containing,B
4822,one,B
4822,or,I
4822,two,I
4822,location,I
4822,entity,I
4822,mentions,I
4822,.,O
4823,2,O
4823,Sen-tiHood,O
4823,contains,O
4823,5215,B
4823,sentences,I
4823,with,B
4823,3862,B
4823,sentences,O
4823,containing,B
4823,a,O
4823,single,B
4823,location,I
4823,and,O
4823,1353,B
4823,sentences,O
4823,containing,O
4823,multiple,B
4823,(,I
4823,two,I
4823,),I
4823,locations,I
4823,.,O
4824,"""",O
4824,Positive,O
4824,"""",O
4824,sentiment,O
4824,is,O
4824,dominant,B
4824,for,I
4824,aspects,B
4824,such,B
4824,as,I
4824,dining,B
4824,and,I
4824,shopping,I
4824,.,O
4825,The,O
4825,general,B
4825,aspect,B
4825,is,B
4825,the,O
4825,most,B
4825,frequent,I
4825,aspect,O
4825,with,B
4825,over,B
4825,2000,I
4825,sentences,I
4825,while,O
4825,aspect,O
4825,touristy,O
4825,has,O
4825,occurred,B
4825,in,I
4825,less,B
4825,than,I
4825,100,I
4825,sentences,O
4825,.,O
4826,Notice,O
4826,that,O
4826,since,B
4826,each,B
4826,sentence,I
4826,can,B
4826,contain,I
4826,one,B
4826,or,I
4826,more,I
4826,opinions,I
4826,",",O
4826,the,O
4826,total,B
4826,number,B
4826,of,I
4826,opinions,O
4826,(,O
4826,5920,O
4826,),O
4826,in,B
4826,the,O
4826,dataset,B
4826,is,O
4826,higher,B
4826,than,I
4826,the,O
4826,number,O
4826,of,O
4826,sentences,O
4826,.,O
4827,Location,O
4827,entity,O
4827,names,O
4827,are,O
4827,masked,B
4827,by,I
4827,location1,B
4827,and,I
4827,location,O
4827,2,O
4827,in,B
4827,the,O
4827,whole,B
4827,dataset,I
4827,",",O
4827,so,O
4827,the,O
4827,task,O
4827,does,O
4827,not,O
4827,involve,O
4827,identification,O
4827,and,O
4827,segmentation,O
4827,of,O
4827,the,O
4827,named,O
4827,entities,O
4827,.,O
4828,SentiHood,O
4828,:,O
4828,Targeted,B
4828,Aspect,I
4828,Based,I
4828,Sentiment,I
4828,Analysis,I
4828,Dataset,O
4828,for,O
4828,Urban,O
4828,Neighbourhoods,O
4829,For,B
4829,cross,B
4829,-,I
4829,sentence,I
4829,n-,I
4829,ary,I
4829,relation,I
4829,extraction,I
4829,task,I
4829,",",O
4829,we,O
4829,consider,O
4829,three,O
4829,kinds,O
4829,of,O
4829,models,O
4829,as,O
4829,baselines,O
4829,:,O
4830,In,O
4830,this,O
4830,paper,O
4830,",",O
4830,we,O
4830,introduce,O
4830,the,O
4830,task,O
4830,of,O
4830,targeted,B
4830,aspect,I
4830,-,I
4830,based,I
4830,sentiment,I
4830,analysis,I
4830,.,O
4831,As,O
4831,we,O
4831,can,O
4831,see,B
4831,",",O
4831,the,O
4831,n-gram,B
4831,representation,I
4831,with,B
4831,location,B
4831,masking,I
4831,achieves,B
4831,slightly,B
4831,better,I
4831,results,I
4831,over,B
4831,the,O
4831,left,B
4831,-,I
4831,right,I
4831,context,I
4831,.,O
4832,Also,O
4832,",",O
4832,by,B
4832,adding,I
4832,POS,B
4832,information,I
4832,",",O
4832,we,O
4832,gain,B
4832,an,O
4832,increase,B
4832,in,B
4832,the,O
4832,performance,B
4832,.,O
4833,Separating,B
4833,the,I
4833,left,I
4833,and,I
4833,the,O
4833,right,O
4833,context,O
4833,(,O
4833,LR,O
4833,-,O
4833,Left,O
4833,-,O
4833,Right,O
4833,),O
4833,for,B
4833,BoW,B
4833,representation,I
4833,",",O
4833,does,B
4833,not,I
4833,improve,I
4833,the,O
4833,performance,B
4833,.,O
4834,Amongst,B
4834,the,I
4834,two,B
4834,variations,I
4834,of,I
4834,LSTM,I
4834,",",O
4834,the,O
4834,model,B
4834,with,B
4834,final,B
4834,state,I
4834,embeddings,B
4834,does,B
4834,slightly,B
4834,better,I
4834,than,B
4834,the,O
4834,model,O
4834,where,O
4834,we,O
4834,use,B
4834,the,O
4834,embeddings,O
4834,at,O
4834,the,O
4834,location,O
4834,index,O
4834,",",O
4834,however,O
4834,they,O
4834,are,O
4834,not,O
4834,significantly,O
4834,different,O
4834,(,O
4834,with,O
4834,a,O
4834,p,O
4834,valueless,O
4834,than,O
4834,0.01,O
4834,),O
4834,.,O
4835,It,O
4835,is,O
4835,interesting,B
4835,to,I
4835,note,I
4835,that,O
4835,the,O
4835,best,B
4835,LSTM,I
4835,model,I
4835,is,O
4835,not,B
4835,superior,I
4835,to,O
4835,logistic,B
4835,regression,I
4835,model,O
4835,",",O
4835,especially,O
4835,in,B
4835,terms,I
4835,of,I
4835,AUC,B
4835,.,O
4836,Another,O
4836,interesting,B
4836,observation,I
4836,is,B
4836,that,I
4836,the,O
4836,F,B
4836,1,I
4836,measure,I
4836,for,B
4836,logistic,B
4836,regression,I
4836,model,I
4836,with,B
4836,n-grams,B
4836,and,I
4836,POS,I
4836,information,I
4836,is,O
4836,very,B
4836,low,I
4836,while,O
4836,this,O
4836,model,O
4836,'s,O
4836,performance,B
4836,is,O
4836,superior,B
4836,to,B
4836,other,B
4836,models,I
4836,in,B
4836,terms,I
4836,of,I
4836,AUC,B
4836,.,O
4837,1,O
4837,),O
4837,a,O
4837,feature,B
4837,-,I
4837,based,B
4837,classifier,I
4837,based,O
4837,on,O
4837,shortest,B
4837,dependency,I
4837,paths,I
4837,between,B
4837,all,B
4837,entity,I
4837,pairs,I
4837,",",O
4837,2,O
4837,),O
4837,Graph,B
4837,-,O
4837,structured,O
4837,LSTM,O
4837,methods,O
4837,",",O
4837,including,B
4837,Graph,O
4837,LSTM,O
4837,",",O
4837,bidirectional,B
4837,DAG,I
4837,LSTM,O
4837,(,O
4837,Bidir,O
4837,DAG,O
4837,LSTM,O
4837,),O
4837,and,O
4837,Graph,O
4837,State,O
4837,LSTM,O
4837,(,O
4837,GS,O
4837,GLSTM,O
4837,),O
4837,.,O
4838,We,O
4838,explore,B
4838,various,B
4838,deep,I
4838,learning,I
4838,based,I
4838,architectures,I
4838,to,O
4838,first,O
4838,get,O
4838,the,O
4838,best,O
4838,individual,O
4838,detection,O
4838,accuracy,O
4838,from,O
4838,each,O
4838,of,O
4838,the,O
4838,different,O
4838,modes,O
4838,.,O
4839,We,O
4839,then,O
4839,combine,B
4839,them,I
4839,in,I
4839,an,O
4839,ensemble,B
4839,based,I
4839,architecture,I
4839,to,B
4839,allow,I
4839,for,O
4839,training,B
4839,across,B
4839,the,I
4839,different,B
4839,modalities,I
4839,using,B
4839,the,O
4839,variations,B
4839,of,I
4839,the,O
4839,better,O
4839,individual,O
4839,models,O
4839,.,O
4840,Our,O
4840,ensemble,O
4840,consists,B
4840,of,I
4840,Long,B
4840,Short,I
4840,Term,I
4840,Memory,I
4840,networks,I
4840,",",O
4840,Convolution,B
4840,Neural,I
4840,Networks,O
4840,",",O
4840,fully,B
4840,connected,I
4840,Multi,I
4840,-,I
4840,Layer,I
4840,Perceptrons,I
4840,and,I
4840,we,O
4840,complement,O
4840,them,O
4840,using,B
4840,techniques,I
4840,such,B
4840,as,I
4840,Dropout,B
4840,",",O
4840,adaptive,B
4840,optimizers,I
4840,such,O
4840,as,O
4840,Adam,B
4840,",",O
4840,pretrained,B
4840,word,I
4840,-,O
4840,embedding,O
4840,models,O
4840,and,O
4840,Attention,O
4840,based,O
4840,RNN,O
4840,decoders,O
4840,.,O
4841,This,O
4841,allows,B
4841,us,I
4841,to,I
4841,individually,B
4841,target,I
4841,each,B
4841,modality,B
4841,and,O
4841,only,O
4841,perform,B
4841,feature,I
4841,fusion,I
4841,at,B
4841,the,O
4841,final,B
4841,stage,I
4841,.,O
4842,For,B
4842,the,I
4842,text,B
4842,transcript,I
4842,of,B
4842,each,B
4842,of,O
4842,the,O
4842,utterance,O
4842,we,O
4842,use,B
4842,pretrained,B
4842,Glove,I
4842,embeddings,I
4842,of,O
4842,dimension,B
4842,300,I
4842,",",O
4842,along,B
4842,with,I
4842,the,O
4842,maximum,B
4842,sequence,I
4842,length,I
4842,of,O
4842,500,B
4842,to,B
4842,obtain,I
4842,a,O
4842,(,B
4842,"500,300",I
4842,),I
4842,vector,I
4842,for,O
4842,each,O
4842,utterance,O
4842,.,O
4843,For,B
4843,the,O
4843,Mocap,B
4843,data,I
4843,",",I
4843,for,O
4843,each,B
4843,different,I
4843,mode,I
4843,such,B
4843,as,I
4843,face,B
4843,",",O
4843,hand,O
4843,",",O
4843,head,O
4843,rotation,O
4843,we,O
4843,sample,B
4843,all,O
4843,the,O
4843,feature,B
4843,values,I
4843,between,B
4843,the,O
4843,start,B
4843,and,I
4843,finish,I
4843,time,I
4843,values,O
4843,and,O
4843,split,B
4843,them,I
4843,into,I
4843,200,B
4843,partitioned,I
4843,arrays,I
4843,.,O
4844,We,O
4844,then,O
4844,average,B
4844,each,I
4844,of,I
4844,the,O
4844,200,B
4844,arrays,I
4844,along,B
4844,the,O
4844,columns,B
4844,(,B
4844,165,I
4844,for,B
4844,faces,I
4844,",",I
4844,18,I
4844,for,O
4844,hands,O
4844,",",O
4844,and,O
4844,6,O
4844,for,O
4844,rotation,O
4844,),O
4844,",",O
4844,and,O
4844,finally,O
4844,concatenate,B
4844,all,I
4844,of,O
4844,them,O
4844,to,O
4844,obtain,O
4844,(,O
4844,"200,189",O
4844,),O
4844,dimension,O
4844,vector,O
4844,for,O
4844,each,O
4844,utterance,B
4844,.,O
4845,Our,O
4845,performance,O
4845,matches,B
4845,the,I
4845,prior,B
4845,state,I
4845,of,I
4845,the,O
4845,art,O
4845,",",O
4845,however,O
4845,the,O
4845,comparison,O
4845,is,O
4845,not,O
4845,fair,O
4845,.,O
4846,These,O
4846,methods,O
4846,extend,O
4846,LSTM,O
4846,to,O
4846,encode,O
4846,graphs,O
4846,constructed,O
4846,from,O
4846,input,O
4846,sentences,O
4846,with,B
4846,dependency,O
4846,edges,O
4846,",",O
4846,3,O
4846,),O
4846,Graph,B
4846,convolutional,I
4846,networks,I
4846,(,I
4846,GCN,I
4846,),O
4846,with,O
4846,pruned,B
4846,trees,I
4846,",",O
4846,6,O
4846,https://nlp.stanford.edu/projects/,O
4847,LSTM,B
4848,Following,O
4848,",",O
4848,the,O
4848,sentence,B
4848,is,O
4848,fed,B
4848,to,B
4848,along,O
4848,short,B
4848,-,I
4848,term,I
4848,memory,I
4848,(,I
4848,LSTM,I
4848,),I
4848,network,I
4848,to,O
4848,propagate,O
4848,context,B
4848,among,B
4848,the,O
4848,constituent,B
4848,words,I
4848,.,O
4849,Following,O
4849,",",O
4849,sequence,B
4849,of,B
4849,words,B
4849,preceding,I
4849,(,I
4849,left,I
4849,context,I
4849,),I
4849,and,I
4849,succeeding,I
4849,(,O
4849,right,O
4849,context,O
4849,),O
4849,target,O
4849,aspect,O
4849,term,O
4849,are,O
4849,fed,B
4849,to,I
4849,two,B
4849,different,I
4849,LSTMs,I
4849,.,O
4850,",",O
4850,ATAE,B
4850,-,I
4850,LSTM,B
4850,is,O
4850,identical,B
4850,to,I
4850,AE,B
4850,-,O
4850,LSTM,O
4850,",",O
4850,except,B
4850,the,O
4850,LSTM,O
4850,is,O
4850,fed,B
4850,with,I
4850,the,O
4850,concatenation,B
4850,of,B
4850,aspect,B
4850,-,O
4850,term,O
4850,representation,O
4850,and,O
4850,word,O
4850,representation,O
4850,.,O
4851,",",O
4851,target,O
4851,-,O
4851,aspect,O
4851,and,O
4851,its,O
4851,context,O
4851,are,O
4851,sent,O
4851,to,O
4851,two,O
4851,distinct,O
4851,LSTMs,O
4851,and,O
4851,the,O
4851,means,O
4851,of,B
4851,the,O
4851,hidden,O
4851,outputs,O
4851,are,O
4851,taken,O
4851,as,O
4851,intermediate,O
4851,aspect,O
4851,representation,O
4851,and,O
4851,context,O
4851,representation,O
4851,respectively,O
4851,.,O
4852,To,O
4852,model,O
4852,these,O
4852,scenarios,O
4852,",",O
4852,firstly,O
4852,",",O
4852,following,O
4852,",",O
4852,we,O
4852,independently,B
4852,generate,I
4852,aspect,B
4852,-,I
4852,aware,I
4852,sentence,I
4852,representations,I
4852,for,B
4852,all,B
4852,the,I
4852,aspects,I
4852,using,B
4852,gated,B
4852,recurrent,I
4852,unit,I
4852,(,I
4852,GRU,I
4852,),I
4852,and,O
4852,attention,B
4852,mechanism,I
4852,.,O
4853,Then,O
4853,",",O
4853,we,O
4853,employ,B
4853,memory,B
4853,networks,I
4853,to,B
4853,repeatedly,I
4853,match,I
4853,the,O
4853,target,B
4853,aspect,I
4853,representation,I
4853,with,B
4853,the,O
4853,other,B
4853,aspects,I
4853,to,O
4853,generate,O
4853,more,B
4853,accurate,I
4853,representation,O
4853,of,B
4853,the,O
4853,target,O
4853,aspect,O
4853,.,O
4854,This,O
4854,refined,B
4854,representation,I
4854,is,O
4854,fed,B
4854,to,I
4854,a,O
4854,softmax,B
4854,classifier,I
4854,for,B
4854,final,B
4854,classification,I
4854,.,O
4855,IARM,O
4855,:,O
4855,Inter-Aspect,O
4855,Relation,O
4855,Modeling,O
4855,with,O
4855,Memory,O
4855,Networks,O
4855,in,O
4855,Aspect,B
4855,-,I
4855,Based,I
4855,Sentiment,I
4855,Analysis,I
4856,Our,O
4856,code,O
4856,is,O
4856,available,O
4856,at,O
4856,https://github.com/Cartus,B
4856,/,I
4856,AGGCN_TACRED,I
4857,The,O
4857,aim,O
4857,of,O
4857,the,O
4857,ABSA,B
4857,classifier,O
4857,is,O
4857,to,O
4857,learn,O
4857,these,O
4857,connections,O
4857,between,O
4857,the,O
4857,aspects,O
4857,and,O
4857,their,O
4857,sentiment,O
4857,bearing,O
4857,phrases,O
4857,.,O
4858,It,O
4858,is,O
4858,evident,B
4858,from,O
4858,the,O
4858,results,O
4858,that,O
4858,our,B
4858,IARM,I
4858,model,I
4858,outperforms,B
4858,all,B
4858,the,O
4858,baseline,O
4858,models,O
4858,",",O
4858,including,B
4858,the,O
4858,state,B
4858,of,I
4858,the,O
4858,art,O
4858,",",O
4858,in,B
4858,both,I
4858,of,O
4858,the,O
4858,domains,B
4858,.,O
4859,We,O
4859,obtained,B
4859,bigger,B
4859,improvement,I
4859,in,B
4859,laptop,B
4859,domain,I
4859,",",O
4859,of,B
4859,1.7,B
4859,%,I
4859,",",O
4859,compared,B
4859,to,I
4859,restaurant,B
4859,domain,O
4859,",",O
4859,of,O
4859,1.4,B
4859,%,O
4859,.,O
4860,The,O
4860,size,B
4860,of,I
4860,the,O
4860,embedding,B
4860,layer,I
4860,is,B
4860,300,B
4860,",",O
4860,and,O
4860,the,O
4860,LSTM,B
4860,layers,I
4860,150,I
4860,(,O
4860,300,O
4860,for,O
4860,BiLSTM,O
4860,),O
4860,.,O
4861,We,O
4861,add,B
4861,Gaussian,B
4861,noise,I
4861,with,B
4861,?,O
4862,=,O
4862,0.2,O
4862,and,O
4862,dropout,B
4862,of,B
4862,0.3,B
4862,at,B
4862,the,O
4862,embedding,B
4862,layer,I
4862,",",O
4862,dropout,O
4862,of,O
4862,0.5,B
4862,at,O
4862,the,O
4862,LSTM,B
4862,layers,I
4862,and,O
4862,dropout,O
4862,of,O
4862,0.25,B
4862,at,O
4862,the,O
4862,recurrent,B
4862,connections,I
4862,of,O
4862,the,O
4862,LSTM,O
4862,.,O
4863,Finally,O
4863,",",O
4863,we,O
4863,add,O
4863,L,B
4863,2,I
4863,regularization,I
4863,of,B
4863,0.0001,B
4863,at,B
4863,the,O
4863,loss,B
4863,function,I
4863,.,O
4864,The,O
4864,size,B
4864,of,I
4864,the,O
4864,embedding,B
4864,layer,I
4864,is,B
4864,300,B
4864,",",O
4864,and,O
4864,the,O
4864,LSTM,B
4864,layers,I
4864,64,B
4864,(,O
4864,128,O
4864,for,O
4864,BiLSTM,O
4864,),O
4864,.,O
4865,We,O
4865,choose,B
4865,the,O
4865,number,B
4865,of,I
4865,heads,I
4865,N,I
4865,for,B
4865,attention,B
4865,guided,I
4865,layer,I
4865,from,B
4865,{,B
4865,1,I
4865,",",I
4865,2,I
4865,",",O
4865,3,O
4865,",",O
4865,4,O
4865,},O
4865,",",O
4865,the,O
4865,block,B
4865,number,O
4865,M,O
4865,from,O
4865,{,O
4865,1,O
4865,",",O
4865,2,O
4865,",",O
4865,3,O
4865,},O
4865,",",O
4865,the,O
4865,number,O
4865,of,O
4865,sub,O
4865,-,O
4865,layers,O
4865,L,O
4865,in,B
4865,each,B
4865,densely,I
4865,connected,I
4865,layer,O
4865,from,O
4865,{,O
4865,2,O
4865,",",O
4865,3,O
4865,",",O
4865,4,O
4865,}.,O
4866,We,O
4866,insert,B
4866,Gaussian,B
4866,noise,I
4866,with,B
4866,?,O
4867,=,O
4867,0.2,B
4867,at,B
4867,the,I
4867,embedding,B
4867,layer,I
4867,of,B
4867,both,B
4867,inputs,I
4867,and,I
4867,dropout,B
4867,of,O
4867,0.3,B
4867,at,O
4867,the,O
4867,embedding,O
4867,layer,O
4867,of,O
4867,the,O
4867,message,B
4867,",",O
4867,dropout,O
4867,of,O
4867,0.2,O
4867,at,O
4867,the,O
4867,LSTM,B
4867,layer,O
4867,and,O
4867,the,O
4867,recurrent,B
4867,connection,I
4867,of,O
4867,the,O
4867,LSTM,O
4867,layer,O
4867,and,O
4867,dropout,O
4867,of,O
4867,0.3,O
4867,at,O
4867,the,O
4867,attention,B
4867,layer,O
4867,and,O
4867,the,O
4867,Maxout,O
4867,layer,O
4867,.,O
4868,Finally,O
4868,",",O
4868,we,O
4868,add,B
4868,L,B
4868,2,I
4868,regularization,I
4868,of,B
4868,0.001,B
4868,at,B
4868,the,O
4868,loss,B
4868,function,I
4868,.,O
4869,In,O
4869,this,O
4869,paper,O
4869,",",O
4869,we,O
4869,present,B
4869,two,B
4869,deep,I
4869,-,I
4869,learning,I
4869,systems,I
4869,that,O
4869,competed,B
4869,at,I
4869,SemEval,B
4869,-,O
4869,2017,O
4869,Task,O
4869,4,O
4869,.,O
4870,Our,O
4870,first,B
4870,model,I
4870,is,O
4870,designed,B
4870,for,I
4870,addressing,I
4870,the,O
4870,problem,B
4870,of,I
4870,messagelevel,I
4870,sentiment,I
4870,analysis,I
4870,.,O
4871,We,O
4871,employ,B
4871,a,O
4871,2,B
4871,-,I
4871,layer,I
4871,Bidirectional,I
4871,LSTM,I
4871,",",O
4871,equipped,B
4871,with,I
4871,an,O
4871,attention,B
4871,mechanism,I
4871,.,O
4872,For,B
4872,the,O
4872,topic,B
4872,-,I
4872,based,I
4872,sentiment,I
4872,analysis,I
4872,tasks,I
4872,",",O
4872,we,O
4872,propose,B
4872,a,O
4872,Siamese,B
4872,Bidirectional,I
4872,LSTM,I
4872,with,B
4872,a,O
4872,contextaware,B
4872,attention,I
4872,mechanism,I
4872,.,O
4873,DataStories,O
4873,at,O
4873,SemEval-2017,O
4873,Task,O
4873,4,O
4873,:,O
4873,Deep,O
4873,LSTM,O
4873,with,O
4873,Attention,O
4873,for,O
4873,Message,B
4873,-,I
4873,level,I
4873,and,I
4873,Topic,I
4873,-,O
4873,based,O
4873,Sentiment,O
4873,Analysis,O
4874,In,O
4874,this,O
4874,paper,O
4874,we,O
4874,present,O
4874,two,O
4874,deep,O
4874,-,O
4874,learning,O
4874,systems,O
4874,that,O
4874,competed,O
4874,at,O
4874,SemEval,O
4874,-,O
4874,2017,O
4874,Task,O
4874,4,O
4874,"""",O
4874,Sentiment,B
4874,Analysis,I
4874,in,O
4874,Twitter,O
4874,"""",O
4874,.,O
4875,Our,O
4875,official,O
4875,ranking,O
4875,is,B
4875,1/38,B
4875,(,I
4875,tie,I
4875,),I
4875,in,B
4875,Subtask,B
4875,A,I
4875,",",O
4875,2/24,B
4875,in,O
4875,Subtask,O
4875,B,O
4875,",",O
4875,2/16,B
4875,in,O
4875,Subtask,O
4875,C,O
4875,",",O
4875,2/16,O
4875,in,O
4875,Subtask,O
4875,D,O
4875,and,O
4875,11/12,B
4875,in,O
4875,Subtask,O
4875,E.,O
